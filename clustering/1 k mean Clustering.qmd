---
title: "K mean Clustering"
subtitle: "with Mall Customers Datase"

author: "Tony Duan"


execute:
  warning: false
  error: false
format:
  html:
    toc: true
    toc-location: right
    code-fold: show
    code-tools: true
    number-sections: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
---

![](images/p3GHQXL.png){width="500"}

# load package

```{r}
library(tidyverse)
library(broom)
library(janitor)
```


# data

## download data

https://www.kaggle.com/datasets/shwetabh123/mall-customer

## input data

```{r}
df_train=read.csv('./data/Mall_Customers.csv')
```



```{r}
names(df_train)
```

```{r}
df_train=df_train %>% clean_names()
```


```{r}
names(df_train)
```

## data EDA

# model with Annual Income (k$) and Spending Score (1-100)

The standard k-means algorithm isn't directly applicable to categorical data, for various reasons. The sample space for categorical data is discrete, and doesn't have a natural origin. A Euclidean distance function on such a space isn't really meaningful. As someone put it, "The fact a snake possesses neither wheels nor legs allows us to say nothing about the relative value of wheels and legs."

There's a variation of k-means known as k-modes,if we need to include categorical data

So only get Annual Income (k$) and Spending Score (1-100).


```{r}
df_train2=df_train %>% select(annual_income_k,spending_score_1_100)
```

# Optimal number of k-clusters


```{r}
kclusts <- 
  tibble(k = 1:9) %>%
  mutate(
    kclust = map(k, ~kmeans(df_train2, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, df_train2)
  )

kclusts
```


```{r}
clusters <- 
  kclusts %>%
  unnest(cols = c(tidied))

assignments <- 
  kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- 
  kclusts %>%
  unnest(cols = c(glanced))
```



```{r}
ggplot(clusterings, aes(k, tot.withinss)) +
  geom_line() +
  geom_point()
```




![](images/0k6ALfB.png){width="500"}

# 5 groups

```{r}
kclust <- kmeans(df_train2, centers = 5)
```

```{r}
result=augment(kclust, df_train2)
```





# profiling

```{r}
df_train3=cbind(df_train,result)%>% clean_names()
```

```{r}
head(df_train3)
```

```{r}
p=ggplot(df_train3, aes(annual_income_k, spending_score_1_100,color=cluster)) + geom_point()
p
```


## 'annual_income_k'

```{r}
p=ggplot(df_train3, aes(cluster,annual_income_k,fill=cluster)) + geom_boxplot()
p
```




## 'spending_score_1_100'


```{r}
p=ggplot(df_train3, aes(cluster,spending_score_1_100,fill=cluster)) + geom_boxplot()
p
```

## Age


# reference:

https://www.kaggle.com/code/sangwookchn/clustering-techniques-using-scikit-learn
