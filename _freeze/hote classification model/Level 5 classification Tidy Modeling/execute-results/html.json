{
  "hash": "f49fbf6a77bdaf9a4412ba1b9a1b44db",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Level 5 classification Tidy Modeling\"\nsubtitle: \"with hotel booking data\"\nauthor: \"Tony Duan\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n\nLevel 5 classification Tidy Modeling with 1 tuning model and 1 recipe : \n\n* using Recipe to down sample.\n* add resamples to estimate the performance of our two models\n* add workflow with tuning\n* add quick tuning `tune_race_anova()`\n\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\n\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nhotels <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays <- hotels %>%\n  filter(is_canceled == 0) %>%\n  mutate(\n    children = case_when(\n      children + babies > 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces > 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %>%\n  select(-is_canceled, -reservation_status, -babies)\n```\n:::\n\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\nall_hotels_df <- hotel_stays %>%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %>%\n  mutate_if(is.character, factor) %>% rename(target_variable=children) %>% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%>% sample_n(50000) \n\nhold_hotels_df <- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n#hotels_df=hotels_df %>% select(-rownum)\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 35000    11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5000   11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000    11\n```\n\n\n:::\n:::\n\n\n10 fold for tunning\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nfolds <- vfold_cv(data_train)\n```\n:::\n\n\n\n\n\n# modeling\n\n## recipe\n\nbecasue the target class is not balance so using downsample\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  step_rm(rownum) %>% \n  step_downsample(target_variable) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric())\n```\n:::\n\n\n\n## model\n\ndecision tree model with cost_complexity and tree_depth to tune\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec |> \n  extract_parameter_set_dials()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_leaves()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of Leaves (quantitative)\nRange: [5, 100]\n```\n\n\n:::\n:::\n\n\ntunning grid\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune <- \n  tune_spec |> \n  extract_parameter_set_dials() |> \n  grid_latin_hypercube(size = 200)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune |> glimpse(width = 200)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 200\nColumns: 2\n$ cost_complexity <dbl> 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      <int> 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune %>% count(tree_depth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 2\n   tree_depth     n\n        <int> <int>\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7\n```\n\n\n:::\n:::\n\n\n## workflow \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(finetune)\ncntl <- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_workflow =\n  workflow() %>% \n  add_model(tune_spec) %>% \n  add_recipe(data_rec)\n```\n:::\n\n\n\n\n\n## training and tunning\n\nusing tune_race_anova() instead of tune_grid()\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %>% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(tree_res)\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_race(tree_res)\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>% \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 78 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>     \n 1   0.000104              10 accuracy binary     0.757    10 0.00623 Preproces…\n 2   0.000104              10 roc_auc  binary     0.822    10 0.00459 Preproces…\n 3   0.00000000437         11 accuracy binary     0.756    10 0.00487 Preproces…\n 4   0.00000000437         11 roc_auc  binary     0.821    10 0.00461 Preproces…\n 5   0.0000000616          10 accuracy binary     0.757    10 0.00626 Preproces…\n 6   0.0000000616          10 roc_auc  binary     0.822    10 0.00463 Preproces…\n 7   0.0000750             13 accuracy binary     0.751    10 0.00503 Preproces…\n 8   0.0000750             13 roc_auc  binary     0.821    10 0.00471 Preproces…\n 9   0.0000000664          14 accuracy binary     0.747    10 0.00672 Preproces…\n10   0.0000000664          14 roc_auc  binary     0.821    10 0.00506 Preproces…\n# ℹ 68 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  collect_metrics() %>%\n  mutate(tree_depth = factor(tree_depth)) %>%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  show_best()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1    0.000142             14 roc_auc binary     0.822    10 0.00505 Preprocesso…\n2    0.000104             10 roc_auc binary     0.822    10 0.00459 Preprocesso…\n3    0.0000000616         10 roc_auc binary     0.822    10 0.00463 Preprocesso…\n4    0.000000833          10 roc_auc binary     0.822    10 0.00463 Preprocesso…\n5    0.0000000245         10 roc_auc binary     0.822    10 0.00463 Preprocesso…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_tree <- tree_res %>%\n  select_best()\n\nbest_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            <dbl>      <int> <chr>                 \n1        0.000142         14 Preprocessor1_Model052\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <- \n  model_workflow %>% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 0.000141543693071946\n  tree_depth = 14\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n\n## last fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- \n  final_wf %>%\n  last_fit(data_split) \n```\n:::\n\n\n\n# model result\n\n## Evaluate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.751 Preprocessor1_Model1\n2 roc_auc  binary         0.814 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics <- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %>% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 accuracy  binary         0.751\n2 recall    binary         0.725\n3 precision binary         0.215\n4 f_meas    binary         0.331\n5 kap       binary         0.230\n6 sens      binary         0.725\n7 spec      binary         0.753\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_predictions() %>% \n  roc_curve(target_variable, .pred_children) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree <- extract_workflow(final_fit)\nfinal_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5524 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n    1) root 5524 2762 children (0.50000000 0.50000000)  \n      2) adr>=0.1157544 2157  529 children (0.75475197 0.24524803)  \n        4) adr>=0.9221342 925  117 children (0.87351351 0.12648649)  \n          8) adr>=1.245399 635   60 children (0.90551181 0.09448819)  \n           16) meal_HB< 1.056483 449   33 children (0.92650334 0.07349666) *\n           17) meal_HB>=1.056483 186   27 children (0.85483871 0.14516129)  \n             34) arrival_date_month_September< 1.758524 179   23 children (0.87150838 0.12849162) *\n             35) arrival_date_month_September>=1.758524 7    3 none (0.42857143 0.57142857) *\n          9) adr< 1.245399 290   57 children (0.80344828 0.19655172)  \n           18) adults< 1.273727 256   41 children (0.83984375 0.16015625)  \n             36) adults>=-0.8159875 242   33 children (0.86363636 0.13636364)  \n               72) hotel_Resort.Hotel< 0.2275968 142   10 children (0.92957746 0.07042254)  \n                144) adr< 1.081823 71    1 children (0.98591549 0.01408451) *\n                145) adr>=1.081823 71    9 children (0.87323944 0.12676056)  \n                  290) adr>=1.085872 64    5 children (0.92187500 0.07812500) *\n                  291) adr< 1.085872 7    3 none (0.42857143 0.57142857) *\n               73) hotel_Resort.Hotel>=0.2275968 100   23 children (0.77000000 0.23000000)  \n                146) required_car_parking_spaces_parking>=1.029184 27    2 children (0.92592593 0.07407407) *\n                147) required_car_parking_spaces_parking< 1.029184 73   21 children (0.71232877 0.28767123)  \n                  294) arrival_date_month_August< 0.9019664 46    9 children (0.80434783 0.19565217) *\n                  295) arrival_date_month_August>=0.9019664 27   12 children (0.55555556 0.44444444)  \n                    590) meal_HB< 1.056483 20    7 children (0.65000000 0.35000000) *\n                    591) meal_HB>=1.056483 7    2 none (0.28571429 0.71428571) *\n             37) adults< -0.8159875 14    6 none (0.42857143 0.57142857) *\n           19) adults>=1.273727 34   16 children (0.52941176 0.47058824)  \n             38) hotel_Resort.Hotel>=0.2275968 13    0 children (1.00000000 0.00000000) *\n             39) hotel_Resort.Hotel< 0.2275968 21    5 none (0.23809524 0.76190476) *\n        5) adr< 0.9221342 1232  412 children (0.66558442 0.33441558)  \n         10) adults< 1.273727 1113  319 children (0.71338724 0.28661276)  \n           20) adults>=-0.8159875 1057  285 children (0.73036897 0.26963103)  \n             40) meal_SC< 1.820907 1022  263 children (0.74266145 0.25733855)  \n               80) total_of_special_requests>=0.6389178 341   57 children (0.83284457 0.16715543) *\n               81) total_of_special_requests< 0.6389178 681  206 children (0.69750367 0.30249633)  \n                162) adr>=0.2898573 506  136 children (0.73122530 0.26877470)  \n                  324) arrival_date_month_May< 1.575526 474  121 children (0.74472574 0.25527426)  \n                    648) arrival_date_month_September< 1.758524 432  103 children (0.76157407 0.23842593)  \n                     1296) hotel_Resort.Hotel< 0.2275968 263   53 children (0.79847909 0.20152091)  \n                       2592) arrival_date_month_June< 1.468481 234   41 children (0.82478632 0.17521368)  \n                         5184) adr>=0.4716531 151   17 children (0.88741722 0.11258278) *\n                         5185) adr< 0.4716531 83   24 children (0.71084337 0.28915663)  \n                          10370) adr< 0.4178026 42    5 children (0.88095238 0.11904762) *\n                          10371) adr>=0.4178026 41   19 children (0.53658537 0.46341463)  \n                            20742) stays_in_weekend_nights>=-0.4687777 28   10 children (0.64285714 0.35714286) *\n                            20743) stays_in_weekend_nights< -0.4687777 13    4 none (0.30769231 0.69230769) *\n                       2593) arrival_date_month_June>=1.468481 29   12 children (0.58620690 0.41379310)  \n\n...\nand 256 more lines.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n\nfinal_tree %>% \n  extract_fit_parsnip() %>% \n  vip()\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n\n\n## save model\n\ncheck model size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)\nobj_size(final_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.51 MB\n```\n\n\n:::\n:::\n\n\nbundle and save model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bundle)\nmodel_bundle <- bundle(final_tree)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')\n```\n:::\n\n\n## make predication\n\nload model and unbundle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel <- unbundle(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 none       \n2 none       \n3 children   \n4 none       \n5 children   \n6 children   \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      630 2220\n  none          224 6926\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.756\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(target_variable)%>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  <fct>           <int>\n1 children          854\n2 none             9146\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(.pred_class) %>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  <fct>       <int>\n1 children     2850\n2 none         7150\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      630 2220\n  none          224 6926\n```\n\n\n:::\n:::\n\n\n# reference:\n\n\nhttps://www.tmwr.org\n\nhttps://www.youtube.com/watch?v=IzjmuGJgwKQ\n\nhttps://www.youtube.com/watch?v=_e0NFIaHY2c\n\n\n",
    "supporting": [
      "Level-5-classification-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}