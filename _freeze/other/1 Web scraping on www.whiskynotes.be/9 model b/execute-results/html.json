{
  "hash": "431d23d6ddde9b7bc268b47187014b95",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Model b include bottle info\"\nsubtitle: \"with whiskynote.be data\"\nauthor: \"Tony Duan\"\n\nexecute:\n  warning: false\n  error: false\n\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n::: {#839625ea .cell execution_count=1}\n``` {.python .cell-code}\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n```\n:::\n\n\n# read in data\n\n::: {#1217ab92 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\ndata=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n```\n:::\n\n\n::: {#0feb9565 .cell execution_count=3}\n``` {.python .cell-code}\nlist(data)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n['bottle_name',\n 'bottle_review_Nose',\n 'bottle_review_Mouth',\n 'bottle_review_Finish',\n 'all_page_score',\n 'page_class',\n 'page_published_date',\n 'page_title',\n 'review_url']\n```\n:::\n:::\n\n\n::: {#e0d6598d .cell execution_count=4}\n``` {.python .cell-code}\ndata.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4934 entries, 0 to 4933\nData columns (total 9 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4934 non-null   object\n 1   bottle_review_Nose    4934 non-null   object\n 2   bottle_review_Mouth   4934 non-null   object\n 3   bottle_review_Finish  4934 non-null   object\n 4   all_page_score        4934 non-null   int64 \n 5   page_class            4934 non-null   object\n 6   page_published_date   4934 non-null   object\n 7   page_title            4934 non-null   object\n 8   review_url            4934 non-null   object\ndtypes: int64(1), object(8)\nmemory usage: 347.1+ KB\n```\n:::\n:::\n\n\n::: {#287a244e .cell execution_count=5}\n``` {.python .cell-code}\nimport re\ndata001=data>> filter(_.all_page_score >=70\n                      ,_.all_page_score <100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) >>mutate(\n                      review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )>>mutate(review=_.bottle_name+_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',','').str.replace('(','').str.replace(')','').str.replace('-','').str.replace('apples','apple').str.replace('oranges','orange').str.replace('sweetness','sweet').str.replace('fruits','fruit'))>>mutate(review_len=_.review.str.count(' ') + 1)\n\n```\n:::\n\n\n::: {#eb534654 .cell execution_count=6}\n``` {.python .cell-code}\ndata001['review_flag']= np.where(data001['all_page_score']>=90, 1, 0)\n```\n:::\n\n\n# shuffle data\n\n::: {#dd9fb186 .cell execution_count=7}\n``` {.python .cell-code}\ndata002=data001.sample(frac=1)\n```\n:::\n\n\n::: {#2a16c631 .cell execution_count=8}\n``` {.python .cell-code}\ndata002.to_excel('data002.xlsx')\n```\n:::\n\n\n::: {#e85db840 .cell execution_count=9}\n``` {.python .cell-code}\ndata002.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 4633 entries, 334 to 4848\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4633 non-null   object\n 1   bottle_review_Nose    4633 non-null   object\n 2   bottle_review_Mouth   4633 non-null   object\n 3   bottle_review_Finish  4633 non-null   object\n 4   all_page_score        4633 non-null   int64 \n 5   page_class            4633 non-null   object\n 6   page_published_date   4633 non-null   object\n 7   page_title            4633 non-null   object\n 8   review_url            4633 non-null   object\n 9   review                4633 non-null   object\n 10  review_len            4633 non-null   int64 \n 11  review_flag           4633 non-null   int64 \ndtypes: int64(3), object(9)\nmemory usage: 470.5+ KB\n```\n:::\n:::\n\n\n::: {#11c3799d .cell execution_count=10}\n``` {.python .cell-code}\nreview=data002['review'].tolist()\n```\n:::\n\n\n::: {#1a44ab67 .cell execution_count=11}\n``` {.python .cell-code}\nreview[2]\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\n'New Yarmouth 27 yo 1994 (60,1%, Thompson Bros 2022, refill barrel, 285 btl.) a really solventy profile this time a firm hint of nail polish remover and metal polish then coconut sweet and ripe pineapple move forward as well as cinnamon pastry old grain whisky comes to mind – i believe this is column still production after all crème brûlée aniseed and plums too a bit rough now with some alcohol pungency caramel sweet and latte with vanilla syrup still estery and solventy with a hint of glue then candied ginger hints of orange peels more anise black tea and a herbal bitterness clove burnt mint leaves quite long but quite hot as well oak spice black tea chocolate and liquorice allsorts'\n```\n:::\n:::\n\n\n::: {#d22a55e6 .cell execution_count=12}\n``` {.python .cell-code}\nreview_flag=data002[\"review_flag\"].tolist()\n```\n:::\n\n\n::: {#d2a88108 .cell execution_count=13}\n``` {.python .cell-code}\nreview_score=data002[\"all_page_score\"].tolist()\n```\n:::\n\n\n::: {#f346d137 .cell execution_count=14}\n``` {.python .cell-code}\nreview_flag[2]\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\n0\n```\n:::\n:::\n\n\n::: {#17916e47 .cell execution_count=15}\n``` {.python .cell-code}\nfrom collections import Counter\nCounter(review_flag)\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nCounter({0: 3402, 1: 1231})\n```\n:::\n:::\n\n\n::: {#18a5f2d0 .cell execution_count=16}\n``` {.python .cell-code}\nprint(len(review))\n\nprint(len(review_flag))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4633\n4633\n```\n:::\n:::\n\n\n# transfer data\n\n::: {#d70dffa6 .cell execution_count=17}\n``` {.python .cell-code}\nimport tensorflow as tf\nimport numpy as np \nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n```\n:::\n\n\n::: {#014da44f .cell execution_count=18}\n``` {.python .cell-code}\n# Initialize the Tokenizer class\ntokenizer = Tokenizer()\n\n# Generate the word index dictionary\ntokenizer.fit_on_texts(review)\n\n# Define the total words. You add 1 for the index `0` which is just the padding token.\ntotal_words = len(tokenizer.word_index) + 1\n```\n:::\n\n\n::: {#4a0afc90 .cell execution_count=19}\n``` {.python .cell-code}\nprint(f'total words: {total_words}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntotal words: 12398\n```\n:::\n:::\n\n\n::: {#3e7c429f .cell execution_count=20}\n``` {.python .cell-code}\n# Convert labels lists to numpy array\nreview_flag_final = np.array(review_flag)\nreview_score_final = np.array(review_score)\n```\n:::\n\n\n::: {#bb8276d6 .cell execution_count=21}\n``` {.python .cell-code}\n# Parameters\nvocab_size = 7000\nmax_length = 300\nembedding_dim = 16\n#trunc_type='pre'\ntrunc_type='post'\noov_tok = \"<OOV>\"\n```\n:::\n\n\n::: {#9936151f .cell execution_count=22}\n``` {.python .cell-code}\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Initialize the Tokenizer class\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n\n# Generate the word index dictionary for the training sentences\ntokenizer.fit_on_texts(review)\nword_index = tokenizer.word_index\n\n# Generate and pad the training sequences\nsequences = tokenizer.texts_to_sequences(review)\npadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n```\n:::\n\n\n::: {#1d65cb24 .cell execution_count=23}\n``` {.python .cell-code}\nlen(review[4])\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```\n1957\n```\n:::\n:::\n\n\n::: {#a5d2d79e .cell execution_count=24}\n``` {.python .cell-code}\nlen(padded[4])\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n300\n```\n:::\n:::\n\n\n::: {#d225a5b7 .cell execution_count=25}\n``` {.python .cell-code}\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])            \n\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n```\n:::\n\n\n::: {#744d5838 .cell execution_count=26}\n``` {.python .cell-code}\nprint(decode_review(padded[0]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? fontagard pndc 9918 9 2018 44 ob 2021 cognac pineau des charentes casks quite young with mashy notes leafy notes and the barley core that reminds me of waterford at times subtle hints of yellow fruit and pencil shavings rather clean but also rather neutral again very close to a grain eaudevie some caramel sweet in the background as well as barley syrup and citrus peel pleasant notes of dusty wood later it becomes darker with the warmth of black pepper not too long still really grainy\n```\n:::\n:::\n\n\nafter tokenizer\n\n::: {#a52b9004 .cell execution_count=27}\n``` {.python .cell-code}\nprint(sequences[0])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[6437, 6438, 6439, 249, 313, 662, 42, 174, 343, 2737, 2263, 3791, 330, 23, 456, 5, 1284, 7, 149, 7, 2, 6, 213, 479, 75, 444, 300, 3, 1707, 106, 894, 54, 8, 3, 154, 16, 2, 606, 279, 62, 227, 12, 35, 62, 679, 33, 22, 598, 34, 4, 601, 612, 9, 113, 11, 14, 6, 61, 10, 15, 10, 213, 150, 2, 70, 183, 506, 7, 3, 231, 51, 337, 24, 291, 353, 5, 6, 1022, 3, 129, 32, 47, 44, 17, 50, 92, 325]\n```\n:::\n:::\n\n\n::: {#853e32c5 .cell execution_count=28}\n``` {.python .cell-code}\nreview_flag[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\n0\n```\n:::\n:::\n\n\n# using 4000 to train and 633 to test\n\n::: {#b78cf25d .cell execution_count=29}\n``` {.python .cell-code}\npadded_train=padded[0:4000]\npadded_test=padded[4000:]\n```\n:::\n\n\n::: {#379c32d0 .cell execution_count=30}\n``` {.python .cell-code}\nreview_flag_final_train=review_flag_final[0:4000]\nreview_flag_final_test=review_flag_final[4000:]\n```\n:::\n\n\n::: {#8cdeb0ab .cell execution_count=31}\n``` {.python .cell-code}\nreview_socre_final_train=review_score_final[0:4000]\nreview_socre_final_test=review_score_final[4000:]\n```\n:::\n\n\n## total\n\n::: {#1157fb60 .cell execution_count=32}\n``` {.python .cell-code}\nlen(padded)\nlen(review_flag_final)\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n4633\n```\n:::\n:::\n\n\n## train\n\n::: {#9a1f75fe .cell execution_count=33}\n``` {.python .cell-code}\nlen(padded_train)\nlen(review_flag_final_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```\n4000\n```\n:::\n:::\n\n\n## test\n\n::: {#723f8d33 .cell execution_count=34}\n``` {.python .cell-code}\nlen(padded_test)\nlen(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=34}\n```\n633\n```\n:::\n:::\n\n\n::: {#9af5a61b .cell execution_count=35}\n``` {.python .cell-code}\nsum(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=35}\n```\n156\n```\n:::\n:::\n\n\n## if all guess lower than 90 points then 0.75 accuracy \n\n::: {#5ac5bb1e .cell execution_count=36}\n``` {.python .cell-code}\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=36}\n```\n0.7535545023696683\n```\n:::\n:::\n\n\n# DNN classificaiton model \n\n## define model\n\n::: {#1b810dcb .cell execution_count=37}\n``` {.python .cell-code}\n# Build the model\nmodel_dnn_classificaiton = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=32),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='tanh'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n```\n:::\n\n\n## compile model\n\n::: {#7fdc184b .cell execution_count=38}\n``` {.python .cell-code}\n# Setup the training parameters\nmodel_dnn_classificaiton.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```\n:::\n\n\n::: {#738dd9f8 .cell execution_count=39}\n``` {.python .cell-code}\nmodel_dnn_classificaiton.summary()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n:::\n\n\n## Callbacks\n\n::: {#4c7bd326 .cell execution_count=40}\n``` {.python .cell-code}\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('val_accuracy')>0.90):\n      print(\"\\nReached 88% val_accuracy so cancelling training!\")\n      self.model.stop_training = True\n\n# Instantiate class\ncallbacks = myCallback()\n```\n:::\n\n\n## train model\n\n::: {#0234e1df .cell execution_count=41}\n``` {.python .cell-code}\nnum_epochs = 20\n\n# Train the model\nhistory=model_dnn_classificaiton.fit(x=padded_train, y=review_flag_final_train, validation_data=(padded_test, review_flag_final_test),epochs=num_epochs,shuffle=True,callbacks=[callbacks],verbose=0)\n\n#history=model.fit(x=padded, y=review_flag_final, validation_split=0.2, shuffle=True,epochs=num_epochs,callbacks=[callbacks])\n```\n:::\n\n\n::: {#7fee1df6 .cell execution_count=42}\n``` {.python .cell-code}\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n```\n:::\n\n\n::: {#47ba91f0 .cell execution_count=43}\n``` {.python .cell-code}\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](9 model b_files/figure-html/cell-44-output-1.png){width=579 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](9 model b_files/figure-html/cell-44-output-2.png){width=571 height=431}\n:::\n:::\n\n\n## predication\n\n::: {#4f47230a .cell execution_count=44}\n``` {.python .cell-code}\nx = padded_test\ny = model_dnn_classificaiton.predict(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r 1/20 ━━━━━━━━━━━━━━━━━━━━ 0s 23ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \n```\n:::\n:::\n\n\n::: {#7469964f .cell execution_count=45}\n``` {.python .cell-code}\nsum(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\n156\n```\n:::\n:::\n\n\n::: {#770018d1 .cell execution_count=46}\n``` {.python .cell-code}\npredicted = np.argmax(y, axis=-1)\n```\n:::\n\n\n::: {#7e55ac0d .cell execution_count=47}\n``` {.python .cell-code}\nsum(predicted)\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```\n0\n```\n:::\n:::\n\n\n::: {#6a5c849d .cell execution_count=48}\n``` {.python .cell-code}\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(review_flag_final_test, predicted)  \naccuracy\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\n0.7535545023696683\n```\n:::\n:::\n\n\n::: {#208d5fc0 .cell execution_count=49}\n``` {.python .cell-code}\nfrom sklearn.metrics import confusion_matrix \nconfusion_matrix(review_flag_final_test, predicted)\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```\narray([[477,   0],\n       [156,   0]])\n```\n:::\n:::\n\n\n# LSTM model\n\n## define model\n\n::: {#ec759b1d .cell execution_count=50}\n``` {.python .cell-code}\nmodel_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim= 32),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n```\n:::\n\n\n## compile model\n\n::: {#3b94226e .cell execution_count=51}\n``` {.python .cell-code}\n# Setup the training parameters\nmodel_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```\n:::\n\n\n::: {#3b7ba023 .cell execution_count=52}\n``` {.python .cell-code}\nmodel_lstm.summary()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n:::\n\n\n# train model\n\n::: {#b74a593c .cell execution_count=53}\n``` {.python .cell-code}\nnum_epochs = 5\n\n# Train the model\n # history2=model_lstm.fit(x=padded_train, y=review_flag_final_train, validation_data=(padded_test, review_flag_final_test),epochs=num_epochs,shuffle=True,callbacks=[callbacks])\n```\n:::\n\n\n::: {#e7ca35f7 .cell execution_count=54}\n``` {.python .cell-code}\n# acc = history2.history['accuracy']\n# val_acc = history2.history['val_accuracy']\n# loss = history2.history['loss']\n# val_loss = history2.history['val_loss']\n# epochs = range(len(acc))\n```\n:::\n\n\n::: {#6425dfce .cell execution_count=55}\n``` {.python .cell-code}\n# import matplotlib.image as mpimg\n# import matplotlib.pyplot as plt\n# #------------------------------------------------\n# # Plot training and validation accuracy per epoch\n# #------------------------------------------------\n# plt.plot(epochs, acc, 'r', label='Training accuracy')\n# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n# plt.show()\n# plt.figure()\n# \n# plt.plot(epochs, loss, 'r', label='Training Loss')\n# plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n# plt.title('LSTM model Training and validation loss')\n# plt.legend()\n# \n# plt.show()\n```\n:::\n\n\n# dummy model\n\ntrainning score average is 86\n\n::: {#b49890c9 .cell execution_count=56}\n``` {.python .cell-code}\nsum(review_socre_final_train)/len(review_socre_final_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=56}\n```\n86.618\n```\n:::\n:::\n\n\n::: {#40e4f8a4 .cell execution_count=57}\n``` {.python .cell-code}\nimport numpy as np\nsum(np.absolute(86-review_socre_final_test))/len(review_socre_final_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=57}\n```\n0.53425\n```\n:::\n:::\n\n\n# DNN regression model \n\n::: {#8f6f56d9 .cell execution_count=58}\n``` {.python .cell-code}\n# Build the model\nmodel_dnn= tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=32),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1)\n])\n```\n:::\n\n\n::: {#5b9af510 .cell execution_count=59}\n``` {.python .cell-code}\n# Initialize the optimizer\noptimizer = tf.keras.optimizers.Adam(0.001)\n\n# Set the training parameters\nmodel_dnn.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=[\"mae\"])\n```\n:::\n\n\n::: {#9e048c90 .cell execution_count=60}\n``` {.python .cell-code}\nmodel_dnn.summary()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_1      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n:::\n\n\n## train model\n\n::: {#c29bfb1d .cell execution_count=61}\n``` {.python .cell-code}\n# Train the model\nhistory = model_dnn.fit(x=padded_train, y=review_socre_final_train,validation_data=(padded_test, review_socre_final_test),epochs=200,verbose=0 )\n\n#history = model_dnn.fit(x=padded_train, y=review_socre_final_train,validation_split=0.2,epochs=20)\n```\n:::\n\n\n## save model\n\n::: {#ea7ece9d .cell execution_count=62}\n``` {.python .cell-code}\nmodel_dnn.save('whiskynote_score_dnn.keras')\n```\n:::\n\n\n## load model\n\n::: {#97febe09 .cell execution_count=63}\n``` {.python .cell-code}\nnew_model = tf.keras.models.load_model('whiskynote_score_dnn.keras')\n```\n:::\n\n\n::: {#368cd913 .cell execution_count=64}\n``` {.python .cell-code}\nnew_model.summary()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">224,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_1      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">792</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">679,421</span> (2.59 MB)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">226,473</span> (884.66 KB)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452,948</span> (1.73 MB)\n</pre>\n```\n:::\n:::\n\n\n::: {#f1f34379 .cell execution_count=65}\n``` {.python .cell-code}\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nmae = history.history['mae']\nval_mae = history.history['val_mae']\n\nepochs = range(len(val_loss))\n```\n:::\n\n\n::: {#9147359f .cell execution_count=66}\n``` {.python .cell-code}\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](9 model b_files/figure-html/cell-67-output-1.png){width=566 height=431}\n:::\n:::\n\n\n::: {#9bbaad63 .cell execution_count=67}\n``` {.python .cell-code}\n# Only plot the last 80% of the epochs\nzoom_split = int(epochs[-1] * 0.2)\nepochs_zoom = epochs[zoom_split:]\nval_loss_zoom = val_loss[zoom_split:]\nloss_zoom = loss[zoom_split:]\n\n# Plot zoomed mae and loss\nplt.plot(epochs_zoom, loss_zoom, 'r', label='Training Loss')\nplt.plot(epochs_zoom, val_loss_zoom, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](9 model b_files/figure-html/cell-68-output-1.png){width=579 height=431}\n:::\n:::\n\n\n::: {#8d6e7cb6 .cell execution_count=68}\n``` {.python .cell-code}\n# Only plot the last 80% of the epochs\nzoom_split = int(epochs[-1] * 0.2)\nepochs_zoom = epochs[zoom_split:]\n\nmae_zoom = mae[zoom_split:]\nval_mae_zoom = val_mae[zoom_split:]\n\n\n# Plot zoomed mae and loss\nplt.plot(epochs_zoom, mae_zoom, 'r', label='mae_zoom')\nplt.plot(epochs_zoom, val_mae_zoom, 'b', label='val_mae_zooms')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](9 model b_files/figure-html/cell-69-output-1.png){width=579 height=431}\n:::\n:::\n\n\n## predication\n\n::: {#b033857c .cell execution_count=69}\n``` {.python .cell-code}\nx = padded_test\ny = model_dnn.predict(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\r 1/20 ━━━━━━━━━━━━━━━━━━━━ 0s 28ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \n```\n:::\n:::\n\n\n::: {#245bbe84 .cell execution_count=70}\n``` {.python .cell-code}\nlen(padded_test)\nlen(y)\nlen(review_socre_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\n633\n```\n:::\n:::\n\n\n::: {#28aef20c .cell execution_count=71}\n``` {.python .cell-code}\nreview_socre_final_test.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\n(633,)\n```\n:::\n:::\n\n\n::: {#69df0c72 .cell execution_count=72}\n``` {.python .cell-code}\ny.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```\n(633, 1)\n```\n:::\n:::\n\n\n::: {#18f2e23d .cell execution_count=73}\n``` {.python .cell-code}\ny2 = y.flatten()\n```\n:::\n\n\n::: {#4c03ae9d .cell execution_count=74}\n``` {.python .cell-code}\ny2.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=74}\n```\n(633,)\n```\n:::\n:::\n\n\n::: {#7b92dbe8 .cell execution_count=75}\n``` {.python .cell-code}\ndataset = pd.DataFrame({'real': review_socre_final_test, 'predic': list(y2)}, columns=['real', 'predic'])\n```\n:::\n\n\n::: {#c62f3951 .cell execution_count=76}\n``` {.python .cell-code}\ndataset['predic']=round(dataset['predic'])\ndataset['predic']=round(dataset['predic'])\n```\n:::\n\n\n::: {#c14338cd .cell execution_count=77}\n``` {.python .cell-code}\ndataset=dataset>> mutate(predic=if_else(_.predic <70, 70, _.predic)\n                          ,dummy_pred=86\n                         ,diff=_.predic-_.real \n                         ,dummy_diff=_.dummy_pred-_.real\n                          )>> mutate(predic=if_else(_.predic >100,100, _.predic))\n                          \ndataset002 = pd.concat([data002[4000:].reset_index(drop=True),dataset.reset_index(drop=True)], axis=1)                    \n```\n:::\n\n\n::: {#1c09fba3 .cell execution_count=78}\n``` {.python .cell-code}\ndataset002.to_excel('pred.xlsx')\n```\n:::\n\n\n::: {#86a9531a .cell execution_count=79}\n``` {.python .cell-code}\nimport seaborn as sns\nfig, ax = plt.subplots()\n\nsns.scatterplot(data=dataset,x='real',y='predic',ax=ax)\nsns.regplot(data=dataset, x=\"real\", y=\"predic\", x_jitter=.15,ax=ax)\nax.set(xlim=(65, 100),ylim=(65, 100))\n```\n\n::: {.cell-output .cell-output-display}\n![](9 model b_files/figure-html/cell-80-output-1.png){width=606 height=434}\n:::\n:::\n\n\n# resource:\n\nhttps://www.tensorflow.org/tutorials/keras/regression\n\n",
    "supporting": [
      "9 model b_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}