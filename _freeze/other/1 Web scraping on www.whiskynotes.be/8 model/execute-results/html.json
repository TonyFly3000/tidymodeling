{
  "hash": "8d3d5c96eecf29f9132f954fe01f7599",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Model\"\nsubtitle: \"with whiskynote.be data\"\nauthor: \"Tony Duan\"\n\nexecute:\n  warning: false\n  error: false\n\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n::: {#6eb0841b .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nos.system('pip3 install openpyxl')\n```\n:::\n\n\n::: {#d80f308d .cell execution_count=2}\n``` {.python .cell-code}\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n```\n:::\n\n\n::: {#8f25d92d .cell execution_count=3}\n``` {.python .cell-code}\nimport os\nos.system('pip3 show tensorflow')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nName: tensorflow\nVersion: 2.16.1\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, termcolor, typing-extensions, wrapt\nRequired-by: \n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=254}\n```\n0\n```\n:::\n:::\n\n\n# read in data\n\n::: {#da600e6f .cell execution_count=4}\n``` {.python .cell-code}\nimport pandas as pd\ndata=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n```\n:::\n\n\n::: {#aa9120b8 .cell execution_count=5}\n``` {.python .cell-code}\ndata.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=256}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bottle_name</th>\n      <th>bottle_review_Nose</th>\n      <th>bottle_review_Mouth</th>\n      <th>bottle_review_Finish</th>\n      <th>all_page_score</th>\n      <th>page_class</th>\n      <th>page_published_date</th>\n      <th>page_title</th>\n      <th>review_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cognac Chollet Lot 1960 ‘Le Bon Vivant’ – Fins...</td>\n      <td>Nose: a rich, fragrant and fruity style. Honey...</td>\n      <td>Mouth: more spices now. Mint and pepper, leadi...</td>\n      <td>Finish: medium to long, more on fruit tea now,...</td>\n      <td>0</td>\n      <td>* Cognac</td>\n      <td>30 November 2020</td>\n      <td>Cognac Lot 1960 / XO / Lot 1906 (Malternative ...</td>\n      <td>https://www.whiskynotes.be/2020/cognac/cognac-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cognac Vallein-Tercinier XO ‘Bûche de Noël’ (4...</td>\n      <td>Nose: a profile that I haven’t seen before in ...</td>\n      <td>Mouth: same thoughts, this is far from the fru...</td>\n      <td>Finish: not too long, still on sweet spices, c...</td>\n      <td>0</td>\n      <td>* Cognac</td>\n      <td>30 November 2020</td>\n      <td>Cognac Lot 1960 / XO / Lot 1906 (Malternative ...</td>\n      <td>https://www.whiskynotes.be/2020/cognac/cognac-...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cognac Héritage René Rivière Lot 1906 ‘La Fine...</td>\n      <td>Nose: very soft and restrained, especially in ...</td>\n      <td>Mouth: still fresh, certainly not tired, just ...</td>\n      <td>Finish: not too long, I’m afraid. Still on swe...</td>\n      <td>0</td>\n      <td>* Cognac</td>\n      <td>30 November 2020</td>\n      <td>Cognac Lot 1960 / XO / Lot 1906 (Malternative ...</td>\n      <td>https://www.whiskynotes.be/2020/cognac/cognac-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Ledaig 10 yo 2010 (53,2%, The Whisky Jury 2020...</td>\n      <td>Nose: classic Ledaig sharpness at first. Brine...</td>\n      <td>Mouth: aniseed and brine again, then smoked ki...</td>\n      <td>Finish: long, returning to the classic Ledaig ...</td>\n      <td>0</td>\n      <td>Ledaig</td>\n      <td>13 November 2020</td>\n      <td>Ledaig 2010 Oloroso (The Whisky Jury)</td>\n      <td>https://www.whiskynotes.be/2020/ledaig/ledaig-...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ledaig 10 yo 2010 (54,1%, The Whisky Jury for ...</td>\n      <td>Nose: right, this is going to be difficult. It...</td>\n      <td>Mouth: despite the higher ABV, this takes a bi...</td>\n      <td>Finish: so similar, really.</td>\n      <td>0</td>\n      <td>Ledaig</td>\n      <td>13 November 2020</td>\n      <td>Ledaig 2010 Oloroso (The Whisky Jury)</td>\n      <td>https://www.whiskynotes.be/2020/ledaig/ledaig-...</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#02247e0c .cell execution_count=6}\n``` {.python .cell-code}\nlist(data)\n```\n\n::: {.cell-output .cell-output-display execution_count=257}\n```\n['bottle_name',\n 'bottle_review_Nose',\n 'bottle_review_Mouth',\n 'bottle_review_Finish',\n 'all_page_score',\n 'page_class',\n 'page_published_date',\n 'page_title',\n 'review_url']\n```\n:::\n:::\n\n\n::: {#05e5b222 .cell execution_count=7}\n``` {.python .cell-code}\ndata.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4921 entries, 0 to 4920\nData columns (total 9 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4921 non-null   object\n 1   bottle_review_Nose    4921 non-null   object\n 2   bottle_review_Mouth   4921 non-null   object\n 3   bottle_review_Finish  4921 non-null   object\n 4   all_page_score        4921 non-null   int64 \n 5   page_class            4921 non-null   object\n 6   page_published_date   4921 non-null   object\n 7   page_title            4921 non-null   object\n 8   review_url            4921 non-null   object\ndtypes: int64(1), object(8)\nmemory usage: 346.1+ KB\n```\n:::\n:::\n\n\n::: {#013a4442 .cell execution_count=8}\n``` {.python .cell-code}\ndata001=data>> filter(_.all_page_score >0\n                      ,_.all_page_score <100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) >>mutate(\n                      review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )>>mutate(review=_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',',''))>>mutate(review_len=_.review.str.count(' ') + 1)\n\n```\n:::\n\n\n::: {#739db853 .cell execution_count=9}\n``` {.python .cell-code}\ndata001['review_flag']= np.where(data001['all_page_score']>=90, 1, 0)\n```\n:::\n\n\n# shuffle data\n\n::: {#73246a41 .cell execution_count=10}\n``` {.python .cell-code}\ndata002=data001.sample(frac=1)\n```\n:::\n\n\n::: {#19543ef1 .cell execution_count=11}\n``` {.python .cell-code}\ndata002.to_excel('data002.xlsx')\n```\n:::\n\n\n::: {#60f30c11 .cell execution_count=12}\n``` {.python .cell-code}\ndata002.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 4655 entries, 3790 to 2286\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4655 non-null   object\n 1   bottle_review_Nose    4655 non-null   object\n 2   bottle_review_Mouth   4655 non-null   object\n 3   bottle_review_Finish  4655 non-null   object\n 4   all_page_score        4655 non-null   int64 \n 5   page_class            4655 non-null   object\n 6   page_published_date   4655 non-null   object\n 7   page_title            4655 non-null   object\n 8   review_url            4655 non-null   object\n 9   review                4655 non-null   object\n 10  review_len            4655 non-null   int64 \n 11  review_flag           4655 non-null   int64 \ndtypes: int64(3), object(9)\nmemory usage: 472.8+ KB\n```\n:::\n:::\n\n\n::: {#de4ae583 .cell execution_count=13}\n``` {.python .cell-code}\nreview=data002['review'].tolist()\n```\n:::\n\n\n::: {#e0b6d98b .cell execution_count=14}\n``` {.python .cell-code}\nreview[2]\n```\n\n::: {.cell-output .cell-output-display execution_count=265}\n```\n' a lightly vegetal mossy kind of peat smoke sweetened with some honey and vanilla from the oak light apricot aromas and stewed apples fresh aromatic lemons bordering on bergamot hints of dusty cereals underneath fairly light but very pleasant starts on rather deep earthy smoke joined by some chocolate notes later on hints of granny smith lemons and nectarine vanilla custard hints of mint too not too long peppery\\xa0 keeping a nice balance between fruity notes and gentle peat smoke'\n```\n:::\n:::\n\n\n::: {#5afe539b .cell execution_count=15}\n``` {.python .cell-code}\nreview_flag=data002[\"review_flag\"].tolist()\n```\n:::\n\n\n::: {#e46bfe03 .cell execution_count=16}\n``` {.python .cell-code}\nreview_flag[2]\n```\n\n::: {.cell-output .cell-output-display execution_count=267}\n```\n0\n```\n:::\n:::\n\n\n::: {#3d91ca96 .cell execution_count=17}\n``` {.python .cell-code}\nfrom collections import Counter\nCounter(review_flag)\n```\n\n::: {.cell-output .cell-output-display execution_count=268}\n```\nCounter({0: 3428, 1: 1227})\n```\n:::\n:::\n\n\n::: {#ec6bde5d .cell execution_count=18}\n``` {.python .cell-code}\nprint(len(review))\n\nprint(len(review_flag))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4655\n4655\n```\n:::\n:::\n\n\nRemoving stop words with SkLearn\n\n::: {#882a7d6d .cell execution_count=19}\n``` {.python .cell-code}\nimport nltk\nimport ssl\n\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('stopwords')\n```\n\n::: {.cell-output .cell-output-display execution_count=270}\n```\nTrue\n```\n:::\n:::\n\n\n::: {#0a7e6546 .cell execution_count=20}\n``` {.python .cell-code}\nfrom stop_words import get_stop_words\nfrom nltk.corpus import stopwords\n\nstop_words = list(get_stop_words('en'))         #About 900 stopwords\nnltk_words = list(stopwords.words('english')) #About 150 stopwords\nstop_words.extend(nltk_words)\n```\n:::\n\n\n::: {#ee25231c .cell execution_count=21}\n``` {.python .cell-code}\nfrom nltk.corpus import stopwords\nimport string\n\n#stop_words = set(stopwords.words(\"english\"))\nexclude = set(string.punctuation)\n\ndef remove_stopwords(data):\n    output_array=[]\n    for sentence in data:\n        temp_list=[]\n        for word in sentence.split():\n            if word.lower() not in stop_words and word.lower() not in exclude :\n                temp_list.append(word)\n        output_array.append(' '.join(temp_list))\n    return output_array\n\nreview_remove_stop_word=remove_stopwords(review)\n```\n:::\n\n\n::: {#779c1048 .cell execution_count=22}\n``` {.python .cell-code}\nreview_remove_stop_word[3]\n```\n\n::: {.cell-output .cell-output-display execution_count=273}\n```\n'earthy side spirit amplified wine lot exhaust fumes smoked ham leatherette burnt heather hand there’s sour fruity side red plums grapes orange peels hints lanolin roasted nuts brown sugar good dark bittersweet pronounced winey side mistaken sherry cask dark chocolate coal smoke burnt caramel hints red berries italian vermouth heather honey dried herbs cloves hint cedar wood well long oak spice dark fruit flavours roasted nuts peat smoke'\n```\n:::\n:::\n\n\n::: {#7d311fb7 .cell execution_count=23}\n``` {.python .cell-code}\nreview[3]\n```\n\n::: {.cell-output .cell-output-display execution_count=274}\n```\n' the earthy side of the spirit is amplified by the wine a lot of exhaust fumes smoked ham leatherette and burnt heather on the other hand there’s a sour fruity side with red plums grapes and orange peels hints of lanolin roasted nuts and brown sugar good dark and bittersweet with a more pronounced winey side but it could be mistaken for a sherry cask dark chocolate coal smoke and burnt caramel hints of red berries and italian vermouth heather honey and dried herbs cloves a hint of cedar wood as well long on oak spice and dark fruit flavours with roasted nuts and peat smoke'\n```\n:::\n:::\n\n\n::: {#17dbfcbf .cell execution_count=24}\n``` {.python .cell-code}\n# Calculating the frequency of each word\nres = data002.review.str.split(expand=True).stack().value_counts()\n```\n:::\n\n\n::: {#27ae9137 .cell execution_count=25}\n``` {.python .cell-code}\nres.to_excel('res.xlsx')\n```\n:::\n\n\n::: {#21beb5e0 .cell execution_count=26}\n``` {.python .cell-code}\n# wordcloud function\n\n# from wordcloud import WordCloud\n# import matplotlib.pyplot as plt\n# \n# def show_wordcloud(data, title = None):\n#     wordcloud = WordCloud(\n#         background_color = 'white',\n#         max_words = 200,\n#         max_font_size = 40, \n#         scale = 3,\n#         random_state = 42\n#     ).generate(str(data))\n# \n#     fig = plt.figure(1, figsize = (20, 20))\n#     plt.axis('off')\n#     if title: \n#         fig.suptitle(title, fontsize = 20)\n#         fig.subplots_adjust(top = 2.3)\n# \n#     plt.imshow(wordcloud)\n#     plt.show()\n```\n:::\n\n\n::: {#643f11a6 .cell execution_count=27}\n``` {.python .cell-code}\ndef drop_words(phrase, disallowed_wordlist):\n  # 1. Split the phrase into an array of strings\n  phrase_split = phrase.split()\n\n  # 2. Create an empty array to contain the allowed words\n  allowed_words_list = []\n\n  # 3. Loop through the array of strings from step#1\n  for word in phrase_split:\n\n    # 4. Inside the loop, check if the word is present in the list of disallowed words\n    if word not in disallowed_wordlist:\n\n       # 5. Add the word to the list of allowed words from step#2\n       allowed_words_list.append(word)\n\n  # 6. Join all the strings in the allowed words list using the .join() string method.\n  new_phrase = \" \".join(allowed_words_list)\n  return new_phrase\n```\n:::\n\n\n::: {#be6cb4fc .cell execution_count=28}\n``` {.python .cell-code}\ntest_list = review_remove_stop_word\nchar_list = ['hint', 'hints','long','quite','rather','well','plenty','lot','still','start','end','towards','little','light','big','slightly','subtle','soft','really','background','even','nice','smoke','note','maybe','medium','side','time']\n\nnew_all=[]\nfor i in test_list:\n  #print(i)\n  #print(\"###############\")\n  new=drop_words(i, char_list)\n  new_all.append(new)\n```\n:::\n\n\n::: {#7e3ef231 .cell execution_count=29}\n``` {.python .cell-code}\nimport numpy as np\nfrom PIL import Image\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\n```\n:::\n\n\n::: {#30fe8468 .cell execution_count=30}\n``` {.python .cell-code}\nimage = Image.open('logo.png')\nnew_image = image.resize((3000, 3000))\nmeta_mask = np.array(new_image)\n\nmeta_mask[meta_mask< 10] = 255\nmeta_mask[meta_mask!=246] = 0\nmeta_mask[meta_mask==246] = 255\n#meta_mask\n#im = Image.fromarray(meta_mask)\n#im.save('myimage_1.jpg')\n\nnp.unique(meta_mask)\n```\n\n::: {.cell-output .cell-output-display execution_count=281}\n```\narray([  0, 255], dtype=uint8)\n```\n:::\n:::\n\n\n::: {#3e807765 .cell execution_count=31}\n``` {.python .cell-code}\nstopword= ['s','lot','lots','note','notes','also','there','bit','hint', 'hints','long','quite','rather','well','plenty','lot','still','start','end','towards','little','light','big','slightly','subtle','soft','really','background','even','nice','smoke','note','maybe','medium','side','time','like']\n\nunique_string=(\" \").join(new_all)\nwc = WordCloud(stopwords =stopword,background_color = '#FFFFFF', contour_width = 2,\n     contour_color = '#FFFFFF', colormap = 'bone',mask = meta_mask).generate(unique_string)\nplt.imshow(wc)\n#plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](8 model_files/figure-html/cell-32-output-1.png){width=432 height=416}\n:::\n:::\n\n\n::: {#c789e11e .cell execution_count=32}\n``` {.python .cell-code}\n# print wordcloud\n#show_wordcloud(new_all)\n```\n:::\n\n\n::: {#51f7aa1b .cell execution_count=33}\n``` {.python .cell-code}\n# add tf-idfs columns\n#from sklearn.feature_extraction.text import TfidfVectorizer\n#tfidf = TfidfVectorizer(min_df = 10)\n#tfidf_result = tfidf.fit_transform(review).toarray()\n#tfidf_df = pd.DataFrame(tfidf_result, columns = #tfidf.get_feature_names_out())\n#tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n#reviews_df = pd.concat([data002, tfidf_df], axis=1)\n```\n:::\n\n\n# transfer data\n\n::: {#b647279e .cell execution_count=34}\n``` {.python .cell-code}\nimport tensorflow as tf\nimport numpy as np \nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n```\n:::\n\n\n::: {#9fe6f7b2 .cell execution_count=35}\n``` {.python .cell-code}\n# Initialize the Tokenizer class\ntokenizer = Tokenizer()\n\n# Generate the word index dictionary\ntokenizer.fit_on_texts(review)\n\n# Define the total words. You add 1 for the index `0` which is just the padding token.\ntotal_words = len(tokenizer.word_index) + 1\n```\n:::\n\n\n::: {#5d34da55 .cell execution_count=36}\n``` {.python .cell-code}\nprint(f'total words: {total_words}')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntotal words: 7630\n```\n:::\n:::\n\n\n::: {#f695a4c7 .cell execution_count=37}\n``` {.python .cell-code}\n# Convert labels lists to numpy array\nreview_flag_final = np.array(review_flag)\n```\n:::\n\n\n::: {#5f232ea0 .cell execution_count=38}\n``` {.python .cell-code}\n# Parameters\nvocab_size = 7000\nmax_length = 300\nembedding_dim = 16\n#trunc_type='pre'\ntrunc_type='post'\noov_tok = \"<OOV>\"\n```\n:::\n\n\n::: {#b77d5c80 .cell execution_count=39}\n``` {.python .cell-code}\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Initialize the Tokenizer class\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n\n# Generate the word index dictionary for the training sentences\ntokenizer.fit_on_texts(review)\nword_index = tokenizer.word_index\n\n# Generate and pad the training sequences\nsequences = tokenizer.texts_to_sequences(review)\npadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n```\n:::\n\n\n::: {#6dbf5c26 .cell execution_count=40}\n``` {.python .cell-code}\nlen(review[4])\n```\n\n::: {.cell-output .cell-output-display execution_count=291}\n```\n1518\n```\n:::\n:::\n\n\n::: {#3a40163d .cell execution_count=41}\n``` {.python .cell-code}\nlen(padded[4])\n```\n\n::: {.cell-output .cell-output-display execution_count=292}\n```\n300\n```\n:::\n:::\n\n\n::: {#2a522214 .cell execution_count=42}\n``` {.python .cell-code}\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])            \n\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n```\n:::\n\n\n::: {#5f9f44ed .cell execution_count=43}\n``` {.python .cell-code}\nprint(decode_review(padded[4]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? more fruits again – acidic kinds like green apple lime and unripe pineapple vibrant but a bit greener fruit tea thin smoke again hints of hay spearmint and eucalyptus herbal ointments always a bit of vanilla too really good with a creamy character waxy notes and polished oak but also a nice hint of roast mocha and crushed peppercorns behind this is that citrusy top note lime and a green but almost tropical fruitiness long still showing this bright and vibrant citrusy side with waxy notes and pepper more fruits again – acidic kinds like green apple lime and unripe pineapple vibrant but a bit greener fruit tea thin smoke again hints of hay spearmint and eucalyptus herbal ointments always a bit of vanilla too really good with a creamy character waxy notes and polished oak but also a nice hint of roast mocha and crushed peppercorns behind this is that citrusy top note lime and a green but almost tropical fruitiness long still showing this bright and vibrant citrusy side with waxy notes and pepper more fruits again – acidic kinds like green apple lime and unripe pineapple vibrant but a bit greener fruit tea thin smoke again hints of hay spearmint and eucalyptus herbal ointments always a bit of vanilla too really good with a creamy character waxy notes and polished oak but also a nice hint of roast mocha and crushed peppercorns behind this is that citrusy top note lime and a green but almost tropical fruitiness long still showing this bright and vibrant citrusy side with waxy notes and pepper\n```\n:::\n:::\n\n\nafter tokenizer\n\n::: {#fee45979 .cell execution_count=44}\n``` {.python .cell-code}\nprint(sequences[4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[12, 23, 29, 208, 897, 883, 74, 52, 80, 185, 2, 337, 88, 562, 11, 4, 83, 636, 82, 55, 622, 48, 29, 8, 3, 195, 593, 2, 182, 35, 1532, 380, 4, 83, 3, 18, 38, 89, 168, 5, 4, 136, 264, 104, 7, 2, 198, 17, 11, 31, 4, 43, 32, 3, 944, 304, 2, 458, 285, 498, 36, 41, 72, 289, 423, 66, 185, 2, 4, 52, 11, 238, 137, 130, 15, 44, 224, 36, 175, 2, 562, 289, 63, 5, 104, 7, 2, 27, 12, 23, 29, 208, 897, 883, 74, 52, 80, 185, 2, 337, 88, 562, 11, 4, 83, 636, 82, 55, 622, 48, 29, 8, 3, 195, 593, 2, 182, 35, 1532, 380, 4, 83, 3, 18, 38, 89, 168, 5, 4, 136, 264, 104, 7, 2, 198, 17, 11, 31, 4, 43, 32, 3, 944, 304, 2, 458, 285, 498, 36, 41, 72, 289, 423, 66, 185, 2, 4, 52, 11, 238, 137, 130, 15, 44, 224, 36, 175, 2, 562, 289, 63, 5, 104, 7, 2, 27, 12, 23, 29, 208, 897, 883, 74, 52, 80, 185, 2, 337, 88, 562, 11, 4, 83, 636, 82, 55, 622, 48, 29, 8, 3, 195, 593, 2, 182, 35, 1532, 380, 4, 83, 3, 18, 38, 89, 168, 5, 4, 136, 264, 104, 7, 2, 198, 17, 11, 31, 4, 43, 32, 3, 944, 304, 2, 458, 285, 498, 36, 41, 72, 289, 423, 66, 185, 2, 4, 52, 11, 238, 137, 130, 15, 44, 224, 36, 175, 2, 562, 289, 63, 5, 104, 7, 2, 27]\n```\n:::\n:::\n\n\n::: {#cb8d540e .cell execution_count=45}\n``` {.python .cell-code}\nreview_flag[4]\n```\n\n::: {.cell-output .cell-output-display execution_count=296}\n```\n1\n```\n:::\n:::\n\n\n# using 4000 to train and 655 to test\n\n::: {#4638bf94 .cell execution_count=46}\n``` {.python .cell-code}\npadded_train=padded[0:4000]\npadded_test=padded[4000:]\n```\n:::\n\n\n::: {#8e537b29 .cell execution_count=47}\n``` {.python .cell-code}\nreview_flag_final_train=review_flag_final[0:4000]\nreview_flag_final_test=review_flag_final[4000:]\n```\n:::\n\n\n## total\n\n::: {#f2a697b9 .cell execution_count=48}\n``` {.python .cell-code}\nlen(padded)\nlen(review_flag_final)\n```\n\n::: {.cell-output .cell-output-display execution_count=299}\n```\n4655\n```\n:::\n:::\n\n\n## train\n\n::: {#3395a48e .cell execution_count=49}\n``` {.python .cell-code}\nlen(padded_train)\nlen(review_flag_final_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=300}\n```\n4000\n```\n:::\n:::\n\n\n## test\n\n::: {#93b15748 .cell execution_count=50}\n``` {.python .cell-code}\nlen(padded_test)\nlen(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=301}\n```\n655\n```\n:::\n:::\n\n\n::: {#06a6a349 .cell execution_count=51}\n``` {.python .cell-code}\nsum(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=302}\n```\n169\n```\n:::\n:::\n\n\n## if all guess lower than 90 points then 0.72 accuracy \n\n::: {#979a056c .cell execution_count=52}\n``` {.python .cell-code}\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=303}\n```\n0.7419847328244275\n```\n:::\n:::\n\n\n# define model\n\n::: {#c8e0f56e .cell execution_count=53}\n``` {.python .cell-code}\n# Build the model\nmodel_dnn = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=  32),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n```\n:::\n\n\n::: {#57a7c283 .cell execution_count=54}\n``` {.python .cell-code}\nmodel_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim= 32),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n```\n:::\n\n\n# compile model\n\n::: {#bea7971b .cell execution_count=55}\n``` {.python .cell-code}\n# Setup the training parameters\nmodel_dnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n```\n:::\n\n\n::: {#3abe72cf .cell execution_count=56}\n``` {.python .cell-code}\nmodel_dnn.summary()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_4      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n:::\n\n\n::: {#982f3b0d .cell execution_count=57}\n``` {.python .cell-code}\nmodel_lstm.summary()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n```\n:::\n:::\n\n\n# Callbacks\n\n::: {#fcaecdf8 .cell execution_count=58}\n``` {.python .cell-code}\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('val_accuracy')>0.90):\n      print(\"\\nReached 88% val_accuracy so cancelling training!\")\n      self.model.stop_training = True\n\n# Instantiate class\ncallbacks = myCallback()\n```\n:::\n\n\n# train DNN model\n\n::: {#1933b393 .cell execution_count=59}\n``` {.python .cell-code}\nnum_epochs = 20\n\n# Train the model\nhistory=model_dnn.fit(x=padded_train, y=review_flag_final_train, validation_data=(padded_test, review_flag_final_test),epochs=num_epochs,shuffle=True,callbacks=[callbacks])\n\n#history=model.fit(x=padded, y=review_flag_final, validation_split=0.2, shuffle=True,epochs=num_epochs,callbacks=[callbacks])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 47s 383ms/step - accuracy: 0.2812 - loss: 0.7014\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.6848 - loss: 0.6423   \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 91/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7068 - loss: 0.6157\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step - accuracy: 0.7133 - loss: 0.6064 - val_accuracy: 0.7420 - val_loss: 0.5616\nEpoch 2/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9062 - loss: 0.3990\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7608 - loss: 0.5396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7506 - loss: 0.5502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7475 - loss: 0.5532 - val_accuracy: 0.7405 - val_loss: 0.5653\nEpoch 3/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.7188 - loss: 0.5905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7300 - loss: 0.5678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7320 - loss: 0.5655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7327 - loss: 0.5644 - val_accuracy: 0.7389 - val_loss: 0.5528\nEpoch 4/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.8125 - loss: 0.4828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7397 - loss: 0.5470\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 87/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7402 - loss: 0.5474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7402 - loss: 0.5474 - val_accuracy: 0.7389 - val_loss: 0.5339\nEpoch 5/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.5312 - loss: 0.7607\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7240 - loss: 0.5503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 89/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7322 - loss: 0.5352\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7354 - loss: 0.5269 - val_accuracy: 0.7939 - val_loss: 0.4372\nEpoch 6/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.7812 - loss: 0.4210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8097 - loss: 0.4207\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8164 - loss: 0.4164\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8184 - loss: 0.4151 - val_accuracy: 0.8137 - val_loss: 0.3794\nEpoch 7/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.6875 - loss: 0.5544\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8516 - loss: 0.3621\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 87/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8570 - loss: 0.3503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8587 - loss: 0.3466 - val_accuracy: 0.8168 - val_loss: 0.4228\nEpoch 8/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.9375 - loss: 0.3205\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8714 - loss: 0.3252\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 87/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8694 - loss: 0.3202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8694 - loss: 0.3164 - val_accuracy: 0.8519 - val_loss: 0.3102\nEpoch 9/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9062 - loss: 0.2638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8912 - loss: 0.2702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8876 - loss: 0.2762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8874 - loss: 0.2772 - val_accuracy: 0.8763 - val_loss: 0.3029\nEpoch 10/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9062 - loss: 0.2499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8907 - loss: 0.2715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8916 - loss: 0.2644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.8911 - loss: 0.2614 - val_accuracy: 0.8763 - val_loss: 0.3026\nEpoch 11/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9375 - loss: 0.1326\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9070 - loss: 0.2461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9071 - loss: 0.2407\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9057 - loss: 0.2409 - val_accuracy: 0.8626 - val_loss: 0.3082\nEpoch 12/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.9375 - loss: 0.1919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9119 - loss: 0.2142\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9073 - loss: 0.2229\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9049 - loss: 0.2273 - val_accuracy: 0.8718 - val_loss: 0.2951\nEpoch 13/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.9062 - loss: 0.1901\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9140 - loss: 0.2243\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9129 - loss: 0.2235\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9102 - loss: 0.2277 - val_accuracy: 0.8824 - val_loss: 0.3002\nEpoch 14/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.9062 - loss: 0.2078\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9173 - loss: 0.2033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 89/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9117 - loss: 0.2171\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9108 - loss: 0.2183 - val_accuracy: 0.8595 - val_loss: 0.3216\nEpoch 15/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9062 - loss: 0.2007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9071 - loss: 0.2060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 87/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9085 - loss: 0.2058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9096 - loss: 0.2061 - val_accuracy: 0.8550 - val_loss: 0.3419\nEpoch 16/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 1.0000 - loss: 0.0911\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 43/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9118 - loss: 0.2001\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 86/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9082 - loss: 0.2109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9088 - loss: 0.2117 - val_accuracy: 0.8840 - val_loss: 0.3005\nEpoch 17/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 8ms/step - accuracy: 0.8438 - loss: 0.2382\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9071 - loss: 0.2001\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9127 - loss: 0.1981\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9145 - loss: 0.1989 - val_accuracy: 0.8779 - val_loss: 0.2947\nEpoch 18/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 1.0000 - loss: 0.0882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 45/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9484 - loss: 0.1453\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9429 - loss: 0.1543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9396 - loss: 0.1604 - val_accuracy: 0.8656 - val_loss: 0.3197\nEpoch 19/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9688 - loss: 0.1019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 44/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9366 - loss: 0.1699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 88/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9280 - loss: 0.1874\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9244 - loss: 0.1940 - val_accuracy: 0.8534 - val_loss: 0.3539\nEpoch 20/20\n\r  1/125 ━━━━━━━━━━━━━━━━━━━━ 1s 9ms/step - accuracy: 0.9062 - loss: 0.1722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 42/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9299 - loss: 0.1782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 85/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9335 - loss: 0.1750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r125/125 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.9346 - loss: 0.1734 - val_accuracy: 0.8656 - val_loss: 0.3376\n```\n:::\n:::\n\n\n::: {#142502c8 .cell execution_count=60}\n``` {.python .cell-code}\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n```\n:::\n\n\n::: {#da0f9137 .cell execution_count=61}\n``` {.python .cell-code}\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](8 model_files/figure-html/cell-62-output-1.png){width=579 height=431}\n:::\n\n::: {.cell-output .cell-output-display}\n![](8 model_files/figure-html/cell-62-output-2.png){width=571 height=431}\n:::\n:::\n\n\n# train LSTM model\n\n::: {#73d41e3d .cell execution_count=62}\n``` {.python .cell-code}\nnum_epochs = 5\n\n# Train the model\n# history2=model_lstm.fit(x=padded_train, y=review_flag_final_train, validation_data=(padded_test, review_flag_final_test),epochs=num_epochs,shuffle=True,callbacks=[callbacks])\n```\n:::\n\n\n::: {#ddecb243 .cell execution_count=63}\n``` {.python .cell-code}\n# acc = history2.history['accuracy']\n# val_acc = history2.history['val_accuracy']\n# loss = history2.history['loss']\n# val_loss = history2.history['val_loss']\n# epochs = range(len(acc))\n```\n:::\n\n\n::: {#f2af16d7 .cell execution_count=64}\n``` {.python .cell-code}\n# import matplotlib.image as mpimg\n# import matplotlib.pyplot as plt\n# #------------------------------------------------\n# # Plot training and validation accuracy per epoch\n# #------------------------------------------------\n# plt.plot(epochs, acc, 'r', label='Training accuracy')\n# plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n# plt.show()\n# plt.figure()\n# \n# plt.plot(epochs, loss, 'r', label='Training Loss')\n# plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n# plt.title('LSTM model Training and validation loss')\n# plt.legend()\n# \n# plt.show()\n```\n:::\n\n\n# resource:\n\nhttps://medium.com/@m3redithw/wordclouds-with-python-c287887acc8b\n\n",
    "supporting": [
      "8 model_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}