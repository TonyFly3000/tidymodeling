{
  "hash": "111cf64ea8ca23dc371e604682cb011d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"XGboost classification model\"\nsubtitle: \"with whiskynote.be data\"\nauthor: \"Tony Duan\"\n\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n::: {#be125a3a .cell execution_count=1}\n``` {.python .cell-code}\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n```\n:::\n\n\n# read in data\n\n::: {#2241c6f8 .cell execution_count=2}\n``` {.python .cell-code}\nimport pandas as pd\ndata=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n```\n:::\n\n\n::: {#c689f7f1 .cell execution_count=3}\n``` {.python .cell-code}\nlist(data)\n```\n:::\n\n\n::: {#97885689 .cell execution_count=4}\n``` {.python .cell-code}\ndata.info()\n```\n:::\n\n\n::: {#28b06779 .cell execution_count=5}\n``` {.python .cell-code}\nimport re\ndata001=data>> filter(_.all_page_score >=70\n                      ,_.all_page_score <100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) >>mutate(\n                        review_flag=if_else(_.all_page_score>=90,1,0)\n                      ,review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )>>mutate(review=_.bottle_name+_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',','').str.replace('(','').str.replace(')','').str.replace('-','').str.replace('apples','apple').str.replace('oranges','orange').str.replace('sweetness','sweet').str.replace('fruits','fruit'))>>mutate(review_len=_.review.str.count(' ') + 1)\n\n```\n:::\n\n\n::: {#49163f29 .cell execution_count=6}\n``` {.python .cell-code}\ndata001 = data001.dropna(subset=[\"review_flag\", \"review\"])\n```\n:::\n\n\n::: {#4633668a .cell execution_count=7}\n``` {.python .cell-code}\ndata001.review_flag = data001.review_flag.astype(int)\n```\n:::\n\n\n::: {#94c130c4 .cell execution_count=8}\n``` {.python .cell-code}\ndata001.info()\n```\n:::\n\n\n# shuffle data\n\n::: {#378f6dfa .cell execution_count=9}\n``` {.python .cell-code}\ndata002=data001.sample(frac=1)\n```\n:::\n\n\n::: {#fef6ce4e .cell execution_count=10}\n``` {.python .cell-code}\ndata002.to_excel('data002.xlsx')\n```\n:::\n\n\n::: {#e2f656cb .cell execution_count=11}\n``` {.python .cell-code}\ndata002.info()\n```\n:::\n\n\n::: {#b33bba72 .cell execution_count=12}\n``` {.python .cell-code}\nreview=data002['review'].tolist()\n```\n:::\n\n\n::: {#5f6f82b2 .cell execution_count=13}\n``` {.python .cell-code}\nreview[2]\n```\n:::\n\n\n::: {#97ec8d62 .cell execution_count=14}\n``` {.python .cell-code}\nreview_flag=data002[\"review_flag\"].tolist()\n```\n:::\n\n\n::: {#bf0e9ee4 .cell execution_count=15}\n``` {.python .cell-code}\nreview_score=data002[\"all_page_score\"].tolist()\n```\n:::\n\n\n::: {#1c5d9f75 .cell execution_count=16}\n``` {.python .cell-code}\nreview_flag[2]\n```\n:::\n\n\n::: {#2d52228a .cell execution_count=17}\n``` {.python .cell-code}\nfrom collections import Counter\nCounter(review_flag)\n```\n:::\n\n\n::: {#80fef243 .cell execution_count=18}\n``` {.python .cell-code}\nprint(len(review))\n\nprint(len(review_flag))\n```\n:::\n\n\n# transfer data\n\n::: {#6d6b557a .cell execution_count=19}\n``` {.python .cell-code}\nimport tensorflow as tf\nimport numpy as np \nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n```\n:::\n\n\n::: {#73c1544a .cell execution_count=20}\n``` {.python .cell-code}\n# Initialize the Tokenizer class\ntokenizer = Tokenizer()\n\n# Generate the word index dictionary\ntokenizer.fit_on_texts(review)\n\n# Define the total words. You add 1 for the index `0` which is just the padding token.\ntotal_words = len(tokenizer.word_index) + 1\n```\n:::\n\n\n::: {#34f7a0c0 .cell execution_count=21}\n``` {.python .cell-code}\nprint(f'total words: {total_words}')\n```\n:::\n\n\n::: {#9b1762b2 .cell execution_count=22}\n``` {.python .cell-code}\n# Convert labels lists to numpy array\nreview_flag_final = np.array(review_flag)\nreview_score_final = np.array(review_score)\n```\n:::\n\n\n::: {#72fc990d .cell execution_count=23}\n``` {.python .cell-code}\n# Parameters\nvocab_size = 7000\nmax_length = 300\nembedding_dim = 16\n#trunc_type='pre'\ntrunc_type='post'\noov_tok = \"<OOV>\"\n```\n:::\n\n\n::: {#42a1bb4f .cell execution_count=24}\n``` {.python .cell-code}\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Initialize the Tokenizer class\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n\n# Generate the word index dictionary for the training sentences\ntokenizer.fit_on_texts(review)\nword_index = tokenizer.word_index\n\n# Generate and pad the training sequences\nsequences = tokenizer.texts_to_sequences(review)\npadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n```\n:::\n\n\n::: {#0ac5d721 .cell execution_count=25}\n``` {.python .cell-code}\nlen(review[4])\n```\n:::\n\n\n::: {#2dcb37a3 .cell execution_count=26}\n``` {.python .cell-code}\nlen(padded[4])\n```\n:::\n\n\n::: {#29dbcd69 .cell execution_count=27}\n``` {.python .cell-code}\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])            \n\ndef decode_review(text):\n    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n```\n:::\n\n\n::: {#f699ee8d .cell execution_count=28}\n``` {.python .cell-code}\nprint(decode_review(padded[0]))\n```\n:::\n\n\nafter tokenizer\n\n::: {#25ef7013 .cell execution_count=29}\n``` {.python .cell-code}\nprint(sequences[0])\n```\n:::\n\n\n::: {#724e9fcc .cell execution_count=30}\n``` {.python .cell-code}\nreview_flag[0]\n```\n:::\n\n\n# using 4000 to train and 633 to test\n\n::: {#51f8c784 .cell execution_count=31}\n``` {.python .cell-code}\npadded_train=padded[0:4000]\npadded_test=padded[4000:]\n```\n:::\n\n\n::: {#2b9a1bf6 .cell execution_count=32}\n``` {.python .cell-code}\nreview_flag_final_train=review_flag_final[0:4000]\nreview_flag_final_test=review_flag_final[4000:]\n```\n:::\n\n\n::: {#c33f953d .cell execution_count=33}\n``` {.python .cell-code}\nreview_socre_final_train=review_score_final[0:4000]\nreview_socre_final_test=review_score_final[4000:]\n```\n:::\n\n\n## total\n\n::: {#fc1559cc .cell execution_count=34}\n``` {.python .cell-code}\nlen(padded)\nlen(review_flag_final)\n```\n:::\n\n\n## train\n\n::: {#45638630 .cell execution_count=35}\n``` {.python .cell-code}\nlen(padded_train)\nlen(review_flag_final_train)\n```\n:::\n\n\n## test\n\n::: {#09b73a07 .cell execution_count=36}\n``` {.python .cell-code}\nlen(padded_test)\nlen(review_flag_final_test)\n```\n:::\n\n\n::: {#e95b04e1 .cell execution_count=37}\n``` {.python .cell-code}\nsum(review_flag_final_test)\n```\n:::\n\n\n## if all guess lower than 90 points then 0.75 accuracy \n\n::: {#f7b62a67 .cell execution_count=38}\n``` {.python .cell-code}\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)\n```\n:::\n\n\n# XB bootst model\n\n::: {#c5b3fee2 .cell execution_count=39}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nimport time\nfrom siuba import *\n```\n:::\n\n\n::: {#17d2afc8 .cell execution_count=40}\n``` {.python .cell-code}\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n```\n:::\n\n\n::: {#f77687d2 .cell execution_count=41}\n``` {.python .cell-code}\nfrom xgboost import XGBClassifier\nml_model = XGBClassifier()\nml_model\n```\n:::\n\n\n# define pipline\n\n::: {#236554f6 .cell execution_count=42}\n``` {.python .cell-code}\n#ml_model.fit(padded_train,review_flag_final_train)\n```\n:::\n\n\n::: {#bee9164a .cell execution_count=43}\n``` {.python .cell-code}\npipeline = Pipeline(\n  steps=[\n      \n         ('model', ml_model)\n         ]\n)\n\npipeline\n```\n:::\n\n\n::: {#cabc018e .cell execution_count=44}\n``` {.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV\n\n\nparameters = {\n        'model__learning_rate': [0.08,0.1],\n        'model__max_depth': [9,10,20],\n        'model__min_child_weight': [3,5,8],\n        'model__subsample': [0.7,0.9],\n        \n       # 'model__colsample__bytree': [0.5, 0.7],\n       \n        'model__n_estimators' : [100,200],\n        'model__objective': ['reg:squarederror']\n    }\n```\n:::\n\n\n::: {#9d13b689 .cell execution_count=45}\n``` {.python .cell-code}\nimport itertools\na = parameters.values()\ncombinations = list(itertools.product(*a))\nlen(combinations)\n```\n:::\n\n\n::: {#8a66f63c .cell execution_count=46}\n``` {.python .cell-code}\nGridCV = GridSearchCV(pipeline\n                ,parameters\n                ,scoring='accuracy'\n                , cv=3, n_jobs=-1)\n```\n:::\n\n\n# train model\n\n::: {#3720a3ba .cell execution_count=47}\n``` {.python .cell-code}\nstart_time = time.time()\n\nGridCV.fit(padded_train, review_flag_final_train)\n\nend_time = time.time()\nduration = end_time - start_time\nduration\n```\n:::\n\n\n::: {#4b85278d .cell execution_count=48}\n``` {.python .cell-code}\nmodel_ml = GridCV.best_estimator_\n```\n:::\n\n\n::: {#b51fc173 .cell execution_count=49}\n``` {.python .cell-code}\n#Using predict method to test the model\nY_pred_dt = model_ml.predict(padded_test) #always gets x and retuns y\nY_pred_dt\n```\n:::\n\n\n::: {#38fd07b0 .cell execution_count=50}\n``` {.python .cell-code}\n# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives\n# Here is another way to find the accuracy score\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(review_flag_final_test,Y_pred_dt)  \naccuracy\n```\n:::\n\n\n::: {#11c7084e .cell execution_count=51}\n``` {.python .cell-code}\nimport seaborn as sns\nconfusion_matrix_dt = metrics.confusion_matrix(review_flag_final_test,Y_pred_dt)\nconfusion_matrix_dt\n```\n:::\n\n\n# resource:\n\nhttps://www.tensorflow.org/tutorials/keras/regression\n\n",
    "supporting": [
      "9 XGboost classification model_files"
    ],
    "filters": [],
    "includes": {}
  }
}