{
  "hash": "2c30cbef021ec90bfa3f333d7bd91501",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regression model with Recipe,workflow,tuning\"\nsubtitle: \"with house price data\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n-   using Recipe.\n-   add resamples to estimate the performance of our two models\n-   add workflow with tuning\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n```\n:::\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\ntrain_df <- train  %>% select_if(is.numeric)%>% rename(target_variable=SalePrice)%>% replace(is.na(.), 0)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1021   38\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 293  38\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 146  38\n```\n\n\n:::\n:::\n\n\n# modeling\n\n## recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  #step_downsample(target_variable) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric(), -all_outcomes())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec %>% summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 38 × 4\n   variable     type      role      source  \n   <chr>        <list>    <chr>     <chr>   \n 1 Id           <chr [2]> predictor original\n 2 MSSubClass   <chr [2]> predictor original\n 3 LotFrontage  <chr [2]> predictor original\n 4 LotArea      <chr [2]> predictor original\n 5 OverallQual  <chr [2]> predictor original\n 6 OverallCond  <chr [2]> predictor original\n 7 YearBuilt    <chr [2]> predictor original\n 8 YearRemodAdd <chr [2]> predictor original\n 9 MasVnrArea   <chr [2]> predictor original\n10 BsmtFinSF1   <chr [2]> predictor original\n# ℹ 28 more rows\n```\n\n\n:::\n:::\n\n\n\n## model\n\n![](images/1.png){width=\"214\"}\n\n### lasso regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_tune_spec <- linear_reg(penalty = tune(), mixture = 1) %>%\n  set_engine(\"glmnet\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_grid <- grid_regular(penalty(), levels = 100)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_tune_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n```\n\n\n:::\n:::\n\n\n## workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_workflow =\n  workflow() %>% \n  add_model(lasso_tune_spec) %>% \n  add_recipe(data_rec)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncntl   <- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n```\n:::\n\n\n10 fold for tunning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nfolds <- vfold_cv(data_train)\n```\n:::\n\n\n## training\n\n### train lasso model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_res = model_workflow %>% \n  tune_grid(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_res %>% collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 200 × 7\n    penalty .metric .estimator      mean     n   std_err .config               \n      <dbl> <chr>   <chr>          <dbl> <int>     <dbl> <chr>                 \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model001\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model001\n 3 1.26e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model002\n 4 1.26e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model002\n 5 1.59e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model003\n 6 1.59e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model003\n 7 2.01e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model004\n 8 2.01e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model004\n 9 2.54e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model005\n10 2.54e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model005\n# ℹ 190 more rows\n```\n\n\n:::\n:::\n\n\n# model result\n\n## Evaluate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(lasso_res)\n```\n\n::: {.cell-output-display}\n![](4-Regression-Tidy-Modeling_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nuse best tune model for final fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlowest_rmse <- lasso_res %>%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n       penalty .config               \n         <dbl> <chr>                 \n1 0.0000000001 Preprocessor1_Model001\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <- \n  model_workflow %>% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet \n```\n\n\n:::\n:::\n\n\n## last fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_res <- \n  final_wf %>%\n  last_fit(data_split) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_res %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n# resample with tuned model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\nfolds <- vfold_cv(data_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresample_res <- final_wf %>% extract_spec_parsnip() %>% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen=10000)\nresample_res %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  <chr>   <chr>          <dbl> <int>     <dbl> <chr>               \n1 rmse    standard   39201.       10 4620.     Preprocessor1_Model1\n2 rsq     standard       0.769    10    0.0422 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n# future prediction with last fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfuture_predict=predict(final_res%>% extract_workflow(),data_valid)\n\nglimpse(future_predict)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 146\nColumns: 1\n$ .pred <dbl> 269679.57, 153064.58, 282289.94, 291638.67, 115884.63, 274660.03…\n```\n\n\n:::\n:::\n\n\n# resouece\n\nhttps://www.youtube.com/watch?v=1LEW8APSOJo\n\nhttps://juliasilge.com/blog/lasso-the-office/\n",
    "supporting": [
      "4-Regression-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}