{
  "hash": "eeea5be211ec1675399f04d841b657d0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Classification model with Recipe\"\nsubtitle: \"with titanic data\"\nauthor: \"Tony Duan\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n\nLevel 3 classification Tidy Modeling: \n\n* using Recipe.\n* add resamples to estimate the performance of our two models\n\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n```\n:::\n\n## EDA\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 891\nColumns: 12\n$ PassengerId <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    <dbl> 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      <dbl> 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        <chr> \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         <chr> \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         <dbl> 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       <dbl> 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      <chr> \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        <dbl> 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       <chr> NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    <chr> \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 418\nColumns: 11\n$ PassengerId <dbl> 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      <dbl> 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        <chr> \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         <chr> \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         <dbl> 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       <dbl> 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       <dbl> 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      <chr> \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        <dbl> 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    <chr> \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain %>%\n  count(Survived)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  Survived     n\n     <dbl> <int>\n1        0   549\n2        1   342\n```\n\n\n:::\n:::\n\n\n\n## plotting\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(skimr)\n\nskim(train)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |      |\n|:------------------------|:-----|\n|Name                     |train |\n|Number of rows           |891   |\n|Number of columns        |12    |\n|_______________________  |      |\n|Column type frequency:   |      |\n|character                |5     |\n|numeric                  |7     |\n|________________________ |      |\n|Group variables          |None  |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|Name          |         0|          1.00|  12|  82|     0|      891|          0|\n|Sex           |         0|          1.00|   4|   6|     0|        2|          0|\n|Ticket        |         0|          1.00|   3|  18|     0|      681|          0|\n|Cabin         |       687|          0.23|   1|  15|     0|      147|          0|\n|Embarked      |         2|          1.00|   1|   1|     0|        3|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|     sd|   p0|    p25|    p50|   p75|   p100|hist  |\n|:-------------|---------:|-------------:|------:|------:|----:|------:|------:|-----:|------:|:-----|\n|PassengerId   |         0|           1.0| 446.00| 257.35| 1.00| 223.50| 446.00| 668.5| 891.00|▇▇▇▇▇ |\n|Survived      |         0|           1.0|   0.38|   0.49| 0.00|   0.00|   0.00|   1.0|   1.00|▇▁▁▁▅ |\n|Pclass        |         0|           1.0|   2.31|   0.84| 1.00|   2.00|   3.00|   3.0|   3.00|▃▁▃▁▇ |\n|Age           |       177|           0.8|  29.70|  14.53| 0.42|  20.12|  28.00|  38.0|  80.00|▂▇▅▂▁ |\n|SibSp         |         0|           1.0|   0.52|   1.10| 0.00|   0.00|   0.00|   1.0|   8.00|▇▁▁▁▁ |\n|Parch         |         0|           1.0|   0.38|   0.81| 0.00|   0.00|   0.00|   0.0|   6.00|▇▁▁▁▁ |\n|Fare          |         0|           1.0|  32.20|  49.69| 0.00|   7.91|  14.45|  31.0| 512.33|▇▁▁▁▁ |\n\n\n:::\n:::\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\ntrain_df <- train %>%mutate(Survived=as.factor(Survived)) %>% select(-Name) %>% \n\n  mutate_if(is.character, factor) %>% rename(target_variable=Survived)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 623  11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 179  11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 89 11\n```\n\n\n:::\n:::\n\n\n# modeling\n\n## recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  step_impute_knn(all_predictors(), neighbors = 5) %>%\n  #step_downsample(target_variable) %>%\n  #step_novel(Ticket) %>%\n  step_rm(Ticket) %>% \n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric())\n```\n:::\n\n\n![](images/2-02.png)\n\n## prep the recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec=data_rec %>% prep()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec\n```\n:::\n\n\n## bake the train data with preded recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc <- bake(data_rec, new_data = data_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc2 <- bake(data_rec, new_data = NULL)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_juice <-juice(data_rec)\n```\n:::\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train_proc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 623 128\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train_proc2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 623 128\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train_juice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 623 128\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc %>%\n  count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 0                 379\n2 1                 244\n```\n\n\n:::\n:::\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc2 %>%\n  count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 0                 379\n2 1                 244\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_juice %>%\n  count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 0                 379\n2 1                 244\n```\n\n\n:::\n:::\n\n\n## bake the test data with preded recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_proc <- bake(data_rec, new_data = data_test)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_proc %>%count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 0                 113\n2 1                  66\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_valid %>%count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 0                  57\n2 1                  32\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvalid_proc <- bake(data_rec, new_data = data_valid)\n```\n:::\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)\n\n## model\n\ntree model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_spec <- decision_tree() %>%\n  set_engine(\"rpart\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\nKNN model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_spec <- nearest_neighbor() %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\n## trainning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_fit <- knn_spec %>%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2536116\nBest kernel: optimal\nBest k: 5\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit <- tree_spec %>%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex_male>=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n      4) Age>=-1.700165 388  70 0 (0.81958763 0.18041237) *\n      5) Age< -1.700165 18   4 1 (0.22222222 0.77777778) *\n    3) Sex_male< -0.3181194 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass>=0.2640325 91  42 0 (0.53846154 0.46153846)  \n       12) Fare>=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n       13) Fare< -0.1653079 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked_S>=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n           52) Fare>=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n           53) Fare< -0.3321481 33  16 0 (0.51515152 0.48484848)  \n            106) Fare< -0.4658063 23   8 0 (0.65217391 0.34782609) *\n            107) Fare>=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked_S< -0.4915368 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass< 0.2640325 126   8 1 (0.06349206 0.93650794) *\n```\n\n\n:::\n:::\n\n\n# model result\n\n## Evaluate\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits <- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits           id        \n   <list>           <chr>     \n 1 <split [560/63]> Resample01\n 2 <split [560/63]> Resample02\n 3 <split [560/63]> Resample03\n 4 <split [560/63]> Resample04\n 5 <split [560/63]> Resample05\n 6 <split [560/63]> Resample06\n 7 <split [560/63]> Resample07\n 8 <split [560/63]> Resample08\n 9 <split [560/63]> Resample09\n10 <split [560/63]> Resample10\n# ℹ 15 more rows\n```\n\n\n:::\n:::\n\n\nKKN:\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_res <- knn_spec %>% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %>%collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.726    25 0.0118  Preprocessor1_Model1\n2 roc_auc  binary     0.773    25 0.00998 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\nTree model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res <- tree_spec %>% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %>%collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.788    25  0.0115 Preprocessor1_Model1\n2 roc_auc  binary     0.815    25  0.0117 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_res %>%\n  unnest(.predictions) %>%\n  mutate(model = \"kknn\") %>%\n  bind_rows(tree_res %>%\n    unnest(.predictions) %>%\n    mutate(model = \"rpart\")) %>%\n  group_by(model) %>%\n  roc_curve(target_variable, .pred_0) %>%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](2-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n## save model\n\ncheck model size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)\nobj_size(tree_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n847.94 kB\n```\n\n\n:::\n\n```{.r .cell-code}\nobj_size(knn_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n817.13 kB\n```\n\n\n:::\n:::\n\n\nbundle and save model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bundle)\nmodel_bundle <- bundle(knn_fit)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')\n```\n:::\n\n\n## make predication\n\nload model and unbundle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel <- unbundle(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 0          \n2 0          \n3 1          \n4 0          \n5 1          \n6 0          \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.730\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(target_variable)%>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  <fct>           <int>\n1 0                  57\n2 1                  32\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(.pred_class) %>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  <fct>       <int>\n1 0              53\n2 1              36\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22\n```\n\n\n:::\n:::\n\n\n# reference:\n\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\n\nhttps://juliasilge.com/blog/hotels-recipes/\n\nhttps://www.tidymodels.org/start/case-study/\n",
    "supporting": [
      "2-classification-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}