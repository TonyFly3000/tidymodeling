{
  "hash": "f49fbf6a77bdaf9a4412ba1b9a1b44db",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Level 5 classification Tidy Modeling\"\nsubtitle: \"with hotel booking data\"\nauthor: \"Tony Duan\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n\nLevel 5 classification Tidy Modeling with 1 tuning model and 1 recipe : \n\n* using Recipe to down sample.\n* add resamples to estimate the performance of our two models\n* add workflow with tuning\n* add quick tuning `tune_race_anova()`\n\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\n\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nhotels <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays <- hotels %>%\n  filter(is_canceled == 0) %>%\n  mutate(\n    children = case_when(\n      children + babies > 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces > 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %>%\n  select(-is_canceled, -reservation_status, -babies)\n```\n:::\n\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\nall_hotels_df <- hotel_stays %>%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %>%\n  mutate_if(is.character, factor) %>% rename(target_variable=children) %>% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%>% sample_n(50000) \n\nhold_hotels_df <- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n#hotels_df=hotels_df %>% select(-rownum)\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 35000    11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5000   11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000    11\n```\n\n\n:::\n:::\n\n\n10 fold for tunning\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nfolds <- vfold_cv(data_train)\n```\n:::\n\n\n\n\n\n# modeling\n\n## recipe\n\nbecasue the target class is not balance so using downsample\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  step_rm(rownum) %>% \n  step_downsample(target_variable) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric())\n```\n:::\n\n\n\n## model\n\ndecision tree model with cost_complexity and tree_depth to tune\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec |> \n  extract_parameter_set_dials()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_leaves()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of Leaves (quantitative)\nRange: [5, 100]\n```\n\n\n:::\n:::\n\n\ntunning grid\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune <- \n  tune_spec |> \n  extract_parameter_set_dials() |> \n  grid_latin_hypercube(size = 200)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune |> glimpse(width = 200)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 200\nColumns: 2\n$ cost_complexity <dbl> 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      <int> 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune %>% count(tree_depth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 2\n   tree_depth     n\n        <int> <int>\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7\n```\n\n\n:::\n:::\n\n\n## workflow \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(finetune)\ncntl <- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_workflow =\n  workflow() %>% \n  add_model(tune_spec) %>% \n  add_recipe(data_rec)\n```\n:::\n\n\n\n\n\n## training and tunning\n\nusing tune_race_anova() instead of tune_grid()\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %>% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(tree_res)\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_race(tree_res)\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>% \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 96 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>     \n 1   0.00000000437         11 accuracy binary     0.747    10 0.00458 Preproces…\n 2   0.00000000437         11 roc_auc  binary     0.820    10 0.00526 Preproces…\n 3   0.000000134           15 accuracy binary     0.749    10 0.00502 Preproces…\n 4   0.000000134           15 roc_auc  binary     0.818    10 0.00489 Preproces…\n 5   0.00000708            12 accuracy binary     0.755    10 0.00470 Preproces…\n 6   0.00000708            12 roc_auc  binary     0.819    10 0.00504 Preproces…\n 7   0.00000327            12 accuracy binary     0.755    10 0.00470 Preproces…\n 8   0.00000327            12 roc_auc  binary     0.819    10 0.00504 Preproces…\n 9   0.0000750             13 accuracy binary     0.754    10 0.00539 Preproces…\n10   0.0000750             13 roc_auc  binary     0.818    10 0.00517 Preproces…\n# ℹ 86 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  collect_metrics() %>%\n  mutate(tree_depth = factor(tree_depth)) %>%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  show_best()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1        4.37e- 9         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n2        4.32e- 5         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n3        1.09e-10         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n4        1.45e- 9         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n5        7.52e- 8         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_tree <- tree_res %>%\n  select_best()\n\nbest_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            <dbl>      <int> <chr>                 \n1   0.00000000437         11 Preprocessor1_Model008\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <- \n  model_workflow %>% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 4.37354062320283e-09\n  tree_depth = 11\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n\n## last fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- \n  final_wf %>%\n  last_fit(data_split) \n```\n:::\n\n\n\n# model result\n\n## Evaluate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.741 Preprocessor1_Model1\n2 roc_auc  binary         0.817 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics <- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %>% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 accuracy  binary         0.741\n2 recall    binary         0.767\n3 precision binary         0.212\n4 f_meas    binary         0.333\n5 kap       binary         0.231\n6 sens      binary         0.767\n7 spec      binary         0.738\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_predictions() %>% \n  roc_curve(target_variable, .pred_children) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree <- extract_workflow(final_fit)\nfinal_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5740 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5740 2870 children (0.50000000 0.50000000)  \n     2) adr>=0.284338 1897  389 children (0.79493938 0.20506062)  \n       4) adr>=0.7947756 1158  162 children (0.86010363 0.13989637)  \n         8) adults< 1.283198 1031  121 children (0.88263822 0.11736178)  \n          16) adr>=1.920987 227    9 children (0.96035242 0.03964758) *\n          17) adr< 1.920987 804  112 children (0.86069652 0.13930348)  \n            34) hotel_Resort.Hotel< 0.2015155 447   40 children (0.91051454 0.08948546)  \n              68) arrival_date_month_July>=1.001495 84    0 children (1.00000000 0.00000000) *\n              69) arrival_date_month_July< 1.001495 363   40 children (0.88980716 0.11019284)  \n               138) adr>=1.056165 232   17 children (0.92672414 0.07327586)  \n                 276) arrival_date_month_May< 1.621817 199   10 children (0.94974874 0.05025126) *\n                 277) arrival_date_month_May>=1.621817 33    7 children (0.78787879 0.21212121)  \n                   554) stays_in_weekend_nights< 0.5718426 24    2 children (0.91666667 0.08333333) *\n                   555) stays_in_weekend_nights>=0.5718426 9    4 none (0.44444444 0.55555556) *\n               139) adr< 1.056165 131   23 children (0.82442748 0.17557252)  \n                 278) adr< 1.035544 119   18 children (0.84873950 0.15126050)  \n                   556) adr>=0.9905588 24    0 children (1.00000000 0.00000000) *\n                   557) adr< 0.9905588 95   18 children (0.81052632 0.18947368)  \n                    1114) adr< 0.9722464 84   11 children (0.86904762 0.13095238) *\n                    1115) adr>=0.9722464 11    4 none (0.36363636 0.63636364) *\n                 279) adr>=1.035544 12    5 children (0.58333333 0.41666667) *\n            35) hotel_Resort.Hotel>=0.2015155 357   72 children (0.79831933 0.20168067)  \n              70) stays_in_week_nights>=0.5693529 165   20 children (0.87878788 0.12121212) *\n              71) stays_in_week_nights< 0.5693529 192   52 children (0.72916667 0.27083333)  \n               142) required_car_parking_spaces_parking>=1.065734 67   10 children (0.85074627 0.14925373) *\n               143) required_car_parking_spaces_parking< 1.065734 125   42 children (0.66400000 0.33600000)  \n                 286) stays_in_weekend_nights>=-0.4695205 70   16 children (0.77142857 0.22857143)  \n                   572) adr< 1.125593 25    1 children (0.96000000 0.04000000) *\n                   573) adr>=1.125593 45   15 children (0.66666667 0.33333333)  \n                    1146) adr>=1.199957 37   10 children (0.72972973 0.27027027) *\n                    1147) adr< 1.199957 8    3 none (0.37500000 0.62500000) *\n                 287) stays_in_weekend_nights< -0.4695205 55   26 children (0.52727273 0.47272727)  \n                   574) total_of_special_requests< -0.4165399 20    6 children (0.70000000 0.30000000) *\n                   575) total_of_special_requests>=-0.4165399 35   15 none (0.42857143 0.57142857)  \n                    1150) adr< 1.225674 19    9 children (0.52631579 0.47368421) *\n                    1151) adr>=1.225674 16    5 none (0.31250000 0.68750000) *\n         9) adults>=1.283198 127   41 children (0.67716535 0.32283465)  \n          18) adr>=1.597176 62   10 children (0.83870968 0.16129032) *\n          19) adr< 1.597176 65   31 children (0.52307692 0.47692308)  \n            38) hotel_Resort.Hotel>=0.2015155 21    4 children (0.80952381 0.19047619) *\n            39) hotel_Resort.Hotel< 0.2015155 44   17 none (0.38636364 0.61363636)  \n              78) adr< 1.218269 29   14 none (0.48275862 0.51724138)  \n               156) stays_in_week_nights>=0.007439962 13    5 children (0.61538462 0.38461538) *\n               157) stays_in_week_nights< 0.007439962 16    6 none (0.37500000 0.62500000) *\n              79) adr>=1.218269 15    3 none (0.20000000 0.80000000) *\n\n...\nand 208 more lines.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n\nfinal_tree %>% \n  extract_fit_parsnip() %>% \n  vip()\n```\n\n::: {.cell-output-display}\n![](Level-5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n\n\n## save model\n\ncheck model size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)\nobj_size(final_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.54 MB\n```\n\n\n:::\n:::\n\n\nbundle and save model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bundle)\nmodel_bundle <- bundle(final_tree)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')\n```\n:::\n\n\n## make predication\n\nload model and unbundle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel <- unbundle(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 none       \n2 children   \n3 none       \n4 children   \n5 none       \n6 none       \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      612 2402\n  none          184 6802\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.741\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(target_variable)%>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  <fct>           <int>\n1 children          796\n2 none             9204\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(.pred_class) %>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  <fct>       <int>\n1 children     3014\n2 none         6986\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      612 2402\n  none          184 6802\n```\n\n\n:::\n:::\n\n\n# reference:\n\n\nhttps://www.tmwr.org\n\nhttps://www.youtube.com/watch?v=IzjmuGJgwKQ\n\nhttps://www.youtube.com/watch?v=_e0NFIaHY2c\n\n\n",
    "supporting": [
      "Level-5-classification-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}