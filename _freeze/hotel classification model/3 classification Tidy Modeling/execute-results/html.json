{
  "hash": "81724195501886d18d035d4185d0376c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Classification Model with recipe\"\nsubtitle: \"with hotel booking data\"\nauthor: \"Tony Duan\"\n\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n\nLevel 3 classification Tidy Modeling with 2 model and 1 recipe: \n\n* using Recipe to down sample and with prep(Recipe),jusic(train_data),bake(test_data) process.\n* add resamples(Monte Carlo Cross-Validation) to estimate the performance of our two models with `fit_resamples()`\n\ndecision tree model with rpart engine(tree_spec)\n\nKNN model with knn engine(knn_spec)\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nhotels <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays <- hotels %>%\n  filter(is_canceled == 0) %>%\n  mutate(\n    children = case_when(\n      children + babies > 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces > 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %>%\n  select(-is_canceled, -reservation_status, -babies)\n```\n:::\n\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\nhotels_df <- hotel_stays %>%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %>%\n  mutate_if(is.character, factor) %>% rename(target_variable=children) %>% sample_n(50000)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 35000    10\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5000   10\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000    10\n```\n\n\n:::\n:::\n\n\n# modeling\n\n## recipe\n\nbecasue the target class is not balance so using downsample\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  step_downsample(target_variable) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric())\n```\n:::\n\n\n![](images/2-02.png)\n\n## prep the recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec=data_rec %>% prep()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec\n```\n:::\n\n\n## bake the train data with preded recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc <- bake(data_rec, new_data = data_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc2 <- bake(data_rec, new_data = NULL)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_juice <-juice(data_rec)\n```\n:::\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train_proc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 35000    23\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train_proc2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5594   23\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train_juice)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5594   23\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc %>%\n  count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 children         2797\n2 none            32203\n```\n\n\n:::\n:::\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_proc2 %>%\n  count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 children         2797\n2 none             2797\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain_juice %>%\n  count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 children         2797\n2 none             2797\n```\n\n\n:::\n:::\n\n\n## bake the test data with preded recipe\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_proc <- bake(data_rec, new_data = data_test)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_proc %>%count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 children          406\n2 none             4594\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_valid %>%count(target_variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  target_variable     n\n  <fct>           <int>\n1 children          821\n2 none             9179\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nvalid_proc <- bake(data_rec, new_data = data_valid)\n```\n:::\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)\n\n## model\n\ntree model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_spec <- decision_tree() %>%\n  set_engine(\"rpart\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\nKNN model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_spec <- nearest_neighbor() %>%\n  set_engine(\"kknn\") %>%\n  set_mode(\"classification\")\n```\n:::\n\n\n## trainning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_fit <- knn_spec %>%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2697533\nBest kernel: optimal\nBest k: 5\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_fit <- tree_spec %>%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nparsnip model object\n\nn= 5594 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 5594 2797 children (0.5000000 0.5000000)  \n  2) adr>=0.1701222 2087  506 children (0.7575467 0.2424533) *\n  3) adr< 0.1701222 3507 1216 none (0.3467351 0.6532649)  \n    6) total_of_special_requests>=0.6201001 735  316 children (0.5700680 0.4299320) *\n    7) total_of_special_requests< 0.6201001 2772  797 none (0.2875180 0.7124820) *\n```\n\n\n:::\n:::\n\n\n# model result\n\n## Evaluate\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits <- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits             id        \n   <list>             <chr>     \n 1 <split [5034/560]> Resample01\n 2 <split [5034/560]> Resample02\n 3 <split [5034/560]> Resample03\n 4 <split [5034/560]> Resample04\n 5 <split [5034/560]> Resample05\n 6 <split [5034/560]> Resample06\n 7 <split [5034/560]> Resample07\n 8 <split [5034/560]> Resample08\n 9 <split [5034/560]> Resample09\n10 <split [5034/560]> Resample10\n# ℹ 15 more rows\n```\n\n\n:::\n:::\n\n\nKKN:\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_res <- knn_spec %>% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %>%collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.721    25 0.00253 Preprocessor1_Model1\n2 roc_auc  binary     0.779    25 0.00289 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\nTree model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res <- tree_spec %>% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %>%collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.710    25 0.00285 Preprocessor1_Model1\n2 roc_auc  binary     0.727    25 0.00252 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknn_res %>%\n  unnest(.predictions) %>%\n  mutate(model = \"kknn\") %>%\n  bind_rows(tree_res %>%\n    unnest(.predictions) %>%\n    mutate(model = \"rpart\")) %>%\n  group_by(model) %>%\n  roc_curve(target_variable, .pred_children) %>%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )\n```\n\n::: {.cell-output-display}\n![](3-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n\n\n## save model\n\ncheck model size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)\nobj_size(tree_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1.13 MB\n```\n\n\n:::\n\n```{.r .cell-code}\nobj_size(knn_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1.08 MB\n```\n\n\n:::\n:::\n\n\nbundle and save model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bundle)\nmodel_bundle <- bundle(knn_fit)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')\n```\n:::\n\n\n## make predication\n\nload model and unbundle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel <- unbundle(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 none       \n2 none       \n3 children   \n4 children   \n5 none       \n6 none       \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      561 2401\n  none          260 6778\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.734\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(target_variable)%>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  <fct>           <int>\n1 children          821\n2 none             9179\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(.pred_class) %>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  <fct>       <int>\n1 children     2962\n2 none         7038\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      561 2401\n  none          260 6778\n```\n\n\n:::\n:::\n\n\n# reference:\n\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-02-11/readme.md\n\nhttps://juliasilge.com/blog/hotels-recipes/\n\nhttps://www.tidymodels.org/start/case-study/\n",
    "supporting": [
      "3-classification-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}