{
  "hash": "6c0d3e58de8dc886ce310146dbdaf570",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Level 4 classification Tidy Modeling\"\nsubtitle: \"with hotel booking data\"\nauthor: \"Tony Duan\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n\nLevel 4 classification Tidy Modeling with 1 tuning model and 1 recipe : \n\n* using Recipe to down sample.\n* add workflow with tuning , pick the best tunning set `finalize_model()` and last fit `last_fit()` on initial_split\n\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth) with `tune_grid()`\n\n\n\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nhotels <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays <- hotels %>%\n  filter(is_canceled == 0) %>%\n  mutate(\n    children = case_when(\n      children + babies > 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces > 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %>%\n  select(-is_canceled, -reservation_status, -babies)\n```\n:::\n\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\nall_hotels_df <- hotel_stays %>%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %>%\n  mutate_if(is.character, factor) %>% rename(target_variable=children) %>% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%>% sample_n(50000) \n\nhold_hotels_df <- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n#hotels_df=hotels_df %>% select(-rownum)\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 35000    11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5000   11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000    11\n```\n\n\n:::\n:::\n\n\n10 fold for tunning\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nfolds <- vfold_cv(data_train,v=10)\n```\n:::\n\n\n\n\n\n# modeling\n\n## recipe\n\nbecasue the target class is not balance so using downsample\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  step_rm(rownum) %>% \n  step_downsample(target_variable) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric())\n```\n:::\n\n\n\n## model\n\ntree model with cost_complexity and tree_depth to tune\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             <dbl>      <int>\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_grid %>% count(tree_depth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  tree_depth     n\n       <int> <int>\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5\n```\n\n\n:::\n:::\n\n\n## workflow \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_workflow =\n  workflow() %>% \n  add_model(tune_spec) %>% \n  add_recipe(data_rec)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncntl   <- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n```\n:::\n\n\n## training and tunning\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res = model_workflow %>% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl,\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits               id     .metrics          .notes           .predictions\n   <list>               <chr>  <list>            <list>           <list>      \n 1 <split [31500/3500]> Fold01 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 2 <split [31500/3500]> Fold02 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 3 <split [31500/3500]> Fold03 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 4 <split [31500/3500]> Fold04 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 5 <split [31500/3500]> Fold05 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 6 <split [31500/3500]> Fold06 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 7 <split [31500/3500]> Fold07 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 8 <split [31500/3500]> Fold08 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n 9 <split [31500/3500]> Fold09 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n10 <split [31500/3500]> Fold10 <tibble [50 × 6]> <tibble [0 × 3]> <tibble>    \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>% \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>     \n 1    0.0000000001          1 accuracy binary     0.765    10 0.00851 Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 3    0.0000000178          1 accuracy binary     0.765    10 0.00851 Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 5    0.00000316            1 accuracy binary     0.765    10 0.00851 Preproces…\n 6    0.00000316            1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 7    0.000562              1 accuracy binary     0.765    10 0.00851 Preproces…\n 8    0.000562              1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 9    0.1                   1 accuracy binary     0.765    10 0.00851 Preproces…\n10    0.1                   1 roc_auc  binary     0.704    10 0.00310 Preproces…\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  collect_metrics() %>%\n  mutate(tree_depth = factor(tree_depth)) %>%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n```\n\n::: {.cell-output-display}\n![](Level-4-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  show_best(\"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>      \n1    0.000562             11 accuracy binary     0.767    10 0.00661 Preprocess…\n2    0.0000000001          1 accuracy binary     0.765    10 0.00851 Preprocess…\n3    0.0000000178          1 accuracy binary     0.765    10 0.00851 Preprocess…\n4    0.00000316            1 accuracy binary     0.765    10 0.00851 Preprocess…\n5    0.000562              1 accuracy binary     0.765    10 0.00851 Preprocess…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_tree <- tree_res %>%\n  select_best(\"accuracy\")\n\nbest_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            <dbl>      <int> <chr>                \n1        0.000562         11 Preprocessor1_Model19\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <- \n  model_workflow %>% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 0.000562341325190349\n  tree_depth = 11\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n\n## last fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- \n  final_wf %>%\n  last_fit(data_split) \n```\n:::\n\n\n\n# model result\n\n## Evaluate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.762 Preprocessor1_Model1\n2 roc_auc  binary         0.800 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_predictions() %>% \n  roc_curve(target_variable, .pred_children) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](Level-4-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree <- extract_workflow(final_fit)\nfinal_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5726 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5726 2863 children (0.50000000 0.50000000)  \n     2) adr>=0.1697088 2113  477 children (0.77425461 0.22574539)  \n       4) adr>=0.8986797 1033  128 children (0.87608906 0.12391094)  \n         8) adults< 1.261466 880   77 children (0.91250000 0.08750000) *\n         9) adults>=1.261466 153   51 children (0.66666667 0.33333333)  \n          18) adr>=1.784047 58    5 children (0.91379310 0.08620690) *\n          19) adr< 1.784047 95   46 children (0.51578947 0.48421053)  \n            38) total_of_special_requests< 0.648806 76   32 children (0.57894737 0.42105263)  \n              76) adr>=1.118784 55   19 children (0.65454545 0.34545455) *\n              77) adr< 1.118784 21    8 none (0.38095238 0.61904762)  \n               154) adr< 1.021625 11    4 children (0.63636364 0.36363636) *\n               155) adr>=1.021625 10    1 none (0.10000000 0.90000000) *\n            39) total_of_special_requests>=0.648806 19    5 none (0.26315789 0.73684211) *\n       5) adr< 0.8986797 1080  349 children (0.67685185 0.32314815)  \n        10) adults< 1.261466 979  276 children (0.71807967 0.28192033)  \n          20) adults>=-0.7987603 916  233 children (0.74563319 0.25436681)  \n            40) meal_SC< 1.874245 876  210 children (0.76027397 0.23972603)  \n              80) total_of_special_requests>=0.648806 311   48 children (0.84565916 0.15434084) *\n              81) total_of_special_requests< 0.648806 565  162 children (0.71327434 0.28672566)  \n               162) arrival_date_month_September< 1.714139 508  136 children (0.73228346 0.26771654) *\n               163) arrival_date_month_September>=1.714139 57   26 children (0.54385965 0.45614035)  \n                 326) stays_in_weekend_nights>=0.527525 16    4 children (0.75000000 0.25000000) *\n                 327) stays_in_weekend_nights< 0.527525 41   19 none (0.46341463 0.53658537)  \n                   654) total_of_special_requests>=-0.4298999 24   10 children (0.58333333 0.41666667)  \n                    1308) adr>=0.3102977 17    4 children (0.76470588 0.23529412) *\n                    1309) adr< 0.3102977 7    1 none (0.14285714 0.85714286) *\n                   655) total_of_special_requests< -0.4298999 17    5 none (0.29411765 0.70588235) *\n            41) meal_SC>=1.874245 40   17 none (0.42500000 0.57500000)  \n              82) adr>=0.4268564 24   10 children (0.58333333 0.41666667)  \n               164) adr< 0.5513986 16    3 children (0.81250000 0.18750000) *\n               165) adr>=0.5513986 8    1 none (0.12500000 0.87500000) *\n              83) adr< 0.4268564 16    3 none (0.18750000 0.81250000) *\n          21) adults< -0.7987603 63   20 none (0.31746032 0.68253968)  \n            42) stays_in_week_nights>=-0.02165468 13    5 children (0.61538462 0.38461538) *\n            43) stays_in_week_nights< -0.02165468 50   12 none (0.24000000 0.76000000) *\n        11) adults>=1.261466 101   28 none (0.27722772 0.72277228)  \n          22) hotel_Resort.Hotel>=0.2012867 32   10 children (0.68750000 0.31250000) *\n          23) hotel_Resort.Hotel< 0.2012867 69    6 none (0.08695652 0.91304348) *\n     3) adr< 0.1697088 3613 1227 none (0.33960697 0.66039303)  \n       6) total_of_special_requests>=0.648806 713  282 children (0.60448808 0.39551192)  \n        12) meal_SC< 1.874245 658  238 children (0.63829787 0.36170213)  \n          24) adr>=-0.4024668 331   92 children (0.72205438 0.27794562)  \n            48) adults< 1.261466 322   84 children (0.73913043 0.26086957)  \n              96) arrival_date_month_July>=1.014446 63    7 children (0.88888889 0.11111111) *\n              97) arrival_date_month_July< 1.014446 259   77 children (0.70270270 0.29729730)  \n\n...\nand 86 more lines.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n\nfinal_tree %>% \n  extract_fit_parsnip() %>% \n  vip()\n```\n\n::: {.cell-output-display}\n![](Level-4-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\n## save model\n\ncheck model size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)\nobj_size(final_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.50 MB\n```\n\n\n:::\n:::\n\n\nbundle and save model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bundle)\nmodel_bundle <- bundle(final_tree)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')\n```\n:::\n\n\n## make predication\n\nload model and unbundle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel <- unbundle(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 none       \n2 none       \n3 none       \n4 children   \n5 none       \n6 children   \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      605 2196\n  none          200 6999\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.760\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(target_variable)%>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  <fct>           <int>\n1 children          805\n2 none             9195\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(.pred_class) %>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  <fct>       <int>\n1 children     2801\n2 none         7199\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      605 2196\n  none          200 6999\n```\n\n\n:::\n:::\n\n\n# reference:\n\nhttps://www.tidymodels.org/start/tuning/\n\nhttps://www.tmwr.org\n",
    "supporting": [
      "Level-4-classification-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}