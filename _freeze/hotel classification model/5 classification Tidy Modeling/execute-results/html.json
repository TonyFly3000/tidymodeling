{
  "hash": "8d8fc110fc4b3932b0e13091b5415441",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Classification Model with recipe,workflow,fast tuning\"\nsubtitle: \"with hotel booking data\"\nauthor: \"Tony Duan\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n\nLevel 5 classification Tidy Modeling with 1 tuning model and 1 recipe : \n\n* using Recipe to down sample.\n* add resamples to estimate the performance of our two models\n* add workflow with tuning\n* add quick tuning `tune_race_anova()`\n\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\n\n\n# load package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Load Pacakges & Set Options\"}\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme\n```\n:::\n\n\n# data preparation\n\n## read data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nhotels <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays <- hotels %>%\n  filter(is_canceled == 0) %>%\n  mutate(\n    children = case_when(\n      children + babies > 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces > 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %>%\n  select(-is_canceled, -reservation_status, -babies)\n```\n:::\n\n\n\n## data split\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"Prepare & Split Data\"}\nall_hotels_df <- hotel_stays %>%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %>%\n  mutate_if(is.character, factor) %>% rename(target_variable=children) %>% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%>% sample_n(50000) \n\nhold_hotels_df <- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n#hotels_df=hotels_df %>% select(-rownum)\n#all_hotels_df=all_hotels_df %>% select(-rownum)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\ndata_split <- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 35000    11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5000   11\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(data_valid)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000    11\n```\n\n\n:::\n:::\n\n\n10 fold for tunning\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nfolds <- vfold_cv(data_train)\n```\n:::\n\n\n\n\n\n# modeling\n\n## recipe\n\nbecasue the target class is not balance so using downsample\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_rec <- recipe(target_variable ~ ., data = data_train) %>%\n  step_rm(rownum) %>% \n  step_downsample(target_variable) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>%\n  step_zv(all_numeric()) %>%\n  step_normalize(all_numeric())\n```\n:::\n\n\n\n## model\n\ndecision tree model with cost_complexity and tree_depth to tune\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"classification\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec |> \n  extract_parameter_set_dials()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnum_leaves()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of Leaves (quantitative)\nRange: [5, 100]\n```\n\n\n:::\n:::\n\n\ntunning grid\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune <- \n  tune_spec |> \n  extract_parameter_set_dials() |> \n  grid_latin_hypercube(size = 200)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune |> glimpse(width = 200)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 200\nColumns: 2\n$ cost_complexity <dbl> 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      <int> 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_tune %>% count(tree_depth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 2\n   tree_depth     n\n        <int> <int>\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7\n```\n\n\n:::\n:::\n\n\n## workflow \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(finetune)\ncntl <- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_workflow =\n  workflow() %>% \n  add_model(tune_spec) %>% \n  add_recipe(data_rec)\n```\n:::\n\n\n\n\n\n## training and tunning\n\nusing tune_race_anova() instead of tune_grid()\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %>% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(tree_res)\n```\n\n::: {.cell-output-display}\n![](5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_race(tree_res)\n```\n\n::: {.cell-output-display}\n![](5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>% \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 220 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>     \n 1   0.000000126            7 accuracy binary     0.754    10 0.00567 Preproces…\n 2   0.000000126            7 roc_auc  binary     0.806    10 0.00583 Preproces…\n 3   0.000104              10 accuracy binary     0.762    10 0.00753 Preproces…\n 4   0.000104              10 roc_auc  binary     0.815    10 0.00545 Preproces…\n 5   0.000369               6 accuracy binary     0.745    10 0.00758 Preproces…\n 6   0.000369               6 roc_auc  binary     0.804    10 0.00577 Preproces…\n 7   0.00000000437         11 accuracy binary     0.756    10 0.00610 Preproces…\n 8   0.00000000437         11 roc_auc  binary     0.817    10 0.00538 Preproces…\n 9   0.000000134           15 accuracy binary     0.751    10 0.00305 Preproces…\n10   0.000000134           15 roc_auc  binary     0.815    10 0.00499 Preproces…\n# ℹ 210 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  collect_metrics() %>%\n  mutate(tree_depth = factor(tree_depth)) %>%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n```\n\n::: {.cell-output-display}\n![](5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n  show_best()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1        4.37e- 9         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n2        4.32e- 5         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n3        1.09e-10         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n4        1.45e- 9         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n5        7.52e- 8         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_tree <- tree_res %>%\n  select_best()\n\nbest_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            <dbl>      <int> <chr>                 \n1   0.00000000437         11 Preprocessor1_Model008\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <- \n  model_workflow %>% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 4.37354062320283e-09\n  tree_depth = 11\n\nComputational engine: rpart \n```\n\n\n:::\n:::\n\n\n## last fit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <- \n  final_wf %>%\n  last_fit(data_split) \n```\n:::\n\n\n\n# model result\n\n## Evaluate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.765 Preprocessor1_Model1\n2 roc_auc  binary         0.811 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nall_metrics <- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %>% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 accuracy  binary         0.765\n2 recall    binary         0.701\n3 precision binary         0.208\n4 f_meas    binary         0.320\n5 kap       binary         0.226\n6 sens      binary         0.701\n7 spec      binary         0.770\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit %>%\n  collect_predictions() %>% \n  roc_curve(target_variable, .pred_children) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree <- extract_workflow(final_fit)\nfinal_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5708 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5708 2854 children (0.500000000 0.500000000)  \n     2) adr>=0.1217285 2186  515 children (0.764409881 0.235590119)  \n       4) adr>=0.795892 1118  149 children (0.866726297 0.133273703)  \n         8) adults< 1.258765 992  110 children (0.889112903 0.110887097)  \n          16) hotel_Resort.Hotel< 0.2015753 489   29 children (0.940695297 0.059304703)  \n            32) arrival_date_month_September< 1.809553 451   20 children (0.955654102 0.044345898)  \n              64) adr>=1.310769 220    2 children (0.990909091 0.009090909) *\n              65) adr< 1.310769 231   18 children (0.922077922 0.077922078)  \n               130) adr< 1.227981 210   12 children (0.942857143 0.057142857) *\n               131) adr>=1.227981 21    6 children (0.714285714 0.285714286)  \n                 262) arrival_date_month_August>=0.8845497 10    0 children (1.000000000 0.000000000) *\n                 263) arrival_date_month_August< 0.8845497 11    5 none (0.454545455 0.545454545) *\n            33) arrival_date_month_September>=1.809553 38    9 children (0.763157895 0.236842105)  \n              66) total_of_special_requests>=-0.4338162 29    3 children (0.896551724 0.103448276) *\n              67) total_of_special_requests< -0.4338162 9    3 none (0.333333333 0.666666667) *\n          17) hotel_Resort.Hotel>=0.2015753 503   81 children (0.838966203 0.161033797)  \n            34) adr>=1.806699 184   13 children (0.929347826 0.070652174) *\n            35) adr< 1.806699 319   68 children (0.786833856 0.213166144)  \n              70) arrival_date_month_August< 0.8845497 189   28 children (0.851851852 0.148148148)  \n               140) arrival_date_month_July< 1.00281 69    4 children (0.942028986 0.057971014) *\n               141) arrival_date_month_July>=1.00281 120   24 children (0.800000000 0.200000000)  \n                 282) adr>=1.003498 96   16 children (0.833333333 0.166666667) *\n                 283) adr< 1.003498 24    8 children (0.666666667 0.333333333)  \n                   566) adr< 0.8813067 9    0 children (1.000000000 0.000000000) *\n                   567) adr>=0.8813067 15    7 none (0.466666667 0.533333333) *\n              71) arrival_date_month_August>=0.8845497 130   40 children (0.692307692 0.307692308)  \n               142) required_car_parking_spaces_parking>=1.047041 45    9 children (0.800000000 0.200000000) *\n               143) required_car_parking_spaces_parking< 1.047041 85   31 children (0.635294118 0.364705882)  \n                 286) stays_in_weekend_nights>=0.53872 54   16 children (0.703703704 0.296296296)  \n                   572) adr>=0.9636965 40    9 children (0.775000000 0.225000000)  \n                    1144) stays_in_week_nights< 1.62789 33    5 children (0.848484848 0.151515152) *\n                    1145) stays_in_week_nights>=1.62789 7    3 none (0.428571429 0.571428571) *\n                   573) adr< 0.9636965 14    7 children (0.500000000 0.500000000) *\n                 287) stays_in_weekend_nights< 0.53872 31   15 children (0.516129032 0.483870968)  \n                   574) adr>=1.17385 21    8 children (0.619047619 0.380952381)  \n                    1148) adr< 1.37684 7    0 children (1.000000000 0.000000000) *\n                    1149) adr>=1.37684 14    6 none (0.428571429 0.571428571) *\n                   575) adr< 1.17385 10    3 none (0.300000000 0.700000000) *\n         9) adults>=1.258765 126   39 children (0.690476190 0.309523810)  \n          18) adr>=1.235145 83   14 children (0.831325301 0.168674699)  \n            36) adr>=1.476344 62    7 children (0.887096774 0.112903226)  \n              72) arrival_date_month_August< 0.8845497 40    2 children (0.950000000 0.050000000) *\n              73) arrival_date_month_August>=0.8845497 22    5 children (0.772727273 0.227272727)  \n               146) stays_in_week_nights< 0.5290259 13    0 children (1.000000000 0.000000000) *\n               147) stays_in_week_nights>=0.5290259 9    4 none (0.444444444 0.555555556) *\n\n...\nand 200 more lines.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n\nfinal_tree %>% \n  extract_fit_parsnip() %>% \n  vip()\n```\n\n::: {.cell-output-display}\n![](5-classification-Tidy-Modeling_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n\n\n## save model\n\ncheck model size\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lobstr)\nobj_size(final_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.53 MB\n```\n\n\n:::\n:::\n\n\nbundle and save model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bundle)\nmodel_bundle <- bundle(final_tree)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')\n```\n:::\n\n\n## make predication\n\nload model and unbundle\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel <- unbundle(model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 1\n  .pred_class\n  <fct>      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none       \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      574 2043\n  none          247 7136\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.771\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(target_variable)%>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  <fct>           <int>\n1 children          821\n2 none             9179\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_prediction_data %>% group_by(.pred_class) %>% count()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  <fct>       <int>\n1 children     2617\n2 none         7383\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          Truth\nPrediction children none\n  children      574 2043\n  none          247 7136\n```\n\n\n:::\n:::\n\n\n# reference:\n\n\nhttps://www.tmwr.org\n\nhttps://www.youtube.com/watch?v=IzjmuGJgwKQ\n\nhttps://www.youtube.com/watch?v=_e0NFIaHY2c\n\n\n",
    "supporting": [
      "5-classification-Tidy-Modeling_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}