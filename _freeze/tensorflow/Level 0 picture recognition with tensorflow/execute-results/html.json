{
  "hash": "5b2710759ef7936b614eeefd2e1e410f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Level 0 picture recognition with tensorflow\"\nsubtitle: \"with mnist data in python\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n![](images/MnistExamplesModified.png)\n\n# install tensorflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Requires the latest pip\n#pip install --upgrade pip\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Requires the latest pip\n#pip install tensorflow\n```\n:::\n\n\ncheck tensorflow version\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport tensorflow as tf\n\nprint(tf.__version__)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n2.14.0\n```\n\n\n:::\n:::\n\n\n# load data\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n```\n:::\n\n\ntraining with 60000 picture with 28\\* 28 pixels\n\n\n::: {.cell}\n\n```{.python .cell-code}\nx_train.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(60000, 28, 28)\n```\n\n\n:::\n:::\n\n\ntraining with 60000 label\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_train.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(60000,)\n```\n\n\n:::\n:::\n\n\ntraining with 10000 picture with 28\\* 28 pixels\n\n\n::: {.cell}\n\n```{.python .cell-code}\nx_test.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(10000, 28, 28)\n```\n\n\n:::\n:::\n\n\ntraining with 10000 label\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_test.shape\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(10000,)\n```\n\n\n:::\n:::\n\n\nBoth train and test have 10 calss 0-9\n\n\n::: {.cell}\n\n```{.python .cell-code}\nset(y_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nset(y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport matplotlib.pyplot as plt\nplt.imshow(x_test[0], cmap='gray_r')\n```\n\n::: {.cell-output-display}\n![](Level-0-picture-recognition-with-tensorflow_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n# define model\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10)\n])\n```\n:::\n\n\n# loss function\n\n\n::: {.cell}\n\n```{.python .cell-code}\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n```\n:::\n\n\n# model.compile\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel.compile(optimizer='adam',\n              loss=loss_fn,\n              metrics=['accuracy'])\n```\n:::\n\n\n# training\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel.fit(x_train, y_train, epochs=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEpoch 1/3\n\n   1/1875 [..............................] - ETA: 3:17 - loss: 2.2614 - accuracy: 0.1875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 114/1875 [>.............................] - ETA: 0s - loss: 0.9227 - accuracy: 0.7272  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 230/1875 [==>...........................] - ETA: 0s - loss: 0.6773 - accuracy: 0.8004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 344/1875 [====>.........................] - ETA: 0s - loss: 0.5682 - accuracy: 0.8335\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 457/1875 [======>.......................] - ETA: 0s - loss: 0.5077 - accuracy: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 571/1875 [========>.....................] - ETA: 0s - loss: 0.4618 - accuracy: 0.8643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 677/1875 [=========>....................] - ETA: 0s - loss: 0.4313 - accuracy: 0.8733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 787/1875 [===========>..................] - ETA: 0s - loss: 0.4077 - accuracy: 0.8808\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 900/1875 [=============>................] - ETA: 0s - loss: 0.3868 - accuracy: 0.8865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1008/1875 [===============>..............] - ETA: 0s - loss: 0.3693 - accuracy: 0.8917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1122/1875 [================>.............] - ETA: 0s - loss: 0.3573 - accuracy: 0.8955\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1234/1875 [==================>...........] - ETA: 0s - loss: 0.3439 - accuracy: 0.8995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1344/1875 [====================>.........] - ETA: 0s - loss: 0.3320 - accuracy: 0.9032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1460/1875 [======================>.......] - ETA: 0s - loss: 0.3208 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1576/1875 [========================>.....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9090\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1691/1875 [==========================>...] - ETA: 0s - loss: 0.3034 - accuracy: 0.9111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1808/1875 [===========================>..] - ETA: 0s - loss: 0.2960 - accuracy: 0.9132\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 446us/step - loss: 0.2921 - accuracy: 0.9143\nEpoch 2/3\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.1286 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 108/1875 [>.............................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9482\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 224/1875 [==>...........................] - ETA: 0s - loss: 0.1543 - accuracy: 0.9533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 340/1875 [====>.........................] - ETA: 0s - loss: 0.1572 - accuracy: 0.9532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 454/1875 [======>.......................] - ETA: 0s - loss: 0.1568 - accuracy: 0.9528\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 571/1875 [========>.....................] - ETA: 0s - loss: 0.1565 - accuracy: 0.9532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 687/1875 [=========>....................] - ETA: 0s - loss: 0.1530 - accuracy: 0.9550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 804/1875 [===========>..................] - ETA: 0s - loss: 0.1518 - accuracy: 0.9548\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 920/1875 [=============>................] - ETA: 0s - loss: 0.1505 - accuracy: 0.9554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1036/1875 [===============>..............] - ETA: 0s - loss: 0.1494 - accuracy: 0.9557\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1153/1875 [=================>............] - ETA: 0s - loss: 0.1478 - accuracy: 0.9562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1269/1875 [===================>..........] - ETA: 0s - loss: 0.1468 - accuracy: 0.9561\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1374/1875 [====================>.........] - ETA: 0s - loss: 0.1455 - accuracy: 0.9566\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1490/1875 [======================>.......] - ETA: 0s - loss: 0.1441 - accuracy: 0.9572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1606/1875 [========================>.....] - ETA: 0s - loss: 0.1430 - accuracy: 0.9573\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1718/1875 [==========================>...] - ETA: 0s - loss: 0.1426 - accuracy: 0.9576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1834/1875 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 438us/step - loss: 0.1409 - accuracy: 0.9580\nEpoch 3/3\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.0575 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 110/1875 [>.............................] - ETA: 0s - loss: 0.1123 - accuracy: 0.9676\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 226/1875 [==>...........................] - ETA: 0s - loss: 0.1124 - accuracy: 0.9679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 341/1875 [====>.........................] - ETA: 0s - loss: 0.1082 - accuracy: 0.9697\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 458/1875 [======>.......................] - ETA: 0s - loss: 0.1075 - accuracy: 0.9698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 575/1875 [========>.....................] - ETA: 0s - loss: 0.1075 - accuracy: 0.9694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 692/1875 [==========>...................] - ETA: 0s - loss: 0.1083 - accuracy: 0.9682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 809/1875 [===========>..................] - ETA: 0s - loss: 0.1082 - accuracy: 0.9682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 927/1875 [=============>................] - ETA: 0s - loss: 0.1087 - accuracy: 0.9679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1044/1875 [===============>..............] - ETA: 0s - loss: 0.1068 - accuracy: 0.9685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1161/1875 [=================>............] - ETA: 0s - loss: 0.1068 - accuracy: 0.9683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1273/1875 [===================>..........] - ETA: 0s - loss: 0.1064 - accuracy: 0.9684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1390/1875 [=====================>........] - ETA: 0s - loss: 0.1058 - accuracy: 0.9685\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1507/1875 [=======================>......] - ETA: 0s - loss: 0.1061 - accuracy: 0.9683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1625/1875 [=========================>....] - ETA: 0s - loss: 0.1061 - accuracy: 0.9682\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1742/1875 [==========================>...] - ETA: 0s - loss: 0.1049 - accuracy: 0.9686\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1859/1875 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 433us/step - loss: 0.1054 - accuracy: 0.9684\n<keras.src.callbacks.History object at 0x2cddbb750>\n```\n\n\n:::\n:::\n\n\n# evaluation with test data\n\n\n::: {.cell}\n\n```{.python .cell-code}\nmodel.evaluate(x_test,  y_test, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n313/313 - 0s - loss: 0.0843 - accuracy: 0.9736 - 132ms/epoch - 423us/step\n[0.08427134901285172, 0.9735999703407288]\n```\n\n\n:::\n:::\n\n\n# prediction\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprobability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nprediction=probability_model(x_test[:5])\nprediction\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\narray([[1.2888552e-07, 3.4742172e-08, 3.2478234e-05, 1.3565016e-04,\n        1.5603248e-10, 6.0215291e-07, 4.3520782e-12, 9.9981922e-01,\n        6.6758423e-07, 1.1365682e-05],\n       [2.7735092e-07, 1.1897942e-04, 9.9971014e-01, 1.6855820e-04,\n        4.8963334e-13, 4.7602953e-07, 1.7148294e-07, 1.7899322e-12,\n        1.4407553e-06, 1.9515336e-11],\n       [1.7333437e-06, 9.9953842e-01, 1.5432567e-04, 1.1806583e-05,\n        1.2365077e-05, 1.3622796e-05, 7.4161840e-06, 2.2061566e-04,\n        3.9512357e-05, 2.7622320e-07],\n       [9.9942231e-01, 1.2345678e-06, 5.6421813e-05, 1.2866848e-05,\n        1.7669186e-07, 7.3332631e-05, 9.5162395e-05, 1.3687881e-04,\n        8.2384183e-08, 2.0167023e-04],\n       [6.5326589e-05, 1.3482369e-07, 1.5362046e-05, 1.7510808e-07,\n        9.7209162e-01, 2.1696158e-06, 4.2656764e-05, 2.1884246e-03,\n        1.8679078e-05, 2.5575468e-02]], dtype=float32)>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nnp.argmax(prediction, axis=1) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([7, 2, 1, 0, 4])\n```\n\n\n:::\n:::\n\n\n# resource:\n\nhttps://www.tensorflow.org/tutorials\n",
    "supporting": [
      "Level-0-picture-recognition-with-tensorflow_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}