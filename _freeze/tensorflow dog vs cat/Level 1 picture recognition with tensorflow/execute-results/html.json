{
  "hash": "cea6243d8a0c7038f87b0d964d59e939",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Level 0 Level 0 picture recognition with tensorflow\"\nsubtitle: \"with dog cat data\"\nexecute:\n  warning: false\n  error: false\nformat:\n  html:\n    toc: true\n    toc-location: right\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n---\n\n\n# dog cat data\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"keras\")\n#library(keras)\n#install_keras()\n#install_tensorflow() \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npackageVersion(\"keras\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '2.13.0'\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npackageVersion(\"tensorflow\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] '2.15.0.9000'\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tensorflow)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntf$constant(\"Hello TensorFlow!\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntf.Tensor(b'Hello TensorFlow!', shape=(), dtype=string)\n```\n\n\n:::\n:::\n\n\n# data\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keras)\nmnist <- dataset_mnist()\nx_train <- mnist$train$x\ny_train <- mnist$train$y\nx_test <- mnist$test$x\ny_test <- mnist$test$y\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# reshape\nx_train <- array_reshape(x_train, c(nrow(x_train), 784))\nx_test <- array_reshape(x_test, c(nrow(x_test), 784))\n# rescale\nx_train <- x_train / 255\nx_test <- x_test / 255\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ny_train <- to_categorical(y_train, 10)\ny_test <- to_categorical(y_test, 10)\n```\n:::\n\n\n\n\n# model\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential() \nmodel %>% \n  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>% \n  layer_dropout(rate = 0.4) %>% \n  layer_dense(units = 128, activation = 'relu') %>%\n  layer_dropout(rate = 0.3) %>%\n  layer_dense(units = 10, activation = 'softmax')\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_2 (Dense)                    (None, 256)                     200960      \n dropout_1 (Dropout)                (None, 256)                     0           \n dense_1 (Dense)                    (None, 128)                     32896       \n dropout (Dropout)                  (None, 128)                     0           \n dense (Dense)                      (None, 10)                      1290        \n================================================================================\nTotal params: 235146 (918.54 KB)\nTrainable params: 235146 (918.54 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_rmsprop(),\n  metrics = c('accuracy')\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhistory <- model %>% fit(\n  x_train, y_train, \n  epochs = 20, batch_size = 128, \n  validation_split = 0.2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEpoch 1/20\n375/375 - 1s - loss: 0.4425 - accuracy: 0.8670 - val_loss: 0.1643 - val_accuracy: 0.9517 - 853ms/epoch - 2ms/step\nEpoch 2/20\n375/375 - 1s - loss: 0.2071 - accuracy: 0.9390 - val_loss: 0.1226 - val_accuracy: 0.9651 - 671ms/epoch - 2ms/step\nEpoch 3/20\n375/375 - 1s - loss: 0.1565 - accuracy: 0.9542 - val_loss: 0.1016 - val_accuracy: 0.9709 - 664ms/epoch - 2ms/step\nEpoch 4/20\n375/375 - 1s - loss: 0.1324 - accuracy: 0.9602 - val_loss: 0.0935 - val_accuracy: 0.9725 - 655ms/epoch - 2ms/step\nEpoch 5/20\n375/375 - 1s - loss: 0.1188 - accuracy: 0.9649 - val_loss: 0.0886 - val_accuracy: 0.9742 - 660ms/epoch - 2ms/step\nEpoch 6/20\n375/375 - 1s - loss: 0.1068 - accuracy: 0.9685 - val_loss: 0.0872 - val_accuracy: 0.9760 - 648ms/epoch - 2ms/step\nEpoch 7/20\n375/375 - 1s - loss: 0.0947 - accuracy: 0.9719 - val_loss: 0.0857 - val_accuracy: 0.9758 - 657ms/epoch - 2ms/step\nEpoch 8/20\n375/375 - 1s - loss: 0.0871 - accuracy: 0.9737 - val_loss: 0.0829 - val_accuracy: 0.9778 - 650ms/epoch - 2ms/step\nEpoch 9/20\n375/375 - 1s - loss: 0.0818 - accuracy: 0.9754 - val_loss: 0.0814 - val_accuracy: 0.9783 - 667ms/epoch - 2ms/step\nEpoch 10/20\n375/375 - 1s - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0840 - val_accuracy: 0.9783 - 645ms/epoch - 2ms/step\nEpoch 11/20\n375/375 - 1s - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.0808 - val_accuracy: 0.9795 - 656ms/epoch - 2ms/step\nEpoch 12/20\n375/375 - 1s - loss: 0.0715 - accuracy: 0.9793 - val_loss: 0.0872 - val_accuracy: 0.9783 - 662ms/epoch - 2ms/step\nEpoch 13/20\n375/375 - 1s - loss: 0.0686 - accuracy: 0.9792 - val_loss: 0.0788 - val_accuracy: 0.9786 - 637ms/epoch - 2ms/step\nEpoch 14/20\n375/375 - 1s - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.0784 - val_accuracy: 0.9802 - 713ms/epoch - 2ms/step\nEpoch 15/20\n375/375 - 1s - loss: 0.0639 - accuracy: 0.9799 - val_loss: 0.0851 - val_accuracy: 0.9777 - 644ms/epoch - 2ms/step\nEpoch 16/20\n375/375 - 1s - loss: 0.0585 - accuracy: 0.9818 - val_loss: 0.0863 - val_accuracy: 0.9795 - 640ms/epoch - 2ms/step\nEpoch 17/20\n375/375 - 1s - loss: 0.0556 - accuracy: 0.9837 - val_loss: 0.0853 - val_accuracy: 0.9795 - 644ms/epoch - 2ms/step\nEpoch 18/20\n375/375 - 1s - loss: 0.0585 - accuracy: 0.9824 - val_loss: 0.0860 - val_accuracy: 0.9798 - 636ms/epoch - 2ms/step\nEpoch 19/20\n375/375 - 1s - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0878 - val_accuracy: 0.9792 - 644ms/epoch - 2ms/step\nEpoch 20/20\n375/375 - 1s - loss: 0.0543 - accuracy: 0.9840 - val_loss: 0.0888 - val_accuracy: 0.9803 - 638ms/epoch - 2ms/step\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(history)\n```\n\n::: {.cell-output-display}\n![](Level-1-picture-recognition-with-tensorflow_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel %>% evaluate(x_test, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n313/313 - 0s - loss: 0.0773 - accuracy: 0.9810 - 121ms/epoch - 388us/step\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      loss   accuracy \n0.07734758 0.98100001 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions <- predict(model, x_test)%>% k_argmax() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n313/313 - 0s - 130ms/epoch - 416us/step\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ntf.Tensor([7 2 1 0 4 1], shape=(6), dtype=int64)\n```\n\n\n:::\n:::\n\n\n\n\n# resource:\n\nhttps://cran.r-project.org/web/packages/keras/vignettes/\n\nhttps://tensorflow.rstudio.com/guides/keras/training_with_built_in_methods\n",
    "supporting": [
      "Level-1-picture-recognition-with-tensorflow_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}