---
title: "Level 5 classification Tidy Modeling"
subtitle: "with titanic data"
author: "Tony Duan"
execute:
  warning: false
  error: false
format:
  html:
    toc: true
    toc-location: right
    code-fold: show
    code-tools: true
    number-sections: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
---


Level 5 classification Tidy Modeling: 

* using Recipe.
* add resamples to estimate the performance of our two models
* add workflow with tunning
* add quick tunning

# load package

```{r}
#| code-summary: "Load Pacakges & Set Options"
library(themis)
library(tidyverse)      
library(tidymodels)     
library(palmerpenguins) # penguin dataset
library(gt)             # better tables
library(bonsai)         # tree-based models
library(conflicted)     # function conflicts
library(vetiver)
library(Microsoft365R)
library(pins)
tidymodels_prefer()     # handle conflicts
conflict_prefer("penguins", "palmerpenguins")
options(tidymodels.dark = TRUE) # dark mode
theme_set(theme_bw()) # set default ggplot2 theme
```

# data preparation

## read data
https://www.kaggle.com/competitions/titanic/data
```{r}
library(tidyverse)
train = read_csv("data/train.csv")

test=read_csv("data/test.csv")

```
## EDA

```{r}
glimpse(train)
```


```{r}
glimpse(test)
```


```{r}
train %>%
  count(Survived)
```


## plotting

```{r}
library(skimr)

skim(train)
```

## data split

```{r}
#| code-summary: "Prepare & Split Data"
train_df <- train %>%mutate(Survived=as.factor(Survived)) %>% select(-Name) %>% 

  mutate_if(is.character, factor) %>% rename(target_variable=Survived)
```

```{r}

set.seed(1234)

data_split <- initial_validation_split(data=train_df, prop = c(0.7,0.1))

data_train=training(data_split)  

data_test=testing(data_split)  

data_valid=validation(data_split)

```

```{r}
dim(data_train)
```

```{r}
dim(data_test)
```

```{r}
dim(data_valid)
```

# modeling

## recipe

```{r}
data_rec <- recipe(target_variable ~ ., data = data_train) %>%
  step_impute_knn(all_predictors(), neighbors = 5) %>%
  #step_downsample(target_variable) %>%
  #step_novel(Ticket) %>%
  step_rm(Ticket) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_numeric()) %>%
  step_normalize(all_numeric())
  
```


## model

tree model with cost_complexity and tree_depth to tune

```{r}
tune_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
```



```{r}
tune_spec
```
```{r}
tune_spec |> 
  extract_parameter_set_dials()
```

```{r}

num_leaves()
```

tunning grid
```{r}
grid_tune <- 
  tune_spec |> 
  extract_parameter_set_dials() |> 
  grid_latin_hypercube(size = 200)
```


```{r}
grid_tune |> glimpse(width = 200)
```
```{r}
grid_tune %>% count(tree_depth)
```

## workflow 

using control_race instead of control_grid
```{r}
library(finetune)
cntl <- control_race(save_pred     = TRUE,
                          save_workflow = TRUE)
```



```{r}
model_workflow =
  workflow() %>% 
  add_model(tune_spec) %>% 
  add_recipe(data_rec)
```


10 fold for tunning
```{r}
set.seed(234)
folds <- vfold_cv(data_train)
```

## training and tunning

using tune_race_anova() instead of tune_grid()
```{r}

library(finetune)
doParallel::registerDoParallel()

tree_res = model_workflow %>% 
  tune_race_anova(
    resamples = folds,
    grid = grid_tune,
    control   = cntl
    )
```


```{r}
autoplot(tree_res)
```

```{r}
plot_race(tree_res)
```

```{r}
tree_res %>% 
  collect_metrics()
```


```{r}
tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```


```{r}
tree_res %>%
  show_best()
```


```{r}
best_tree <- tree_res %>%
  select_best()

best_tree
```
```{r}
final_wf <- 
  model_workflow %>% 
  finalize_workflow(best_tree)


final_wf
```

## last fit

```{r}
final_fit <- 
  final_wf %>%
  last_fit(data_split) 
```


# model result

## Evaluate

```{r}
final_fit %>%
  collect_metrics()
```
Accuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)

Sensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)

Specificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)



```{r}
all_metrics <- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)

a=final_fit %>% collect_predictions()

all_metrics(a, truth = target_variable,estimate = .pred_class)
```


```{r}
final_fit %>%
  collect_predictions() %>% rename(.pred_T = 2, .pred_F = 3) %>% 
  roc_curve(target_variable, .pred_T) %>% 
  autoplot()
```

```{r}
final_tree <- extract_workflow(final_fit)
final_tree
```

```{r}
library(vip)

final_tree %>% 
  extract_fit_parsnip() %>% 
  vip()
```



## save model

check model size

```{r}
library(lobstr)
obj_size(final_tree)


```

bundle and save model

```{r}
library(bundle)
model_bundle <- bundle(final_tree)
```

```{r}
saveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')
```

## make predication

load model and unbundle

```{r}
model=readRDS('level 5 classification decision tree hotel model.RDS')

model <- unbundle(model)
```

```{r}
final_prediction=predict(model,data_valid)

head(final_prediction)
```

```{r}

final_prediction_data=cbind(data_valid,final_prediction)

conf_mat(final_prediction_data, truth = target_variable,
    estimate = .pred_class)

```
```{r}
accuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)
```

```{r}
final_prediction_data %>% group_by(target_variable)%>% count()
```

```{r}
final_prediction_data %>% group_by(.pred_class) %>% count()
```


```{r}
conf_mat(final_prediction_data, truth = target_variable,
    estimate = .pred_class)
```

# reference:


https://www.tmwr.org

https://www.youtube.com/watch?v=IzjmuGJgwKQ

https://www.youtube.com/watch?v=_e0NFIaHY2c


