---
title: "Level 6 classification Tidy Modeling"
subtitle: "with titanic data"
author: "Tony Duan"
execute:
  warning: false
  error: false
format:
  html:
    toc: true
    toc-location: right
    code-fold: show
    code-tools: true
    number-sections: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
---


Level 6 classification Tidy Modeling: 

* using Recipe.
* add resamples to estimate the performance of our two models
* add workflow with tuning
* add  tuning
* add workflow set and setting different tuning grid for different model

# load package

```{r}
#| code-summary: "Load Pacakges & Set Options"
library(themis)
library(tidyverse)      
library(tidymodels)     
library(palmerpenguins) # penguin dataset
library(gt)             # better tables
library(bonsai)         # tree-based models
library(conflicted)     # function conflicts
library(vetiver)
library(Microsoft365R)
library(pins)
tidymodels_prefer()     # handle conflicts
conflict_prefer("penguins", "palmerpenguins")
options(tidymodels.dark = TRUE) # dark mode
theme_set(theme_bw()) # set default ggplot2 theme
```

# data preparation

## read data
https://www.kaggle.com/competitions/titanic/data
```{r}
library(tidyverse)
train = read_csv("data/train.csv")

test=read_csv("data/test.csv")

```
## EDA

```{r}
glimpse(train)
```


```{r}
glimpse(test)
```


```{r}
train %>%
  count(Survived)
```


## plotting

```{r}
library(skimr)

skim(train)
```

## data split

```{r}
#| code-summary: "Prepare & Split Data"
train_df <- train %>%mutate(Survived=as.factor(Survived)) %>% select(-Name) %>% 

  mutate_if(is.character, factor) %>% rename(target_variable=Survived)
```

```{r}

set.seed(1234)

data_split <- initial_validation_split(data=train_df, prop = c(0.7,0.1))

data_train=training(data_split)  

data_test=testing(data_split)  

data_valid=validation(data_split)

```

```{r}
dim(data_train)
```

```{r}
dim(data_test)
```

```{r}
dim(data_valid)
```

# modeling

## recipe

```{r}
data_rec <- recipe(target_variable ~ ., data = data_train) %>%
  step_impute_knn(all_predictors(), neighbors = 5) %>%
  #step_downsample(target_variable) %>%
  #step_novel(Ticket) %>%
  step_rm(Ticket) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_zv(all_numeric()) %>%
  step_normalize(all_numeric())
  
```


## model

### decision tree model with cost_complexity and tree_depth to tune

```{r}
tune_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")
```

```{r}
tune_spec |> 
  extract_parameter_set_dials()
```

```{r}
decision_tree_tune_grid <- 
  tune_spec |> 
  extract_parameter_set_dials() |> 
  grid_latin_hypercube(size = 100)
```


### logistic glm model 
```{r}
glm_spec <-
  logistic_reg(penalty = 1) |>
  set_engine("glm")
```


### KNN model

```{r}
knn_spec <- nearest_neighbor() %>%
  set_engine("kknn") %>%
  set_mode("classification")

knn_spec
```




### XG Boost tree

```{r}
xgb_spec <- boost_tree(
  trees = 10,
  tree_depth = tune(), min_n = tune(),
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(),  mtry=tune(),       ## randomness
  learn_rate = tune()                          ## step size
) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

xgb_spec
```

xgb tunning grid

```{r}
xgb_tune_grid= grid_latin_hypercube(
  tree_depth(),learn_rate(),loss_reduction(),min_n(),
  sample_size=sample_prop(),finalize(mtry(),data_train),
  size=50)

head(xgb_tune_grid)
```



### lightGBM Boost tree

```{r}
lightgbm_spec <- boost_tree(
  trees = 10,
  tree_depth = tune(), min_n = tune(),
  loss_reduction = tune(),                     ## first three: model complexity
  sample_size = tune(),   mtry=tune(),     ## randomness
  learn_rate = tune()                          ## step size
) %>%
  set_engine("lightgbm") %>%
  set_mode("classification")

lightgbm_spec
```

```{r}
lightgbm_grid= grid_latin_hypercube(
  tree_depth(),learn_rate(),loss_reduction(),min_n(),
  sample_size=sample_prop(),finalize(mtry(),data_train),
  size=50)

head(lightgbm_grid)
```





## workflow set 


```{r}
library(finetune)
cntl   <- control_grid(save_pred     = TRUE,
                       save_workflow = TRUE)
```



using workflow set instead of workflow to combine many models.





```{r}
workflow_set <-
  workflow_set(
    preproc = list(data_rec),
    models = list(glm   = glm_spec,
                  tree  = tune_spec,
                  knn=knn_spec,
                  xgb=xgb_spec,
                  lightgbm=lightgbm_spec
                  )
  ) %>% option_add(grid = decision_tree_tune_grid, id = "recipe_tree")  %>% 
  option_add(grid = xgb_tune_grid, id = "recipe_xgb")  %>% 
  option_add(grid = lightgbm_grid, id = "recipe_lightgbm") 
```


```{r}
workflow_set %>%
  option_add_parameters()
```
10 fold for tunning
```{r}
set.seed(234)
folds <- vfold_cv(data_train)
```

## training and tunning


```{r}

library(finetune)
doParallel::registerDoParallel()

model_set_res = workflow_set  %>% 
  workflow_map(
              grid = 20,
               resamples = folds,
               control = cntl
  )
```


```{r}
rank_results(model_set_res,
             rank_metric = "roc_auc",
             select_best = TRUE)  %>% 
  gt()
```

```{r}
model_set_res |> autoplot()
```

```{r}
model_set_res |> autoplot( id= 'recipe_xgb')
```

select best model:logistic glm model 
```{r}
best_model_id <- "recipe_xgb"
```

select best parameters
```{r}
best_fit <-
  model_set_res |>
  extract_workflow_set_result(best_model_id) |>
  select_best(metric = "accuracy")
```

```{r}
# create workflow for best model
final_workflow <-
  model_set_res |>
  extract_workflow(best_model_id) |>
  finalize_workflow(best_fit)
```





## last fit

```{r}
final_fit <-
  final_workflow |>
  last_fit(data_split)
```


# model result

## Evaluate

```{r}
final_fit %>%
  collect_metrics()
```
Accuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)

Sensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)

Specificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)



```{r}
all_metrics <- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)

a=final_fit %>% collect_predictions()

all_metrics(a, truth = target_variable,estimate = .pred_class)
```


```{r}
final_fit %>%
  collect_predictions() %>% rename(.pred_T = 2, .pred_F = 3) %>% 
  roc_curve(target_variable, .pred_T) %>% 
  autoplot()
```

```{r}
final_tree <- extract_workflow(final_fit)
final_tree
```

```{r}
library(vip)

final_tree %>% 
  extract_fit_parsnip() %>% 
  vip()
```



## save model

check model size

```{r}
library(lobstr)
obj_size(final_tree)


```

bundle and save model

```{r}
library(bundle)
model_bundle <- bundle(final_tree)
```

```{r}
saveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')
```

## make predication

load model and unbundle

```{r}
model=readRDS('level 6 classification decision tree hotel model.RDS')

model <- unbundle(model)
```

```{r}
final_prediction=predict(model,data_valid)

head(final_prediction)
```

```{r}

final_prediction_data=cbind(data_valid,final_prediction)

conf_mat(final_prediction_data, truth = target_variable,
    estimate = .pred_class)

```
```{r}
accuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)
```

```{r}
final_prediction_data %>% group_by(target_variable)%>% count()
```

```{r}
final_prediction_data %>% group_by(.pred_class) %>% count()
```


```{r}
conf_mat(final_prediction_data, truth = target_variable,
    estimate = .pred_class)
```

# reference:


https://www.tmwr.org

https://www.youtube.com/watch?v=IzjmuGJgwKQ

https://www.youtube.com/watch?v=_e0NFIaHY2c


