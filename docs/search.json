[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "R is based heavily on the S language, first developed in the 1960s and 1970s by researchers at Bell Laboratories in New Jersey\nR’s developers—Ross Ihaka and Robert Gentleman at the Univer- sity of Auckland in New Zealand—released it in the early 1990s under the\nGNU public license. (The software was named for Ross and Robert’s shared first initial.)\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "",
    "text": "using Recipe.",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#measurement",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#measurement",
    "title": "Level 0 Regression Tidy Modeling",
    "section": "",
    "text": "Mean absolute error (MAE)\n\nThe MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. The equation is given in the library references. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n\nRoot Mean Squared Error (RMSE)\n\n\nThe RMSE is a quadratic scoring rule which measures the average magnitude of the error. The equation for the RMSE is given in both of the references. Expressing the formula in words, the difference between forecast and corresponding observed values are each squared and then averaged over the sample. Finally, the square root of the average is taken. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\nBoth the MAE and RMSE can range from 0 to ∞. They are negatively-oriented scores: Lower values are better.",
    "crumbs": [
      "house price regression model",
      "Level 0 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html",
    "title": "Level 2 classification Tidy Modeling",
    "section": "",
    "text": "Level 2 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#read-data",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#eda",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#plotting",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#data-split",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name,-Ticket) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 10",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#prep-the-recipe",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 623 128\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#model",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#model",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#trainning",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.481203\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n      4) Age&gt;=-1.588093 389  70 0 (0.82005141 0.17994859) *\n      5) Age&lt; -1.588093 17   3 1 (0.17647059 0.82352941) *\n    3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked_S&gt;=-0.4947473 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked_S&lt; -0.4947473 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#evaluate",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,test_proc) \n\npredictions_probability &lt;- predict(tree_fit,test_proc,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   0   1\n         0 108  22\n         1   5  44\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 kap      binary         0.658\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.956\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.667\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 sens     binary         0.956\n3 spec     binary         0.667\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.849\n 2 kap                  binary         0.658\n 3 sens                 binary         0.956\n 4 spec                 binary         0.667\n 5 ppv                  binary         0.831\n 6 npv                  binary         0.898\n 7 mcc                  binary         0.673\n 8 j_index              binary         0.622\n 9 bal_accuracy         binary         0.811\n10 detection_prevalence binary         0.726\n11 precision            binary         0.831\n12 recall               binary         0.956\n13 f_meas               binary         0.889\n\n\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_0)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.862\n\n\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_0) %&gt;% \n  autoplot()",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#save-model",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n847.89 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 2 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/Level 2 classification Tidy Modeling.html#make-predication",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.764\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              62\n2 1              27\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19",
    "crumbs": [
      "titanic classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html",
    "title": "Level 1 classification Tidy Modeling",
    "section": "",
    "text": "Level 1 classification Tidy Modeling: using basic Tidymodel package.",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#read-data",
    "title": "Level 1 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#eda",
    "title": "Level 1 classification Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#plotting",
    "title": "Level 1 classification Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#data-split",
    "title": "Level 1 classification Tidy Modeling",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name,-Ticket) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 10",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#recipe",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#model",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#model",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#trainning",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.3 trainning",
    "text": "3.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.3684211\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex=male 406  84 0 (0.79310345 0.20689655)  \n      4) Cabin=A14,A19,A32,A5,B102,B19,B22,B30,B37,B38,B51 B53 B55,B71,B94,C118,C123,C124,C128,C23 C25 C27,C30,C46,C65,C68,C82,C83,C86,C87,C95,D,D26,D30,D48,E38,E58,E63,E67,F G63,F G73,F38,T 288  36 0 (0.87500000 0.12500000) *\n      5) Cabin=A20,A23,A31,A34,B20,B41,B49,B50,B96 B98,C104,C106,C126,C148,C22 C26,C47,C52,C70,C92,C93,D10 D12,D33,D35,D49,D56,E10,E12,E121,E24,E25,E50,F2,F4 118  48 0 (0.59322034 0.40677966)  \n       10) Pclass&gt;=1.5 88  20 0 (0.77272727 0.22727273)  \n         20) Age&gt;=6.5 75  10 0 (0.86666667 0.13333333) *\n         21) Age&lt; 6.5 13   3 1 (0.23076923 0.76923077) *\n       11) Pclass&lt; 1.5 30   2 1 (0.06666667 0.93333333) *\n    3) Sex=female 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=2.5 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=24.80835 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; 24.80835 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked=S 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=17.35 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; 17.35 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; 11.375 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=11.375 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked=C,Q 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 2.5 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#evaluate",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   0   1\n         0 105  19\n         1   8  47\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 kap      binary         0.664\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.929\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.712\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 sens     binary         0.929\n3 spec     binary         0.712\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.849\n 2 kap                  binary         0.664\n 3 sens                 binary         0.929\n 4 spec                 binary         0.712\n 5 ppv                  binary         0.847\n 6 npv                  binary         0.855\n 7 mcc                  binary         0.671\n 8 j_index              binary         0.641\n 9 bal_accuracy         binary         0.821\n10 detection_prevalence binary         0.693\n11 precision            binary         0.847\n12 recall               binary         0.929\n13 f_meas               binary         0.886\n\n\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_0)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.881\n\n\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_0) %&gt;% \n  autoplot()",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#save-model",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n130.17 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 1 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/Level 1 classification Tidy Modeling.html#make-predication",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0",
    "crumbs": [
      "titanic classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html",
    "title": "Level 3 classification Tidy Modeling",
    "section": "",
    "text": "Level 3 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#read-data",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#eda",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#plotting",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#data-split",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#prep-the-recipe",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 623 128\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 113\n2 1                  66\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#model",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#model",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#trainning",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2536116\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n      4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237) *\n      5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n    3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#evaluate",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits           id        \n   &lt;list&gt;           &lt;chr&gt;     \n 1 &lt;split [560/63]&gt; Resample01\n 2 &lt;split [560/63]&gt; Resample02\n 3 &lt;split [560/63]&gt; Resample03\n 4 &lt;split [560/63]&gt; Resample04\n 5 &lt;split [560/63]&gt; Resample05\n 6 &lt;split [560/63]&gt; Resample06\n 7 &lt;split [560/63]&gt; Resample07\n 8 &lt;split [560/63]&gt; Resample08\n 9 &lt;split [560/63]&gt; Resample09\n10 &lt;split [560/63]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.726    25 0.0118  Preprocessor1_Model1\n2 roc_auc  binary     0.773    25 0.00998 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.788    25  0.0115 Preprocessor1_Model1\n2 roc_auc  binary     0.815    25  0.0117 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_0) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#save-model",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n847.94 kB\n\n\nCode\nobj_size(knn_fit)\n\n\n814.76 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 3 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/Level 3 classification Tidy Modeling.html#make-predication",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 0          \n3 1          \n4 0          \n5 1          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.730\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              53\n2 1              36\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22",
    "crumbs": [
      "titanic classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 0 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 0 classification Tidy Modeling.html",
    "title": "Level 0 classification Tidy Modeling",
    "section": "",
    "text": "data download form kaggle\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\nData have 891 record and 12 variable\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;% group_by(Survived) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   Survived [2]\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342\n\n\n\n\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nSpecificity=TN/(TN+FP)\n\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)",
    "crumbs": [
      "titanic classification model",
      "Level 0 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 0 classification Tidy Modeling.html#measurement",
    "href": "titanic classification model/Level 0 classification Tidy Modeling.html#measurement",
    "title": "Level 0 classification Tidy Modeling",
    "section": "",
    "text": "Accuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nSpecificity=TN/(TN+FP)\n\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)",
    "crumbs": [
      "titanic classification model",
      "Level 0 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html",
    "title": "Level 2 classification Tidy Modeling",
    "section": "",
    "text": "Level 2 classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#read-data",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#read-data",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#plotting-and-eda",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#plotting-and-eda",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.2 plotting and EDA",
    "text": "2.2 plotting and EDA\n\n\nCode\nhotel_stays %&gt;%\n  count(children)\n\n\n# A tibble: 2 × 2\n  children     n\n  &lt;chr&gt;    &lt;int&gt;\n1 children  6073\n2 none     69093\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(hotel_stays)\n\n\n\nData summary\n\n\nName\nhotel_stays\n\n\nNumber of rows\n75166\n\n\nNumber of columns\n29\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\ncharacter\n14\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2015-07-01\n2017-09-14\n2016-09-01\n805\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nchildren\n0\n1\n4\n8\n0\n2\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n166\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n7\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n9\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n315\n0\n\n\ncompany\n0\n1\n1\n4\n0\n332\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nrequired_car_parking_spaces\n0\n1\n4\n7\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlead_time\n0\n1\n79.98\n91.11\n0.00\n9.0\n45.0\n124\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.15\n0.70\n2015.00\n2016.0\n2016.0\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.08\n13.90\n1.00\n16.0\n28.0\n38\n53\n▆▇▇▇▆\n\n\narrival_date_day_of_month\n0\n1\n15.84\n8.78\n1.00\n8.0\n16.0\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n0.99\n0.00\n0.0\n1.0\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.46\n1.92\n0.00\n1.0\n2.0\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.83\n0.51\n0.00\n2.0\n2.0\n2\n4\n▁▂▇▁▁\n\n\nis_repeated_guest\n0\n1\n0.04\n0.20\n0.00\n0.0\n0.0\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.02\n0.27\n0.00\n0.0\n0.0\n0\n13\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.20\n1.81\n0.00\n0.0\n0.0\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.29\n0.74\n0.00\n0.0\n0.0\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n1.59\n14.78\n0.00\n0.0\n0.0\n0\n379\n▇▁▁▁▁\n\n\nadr\n0\n1\n99.99\n49.21\n-6.38\n67.5\n92.5\n125\n510\n▇▆▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.71\n0.83\n0.00\n0.0\n1.0\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nCode\nhotel_stays %&gt;%\n  mutate(arrival_date_month = factor(arrival_date_month,\n    levels = month.name\n  )) %&gt;%\n  count(hotel, arrival_date_month, children) %&gt;%\n  group_by(hotel, children) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  ggplot(aes(arrival_date_month, proportion, fill = children)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  facet_wrap(~hotel, nrow = 2) +\n  labs(\n    x = NULL,\n    y = \"Proportion of hotel stays\",\n    fill = NULL\n  )",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#data-split",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#data-split",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children)%&gt;% sample_n(50000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    10",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#recipe",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#prep-the-recipe",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 35000    23\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 5716   23\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 5716   23\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2858\n2 none            32142\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2858\n2 none             2858\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2858\n2 none             2858",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#model",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#model",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#trainning",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#trainning",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2863891\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5716 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 5716 2858 children (0.5000000 0.5000000)  \n  2) adr&gt;=0.2854187 1901  395 children (0.7922146 0.2077854) *\n  3) adr&lt; 0.2854187 3815 1352 none (0.3543906 0.6456094)  \n    6) total_of_special_requests&gt;=0.6562274 795  335 children (0.5786164 0.4213836) *\n    7) total_of_special_requests&lt; 0.6562274 3020  892 none (0.2953642 0.7046358) *",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#evaluate",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#evaluate",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,test_proc) \n\npredictions_probability &lt;- predict(tree_fit,test_proc,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      277 1132\n  none          117 3474\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.750\n2 kap      binary         0.210\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.750\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.703\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.754\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.750\n2 sens     binary         0.703\n3 spec     binary         0.754\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.750\n 2 kap                  binary         0.210\n 3 sens                 binary         0.703\n 4 spec                 binary         0.754\n 5 ppv                  binary         0.197\n 6 npv                  binary         0.967\n 7 mcc                  binary         0.274\n 8 j_index              binary         0.457\n 9 bal_accuracy         binary         0.729\n10 detection_prevalence binary         0.282\n11 precision            binary         0.197\n12 recall               binary         0.703\n13 f_meas               binary         0.307\n\n\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_children)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.751\n\n\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_children) %&gt;% \n  autoplot()",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#save-model",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#save-model",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n1.15 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification tree hotel model.RDS')",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 2 classification Tidy Modeling.html#make-predication",
    "href": "hote classification model/Level 2 classification Tidy Modeling.html#make-predication",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 children   \n5 children   \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      534 2182\n  none          254 7030\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.756\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          788\n2 none             9212\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2716\n2 none         7284\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      534 2182\n  none          254 7030",
    "crumbs": [
      "hote classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html",
    "title": "Level 1 classification Tidy Modeling",
    "section": "",
    "text": "Level 1 classification Tidy Modeling with 2 model and no recipe:\n*using basic Tidymodel package.\nNo recipe\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#read-data",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#read-data",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.1 read data",
    "text": "3.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#plotting",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#plotting",
    "title": "Level 1 classification Tidy Modeling",
    "section": "2.2 plotting",
    "text": "2.2 plotting\n\n\nCode\nhotel_stays %&gt;%\n  mutate(arrival_date_month = factor(arrival_date_month,\n    levels = month.name\n  )) %&gt;%\n  count(hotel, arrival_date_month, children) %&gt;%\n  group_by(hotel, children) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  ggplot(aes(arrival_date_month, proportion, fill = children)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  facet_wrap(~hotel, nrow = 2) +\n  labs(\n    x = NULL,\n    y = \"Proportion of hotel stays\",\n    fill = NULL\n  )",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#data-split",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#data-split",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.2 data split",
    "text": "3.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(10000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 7000   10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 1000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 2000   10",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#recipe",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#recipe",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.1 recipe",
    "text": "4.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#model",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#model",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.2 model",
    "text": "4.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#trainning",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#trainning",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.3 trainning",
    "text": "4.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.08357143\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 7000 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7000 554 none (0.07914286 0.92085714)  \n   2) adr&gt;=172.05 534 190 none (0.35580524 0.64419476)  \n     4) adults&lt; 2.5 422 172 none (0.40758294 0.59241706)  \n       8) hotel=City Hotel 178  84 children (0.52808989 0.47191011)  \n        16) adr&gt;=191 86  25 children (0.70930233 0.29069767) *\n        17) adr&lt; 191 92  33 none (0.35869565 0.64130435)  \n          34) arrival_date_month=January,July 8   0 children (1.00000000 0.00000000) *\n          35) arrival_date_month=April,August,December,February,June,March,May,November,October,September 84  25 none (0.29761905 0.70238095) *\n       9) hotel=Resort Hotel 244  78 none (0.31967213 0.68032787) *\n     5) adults&gt;=2.5 112  18 none (0.16071429 0.83928571) *\n   3) adr&lt; 172.05 6466 364 none (0.05629446 0.94370554) *",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#evaluate",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#evaluate",
    "title": "Level 1 classification Tidy Modeling",
    "section": "5.1 Evaluate",
    "text": "5.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children       15    5\n  none           75  905\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.92 \n2 kap      binary         0.248\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary          0.92\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.167\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.995\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.92 \n2 sens     binary         0.167\n3 spec     binary         0.995\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.92 \n 2 kap                  binary         0.248\n 3 sens                 binary         0.167\n 4 spec                 binary         0.995\n 5 ppv                  binary         0.750\n 6 npv                  binary         0.923\n 7 mcc                  binary         0.329\n 8 j_index              binary         0.161\n 9 bal_accuracy         binary         0.581\n10 detection_prevalence binary         0.02 \n11 precision            binary         0.75 \n12 recall               binary         0.167\n13 f_meas               binary         0.273\n\n\nROC:receiver operating characteristic curve\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\nAUC:Area under ROC Curve\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_children)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.637",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#save-model",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#save-model",
    "title": "Level 1 classification Tidy Modeling",
    "section": "5.2 save model",
    "text": "5.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n545.34 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 1 classification Tidy Modeling.html#make-predication",
    "href": "hote classification model/Level 1 classification Tidy Modeling.html#make-predication",
    "title": "Level 1 classification Tidy Modeling",
    "section": "5.3 make predication",
    "text": "5.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none",
    "crumbs": [
      "hote classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html",
    "title": "Level 3 classification Tidy Modeling",
    "section": "",
    "text": "Level 3 classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#read-data",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#read-data",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#plotting-and-eda",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#plotting-and-eda",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.2 plotting and EDA",
    "text": "2.2 plotting and EDA\n\n\nCode\nhotel_stays %&gt;%\n  count(children)\n\n\n# A tibble: 2 × 2\n  children     n\n  &lt;chr&gt;    &lt;int&gt;\n1 children  6073\n2 none     69093\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(hotel_stays)\n\n\n\nData summary\n\n\nName\nhotel_stays\n\n\nNumber of rows\n75166\n\n\nNumber of columns\n29\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n14\n\n\nDate\n1\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nchildren\n0\n1\n4\n8\n0\n2\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n166\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n7\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n9\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n315\n0\n\n\ncompany\n0\n1\n1\n4\n0\n332\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nrequired_car_parking_spaces\n0\n1\n4\n7\n0\n2\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2015-07-01\n2017-09-14\n2016-09-01\n805\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlead_time\n0\n1\n79.98\n91.11\n0.00\n9.0\n45.0\n124\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.15\n0.70\n2015.00\n2016.0\n2016.0\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.08\n13.90\n1.00\n16.0\n28.0\n38\n53\n▆▇▇▇▆\n\n\narrival_date_day_of_month\n0\n1\n15.84\n8.78\n1.00\n8.0\n16.0\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n0.99\n0.00\n0.0\n1.0\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.46\n1.92\n0.00\n1.0\n2.0\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.83\n0.51\n0.00\n2.0\n2.0\n2\n4\n▁▂▇▁▁\n\n\nis_repeated_guest\n0\n1\n0.04\n0.20\n0.00\n0.0\n0.0\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.02\n0.27\n0.00\n0.0\n0.0\n0\n13\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.20\n1.81\n0.00\n0.0\n0.0\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.29\n0.74\n0.00\n0.0\n0.0\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n1.59\n14.78\n0.00\n0.0\n0.0\n0\n379\n▇▁▁▁▁\n\n\nadr\n0\n1\n99.99\n49.21\n-6.38\n67.5\n92.5\n125\n510\n▇▆▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.71\n0.83\n0.00\n0.0\n1.0\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nCode\nhotel_stays %&gt;%\n  mutate(arrival_date_month = factor(arrival_date_month,\n    levels = month.name\n  )) %&gt;%\n  count(hotel, arrival_date_month, children) %&gt;%\n  group_by(hotel, children) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  ggplot(aes(arrival_date_month, proportion, fill = children)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  facet_wrap(~hotel, nrow = 2) +\n  labs(\n    x = NULL,\n    y = \"Proportion of hotel stays\",\n    fill = NULL\n  )",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#data-split",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#data-split",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(50000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    10",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#recipe",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#prep-the-recipe",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 35000    23\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 5704   23\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 5704   23\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2852\n2 none            32148\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2852\n2 none             2852\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2852\n2 none             2852",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          426\n2 none             4574\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          807\n2 none             9193\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#model",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#model",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#trainning",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#trainning",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2705119\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5704 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 5704 2852 children (0.50000000 0.50000000)  \n   2) adr&gt;=0.006460157 2412  607 children (0.74834163 0.25165837) *\n   3) adr&lt; 0.006460157 3292 1047 none (0.31804374 0.68195626)  \n     6) total_of_special_requests&gt;=0.6642679 592  255 children (0.56925676 0.43074324) *\n     7) total_of_special_requests&lt; 0.6642679 2700  710 none (0.26296296 0.73703704)  \n      14) adults&lt; -2.837546 47    4 children (0.91489362 0.08510638) *\n      15) adults&gt;=-2.837546 2653  667 none (0.25141349 0.74858651) *",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#evaluate",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#evaluate",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits             id        \n   &lt;list&gt;             &lt;chr&gt;     \n 1 &lt;split [5132/572]&gt; Resample01\n 2 &lt;split [5132/572]&gt; Resample02\n 3 &lt;split [5132/572]&gt; Resample03\n 4 &lt;split [5132/572]&gt; Resample04\n 5 &lt;split [5132/572]&gt; Resample05\n 6 &lt;split [5132/572]&gt; Resample06\n 7 &lt;split [5132/572]&gt; Resample07\n 8 &lt;split [5132/572]&gt; Resample08\n 9 &lt;split [5132/572]&gt; Resample09\n10 &lt;split [5132/572]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.73     25 0.00324 Preprocessor1_Model1\n2 roc_auc  binary     0.794    25 0.00370 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.734    25 0.00405 Preprocessor1_Model1\n2 roc_auc  binary     0.749    25 0.00407 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_children) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#save-model",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#save-model",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n1.15 MB\n\n\nCode\nobj_size(knn_fit)\n\n\n1.10 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 3 classification Tidy Modeling.html#make-predication",
    "href": "hote classification model/Level 3 classification Tidy Modeling.html#make-predication",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 children   \n2 none       \n3 children   \n4 none       \n5 none       \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      595 2404\n  none          212 6789\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.738\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          807\n2 none             9193\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2999\n2 none         7001\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      595 2404\n  none          212 6789",
    "crumbs": [
      "hote classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 0 classification Tidy Modeling.html",
    "href": "hote classification model/Level 0 classification Tidy Modeling.html",
    "title": "Level 0 classification Tidy Modeling",
    "section": "",
    "text": "Look at the hotel booking data.The target variable is whether have children",
    "crumbs": [
      "hote classification model",
      "Level 0 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 0 classification Tidy Modeling.html#measurement",
    "href": "hote classification model/Level 0 classification Tidy Modeling.html#measurement",
    "title": "Level 0 classification Tidy Modeling",
    "section": "4.1 Measurement:",
    "text": "4.1 Measurement:\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nSpecificity=TN/(TN+FP)\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)\n\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nF1 score=2/(1/Precision+1/Recall)",
    "crumbs": [
      "hote classification model",
      "Level 0 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 0 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 0 Regression Tidy Modeling.html",
    "title": "Level 0 Regression Tidy Modeling",
    "section": "",
    "text": "1 house price data\n\ndata download form kaggle\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\nData have 1460 record and 81 variable\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n2 Measurement:\n\nMean absolute error (MAE)\n\nThe MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. The equation is given in the library references. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n\nRoot Mean Squared Error (RMSE)\n\n\nThe RMSE is a quadratic scoring rule which measures the average magnitude of the error. The equation for the RMSE is given in both of the references. Expressing the formula in words, the difference between forecast and corresponding observed values are each squared and then averaged over the sample. Finally, the square root of the average is taken. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\nBoth the MAE and RMSE can range from 0 to ∞. They are negatively-oriented scores: Lower values are better.\n\nR^2 (Coefficient of determination): is between 0 to 1. bigger the better.\n\n\nresidual sum of squares(RSS):\n\ntotal sum of squares(TOT):\n\n\n\n3 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\n\n\n4 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n5 EDA\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "house price regression model",
      "Level 0 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 0 Regression Tidy Modeling.html#measurement",
    "href": "house price regression model/Level 0 Regression Tidy Modeling.html#measurement",
    "title": "Level 0 Regression Tidy Modeling",
    "section": "",
    "text": "Mean absolute error (MAE)\n\nThe MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. The equation is given in the library references. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n\nRoot Mean Squared Error (RMSE)\n\n\nThe RMSE is a quadratic scoring rule which measures the average magnitude of the error. The equation for the RMSE is given in both of the references. Expressing the formula in words, the difference between forecast and corresponding observed values are each squared and then averaged over the sample. Finally, the square root of the average is taken. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\nBoth the MAE and RMSE can range from 0 to ∞. They are negatively-oriented scores: Lower values are better.\n\nR^2 (Coefficient of determination): is between 0 to 1. bigger the better.\n\n\nresidual sum of squares(RSS):\n\ntotal sum of squares(TOT):",
    "crumbs": [
      "house price regression model",
      "Level 0 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html",
    "title": "Level 4 classification Tidy Modeling",
    "section": "",
    "text": "Level 4 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth) with tune_grid()",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#read-data",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#read-data",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#plotting-and-eda",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#plotting-and-eda",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.2 plotting and EDA",
    "text": "2.2 plotting and EDA\n\n\nCode\nhotel_stays %&gt;%\n  count(children)\n\n\n# A tibble: 2 × 2\n  children     n\n  &lt;chr&gt;    &lt;int&gt;\n1 children  6073\n2 none     69093\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(hotel_stays)\n\n\n\nData summary\n\n\nName\nhotel_stays\n\n\nNumber of rows\n75166\n\n\nNumber of columns\n29\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\ncharacter\n14\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2015-07-01\n2017-09-14\n2016-09-01\n805\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nchildren\n0\n1\n4\n8\n0\n2\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n166\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n7\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n9\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n315\n0\n\n\ncompany\n0\n1\n1\n4\n0\n332\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nrequired_car_parking_spaces\n0\n1\n4\n7\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlead_time\n0\n1\n79.98\n91.11\n0.00\n9.0\n45.0\n124\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.15\n0.70\n2015.00\n2016.0\n2016.0\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.08\n13.90\n1.00\n16.0\n28.0\n38\n53\n▆▇▇▇▆\n\n\narrival_date_day_of_month\n0\n1\n15.84\n8.78\n1.00\n8.0\n16.0\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n0.99\n0.00\n0.0\n1.0\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.46\n1.92\n0.00\n1.0\n2.0\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.83\n0.51\n0.00\n2.0\n2.0\n2\n4\n▁▂▇▁▁\n\n\nis_repeated_guest\n0\n1\n0.04\n0.20\n0.00\n0.0\n0.0\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.02\n0.27\n0.00\n0.0\n0.0\n0\n13\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.20\n1.81\n0.00\n0.0\n0.0\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.29\n0.74\n0.00\n0.0\n0.0\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n1.59\n14.78\n0.00\n0.0\n0.0\n0\n379\n▇▁▁▁▁\n\n\nadr\n0\n1\n99.99\n49.21\n-6.38\n67.5\n92.5\n125\n510\n▇▆▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.71\n0.83\n0.00\n0.0\n1.0\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nCode\nhotel_stays %&gt;%\n  mutate(arrival_date_month = factor(arrival_date_month,\n    levels = month.name\n  )) %&gt;%\n  count(hotel, arrival_date_month, children) %&gt;%\n  group_by(hotel, children) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  ggplot(aes(arrival_date_month, proportion, fill = children)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  facet_wrap(~hotel, nrow = 2) +\n  labs(\n    x = NULL,\n    y = \"Proportion of hotel stays\",\n    fill = NULL\n  )",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#data-split",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#data-split",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train,v=10)",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#recipe",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#recipe",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#model",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#model",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#workflow",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#workflow",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#training-and-tunning",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl,\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits               id     .metrics          .notes           .predictions\n   &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [31500/3500]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [31500/3500]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [31500/3500]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [31500/3500]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [31500/3500]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [31500/3500]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [31500/3500]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [31500/3500]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [31500/3500]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [31500/3500]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.805    10 0.0108  Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.701    10 0.00546 Preproces…\n 3    0.0000000178          1 accuracy binary     0.805    10 0.0108  Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.701    10 0.00546 Preproces…\n 5    0.00000316            1 accuracy binary     0.805    10 0.0108  Preproces…\n 6    0.00000316            1 roc_auc  binary     0.701    10 0.00546 Preproces…\n 7    0.000562              1 accuracy binary     0.805    10 0.0108  Preproces…\n 8    0.000562              1 roc_auc  binary     0.701    10 0.00546 Preproces…\n 9    0.1                   1 accuracy binary     0.805    10 0.0108  Preproces…\n10    0.1                   1 roc_auc  binary     0.701    10 0.00546 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.0000000001          1 accuracy binary     0.805    10  0.0108 Preprocess…\n2    0.0000000178          1 accuracy binary     0.805    10  0.0108 Preprocess…\n3    0.00000316            1 accuracy binary     0.805    10  0.0108 Preprocess…\n4    0.000562              1 accuracy binary     0.805    10  0.0108 Preprocess…\n5    0.1                   1 accuracy binary     0.805    10  0.0108 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          1 Preprocessor1_Model01\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 1\n\nComputational engine: rpart",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#last-fit",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#last-fit",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#evaluate",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#evaluate",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.835 Preprocessor1_Model1\n2 roc_auc  binary         0.697 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5572 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 5572 2786 children (0.5000000 0.5000000)  \n  2) adr&gt;=0.2793064 1855  380 children (0.7951482 0.2048518) *\n  3) adr&lt; 0.2793064 3717 1311 none (0.3527038 0.6472962) *\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#save-model",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#save-model",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.44 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 4 classification Tidy Modeling.html#make-predication",
    "href": "hote classification model/Level 4 classification Tidy Modeling.html#make-predication",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 children   \n3 none       \n4 none       \n5 children   \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      416 1314\n  none          388 7882\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.830\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          804\n2 none             9196\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     1730\n2 none         8270\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      416 1314\n  none          388 7882",
    "crumbs": [
      "hote classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html",
    "title": "Level 5 classification Tidy Modeling",
    "section": "",
    "text": "Level 5 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#read-data",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#read-data",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#plotting-and-eda",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#plotting-and-eda",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.2 plotting and EDA",
    "text": "2.2 plotting and EDA\n\n\nCode\nhotel_stays %&gt;%\n  count(children)\n\n\n# A tibble: 2 × 2\n  children     n\n  &lt;chr&gt;    &lt;int&gt;\n1 children  6073\n2 none     69093\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(hotel_stays)\n\n\n\nData summary\n\n\nName\nhotel_stays\n\n\nNumber of rows\n75166\n\n\nNumber of columns\n29\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\ncharacter\n14\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2015-07-01\n2017-09-14\n2016-09-01\n805\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nchildren\n0\n1\n4\n8\n0\n2\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n166\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n7\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n9\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n315\n0\n\n\ncompany\n0\n1\n1\n4\n0\n332\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nrequired_car_parking_spaces\n0\n1\n4\n7\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlead_time\n0\n1\n79.98\n91.11\n0.00\n9.0\n45.0\n124\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.15\n0.70\n2015.00\n2016.0\n2016.0\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.08\n13.90\n1.00\n16.0\n28.0\n38\n53\n▆▇▇▇▆\n\n\narrival_date_day_of_month\n0\n1\n15.84\n8.78\n1.00\n8.0\n16.0\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n0.99\n0.00\n0.0\n1.0\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.46\n1.92\n0.00\n1.0\n2.0\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.83\n0.51\n0.00\n2.0\n2.0\n2\n4\n▁▂▇▁▁\n\n\nis_repeated_guest\n0\n1\n0.04\n0.20\n0.00\n0.0\n0.0\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.02\n0.27\n0.00\n0.0\n0.0\n0\n13\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.20\n1.81\n0.00\n0.0\n0.0\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.29\n0.74\n0.00\n0.0\n0.0\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n1.59\n14.78\n0.00\n0.0\n0.0\n0\n379\n▇▁▁▁▁\n\n\nadr\n0\n1\n99.99\n49.21\n-6.38\n67.5\n92.5\n125\n510\n▇▆▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.71\n0.83\n0.00\n0.0\n1.0\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nCode\nhotel_stays %&gt;%\n  mutate(arrival_date_month = factor(arrival_date_month,\n    levels = month.name\n  )) %&gt;%\n  count(hotel, arrival_date_month, children) %&gt;%\n  group_by(hotel, children) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  ggplot(aes(arrival_date_month, proportion, fill = children)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  facet_wrap(~hotel, nrow = 2) +\n  labs(\n    x = NULL,\n    y = \"Proportion of hotel stays\",\n    fill = NULL\n  )",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#data-split",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#data-split",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#recipe",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#recipe",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#model",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#model",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      &lt;int&gt; 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#workflow",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#workflow",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#training-and-tunning",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 78 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.000104              10 accuracy binary     0.757    10 0.00623 Preproces…\n 2   0.000104              10 roc_auc  binary     0.822    10 0.00459 Preproces…\n 3   0.00000000437         11 accuracy binary     0.756    10 0.00487 Preproces…\n 4   0.00000000437         11 roc_auc  binary     0.821    10 0.00461 Preproces…\n 5   0.0000000616          10 accuracy binary     0.757    10 0.00626 Preproces…\n 6   0.0000000616          10 roc_auc  binary     0.822    10 0.00463 Preproces…\n 7   0.0000750             13 accuracy binary     0.751    10 0.00503 Preproces…\n 8   0.0000750             13 roc_auc  binary     0.821    10 0.00471 Preproces…\n 9   0.0000000664          14 accuracy binary     0.747    10 0.00672 Preproces…\n10   0.0000000664          14 roc_auc  binary     0.821    10 0.00506 Preproces…\n# ℹ 68 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1    0.000142             14 roc_auc binary     0.822    10 0.00505 Preprocesso…\n2    0.000104             10 roc_auc binary     0.822    10 0.00459 Preprocesso…\n3    0.0000000616         10 roc_auc binary     0.822    10 0.00463 Preprocesso…\n4    0.000000833          10 roc_auc binary     0.822    10 0.00463 Preprocesso…\n5    0.0000000245         10 roc_auc binary     0.822    10 0.00463 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1        0.000142         14 Preprocessor1_Model052\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 0.000141543693071946\n  tree_depth = 14\n\nComputational engine: rpart",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#last-fit",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#last-fit",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#evaluate",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#evaluate",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.751 Preprocessor1_Model1\n2 roc_auc  binary         0.814 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.751\n2 recall    binary         0.725\n3 precision binary         0.215\n4 f_meas    binary         0.331\n5 kap       binary         0.230\n6 sens      binary         0.725\n7 spec      binary         0.753\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5524 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n    1) root 5524 2762 children (0.50000000 0.50000000)  \n      2) adr&gt;=0.1157544 2157  529 children (0.75475197 0.24524803)  \n        4) adr&gt;=0.9221342 925  117 children (0.87351351 0.12648649)  \n          8) adr&gt;=1.245399 635   60 children (0.90551181 0.09448819)  \n           16) meal_HB&lt; 1.056483 449   33 children (0.92650334 0.07349666) *\n           17) meal_HB&gt;=1.056483 186   27 children (0.85483871 0.14516129)  \n             34) arrival_date_month_September&lt; 1.758524 179   23 children (0.87150838 0.12849162) *\n             35) arrival_date_month_September&gt;=1.758524 7    3 none (0.42857143 0.57142857) *\n          9) adr&lt; 1.245399 290   57 children (0.80344828 0.19655172)  \n           18) adults&lt; 1.273727 256   41 children (0.83984375 0.16015625)  \n             36) adults&gt;=-0.8159875 242   33 children (0.86363636 0.13636364)  \n               72) hotel_Resort.Hotel&lt; 0.2275968 142   10 children (0.92957746 0.07042254)  \n                144) adr&lt; 1.081823 71    1 children (0.98591549 0.01408451) *\n                145) adr&gt;=1.081823 71    9 children (0.87323944 0.12676056)  \n                  290) adr&gt;=1.085872 64    5 children (0.92187500 0.07812500) *\n                  291) adr&lt; 1.085872 7    3 none (0.42857143 0.57142857) *\n               73) hotel_Resort.Hotel&gt;=0.2275968 100   23 children (0.77000000 0.23000000)  \n                146) required_car_parking_spaces_parking&gt;=1.029184 27    2 children (0.92592593 0.07407407) *\n                147) required_car_parking_spaces_parking&lt; 1.029184 73   21 children (0.71232877 0.28767123)  \n                  294) arrival_date_month_August&lt; 0.9019664 46    9 children (0.80434783 0.19565217) *\n                  295) arrival_date_month_August&gt;=0.9019664 27   12 children (0.55555556 0.44444444)  \n                    590) meal_HB&lt; 1.056483 20    7 children (0.65000000 0.35000000) *\n                    591) meal_HB&gt;=1.056483 7    2 none (0.28571429 0.71428571) *\n             37) adults&lt; -0.8159875 14    6 none (0.42857143 0.57142857) *\n           19) adults&gt;=1.273727 34   16 children (0.52941176 0.47058824)  \n             38) hotel_Resort.Hotel&gt;=0.2275968 13    0 children (1.00000000 0.00000000) *\n             39) hotel_Resort.Hotel&lt; 0.2275968 21    5 none (0.23809524 0.76190476) *\n        5) adr&lt; 0.9221342 1232  412 children (0.66558442 0.33441558)  \n         10) adults&lt; 1.273727 1113  319 children (0.71338724 0.28661276)  \n           20) adults&gt;=-0.8159875 1057  285 children (0.73036897 0.26963103)  \n             40) meal_SC&lt; 1.820907 1022  263 children (0.74266145 0.25733855)  \n               80) total_of_special_requests&gt;=0.6389178 341   57 children (0.83284457 0.16715543) *\n               81) total_of_special_requests&lt; 0.6389178 681  206 children (0.69750367 0.30249633)  \n                162) adr&gt;=0.2898573 506  136 children (0.73122530 0.26877470)  \n                  324) arrival_date_month_May&lt; 1.575526 474  121 children (0.74472574 0.25527426)  \n                    648) arrival_date_month_September&lt; 1.758524 432  103 children (0.76157407 0.23842593)  \n                     1296) hotel_Resort.Hotel&lt; 0.2275968 263   53 children (0.79847909 0.20152091)  \n                       2592) arrival_date_month_June&lt; 1.468481 234   41 children (0.82478632 0.17521368)  \n                         5184) adr&gt;=0.4716531 151   17 children (0.88741722 0.11258278) *\n                         5185) adr&lt; 0.4716531 83   24 children (0.71084337 0.28915663)  \n                          10370) adr&lt; 0.4178026 42    5 children (0.88095238 0.11904762) *\n                          10371) adr&gt;=0.4178026 41   19 children (0.53658537 0.46341463)  \n                            20742) stays_in_weekend_nights&gt;=-0.4687777 28   10 children (0.64285714 0.35714286) *\n                            20743) stays_in_weekend_nights&lt; -0.4687777 13    4 none (0.30769231 0.69230769) *\n                       2593) arrival_date_month_June&gt;=1.468481 29   12 children (0.58620690 0.41379310)  \n\n...\nand 256 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#save-model",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#save-model",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.51 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 5 classification Tidy Modeling.html#make-predication",
    "href": "hote classification model/Level 5 classification Tidy Modeling.html#make-predication",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 children   \n4 none       \n5 children   \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      630 2220\n  none          224 6926\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.756\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          854\n2 none             9146\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2850\n2 none         7150\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      630 2220\n  none          224 6926",
    "crumbs": [
      "hote classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html",
    "title": "Level 6 classification Tidy Modeling",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:\nlogistic glm model\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\nKNN model with knn engine(knn_spec)\ntuning XG boost model (tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)\ntuning light gbm boost model(tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#read-data",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#read-data",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#plotting-and-eda",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#plotting-and-eda",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.2 plotting and EDA",
    "text": "2.2 plotting and EDA\n\n\nCode\nhotel_stays %&gt;%\n  count(children)\n\n\n# A tibble: 2 × 2\n  children     n\n  &lt;chr&gt;    &lt;int&gt;\n1 children  6073\n2 none     69093\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(hotel_stays)\n\n\n\nData summary\n\n\nName\nhotel_stays\n\n\nNumber of rows\n75166\n\n\nNumber of columns\n29\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n14\n\n\nDate\n1\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nhotel\n0\n1\n10\n12\n0\n2\n0\n\n\narrival_date_month\n0\n1\n3\n9\n0\n12\n0\n\n\nchildren\n0\n1\n4\n8\n0\n2\n0\n\n\nmeal\n0\n1\n2\n9\n0\n5\n0\n\n\ncountry\n0\n1\n2\n4\n0\n166\n0\n\n\nmarket_segment\n0\n1\n6\n13\n0\n7\n0\n\n\ndistribution_channel\n0\n1\n3\n9\n0\n5\n0\n\n\nreserved_room_type\n0\n1\n1\n1\n0\n9\n0\n\n\nassigned_room_type\n0\n1\n1\n1\n0\n10\n0\n\n\ndeposit_type\n0\n1\n10\n10\n0\n3\n0\n\n\nagent\n0\n1\n1\n4\n0\n315\n0\n\n\ncompany\n0\n1\n1\n4\n0\n332\n0\n\n\ncustomer_type\n0\n1\n5\n15\n0\n4\n0\n\n\nrequired_car_parking_spaces\n0\n1\n4\n7\n0\n2\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nreservation_status_date\n0\n1\n2015-07-01\n2017-09-14\n2016-09-01\n805\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlead_time\n0\n1\n79.98\n91.11\n0.00\n9.0\n45.0\n124\n737\n▇▂▁▁▁\n\n\narrival_date_year\n0\n1\n2016.15\n0.70\n2015.00\n2016.0\n2016.0\n2017\n2017\n▃▁▇▁▆\n\n\narrival_date_week_number\n0\n1\n27.08\n13.90\n1.00\n16.0\n28.0\n38\n53\n▆▇▇▇▆\n\n\narrival_date_day_of_month\n0\n1\n15.84\n8.78\n1.00\n8.0\n16.0\n23\n31\n▇▇▇▇▆\n\n\nstays_in_weekend_nights\n0\n1\n0.93\n0.99\n0.00\n0.0\n1.0\n2\n19\n▇▁▁▁▁\n\n\nstays_in_week_nights\n0\n1\n2.46\n1.92\n0.00\n1.0\n2.0\n3\n50\n▇▁▁▁▁\n\n\nadults\n0\n1\n1.83\n0.51\n0.00\n2.0\n2.0\n2\n4\n▁▂▇▁▁\n\n\nis_repeated_guest\n0\n1\n0.04\n0.20\n0.00\n0.0\n0.0\n0\n1\n▇▁▁▁▁\n\n\nprevious_cancellations\n0\n1\n0.02\n0.27\n0.00\n0.0\n0.0\n0\n13\n▇▁▁▁▁\n\n\nprevious_bookings_not_canceled\n0\n1\n0.20\n1.81\n0.00\n0.0\n0.0\n0\n72\n▇▁▁▁▁\n\n\nbooking_changes\n0\n1\n0.29\n0.74\n0.00\n0.0\n0.0\n0\n21\n▇▁▁▁▁\n\n\ndays_in_waiting_list\n0\n1\n1.59\n14.78\n0.00\n0.0\n0.0\n0\n379\n▇▁▁▁▁\n\n\nadr\n0\n1\n99.99\n49.21\n-6.38\n67.5\n92.5\n125\n510\n▇▆▁▁▁\n\n\ntotal_of_special_requests\n0\n1\n0.71\n0.83\n0.00\n0.0\n1.0\n1\n5\n▇▁▁▁▁\n\n\n\n\n\n\n\nCode\nhotel_stays %&gt;%\n  mutate(arrival_date_month = factor(arrival_date_month,\n    levels = month.name\n  )) %&gt;%\n  count(hotel, arrival_date_month, children) %&gt;%\n  group_by(hotel, children) %&gt;%\n  mutate(proportion = n / sum(n)) %&gt;%\n  ggplot(aes(arrival_date_month, proportion, fill = children)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent_format()) +\n  facet_wrap(~hotel, nrow = 2) +\n  labs(\n    x = NULL,\n    y = \"Proportion of hotel stays\",\n    fill = NULL\n  )",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#data-split",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#data-split",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#recipe",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#recipe",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#model",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#model",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          2   3.42e- 6       8.02e- 9    32       0.734     3\n2          7   4.05e- 5       2.42e- 1    25       0.393     7\n3         14   4.98e- 4       5.17e-10     4       0.465     3\n4         12   4.33e- 8       8.46e- 7     8       0.485     9\n5         10   4.00e-10       2.81e- 5    14       0.387     9\n6          7   7.24e- 5       8.03e- 2     9       0.105    11\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         10   1.14e-10       1.09e- 3    13       0.682     1\n2          6   1.25e- 5       1.81e+ 1    19       0.265     6\n3          2   3.59e- 6       1.55e- 5    18       0.860     8\n4          3   5.01e- 8       2.34e-10    20       0.108     6\n5         15   2.98e- 2       2.05e- 6    21       0.341     5\n6         13   2.28e- 3       2.52e- 7    34       0.124     4",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#workflow-set",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#workflow-set",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#training-and-tunning",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_xgb\nPreprocessor1_Model19\naccuracy\n0.7650286\n0.003452614\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model19\nroc_auc\n0.8412516\n0.004250130\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\naccuracy\n0.7576571\n0.003629009\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nroc_auc\n0.8377707\n0.005030341\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model06\naccuracy\n0.7471714\n0.005203601\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model06\nroc_auc\n0.8223165\n0.007248099\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7663143\n0.001708164\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.8114071\n0.002863346\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7390857\n0.001727358\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7956658\n0.005035380\n10\nrecipe\nnearest_neighbor\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#last-fit",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#last-fit",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#evaluate",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#evaluate",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.784 Preprocessor1_Model1\n2 roc_auc  binary         0.823 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.784\n2 recall    binary         0.714\n3 precision binary         0.217\n4 f_meas    binary         0.333\n5 kap       binary         0.246\n6 sens      binary         0.714\n7 spec      binary         0.790\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 25.2 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.0899069436737191, max_depth = 5L, \n    gamma = 0.832337637488916, colsample_bytree = 1, colsample_bynode = 0.590909090909091, \n    min_child_weight = 4L, subsample = 0.618058206671849), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.0899069436737191\", max_depth = \"5\", gamma = \"0.832337637488916\", colsample_bytree = \"1\", colsample_bynode = \"0.590909090909091\", min_child_weight = \"4\", subsample = \"0.618058206671849\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 22 \nniter: 10\nnfeatures : 22 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6673541\n        2        0.6433716\n---                       \n        9        0.5497512\n       10        0.5410508\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#save-model",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#save-model",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.43 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hote classification model/Level 6 classification Tidy Modeling.html#make-predication",
    "href": "hote classification model/Level 6 classification Tidy Modeling.html#make-predication",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 children   \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      564 2007\n  none          230 7199\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.776\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          794\n2 none             9206\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2571\n2 none         7429\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      564 2007\n  none          230 7199",
    "crumbs": [
      "hote classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site:\nlink:https://tonyfly3000.github.io/tidymodeling/\n\nhttps://www.tidymodels.org/\n\nModeling process\n\n\n\nresource\ntidymodels website: https://www.tidymodels.org/\ntidymodels book: https://www.tmwr.org/\n\n\n\n\n Back to top"
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html",
    "title": "Level 4 classification Tidy Modeling",
    "section": "",
    "text": "Level 4 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#read-data",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#eda",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#plotting",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#data-split",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#recipe",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#model",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#model",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#workflow",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#workflow",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits           id     .metrics          .notes           .predictions\n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [560/63]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [560/63]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [560/63]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [561/62]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [561/62]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [561/62]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [561/62]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [561/62]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [561/62]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [561/62]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.774    10  0.0144 Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 3    0.0000000178          1 accuracy binary     0.774    10  0.0144 Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 5    0.00000316            1 accuracy binary     0.774    10  0.0144 Preproces…\n 6    0.00000316            1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 7    0.000562              1 accuracy binary     0.774    10  0.0144 Preproces…\n 8    0.000562              1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 9    0.1                   1 accuracy binary     0.774    10  0.0144 Preproces…\n10    0.1                   1 roc_auc  binary     0.751    10  0.0161 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.0000000001          4 accuracy binary     0.788    10  0.0179 Preprocess…\n2    0.0000000178          4 accuracy binary     0.788    10  0.0179 Preprocess…\n3    0.00000316            4 accuracy binary     0.788    10  0.0179 Preprocess…\n4    0.000562              4 accuracy binary     0.788    10  0.0179 Preprocess…\n5    0.0000000001          1 accuracy binary     0.774    10  0.0144 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          4 Preprocessor1_Model06\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 4\n\nComputational engine: rpart",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#last-fit",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#evaluate",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.844 Preprocessor1_Model1\n2 roc_auc  binary         0.861 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 623 244 0 (0.60834671 0.39165329)  \n   2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n     4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237) *\n     5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n   3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n     6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n      12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n      13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n        26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143) *\n        27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970) *\n     7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#save-model",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.14 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 4 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/Level 4 classification Tidy Modeling.html#make-predication",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.764\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              62\n2 1              27\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19",
    "crumbs": [
      "titanic classification model",
      "Level 4 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html",
    "title": "Level 5 classification Tidy Modeling",
    "section": "",
    "text": "Level 5 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#read-data",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#eda",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#plotting",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#data-split",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#recipe",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#model",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#model",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.604226e-02, 1.240402e-07, 2.627129e-08, 9.554920e-09, 4.573048e-07, 4.382004e-07, 7.226307e-10, 5.853203e-03, 3.898687e-03, 6.021893e-02, 2.083316e-02, 1.088783e-05, 5.4962…\n$ tree_depth      &lt;int&gt; 8, 7, 6, 4, 12, 4, 11, 5, 3, 11, 15, 1, 5, 13, 8, 12, 10, 11, 9, 4, 7, 10, 3, 6, 15, 4, 9, 10, 4, 2, 1, 4, 14, 4, 11, 8, 12, 6, 10, 12, 13, 13, 7, 7, 2, 12, 4, 3, 2, 8, 13, 3…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    13\n 4          4    15\n 5          5    14\n 6          6    15\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    15\n13         13    14\n14         14    14\n15         15     7",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#workflow",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#workflow",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 68 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.000220              10 accuracy binary     0.772    10  0.0149 Preproces…\n 2   0.000220              10 roc_auc  binary     0.821    10  0.0159 Preproces…\n 3   0.0000270             11 accuracy binary     0.774    10  0.0142 Preproces…\n 4   0.0000270             11 roc_auc  binary     0.824    10  0.0150 Preproces…\n 5   0.0000000994          10 accuracy binary     0.764    10  0.0148 Preproces…\n 6   0.0000000994          10 roc_auc  binary     0.826    10  0.0147 Preproces…\n 7   0.0000000238          12 accuracy binary     0.772    10  0.0145 Preproces…\n 8   0.0000000238          12 roc_auc  binary     0.829    10  0.0144 Preproces…\n 9   0.00000000920         13 accuracy binary     0.764    10  0.0123 Preproces…\n10   0.00000000920         13 roc_auc  binary     0.823    10  0.0164 Preproces…\n# ℹ 58 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1    0.0000000238         12 roc_auc binary     0.829    10  0.0144 Preprocesso…\n2    0.000000749          13 roc_auc binary     0.828    10  0.0177 Preprocesso…\n3    0.000000587          12 roc_auc binary     0.827    10  0.0155 Preprocesso…\n4    0.00000161           12 roc_auc binary     0.827    10  0.0154 Preprocesso…\n5    0.000674              8 roc_auc binary     0.826    10  0.0169 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1    0.0000000238         12 Preprocessor1_Model040\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 2.37513046201816e-08\n  tree_depth = 12\n\nComputational engine: rpart",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#last-fit",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#evaluate",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.816 Preprocessor1_Model1\n2 roc_auc  binary         0.885 Preprocessor1_Model1\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.816\n2 recall    binary         0.903\n3 precision binary         0.823\n4 f_meas    binary         0.861\n5 kap       binary         0.590\n6 sens      binary         0.903\n7 spec      binary         0.667\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 623 244 0 (0.60834671 0.39165329)  \n     2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n       4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237)  \n         8) Pclass&gt;=-0.9236371 305  39 0 (0.87213115 0.12786885)  \n          16) Fare&lt; 0.4362002 295  35 0 (0.88135593 0.11864407)  \n            32) Cabin_E121&gt;=1.925855 26   0 0 (1.00000000 0.00000000) *\n            33) Cabin_E121&lt; 1.925855 269  35 0 (0.86988848 0.13011152)  \n              66) Age&gt;=-0.6289231 209  23 0 (0.88995215 0.11004785) *\n              67) Age&lt; -0.6289231 60  12 0 (0.80000000 0.20000000)  \n               134) Embarked_S&gt;=-0.4915368 49   7 0 (0.85714286 0.14285714)  \n                 268) PassengerId&gt;=0.8547689 16   0 0 (1.00000000 0.00000000) *\n                 269) PassengerId&lt; 0.8547689 33   7 0 (0.78787879 0.21212121)  \n                   538) Fare&lt; -0.543308 8   0 0 (1.00000000 0.00000000) *\n                   539) Fare&gt;=-0.543308 25   7 0 (0.72000000 0.28000000)  \n                    1078) Fare&gt;=-0.5171166 18   3 0 (0.83333333 0.16666667) *\n                    1079) Fare&lt; -0.5171166 7   3 1 (0.42857143 0.57142857) *\n               135) Embarked_S&lt; -0.4915368 11   5 0 (0.54545455 0.45454545) *\n          17) Fare&gt;=0.4362002 10   4 0 (0.60000000 0.40000000) *\n         9) Pclass&lt; -0.9236371 83  31 0 (0.62650602 0.37349398)  \n          18) PassengerId&lt; -1.024023 15   1 0 (0.93333333 0.06666667) *\n          19) PassengerId&gt;=-1.024023 68  30 0 (0.55882353 0.44117647)  \n            38) Age&gt;=0.4276941 48  17 0 (0.64583333 0.35416667)  \n              76) SibSp&lt; -0.03494193 34   9 0 (0.73529412 0.26470588)  \n               152) Fare&gt;=0.01793593 7   0 0 (1.00000000 0.00000000) *\n               153) Fare&lt; 0.01793593 27   9 0 (0.66666667 0.33333333)  \n                 306) Fare&lt; -0.05252826 20   5 0 (0.75000000 0.25000000) *\n                 307) Fare&gt;=-0.05252826 7   3 1 (0.42857143 0.57142857) *\n              77) SibSp&gt;=-0.03494193 14   6 1 (0.42857143 0.57142857) *\n            39) Age&lt; 0.4276941 20   7 1 (0.35000000 0.65000000) *\n       5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n     3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n       6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n        12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n        13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n          26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n            52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n            53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n             106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609)  \n               212) PassengerId&lt; 0.1220595 14   3 0 (0.78571429 0.21428571) *\n               213) PassengerId&gt;=0.1220595 9   4 1 (0.44444444 0.55555556) *\n             107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n          27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970)  \n            54) Cabin_G6&lt; 1.120627 13   6 0 (0.53846154 0.46153846) *\n            55) Cabin_G6&gt;=1.120627 20   3 1 (0.15000000 0.85000000) *\n       7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *\n\n...\nand 0 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#save-model",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.14 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 5 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/Level 5 classification Tidy Modeling.html#make-predication",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 47 13\n         1 10 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.742\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              60\n2 1              29\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 47 13\n         1 10 19",
    "crumbs": [
      "titanic classification model",
      "Level 5 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html",
    "title": "Level 6 classification Tidy Modeling",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#read-data",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#eda",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#plotting",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#data-split",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#recipe",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#model",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#model",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          6   3.33e- 5       2.32e+ 1    34       0.746     2\n2          6   6.19e- 4       2.32e- 2    22       0.580     5\n3          5   3.66e- 2       4.50e-10    24       0.949     1\n4          9   9.47e-10       2.06e- 5     2       0.340    11\n5          9   9.81e- 2       5.39e- 8     7       0.787     3\n6         12   2.50e- 6       6.99e- 3    16       0.151     5\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth   learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;        &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         12 0.00000156         6.09e-10    14       0.917     6\n2          3 0.0134             5.25e- 6    22       0.151     1\n3          2 0.0000000634       1.79e-10    15       0.132     5\n4          6 0.0206             1.84e- 5    19       0.863     9\n5          6 0.00000358         4.57e- 1    38       0.818     8\n6          4 0.00384            3.55e- 4    15       0.552     4",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#workflow-set",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#workflow-set",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_lightgbm\nPreprocessor1_Model11\naccuracy\n0.7301587\nNA\n1\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model11\nroc_auc\n0.8858093\nNA\n1\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model09\naccuracy\n0.7704813\n0.01220734\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_xgb\nPreprocessor1_Model09\nroc_auc\n0.8316034\n0.01125249\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model20\naccuracy\n0.7721710\n0.01523136\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model20\nroc_auc\n0.8284261\n0.01503274\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7063236\n0.01911126\n10\nrecipe\nnearest_neighbor\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7420401\n0.01885929\n10\nrecipe\nnearest_neighbor\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7398105\n0.01844242\n10\nrecipe\nlogistic_reg\n5\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7301929\n0.03339075\n10\nrecipe\nlogistic_reg\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\n\n\nCode\nxgb_model_set_res=model_set_res %&gt;% extract_workflow_set_result(id= 'recipe_xgb')\n\n\n\n\nCode\nglimpse(xgb_model_set_res)\n\n\nRows: 10\nColumns: 5\n$ splits       &lt;list&gt; [&lt;vfold_split[560 x 63 x 623 x 11]&gt;], [&lt;vfold_split[560 …\n$ id           &lt;chr&gt; \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     &lt;list&gt; [&lt;tbl_df[40 x 10]&gt;], [&lt;tbl_df[40 x 10]&gt;], [&lt;tbl_df[40 x …\n$ .notes       &lt;list&gt; [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;],…\n$ .predictions &lt;list&gt; [&lt;tbl_df[1260 x 12]&gt;], [&lt;tbl_df[1260 x 12]&gt;], [&lt;tbl_df[1…\n\n\n\n\nCode\n#xgb_model_set_res %&gt;% plot_race()\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#last-fit",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#evaluate",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.827 Preprocessor1_Model1\n2 roc_auc  binary         0.915 Preprocessor1_Model1\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.827\n2 recall    binary         0.982\n3 precision binary         0.793\n4 f_meas    binary         0.877\n5 kap       binary         0.593\n6 sens      binary         0.982\n7 spec      binary         0.561\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 14.8 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.080098505877286, max_depth = 12L, \n    gamma = 5.39858008778608e-07, colsample_bytree = 1, colsample_bynode = 0.645669291338583, \n    min_child_weight = 9L, subsample = 0.771166819442296), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.080098505877286\", max_depth = \"12\", gamma = \"5.39858008778608e-07\", colsample_bytree = \"1\", colsample_bynode = \"0.645669291338583\", min_child_weight = \"9\", subsample = \"0.771166819442296\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 127 \nniter: 10\nnfeatures : 127 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6633661\n        2        0.6379807\n---                       \n        9        0.5294025\n       10        0.5201621\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#save-model",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.04 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "titanic classification model/Level 6 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/Level 6 classification Tidy Modeling.html#make-predication",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 0          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 53 14\n         1  4 18\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.798\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              67\n2 1              22\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 53 14\n         1  4 18",
    "crumbs": [
      "titanic classification model",
      "Level 6 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "",
    "text": "Load Pacakges & Set Options\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#measurement",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#measurement",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "",
    "text": "Mean absolute error (MAE)\n\nThe MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. The equation is given in the library references. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n\nRoot Mean Squared Error (RMSE)\n\n\nThe RMSE is a quadratic scoring rule which measures the average magnitude of the error. The equation for the RMSE is given in both of the references. Expressing the formula in words, the difference between forecast and corresponding observed values are each squared and then averaged over the sample. Finally, the square root of the average is taken. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\nBoth the MAE and RMSE can range from 0 to ∞. They are negatively-oriented scores: Lower values are better.",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#read-data",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#eda",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#eda",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 1,460\nColumns: 81\n$ Id            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ MSSubClass    &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 20,…\n$ MSZoning      &lt;chr&gt; \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RM\", \"R…\n$ LotFrontage   &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, NA, 51, 50, 70, 85, NA, 91, …\n$ LotArea       &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 612…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"Reg\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"FR2\", \"Inside\", \"Corner\", \"FR2\", \"Inside\", \"I…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"CollgCr\", \"Veenker\", \"CollgCr\", \"Crawfor\", \"NoRidge\", \"…\n$ Condition1    &lt;chr&gt; \"Norm\", \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", …\n$ HouseStyle    &lt;chr&gt; \"2Story\", \"1Story\", \"2Story\", \"2Story\", \"2Story\", \"1.5Fi…\n$ OverallQual   &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, 5,…\n$ OverallCond   &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, 19…\n$ YearRemodAdd  &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"G…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Shng\", \"VinylSd\", \"…\n$ MasVnrType    &lt;chr&gt; \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\",…\n$ MasVnrArea    &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306, …\n$ ExterQual     &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"PConc\", \"CBlock\", \"PConc\", \"BrkTil\", \"PConc\", \"Wood\", \"…\n$ BsmtQual      &lt;chr&gt; \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Ex\", \"Gd\", \"TA\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"Gd\", \"Mn\", \"No\", \"Av\", \"No\", \"Av\", \"Mn\", \"No\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"GLQ\", \"ALQ\", \"GLQ\", \"ALQ\", \"GLQ\", \"GLQ\", \"GLQ\", \"ALQ\", …\n$ BsmtFinSF1    &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, 99…\n$ BsmtFinType2  &lt;chr&gt; \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"BLQ\", …\n$ BsmtFinSF2    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ BsmtUnfSF     &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, 17…\n$ TotalBsmtSF   &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, 10…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"E…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077, …\n$ `2ndFlrSF`    &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, 0,…\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, 10…\n$ BsmtFullBath  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1,…\n$ HalfBath      &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,…\n$ BedroomAbvGr  &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ KitchenQual   &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6, 6…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0,…\n$ FireplaceQu   &lt;chr&gt; NA, \"TA\", \"TA\", \"Gd\", \"TA\", NA, \"Gd\", \"TA\", \"TA\", \"TA\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Detchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, 19…\n$ GarageFinish  &lt;chr&gt; \"RFn\", \"RFn\", \"RFn\", \"Unf\", \"RFn\", \"Unf\", \"RFn\", \"RFn\", …\n$ GarageCars    &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, 2,…\n$ GarageArea    &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384, 7…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Fa\", \"G…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 160…\n$ OpenPorchSF   &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 213,…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0, …\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ScreenPorch   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, …\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; NA, NA, NA, NA, NA, \"MnPrv\", NA, NA, NA, NA, NA, NA, NA,…\n$ MiscFeature   &lt;chr&gt; NA, NA, NA, NA, NA, \"Shed\", NA, \"Shed\", NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 700,…\n$ MoSold        &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, 10…\n$ YrSold        &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Abnorml\", \"Normal\", \"Norm…\n$ SalePrice     &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000, …\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 1,459\nColumns: 80\n$ Id            &lt;dbl&gt; 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 14…\n$ MSSubClass    &lt;dbl&gt; 20, 20, 60, 60, 120, 60, 20, 60, 20, 20, 120, 160, 160, …\n$ MSZoning      &lt;chr&gt; \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"R…\n$ LotFrontage   &lt;dbl&gt; 80, 81, 74, 78, 43, 75, NA, 63, 85, 70, 26, 21, 21, 24, …\n$ LotArea       &lt;dbl&gt; 11622, 14267, 13830, 9978, 5005, 10000, 7980, 8402, 1017…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"HLS\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"Inside\", \"Corne…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"NAmes\", \"NAmes\", \"Gilbert\", \"Gilbert\", \"StoneBr\", \"Gilb…\n$ Condition1    &lt;chr&gt; \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"1Fam\", \"1Fam\"…\n$ HouseStyle    &lt;chr&gt; \"1Story\", \"1Story\", \"2Story\", \"2Story\", \"1Story\", \"2Stor…\n$ OverallQual   &lt;dbl&gt; 5, 6, 5, 6, 8, 6, 6, 6, 7, 4, 7, 6, 5, 6, 7, 9, 8, 9, 8,…\n$ OverallCond   &lt;dbl&gt; 6, 6, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ YearRemodAdd  &lt;dbl&gt; 1961, 1958, 1998, 1998, 1992, 1994, 2007, 1998, 1990, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Hip\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gab…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ MasVnrType    &lt;chr&gt; \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"None\", \"N…\n$ MasVnrArea    &lt;dbl&gt; 0, 108, 0, 20, 0, 0, 0, 0, 0, 0, 0, 504, 492, 0, 0, 162,…\n$ ExterQual     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"CBlock\", \"CBlock\", \"PConc\", \"PConc\", \"PConc\", \"PConc\", …\n$ BsmtQual      &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Gd\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"Rec\", \"ALQ\", \"GLQ\", \"GLQ\", \"ALQ\", \"Unf\", \"ALQ\", \"Unf\", …\n$ BsmtFinSF1    &lt;dbl&gt; 468, 923, 791, 602, 263, 0, 935, 0, 637, 804, 1051, 156,…\n$ BsmtFinType2  &lt;chr&gt; \"LwQ\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", …\n$ BsmtFinSF2    &lt;dbl&gt; 144, 0, 0, 0, 0, 0, 0, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF     &lt;dbl&gt; 270, 406, 137, 324, 1017, 763, 233, 789, 663, 0, 354, 32…\n$ TotalBsmtSF   &lt;dbl&gt; 882, 1329, 928, 926, 1280, 763, 1168, 789, 1300, 882, 14…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Gd\", \"Gd\", \"T…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 896, 1329, 928, 926, 1280, 763, 1187, 789, 1341, 882, 13…\n$ `2ndFlrSF`    &lt;dbl&gt; 0, 0, 701, 678, 0, 892, 0, 676, 0, 0, 0, 504, 567, 601, …\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 896, 1329, 1629, 1604, 1280, 1655, 1187, 1465, 1341, 882…\n$ BsmtFullBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ HalfBath      &lt;dbl&gt; 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,…\n$ BedroomAbvGr  &lt;dbl&gt; 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ KitchenQual   &lt;chr&gt; \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"TA\", \"TA\", \"TA\", \"Gd\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 5, 6, 6, 7, 5, 7, 6, 7, 5, 4, 5, 5, 6, 6, 4, 10, 7, 7, 8…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,…\n$ FireplaceQu   &lt;chr&gt; NA, NA, \"TA\", \"Gd\", NA, \"TA\", NA, \"Gd\", \"Po\", NA, \"Fa\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ GarageFinish  &lt;chr&gt; \"Unf\", \"Unf\", \"Fin\", \"Fin\", \"RFn\", \"Fin\", \"Fin\", \"Fin\", …\n$ GarageCars    &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 3, 3, 3, 3,…\n$ GarageArea    &lt;dbl&gt; 730, 312, 482, 470, 506, 440, 420, 393, 506, 525, 511, 2…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 140, 393, 212, 360, 0, 157, 483, 0, 192, 240, 203, 275, …\n$ OpenPorchSF   &lt;dbl&gt; 0, 36, 34, 36, 82, 84, 21, 75, 0, 0, 68, 0, 0, 0, 30, 13…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ScreenPorch   &lt;dbl&gt; 120, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; \"MnPrv\", NA, \"MnPrv\", NA, NA, NA, \"GdPrv\", NA, NA, \"MnPr…\n$ MiscFeature   &lt;chr&gt; NA, \"Gar2\", NA, NA, NA, NA, \"Shed\", NA, NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 12500, 0, 0, 0, 0, 500, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ MoSold        &lt;dbl&gt; 6, 6, 3, 6, 1, 4, 3, 5, 2, 4, 6, 2, 3, 6, 6, 1, 6, 6, 2,…\n$ YrSold        &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Norma…",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#plotting",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#plotting",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#data-split",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#recipe",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#model",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#model",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.2.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.2.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#trainning",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "3.3 trainning",
    "text": "3.3 trainning\n\n3.3.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    6.786e+05      1.851e+00     -1.899e+02      2.506e+01      1.804e-01  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n    1.890e+04      4.588e+03      2.974e+02      1.226e+02      3.001e+01  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n    1.411e+01      8.770e+00      6.529e+00             NA      4.605e+01  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n    4.830e+01      6.035e-01             NA      9.801e+03      4.500e+03  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n    3.766e+03     -1.734e+03     -8.997e+03     -1.285e+04      3.689e+03  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n    4.535e+03     -1.615e+01      1.789e+04      2.146e+00      2.358e+01  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n   -2.548e+01     -5.078e+00      3.999e+01      4.278e+01     -5.265e+01  \n      MiscVal         MoSold         YrSold  \n   -2.539e-01     -2.339e+02     -7.699e+02  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term           estimate   std.error statistic  p.value\n   &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)  678634.    1808073.        0.375 7.07e- 1\n 2 Id                1.85        2.81      0.659 5.10e- 1\n 3 MSSubClass     -190.         33.7      -5.63  2.29e- 8\n 4 LotFrontage      25.1        35.2       0.712 4.77e- 1\n 5 LotArea           0.180       0.146     1.23  2.18e- 1\n 6 OverallQual   18904.       1515.       12.5   2.69e-33\n 7 OverallCond    4588.       1332.        3.44  5.98e- 4\n 8 YearBuilt       297.         77.4       3.84  1.30e- 4\n 9 YearRemodAdd    123.         84.7       1.45  1.48e- 1\n10 MasVnrArea       30.0         7.28      4.12  4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.3.2 train lm model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00  63480\n2   1 10.62  57840\n3   1 19.45  52700\n4   1 26.77  48020\n5   2 32.89  43760\n6   2 39.26  39870\n7   2 44.56  36330\n8   2 48.95  33100\n9   3 52.79  30160\n10  4 56.28  27480\n11  5 59.43  25040\n12  5 62.05  22810\n13  5 64.22  20790\n14  5 66.03  18940\n15  5 67.53  17260\n16  5 68.77  15720\n17  5 69.80  14330\n18  7 70.71  13060\n19  9 71.66  11900\n20 10 72.51  10840\n21 10 73.26   9876\n22 10 73.87   8998\n23 11 74.40   8199\n24 11 74.86   7471\n25 13 75.37   6807\n26 13 75.86   6202\n27 13 76.28   5651\n28 13 76.64   5149\n29 13 76.95   4692\n30 13 77.21   4275\n31 13 77.42   3895\n32 14 77.60   3549\n33 14 77.75   3234\n34 15 77.88   2947\n35 15 77.99   2685\n36 16 78.09   2446\n37 17 78.27   2229\n38 19 78.44   2031\n39 20 78.62   1851\n40 21 78.76   1686\n41 22 78.90   1536\n42 23 79.03   1400\n43 24 79.14   1275\n44 25 79.24   1162\n45 25 79.32   1059\n46 25 79.39    965\n47 26 79.45    879\n48 26 79.50    801\n49 27 79.54    730\n50 28 79.59    665\n51 29 79.62    606\n52 30 79.65    552\n53 30 79.68    503\n54 31 79.70    458\n55 31 79.72    418\n56 31 79.73    381\n57 32 79.74    347\n58 33 79.75    316\n59 33 79.76    288\n60 34 79.77    262\n61 34 79.78    239\n62 33 79.78    218\n63 33 79.79    198\n64 33 79.79    181\n65 33 79.79    165\n66 33 79.80    150\n67 34 79.80    137\n68 35 79.80    125\n69 35 79.80    114\n70 35 79.80    104\n71 35 79.81     94\n72 35 79.81     86\n73 35 79.81     78\n74 35 79.81     71\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term           estimate penalty\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)  528464.        0.1\n 2 Id                1.65      0.1\n 3 MSSubClass     -187.        0.1\n 4 LotFrontage      24.0       0.1\n 5 LotArea           0.177     0.1\n 6 OverallQual   18970.        0.1\n 7 OverallCond    4464.        0.1\n 8 YearBuilt       290.        0.1\n 9 YearRemodAdd    125.        0.1\n10 MasVnrArea       29.9       0.1\n# ℹ 28 more rows\n\n\n\n\n3.3.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       959255491 \nR squared (OOB):                  0.8511865",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#evaluate",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = data_train) %&gt;%\n  mutate(\n    truth = data_train$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = data_train) %&gt;%\n    mutate(\n      truth = data_train$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = data_train) %&gt;%\n    mutate(\n      truth = data_train$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = data_test) %&gt;%\n  mutate(\n    truth = data_test$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = data_test) %&gt;%\n    mutate(\n      truth = data_test$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = data_test) %&gt;%\n    mutate(\n      truth = data_test$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      36059.\n2 lm    rmse    standard      36055.\n3 rf    rmse    standard      13542.\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      31122.\n2 lm    rmse    standard      31139.\n3 rf    rmse    standard      28428.\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 1 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/Level 1 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Level 1 Regression Tidy Modeling",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   39279.       10 4626.     Preprocessor1_Model1\n2 rsq     standard       0.768    10    0.0422 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Level 1 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#read-data",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#eda",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#eda",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 1,460\nColumns: 81\n$ Id            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ MSSubClass    &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 20,…\n$ MSZoning      &lt;chr&gt; \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RM\", \"R…\n$ LotFrontage   &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, NA, 51, 50, 70, 85, NA, 91, …\n$ LotArea       &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 612…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"Reg\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"FR2\", \"Inside\", \"Corner\", \"FR2\", \"Inside\", \"I…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"CollgCr\", \"Veenker\", \"CollgCr\", \"Crawfor\", \"NoRidge\", \"…\n$ Condition1    &lt;chr&gt; \"Norm\", \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", …\n$ HouseStyle    &lt;chr&gt; \"2Story\", \"1Story\", \"2Story\", \"2Story\", \"2Story\", \"1.5Fi…\n$ OverallQual   &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, 5,…\n$ OverallCond   &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, 19…\n$ YearRemodAdd  &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"G…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Shng\", \"VinylSd\", \"…\n$ MasVnrType    &lt;chr&gt; \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\",…\n$ MasVnrArea    &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306, …\n$ ExterQual     &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"PConc\", \"CBlock\", \"PConc\", \"BrkTil\", \"PConc\", \"Wood\", \"…\n$ BsmtQual      &lt;chr&gt; \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Ex\", \"Gd\", \"TA\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"Gd\", \"Mn\", \"No\", \"Av\", \"No\", \"Av\", \"Mn\", \"No\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"GLQ\", \"ALQ\", \"GLQ\", \"ALQ\", \"GLQ\", \"GLQ\", \"GLQ\", \"ALQ\", …\n$ BsmtFinSF1    &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, 99…\n$ BsmtFinType2  &lt;chr&gt; \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"BLQ\", …\n$ BsmtFinSF2    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ BsmtUnfSF     &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, 17…\n$ TotalBsmtSF   &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, 10…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"E…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077, …\n$ `2ndFlrSF`    &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, 0,…\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, 10…\n$ BsmtFullBath  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1,…\n$ HalfBath      &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,…\n$ BedroomAbvGr  &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ KitchenQual   &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6, 6…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0,…\n$ FireplaceQu   &lt;chr&gt; NA, \"TA\", \"TA\", \"Gd\", \"TA\", NA, \"Gd\", \"TA\", \"TA\", \"TA\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Detchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, 19…\n$ GarageFinish  &lt;chr&gt; \"RFn\", \"RFn\", \"RFn\", \"Unf\", \"RFn\", \"Unf\", \"RFn\", \"RFn\", …\n$ GarageCars    &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, 2,…\n$ GarageArea    &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384, 7…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Fa\", \"G…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 160…\n$ OpenPorchSF   &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 213,…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0, …\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ScreenPorch   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, …\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; NA, NA, NA, NA, NA, \"MnPrv\", NA, NA, NA, NA, NA, NA, NA,…\n$ MiscFeature   &lt;chr&gt; NA, NA, NA, NA, NA, \"Shed\", NA, \"Shed\", NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 700,…\n$ MoSold        &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, 10…\n$ YrSold        &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Abnorml\", \"Normal\", \"Norm…\n$ SalePrice     &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000, …\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 1,459\nColumns: 80\n$ Id            &lt;dbl&gt; 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 14…\n$ MSSubClass    &lt;dbl&gt; 20, 20, 60, 60, 120, 60, 20, 60, 20, 20, 120, 160, 160, …\n$ MSZoning      &lt;chr&gt; \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"R…\n$ LotFrontage   &lt;dbl&gt; 80, 81, 74, 78, 43, 75, NA, 63, 85, 70, 26, 21, 21, 24, …\n$ LotArea       &lt;dbl&gt; 11622, 14267, 13830, 9978, 5005, 10000, 7980, 8402, 1017…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"HLS\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"Inside\", \"Corne…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"NAmes\", \"NAmes\", \"Gilbert\", \"Gilbert\", \"StoneBr\", \"Gilb…\n$ Condition1    &lt;chr&gt; \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"1Fam\", \"1Fam\"…\n$ HouseStyle    &lt;chr&gt; \"1Story\", \"1Story\", \"2Story\", \"2Story\", \"1Story\", \"2Stor…\n$ OverallQual   &lt;dbl&gt; 5, 6, 5, 6, 8, 6, 6, 6, 7, 4, 7, 6, 5, 6, 7, 9, 8, 9, 8,…\n$ OverallCond   &lt;dbl&gt; 6, 6, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ YearRemodAdd  &lt;dbl&gt; 1961, 1958, 1998, 1998, 1992, 1994, 2007, 1998, 1990, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Hip\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gab…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ MasVnrType    &lt;chr&gt; \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"None\", \"N…\n$ MasVnrArea    &lt;dbl&gt; 0, 108, 0, 20, 0, 0, 0, 0, 0, 0, 0, 504, 492, 0, 0, 162,…\n$ ExterQual     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"CBlock\", \"CBlock\", \"PConc\", \"PConc\", \"PConc\", \"PConc\", …\n$ BsmtQual      &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Gd\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"Rec\", \"ALQ\", \"GLQ\", \"GLQ\", \"ALQ\", \"Unf\", \"ALQ\", \"Unf\", …\n$ BsmtFinSF1    &lt;dbl&gt; 468, 923, 791, 602, 263, 0, 935, 0, 637, 804, 1051, 156,…\n$ BsmtFinType2  &lt;chr&gt; \"LwQ\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", …\n$ BsmtFinSF2    &lt;dbl&gt; 144, 0, 0, 0, 0, 0, 0, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF     &lt;dbl&gt; 270, 406, 137, 324, 1017, 763, 233, 789, 663, 0, 354, 32…\n$ TotalBsmtSF   &lt;dbl&gt; 882, 1329, 928, 926, 1280, 763, 1168, 789, 1300, 882, 14…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Gd\", \"Gd\", \"T…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 896, 1329, 928, 926, 1280, 763, 1187, 789, 1341, 882, 13…\n$ `2ndFlrSF`    &lt;dbl&gt; 0, 0, 701, 678, 0, 892, 0, 676, 0, 0, 0, 504, 567, 601, …\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 896, 1329, 1629, 1604, 1280, 1655, 1187, 1465, 1341, 882…\n$ BsmtFullBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ HalfBath      &lt;dbl&gt; 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,…\n$ BedroomAbvGr  &lt;dbl&gt; 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ KitchenQual   &lt;chr&gt; \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"TA\", \"TA\", \"TA\", \"Gd\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 5, 6, 6, 7, 5, 7, 6, 7, 5, 4, 5, 5, 6, 6, 4, 10, 7, 7, 8…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,…\n$ FireplaceQu   &lt;chr&gt; NA, NA, \"TA\", \"Gd\", NA, \"TA\", NA, \"Gd\", \"Po\", NA, \"Fa\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ GarageFinish  &lt;chr&gt; \"Unf\", \"Unf\", \"Fin\", \"Fin\", \"RFn\", \"Fin\", \"Fin\", \"Fin\", …\n$ GarageCars    &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 3, 3, 3, 3,…\n$ GarageArea    &lt;dbl&gt; 730, 312, 482, 470, 506, 440, 420, 393, 506, 525, 511, 2…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 140, 393, 212, 360, 0, 157, 483, 0, 192, 240, 203, 275, …\n$ OpenPorchSF   &lt;dbl&gt; 0, 36, 34, 36, 82, 84, 21, 75, 0, 0, 68, 0, 0, 0, 30, 13…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ScreenPorch   &lt;dbl&gt; 120, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; \"MnPrv\", NA, \"MnPrv\", NA, NA, NA, \"GdPrv\", NA, NA, \"MnPr…\n$ MiscFeature   &lt;chr&gt; NA, \"Gar2\", NA, NA, NA, NA, \"Shed\", NA, NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 12500, 0, 0, 0, 0, 500, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ MoSold        &lt;dbl&gt; 6, 6, 3, 6, 1, 4, 3, 5, 2, 4, 6, 2, 3, 6, 6, 1, 6, 6, 2,…\n$ YrSold        &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Norma…",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#plotting",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#plotting",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#data-split",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#recipe",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\n\nCode\ndata_rec %&gt;% summary()\n\n\n# A tibble: 38 × 4\n   variable     type      role      source  \n   &lt;chr&gt;        &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 Id           &lt;chr [2]&gt; predictor original\n 2 MSSubClass   &lt;chr [2]&gt; predictor original\n 3 LotFrontage  &lt;chr [2]&gt; predictor original\n 4 LotArea      &lt;chr [2]&gt; predictor original\n 5 OverallQual  &lt;chr [2]&gt; predictor original\n 6 OverallCond  &lt;chr [2]&gt; predictor original\n 7 YearBuilt    &lt;chr [2]&gt; predictor original\n 8 YearRemodAdd &lt;chr [2]&gt; predictor original\n 9 MasVnrArea   &lt;chr [2]&gt; predictor original\n10 BsmtFinSF1   &lt;chr [2]&gt; predictor original\n# ℹ 28 more rows",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#model",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#model",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 100)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#workflow",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(lasso_tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#trainning",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "3.4 trainning",
    "text": "3.4 trainning\n\n3.4.1 train lasso model\n\n\nCode\nlasso_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 100 × 7\n    penalty .metric .estimator  mean     n std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 rmse    standard   0.340     1      NA Preprocessor1_Model01\n 2 1   e-10 rsq     standard   0.822     1      NA Preprocessor1_Model01\n 3 1.60e-10 rmse    standard   0.340     1      NA Preprocessor1_Model02\n 4 1.60e-10 rsq     standard   0.822     1      NA Preprocessor1_Model02\n 5 2.56e-10 rmse    standard   0.340     1      NA Preprocessor1_Model03\n 6 2.56e-10 rsq     standard   0.822     1      NA Preprocessor1_Model03\n 7 4.09e-10 rmse    standard   0.340     1      NA Preprocessor1_Model04\n 8 4.09e-10 rsq     standard   0.822     1      NA Preprocessor1_Model04\n 9 6.55e-10 rmse    standard   0.340     1      NA Preprocessor1_Model05\n10 6.55e-10 rsq     standard   0.822     1      NA Preprocessor1_Model05\n# ℹ 90 more rows",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#evaluate",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nautoplot(lasso_res)\n\n\n\n\n\n\n\n\n\nuse best tune model for final fit\n\n\nCode\nlowest_rmse &lt;- lasso_res %&gt;%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n\n\n# A tibble: 1 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#last-fit",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "4.2 last fit",
    "text": "4.2 last fit\n\n\nCode\nfinal_res &lt;- \n  final_wf %&gt;%\n  last_fit(data_split) \n\n\n\n\nCode\nfinal_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#resample-with-tuned-model",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#resample-with-tuned-model",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "4.3 resample with tuned model",
    "text": "4.3 resample with tuned model",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "recipe.html",
    "href": "recipe.html",
    "title": "recipe",
    "section": "",
    "text": "create recipe step_xxx\n\ntree_rec &lt;- recipe(legal_status ~ ., data = trees_train) %&gt;%\n  \n # update the role for tree_id, since this is a variable we might like to keep around for convenience as an identifier for rows but is not a predictor or outcome. \n  update_role(tree_id, new_role = \"ID\") %&gt;%\n  \n# step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step, there were 300+ species!\n  step_other(species, caretaker, threshold = 0.01) %&gt;%\n  \n# create dummy for nominal data exclude outcome\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  \n# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date, given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.  \n  step_date(date, features = c(\"year\")) %&gt;%step_rm(date) %&gt;%\n  \n# There are many more DPW maintained trees than not, so let’s downsample the data for training.  \n  step_downsample(legal_status)%&gt;%\n\n# will remove all. predictor variables that contain only a single value\n    step_zv(all_numeric(all_predictors())) %&gt;% \n  \n#  normalize all numeric data\n  step_normalize(all_numeric()) %&gt;% \n\n# use KNN to impute all predictors\nstep_impute_knn(all_predictors()) \n\n\n\ncheck recipe check_xxx\n\n#&gt; [1] \"check_class\"      \"check_cols\"       \"check_missing\"   \n#&gt; [4] \"check_name\"       \"check_new_data\"   \"check_new_values\"\n#&gt; [7] \"check_range\"      \"check_type\"\n\n\n\nroles to select variables\nIn most cases, the right approach for users will be use to use the predictor-specific selectors such as all_numeric_predictors() and all_nominal_predictors().\n\nhas_role(match = \"predictor\")\n\nhas_type(match = \"numeric\")\n\nall_outcomes()\n\nall_predictors()\n\nall_date()\n\nall_date_predictors()\n\nall_datetime()\n\nall_datetime_predictors()\n\nall_double()\n\nall_double_predictors()\n\nall_factor()\n\nall_factor_predictors()\n\nall_integer()\n\nall_integer_predictors()\n\nall_logical()\n\nall_logical_predictors()\n\nall_nominal()\n\nall_nominal_predictors()\n\nall_numeric()\n\nall_numeric_predictors()\n\nall_ordered()\n\nall_ordered_predictors()\n\nall_string()\n\nall_string_predictors()\n\nall_unordered()\n\nall_unordered_predictors()\n\ncurrent_info()\n\n\n\nreference:\nhttps://recipes.tidymodels.org/reference/has_role.html\n\n\n\n\n Back to top"
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#read-data",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#eda",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#eda",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 1,460\nColumns: 81\n$ Id            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ MSSubClass    &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 20,…\n$ MSZoning      &lt;chr&gt; \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RM\", \"R…\n$ LotFrontage   &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, NA, 51, 50, 70, 85, NA, 91, …\n$ LotArea       &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 612…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"Reg\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"FR2\", \"Inside\", \"Corner\", \"FR2\", \"Inside\", \"I…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"CollgCr\", \"Veenker\", \"CollgCr\", \"Crawfor\", \"NoRidge\", \"…\n$ Condition1    &lt;chr&gt; \"Norm\", \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", …\n$ HouseStyle    &lt;chr&gt; \"2Story\", \"1Story\", \"2Story\", \"2Story\", \"2Story\", \"1.5Fi…\n$ OverallQual   &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, 5,…\n$ OverallCond   &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, 19…\n$ YearRemodAdd  &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"G…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Shng\", \"VinylSd\", \"…\n$ MasVnrType    &lt;chr&gt; \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\",…\n$ MasVnrArea    &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306, …\n$ ExterQual     &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"PConc\", \"CBlock\", \"PConc\", \"BrkTil\", \"PConc\", \"Wood\", \"…\n$ BsmtQual      &lt;chr&gt; \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Ex\", \"Gd\", \"TA\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"Gd\", \"Mn\", \"No\", \"Av\", \"No\", \"Av\", \"Mn\", \"No\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"GLQ\", \"ALQ\", \"GLQ\", \"ALQ\", \"GLQ\", \"GLQ\", \"GLQ\", \"ALQ\", …\n$ BsmtFinSF1    &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, 99…\n$ BsmtFinType2  &lt;chr&gt; \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"BLQ\", …\n$ BsmtFinSF2    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ BsmtUnfSF     &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, 17…\n$ TotalBsmtSF   &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, 10…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"E…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077, …\n$ `2ndFlrSF`    &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, 0,…\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, 10…\n$ BsmtFullBath  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1,…\n$ HalfBath      &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,…\n$ BedroomAbvGr  &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ KitchenQual   &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6, 6…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0,…\n$ FireplaceQu   &lt;chr&gt; NA, \"TA\", \"TA\", \"Gd\", \"TA\", NA, \"Gd\", \"TA\", \"TA\", \"TA\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Detchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, 19…\n$ GarageFinish  &lt;chr&gt; \"RFn\", \"RFn\", \"RFn\", \"Unf\", \"RFn\", \"Unf\", \"RFn\", \"RFn\", …\n$ GarageCars    &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, 2,…\n$ GarageArea    &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384, 7…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Fa\", \"G…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 160…\n$ OpenPorchSF   &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 213,…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0, …\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ScreenPorch   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, …\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; NA, NA, NA, NA, NA, \"MnPrv\", NA, NA, NA, NA, NA, NA, NA,…\n$ MiscFeature   &lt;chr&gt; NA, NA, NA, NA, NA, \"Shed\", NA, \"Shed\", NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 700,…\n$ MoSold        &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, 10…\n$ YrSold        &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Abnorml\", \"Normal\", \"Norm…\n$ SalePrice     &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000, …\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 1,459\nColumns: 80\n$ Id            &lt;dbl&gt; 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 14…\n$ MSSubClass    &lt;dbl&gt; 20, 20, 60, 60, 120, 60, 20, 60, 20, 20, 120, 160, 160, …\n$ MSZoning      &lt;chr&gt; \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"R…\n$ LotFrontage   &lt;dbl&gt; 80, 81, 74, 78, 43, 75, NA, 63, 85, 70, 26, 21, 21, 24, …\n$ LotArea       &lt;dbl&gt; 11622, 14267, 13830, 9978, 5005, 10000, 7980, 8402, 1017…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"HLS\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"Inside\", \"Corne…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"NAmes\", \"NAmes\", \"Gilbert\", \"Gilbert\", \"StoneBr\", \"Gilb…\n$ Condition1    &lt;chr&gt; \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"1Fam\", \"1Fam\"…\n$ HouseStyle    &lt;chr&gt; \"1Story\", \"1Story\", \"2Story\", \"2Story\", \"1Story\", \"2Stor…\n$ OverallQual   &lt;dbl&gt; 5, 6, 5, 6, 8, 6, 6, 6, 7, 4, 7, 6, 5, 6, 7, 9, 8, 9, 8,…\n$ OverallCond   &lt;dbl&gt; 6, 6, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ YearRemodAdd  &lt;dbl&gt; 1961, 1958, 1998, 1998, 1992, 1994, 2007, 1998, 1990, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Hip\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gab…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ MasVnrType    &lt;chr&gt; \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"None\", \"N…\n$ MasVnrArea    &lt;dbl&gt; 0, 108, 0, 20, 0, 0, 0, 0, 0, 0, 0, 504, 492, 0, 0, 162,…\n$ ExterQual     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"CBlock\", \"CBlock\", \"PConc\", \"PConc\", \"PConc\", \"PConc\", …\n$ BsmtQual      &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Gd\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"Rec\", \"ALQ\", \"GLQ\", \"GLQ\", \"ALQ\", \"Unf\", \"ALQ\", \"Unf\", …\n$ BsmtFinSF1    &lt;dbl&gt; 468, 923, 791, 602, 263, 0, 935, 0, 637, 804, 1051, 156,…\n$ BsmtFinType2  &lt;chr&gt; \"LwQ\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", …\n$ BsmtFinSF2    &lt;dbl&gt; 144, 0, 0, 0, 0, 0, 0, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF     &lt;dbl&gt; 270, 406, 137, 324, 1017, 763, 233, 789, 663, 0, 354, 32…\n$ TotalBsmtSF   &lt;dbl&gt; 882, 1329, 928, 926, 1280, 763, 1168, 789, 1300, 882, 14…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Gd\", \"Gd\", \"T…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 896, 1329, 928, 926, 1280, 763, 1187, 789, 1341, 882, 13…\n$ `2ndFlrSF`    &lt;dbl&gt; 0, 0, 701, 678, 0, 892, 0, 676, 0, 0, 0, 504, 567, 601, …\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 896, 1329, 1629, 1604, 1280, 1655, 1187, 1465, 1341, 882…\n$ BsmtFullBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ HalfBath      &lt;dbl&gt; 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,…\n$ BedroomAbvGr  &lt;dbl&gt; 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ KitchenQual   &lt;chr&gt; \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"TA\", \"TA\", \"TA\", \"Gd\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 5, 6, 6, 7, 5, 7, 6, 7, 5, 4, 5, 5, 6, 6, 4, 10, 7, 7, 8…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,…\n$ FireplaceQu   &lt;chr&gt; NA, NA, \"TA\", \"Gd\", NA, \"TA\", NA, \"Gd\", \"Po\", NA, \"Fa\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ GarageFinish  &lt;chr&gt; \"Unf\", \"Unf\", \"Fin\", \"Fin\", \"RFn\", \"Fin\", \"Fin\", \"Fin\", …\n$ GarageCars    &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 3, 3, 3, 3,…\n$ GarageArea    &lt;dbl&gt; 730, 312, 482, 470, 506, 440, 420, 393, 506, 525, 511, 2…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 140, 393, 212, 360, 0, 157, 483, 0, 192, 240, 203, 275, …\n$ OpenPorchSF   &lt;dbl&gt; 0, 36, 34, 36, 82, 84, 21, 75, 0, 0, 68, 0, 0, 0, 30, 13…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ScreenPorch   &lt;dbl&gt; 120, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; \"MnPrv\", NA, \"MnPrv\", NA, NA, NA, \"GdPrv\", NA, NA, \"MnPr…\n$ MiscFeature   &lt;chr&gt; NA, \"Gar2\", NA, NA, NA, NA, \"Shed\", NA, NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 12500, 0, 0, 0, 0, 500, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ MoSold        &lt;dbl&gt; 6, 6, 3, 6, 1, 4, 3, 5, 2, 4, 6, 2, 3, 6, 6, 1, 6, 6, 2,…\n$ YrSold        &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Norma…",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#plotting",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#plotting",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#data-split",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\nglimpse(train_df)\n\n\nRows: 1,460\nColumns: 38\n$ Id              &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ MSSubClass      &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 2…\n$ LotFrontage     &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, 0, 51, 50, 70, 85, 0, 91, …\n$ LotArea         &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 6…\n$ OverallQual     &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, …\n$ OverallCond     &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, …\n$ YearBuilt       &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, …\n$ YearRemodAdd    &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, …\n$ MasVnrArea      &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306…\n$ BsmtFinSF1      &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, …\n$ BsmtFinSF2      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF       &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, …\n$ TotalBsmtSF     &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, …\n$ `1stFlrSF`      &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077…\n$ `2ndFlrSF`      &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, …\n$ LowQualFinSF    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ GrLivArea       &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, …\n$ BsmtFullBath    &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, …\n$ BsmtHalfBath    &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FullBath        &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, …\n$ HalfBath        &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ BedroomAbvGr    &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, …\n$ KitchenAbvGr    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, …\n$ TotRmsAbvGrd    &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6,…\n$ Fireplaces      &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, …\n$ GarageYrBlt     &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, …\n$ GarageCars      &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, …\n$ GarageArea      &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384,…\n$ WoodDeckSF      &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 1…\n$ OpenPorchSF     &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 21…\n$ EnclosedPorch   &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0…\n$ `3SsnPorch`     &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ScreenPorch     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0…\n$ PoolArea        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ MiscVal         &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 70…\n$ MoSold          &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, …\n$ YrSold          &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, …\n$ target_variable &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000…\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#recipe",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#prep-the-recipe",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#prep-the-recipe",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#model",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#model",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\n\n3.5.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.5.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.5.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#trainning",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n3.6.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    180421.70         767.46       -8094.25         903.70        1599.01  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n     26128.59        5018.48        8945.07        2525.17        5672.04  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n      6631.92        1406.69        2868.07             NA       18015.90  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n     20898.31          28.81             NA        5099.47        1079.56  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n      2064.26        -865.84       -7429.07       -2969.90        6013.58  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n      2906.10       -7470.78       13312.87         454.85        2970.22  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n     -1630.78        -296.59        1206.28        2450.60       -2053.73  \n      MiscVal         MoSold         YrSold  \n      -145.90        -645.51       -1011.23  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term         estimate std.error statistic  p.value\n   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)   180422.     1149.   157.    0       \n 2 Id               767.     1165.     0.659 5.10e- 1\n 3 MSSubClass     -8094.     1437.    -5.63  2.29e- 8\n 4 LotFrontage      904.     1270.     0.712 4.77e- 1\n 5 LotArea         1599.     1297.     1.23  2.18e- 1\n 6 OverallQual    26129.     2093.    12.5   2.69e-33\n 7 OverallCond     5018.     1457.     3.44  5.98e- 4\n 8 YearBuilt       8945.     2329.     3.84  1.30e- 4\n 9 YearRemodAdd    2525.     1745.     1.45  1.48e- 1\n10 MasVnrArea      5672.     1375.     4.12  4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.6.2 train lasso model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00  63480\n2   1 10.62  57840\n3   1 19.45  52700\n4   1 26.77  48020\n5   2 32.89  43760\n6   2 39.26  39870\n7   2 44.56  36330\n8   2 48.95  33100\n9   3 52.79  30160\n10  4 56.28  27480\n11  5 59.43  25040\n12  5 62.05  22810\n13  5 64.22  20790\n14  5 66.03  18940\n15  5 67.53  17260\n16  5 68.77  15720\n17  5 69.80  14330\n18  7 70.71  13060\n19  9 71.66  11900\n20 10 72.51  10840\n21 10 73.26   9876\n22 10 73.87   8998\n23 11 74.40   8199\n24 11 74.86   7471\n25 13 75.37   6807\n26 13 75.86   6202\n27 13 76.28   5651\n28 13 76.64   5149\n29 13 76.95   4692\n30 13 77.21   4275\n31 13 77.42   3895\n32 14 77.60   3549\n33 14 77.75   3234\n34 15 77.88   2947\n35 15 77.99   2685\n36 16 78.09   2446\n37 17 78.27   2229\n38 19 78.44   2031\n39 20 78.62   1851\n40 21 78.76   1686\n41 22 78.90   1536\n42 23 79.03   1400\n43 24 79.14   1275\n44 25 79.24   1162\n45 25 79.32   1059\n46 25 79.39    965\n47 26 79.45    879\n48 26 79.50    801\n49 27 79.54    730\n50 28 79.59    665\n51 29 79.62    606\n52 30 79.65    552\n53 30 79.68    503\n54 31 79.70    458\n55 31 79.72    418\n56 31 79.73    381\n57 32 79.74    347\n58 33 79.75    316\n59 33 79.76    288\n60 34 79.77    262\n61 34 79.78    239\n62 33 79.78    218\n63 33 79.79    198\n64 33 79.79    181\n65 33 79.79    165\n66 33 79.80    150\n67 34 79.80    137\n68 35 79.80    125\n69 35 79.80    114\n70 35 79.80    104\n71 35 79.81     94\n72 35 79.81     86\n73 35 79.81     78\n74 35 79.81     71\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term         estimate penalty\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)   180422.     0.1\n 2 Id               684.     0.1\n 3 MSSubClass     -7967.     0.1\n 4 LotFrontage      867.     0.1\n 5 LotArea         1564.     0.1\n 6 OverallQual    26220.     0.1\n 7 OverallCond     4883.     0.1\n 8 YearBuilt       8728.     0.1\n 9 YearRemodAdd    2583.     0.1\n10 MasVnrArea      5657.     0.1\n# ℹ 28 more rows\n\n\n\n\n3.6.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1006353699 \nR squared (OOB):                  0.8438799",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#evaluate",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = train_juice) %&gt;%\n  mutate(\n    truth = train_juice$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = test_proc) %&gt;%\n  mutate(\n    truth = test_proc$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      36059.\n2 lm    rmse    standard      36055.\n3 rf    rmse    standard      13540.\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      31122.\n2 lm    rmse    standard      31139.\n3 rf    rmse    standard      28348.\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 3 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/Level 3 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Level 3 Regression Tidy Modeling",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- rf_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   30645.       10 2324.     Preprocessor1_Model1\n2 rsq     standard       0.859    10    0.0218 Preprocessor1_Model1\n\n\n\n\nCode\nlasso_res &lt;- lasso_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nlasso_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   39201.       10 4620.     Preprocessor1_Model1\n2 rsq     standard       0.769    10    0.0422 Preprocessor1_Model1\n\n\n\n\nCode\nlm_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nlm_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46227.        1      NA Preprocessor1_Model1\n2 rsq     standard       0.830     1      NA Preprocessor1_Model1\n\n\nShow all resample result:\n\n\nCode\nrf_res %&gt;%\n  unnest(.predictions) %&gt;%\n  ggplot(aes(target_variable, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  labs(\n    x = \"Truth\",\n    y = \"Prediction\",\n    color = NULL\n  )\n\n\n\n\n\n\n\n\n\nShow each resample result:\n\n\nCode\nlibrary(gganimate)\n\np=rf_res %&gt;%\n  unnest(.predictions) %&gt;%\n  ggplot(aes(target_variable, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  labs(\n    x = \"Truth\",\n    y = \"Prediction\",\n    color = NULL\n  )+transition_states(id)\n\np",
    "crumbs": [
      "house price regression model",
      "Level 3 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#read-data",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#eda",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#eda",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 1,460\nColumns: 81\n$ Id            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…\n$ MSSubClass    &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 20,…\n$ MSZoning      &lt;chr&gt; \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RM\", \"R…\n$ LotFrontage   &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, NA, 51, 50, 70, 85, NA, 91, …\n$ LotArea       &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 612…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"Reg\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"FR2\", \"Inside\", \"Corner\", \"FR2\", \"Inside\", \"I…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"CollgCr\", \"Veenker\", \"CollgCr\", \"Crawfor\", \"NoRidge\", \"…\n$ Condition1    &lt;chr&gt; \"Norm\", \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", …\n$ HouseStyle    &lt;chr&gt; \"2Story\", \"1Story\", \"2Story\", \"2Story\", \"2Story\", \"1.5Fi…\n$ OverallQual   &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, 5,…\n$ OverallCond   &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, 19…\n$ YearRemodAdd  &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"G…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"MetalSd\", \"VinylSd\", \"Wd Shng\", \"VinylSd\", \"…\n$ MasVnrType    &lt;chr&gt; \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\",…\n$ MasVnrArea    &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306, …\n$ ExterQual     &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"PConc\", \"CBlock\", \"PConc\", \"BrkTil\", \"PConc\", \"Wood\", \"…\n$ BsmtQual      &lt;chr&gt; \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Ex\", \"Gd\", \"TA\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"Gd\", \"Mn\", \"No\", \"Av\", \"No\", \"Av\", \"Mn\", \"No\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"GLQ\", \"ALQ\", \"GLQ\", \"ALQ\", \"GLQ\", \"GLQ\", \"GLQ\", \"ALQ\", …\n$ BsmtFinSF1    &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, 99…\n$ BsmtFinType2  &lt;chr&gt; \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"BLQ\", …\n$ BsmtFinSF2    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ BsmtUnfSF     &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, 17…\n$ TotalBsmtSF   &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, 10…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Ex\", \"Ex\", \"Ex\", \"Gd\", \"E…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077, …\n$ `2ndFlrSF`    &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, 0,…\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, 10…\n$ BsmtFullBath  &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1,…\n$ HalfBath      &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,…\n$ BedroomAbvGr  &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1,…\n$ KitchenQual   &lt;chr&gt; \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6, 6…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0,…\n$ FireplaceQu   &lt;chr&gt; NA, \"TA\", \"TA\", \"Gd\", \"TA\", NA, \"Gd\", \"TA\", \"TA\", \"TA\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Detchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, 19…\n$ GarageFinish  &lt;chr&gt; \"RFn\", \"RFn\", \"RFn\", \"Unf\", \"RFn\", \"Unf\", \"RFn\", \"RFn\", …\n$ GarageCars    &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, 2,…\n$ GarageArea    &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384, 7…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Fa\", \"G…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 160…\n$ OpenPorchSF   &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 213,…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0, …\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ScreenPorch   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0, …\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; NA, NA, NA, NA, NA, \"MnPrv\", NA, NA, NA, NA, NA, NA, NA,…\n$ MiscFeature   &lt;chr&gt; NA, NA, NA, NA, NA, \"Shed\", NA, \"Shed\", NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 700,…\n$ MoSold        &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, 10…\n$ YrSold        &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Abnorml\", \"Normal\", \"Norm…\n$ SalePrice     &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000, …\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 1,459\nColumns: 80\n$ Id            &lt;dbl&gt; 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 14…\n$ MSSubClass    &lt;dbl&gt; 20, 20, 60, 60, 120, 60, 20, 60, 20, 20, 120, 160, 160, …\n$ MSZoning      &lt;chr&gt; \"RH\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"RL\", \"R…\n$ LotFrontage   &lt;dbl&gt; 80, 81, 74, 78, 43, 75, NA, 63, 85, 70, 26, 21, 21, 24, …\n$ LotArea       &lt;dbl&gt; 11622, 14267, 13830, 9978, 5005, 10000, 7980, 8402, 1017…\n$ Street        &lt;chr&gt; \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", \"Pave\", …\n$ Alley         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ LotShape      &lt;chr&gt; \"Reg\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", \"IR1\", …\n$ LandContour   &lt;chr&gt; \"Lvl\", \"Lvl\", \"Lvl\", \"Lvl\", \"HLS\", \"Lvl\", \"Lvl\", \"Lvl\", …\n$ Utilities     &lt;chr&gt; \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPub\", \"AllPu…\n$ LotConfig     &lt;chr&gt; \"Inside\", \"Corner\", \"Inside\", \"Inside\", \"Inside\", \"Corne…\n$ LandSlope     &lt;chr&gt; \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", \"Gtl\", …\n$ Neighborhood  &lt;chr&gt; \"NAmes\", \"NAmes\", \"Gilbert\", \"Gilbert\", \"StoneBr\", \"Gilb…\n$ Condition1    &lt;chr&gt; \"Feedr\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\",…\n$ Condition2    &lt;chr&gt; \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", \"Norm\", …\n$ BldgType      &lt;chr&gt; \"1Fam\", \"1Fam\", \"1Fam\", \"1Fam\", \"TwnhsE\", \"1Fam\", \"1Fam\"…\n$ HouseStyle    &lt;chr&gt; \"1Story\", \"1Story\", \"2Story\", \"2Story\", \"1Story\", \"2Stor…\n$ OverallQual   &lt;dbl&gt; 5, 6, 5, 6, 8, 6, 6, 6, 7, 4, 7, 6, 5, 6, 7, 9, 8, 9, 8,…\n$ OverallCond   &lt;dbl&gt; 6, 6, 5, 6, 5, 5, 7, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5,…\n$ YearBuilt     &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ YearRemodAdd  &lt;dbl&gt; 1961, 1958, 1998, 1998, 1992, 1994, 2007, 1998, 1990, 19…\n$ RoofStyle     &lt;chr&gt; \"Gable\", \"Hip\", \"Gable\", \"Gable\", \"Gable\", \"Gable\", \"Gab…\n$ RoofMatl      &lt;chr&gt; \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"CompShg\", \"…\n$ Exterior1st   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ Exterior2nd   &lt;chr&gt; \"VinylSd\", \"Wd Sdng\", \"VinylSd\", \"VinylSd\", \"HdBoard\", \"…\n$ MasVnrType    &lt;chr&gt; \"None\", \"BrkFace\", \"None\", \"BrkFace\", \"None\", \"None\", \"N…\n$ MasVnrArea    &lt;dbl&gt; 0, 108, 0, 20, 0, 0, 0, 0, 0, 0, 0, 504, 492, 0, 0, 162,…\n$ ExterQual     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ ExterCond     &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"Gd\", \"TA\", \"TA\", \"T…\n$ Foundation    &lt;chr&gt; \"CBlock\", \"CBlock\", \"PConc\", \"PConc\", \"PConc\", \"PConc\", …\n$ BsmtQual      &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"Gd\", \"T…\n$ BsmtCond      &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ BsmtExposure  &lt;chr&gt; \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"Gd\", \"N…\n$ BsmtFinType1  &lt;chr&gt; \"Rec\", \"ALQ\", \"GLQ\", \"GLQ\", \"ALQ\", \"Unf\", \"ALQ\", \"Unf\", …\n$ BsmtFinSF1    &lt;dbl&gt; 468, 923, 791, 602, 263, 0, 935, 0, 637, 804, 1051, 156,…\n$ BsmtFinType2  &lt;chr&gt; \"LwQ\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", \"Unf\", …\n$ BsmtFinSF2    &lt;dbl&gt; 144, 0, 0, 0, 0, 0, 0, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF     &lt;dbl&gt; 270, 406, 137, 324, 1017, 763, 233, 789, 663, 0, 354, 32…\n$ TotalBsmtSF   &lt;dbl&gt; 882, 1329, 928, 926, 1280, 763, 1168, 789, 1300, 882, 14…\n$ Heating       &lt;chr&gt; \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", \"GasA\", …\n$ HeatingQC     &lt;chr&gt; \"TA\", \"TA\", \"Gd\", \"Ex\", \"Ex\", \"Gd\", \"Ex\", \"Gd\", \"Gd\", \"T…\n$ CentralAir    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ Electrical    &lt;chr&gt; \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"SBrkr\", \"S…\n$ `1stFlrSF`    &lt;dbl&gt; 896, 1329, 928, 926, 1280, 763, 1187, 789, 1341, 882, 13…\n$ `2ndFlrSF`    &lt;dbl&gt; 0, 0, 701, 678, 0, 892, 0, 676, 0, 0, 0, 504, 567, 601, …\n$ LowQualFinSF  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ GrLivArea     &lt;dbl&gt; 896, 1329, 1629, 1604, 1280, 1655, 1187, 1465, 1341, 882…\n$ BsmtFullBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtHalfBath  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FullBath      &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2,…\n$ HalfBath      &lt;dbl&gt; 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,…\n$ BedroomAbvGr  &lt;dbl&gt; 2, 3, 3, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 3,…\n$ KitchenAbvGr  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ KitchenQual   &lt;chr&gt; \"TA\", \"Gd\", \"TA\", \"Gd\", \"Gd\", \"TA\", \"TA\", \"TA\", \"Gd\", \"T…\n$ TotRmsAbvGrd  &lt;dbl&gt; 5, 6, 6, 7, 5, 7, 6, 7, 5, 4, 5, 5, 6, 6, 4, 10, 7, 7, 8…\n$ Functional    &lt;chr&gt; \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", \"Typ\", …\n$ Fireplaces    &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,…\n$ FireplaceQu   &lt;chr&gt; NA, NA, \"TA\", \"Gd\", NA, \"TA\", NA, \"Gd\", \"Po\", NA, \"Fa\", …\n$ GarageType    &lt;chr&gt; \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attchd\", \"Attch…\n$ GarageYrBlt   &lt;dbl&gt; 1961, 1958, 1997, 1998, 1992, 1993, 1992, 1998, 1990, 19…\n$ GarageFinish  &lt;chr&gt; \"Unf\", \"Unf\", \"Fin\", \"Fin\", \"RFn\", \"Fin\", \"Fin\", \"Fin\", …\n$ GarageCars    &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 3, 3, 3, 3,…\n$ GarageArea    &lt;dbl&gt; 730, 312, 482, 470, 506, 440, 420, 393, 506, 525, 511, 2…\n$ GarageQual    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ GarageCond    &lt;chr&gt; \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"TA\", \"T…\n$ PavedDrive    &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"Y\", \"…\n$ WoodDeckSF    &lt;dbl&gt; 140, 393, 212, 360, 0, 157, 483, 0, 192, 240, 203, 275, …\n$ OpenPorchSF   &lt;dbl&gt; 0, 36, 34, 36, 82, 84, 21, 75, 0, 0, 68, 0, 0, 0, 30, 13…\n$ EnclosedPorch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ `3SsnPorch`   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ScreenPorch   &lt;dbl&gt; 120, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PoolArea      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ PoolQC        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Fence         &lt;chr&gt; \"MnPrv\", NA, \"MnPrv\", NA, NA, NA, \"GdPrv\", NA, NA, \"MnPr…\n$ MiscFeature   &lt;chr&gt; NA, \"Gar2\", NA, NA, NA, NA, \"Shed\", NA, NA, NA, NA, NA, …\n$ MiscVal       &lt;dbl&gt; 0, 12500, 0, 0, 0, 0, 500, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ MoSold        &lt;dbl&gt; 6, 6, 3, 6, 1, 4, 3, 5, 2, 4, 6, 2, 3, 6, 6, 1, 6, 6, 2,…\n$ YrSold        &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…\n$ SaleType      &lt;chr&gt; \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"WD\", \"W…\n$ SaleCondition &lt;chr&gt; \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Normal\", \"Norma…",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#plotting",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#plotting",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#data-split",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#recipe",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#prep-the-recipe",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#prep-the-recipe",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#model",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#model",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\n\n3.5.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.5.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.5.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#trainning",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n3.6.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    5.669e-16      9.559e-03     -1.008e-01      1.126e-02      1.992e-02  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n    3.254e-01      6.251e-02      1.114e-01      3.145e-02      7.065e-02  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n    8.260e-02      1.752e-02      3.572e-02             NA      2.244e-01  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n    2.603e-01      3.589e-04             NA      6.352e-02      1.345e-02  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n    2.571e-02     -1.078e-02     -9.253e-02     -3.699e-02      7.490e-02  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n    3.620e-02     -9.305e-02      1.658e-01      5.665e-03      3.699e-02  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n   -2.031e-02     -3.694e-03      1.502e-02      3.052e-02     -2.558e-02  \n      MiscVal         MoSold         YrSold  \n   -1.817e-03     -8.040e-03     -1.260e-02  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term          estimate std.error statistic  p.value\n   &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)   5.67e-16    0.0143  3.96e-14 1.00e+ 0\n 2 Id            9.56e- 3    0.0145  6.59e- 1 5.10e- 1\n 3 MSSubClass   -1.01e- 1    0.0179 -5.63e+ 0 2.29e- 8\n 4 LotFrontage   1.13e- 2    0.0158  7.12e- 1 4.77e- 1\n 5 LotArea       1.99e- 2    0.0162  1.23e+ 0 2.18e- 1\n 6 OverallQual   3.25e- 1    0.0261  1.25e+ 1 2.69e-33\n 7 OverallCond   6.25e- 2    0.0182  3.44e+ 0 5.98e- 4\n 8 YearBuilt     1.11e- 1    0.0290  3.84e+ 0 1.30e- 4\n 9 YearRemodAdd  3.15e- 2    0.0217  1.45e+ 0 1.48e- 1\n10 MasVnrArea    7.06e- 2    0.0171  4.12e+ 0 4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.6.2 train lasso model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev  Lambda\n1   0  0.00 0.79070\n2   1 10.62 0.72040\n3   1 19.45 0.65640\n4   1 26.77 0.59810\n5   2 32.89 0.54500\n6   2 39.26 0.49660\n7   2 44.56 0.45250\n8   2 48.95 0.41230\n9   3 52.79 0.37560\n10  4 56.28 0.34230\n11  5 59.43 0.31190\n12  5 62.05 0.28420\n13  5 64.22 0.25890\n14  5 66.03 0.23590\n15  5 67.53 0.21500\n16  5 68.77 0.19590\n17  5 69.80 0.17850\n18  7 70.71 0.16260\n19  9 71.66 0.14820\n20 10 72.51 0.13500\n21 10 73.26 0.12300\n22 10 73.87 0.11210\n23 11 74.40 0.10210\n24 11 74.86 0.09305\n25 13 75.37 0.08478\n26 13 75.86 0.07725\n27 13 76.28 0.07039\n28 13 76.64 0.06413\n29 13 76.95 0.05844\n30 13 77.21 0.05325\n31 13 77.42 0.04852\n32 14 77.60 0.04421\n33 14 77.75 0.04028\n34 15 77.88 0.03670\n35 15 77.99 0.03344\n36 16 78.09 0.03047\n37 17 78.27 0.02776\n38 19 78.44 0.02530\n39 20 78.62 0.02305\n40 21 78.76 0.02100\n41 22 78.90 0.01914\n42 23 79.03 0.01744\n43 24 79.14 0.01589\n44 25 79.24 0.01448\n45 25 79.32 0.01319\n46 25 79.39 0.01202\n47 26 79.45 0.01095\n48 26 79.50 0.00998\n49 27 79.54 0.00909\n50 28 79.59 0.00828\n51 29 79.62 0.00755\n52 30 79.65 0.00688\n53 30 79.68 0.00627\n54 31 79.70 0.00571\n55 31 79.72 0.00520\n56 31 79.73 0.00474\n57 32 79.74 0.00432\n58 33 79.75 0.00394\n59 33 79.76 0.00359\n60 34 79.77 0.00327\n61 34 79.78 0.00298\n62 33 79.78 0.00271\n63 33 79.79 0.00247\n64 33 79.79 0.00225\n65 33 79.79 0.00205\n66 33 79.80 0.00187\n67 34 79.80 0.00170\n68 35 79.80 0.00155\n69 35 79.80 0.00141\n70 35 79.80 0.00129\n71 35 79.81 0.00117\n72 35 79.81 0.00107\n73 35 79.81 0.00097\n74 35 79.81 0.00089\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term         estimate penalty\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)  9.98e-17     0.1\n 2 Id           0            0.1\n 3 MSSubClass   0            0.1\n 4 LotFrontage  0            0.1\n 5 LotArea      0            0.1\n 6 OverallQual  3.79e- 1     0.1\n 7 OverallCond  0            0.1\n 8 YearBuilt    3.02e- 2     0.1\n 9 YearRemodAdd 2.31e- 2     0.1\n10 MasVnrArea   2.36e- 2     0.1\n# ℹ 28 more rows\n\n\n\n\n3.6.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       0.1557719 \nR squared (OOB):                  0.8442281",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#evaluate",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = train_juice) %&gt;%\n  mutate(\n    truth = train_juice$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = test_proc) %&gt;%\n  mutate(\n    truth = test_proc$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard       0.505\n2 lm    rmse    standard       0.449\n3 rf    rmse    standard       0.169\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard       0.459\n2 lm    rmse    standard       0.388\n3 rf    rmse    standard       0.353\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 2 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/Level 2 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Level 2 Regression Tidy Modeling",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46227.        1      NA Preprocessor1_Model1\n2 rsq     standard       0.830     1      NA Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Level 2 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "tensorflow dog vs cat/Level 1 picture recognition with tensorflow.html",
    "href": "tensorflow dog vs cat/Level 1 picture recognition with tensorflow.html",
    "title": "Level 0 Level 0 picture recognition with tensorflow",
    "section": "",
    "text": "1 dog cat data\n\n\nCode\n#install.packages(\"keras\")\n#library(keras)\n#install_keras()\n#install_tensorflow() \n\n\n\n\nCode\npackageVersion(\"keras\")\n\n\n[1] '2.13.0'\n\n\n\n\nCode\npackageVersion(\"tensorflow\")\n\n\n[1] '2.15.0.9000'\n\n\n\n\nCode\nlibrary(tensorflow)\n\n\n\n\nCode\ntf$constant(\"Hello TensorFlow!\")\n\n\ntf.Tensor(b'Hello TensorFlow!', shape=(), dtype=string)\n\n\n\n\n2 data\n\n\nCode\nlibrary(keras)\nmnist &lt;- dataset_mnist()\nx_train &lt;- mnist$train$x\ny_train &lt;- mnist$train$y\nx_test &lt;- mnist$test$x\ny_test &lt;- mnist$test$y\n\n\n\n\nCode\n# reshape\nx_train &lt;- array_reshape(x_train, c(nrow(x_train), 784))\nx_test &lt;- array_reshape(x_test, c(nrow(x_test), 784))\n# rescale\nx_train &lt;- x_train / 255\nx_test &lt;- x_test / 255\n\n\n\n\nCode\ny_train &lt;- to_categorical(y_train, 10)\ny_test &lt;- to_categorical(y_test, 10)\n\n\n\n\n3 model\n\n\nCode\nmodel &lt;- keras_model_sequential() \nmodel %&gt;% \n  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %&gt;% \n  layer_dropout(rate = 0.4) %&gt;% \n  layer_dense(units = 128, activation = 'relu') %&gt;%\n  layer_dropout(rate = 0.3) %&gt;%\n  layer_dense(units = 10, activation = 'softmax')\n\n\n\n\nCode\nsummary(model)\n\n\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n dense_2 (Dense)                    (None, 256)                     200960      \n dropout_1 (Dropout)                (None, 256)                     0           \n dense_1 (Dense)                    (None, 128)                     32896       \n dropout (Dropout)                  (None, 128)                     0           \n dense (Dense)                      (None, 10)                      1290        \n================================================================================\nTotal params: 235146 (918.54 KB)\nTrainable params: 235146 (918.54 KB)\nNon-trainable params: 0 (0.00 Byte)\n________________________________________________________________________________\n\n\n\n\nCode\nmodel %&gt;% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_rmsprop(),\n  metrics = c('accuracy')\n)\n\n\n\n\nCode\nhistory &lt;- model %&gt;% fit(\n  x_train, y_train, \n  epochs = 20, batch_size = 128, \n  validation_split = 0.2\n)\n\n\nEpoch 1/20\n375/375 - 1s - loss: 0.4425 - accuracy: 0.8670 - val_loss: 0.1643 - val_accuracy: 0.9517 - 853ms/epoch - 2ms/step\nEpoch 2/20\n375/375 - 1s - loss: 0.2071 - accuracy: 0.9390 - val_loss: 0.1226 - val_accuracy: 0.9651 - 671ms/epoch - 2ms/step\nEpoch 3/20\n375/375 - 1s - loss: 0.1565 - accuracy: 0.9542 - val_loss: 0.1016 - val_accuracy: 0.9709 - 664ms/epoch - 2ms/step\nEpoch 4/20\n375/375 - 1s - loss: 0.1324 - accuracy: 0.9602 - val_loss: 0.0935 - val_accuracy: 0.9725 - 655ms/epoch - 2ms/step\nEpoch 5/20\n375/375 - 1s - loss: 0.1188 - accuracy: 0.9649 - val_loss: 0.0886 - val_accuracy: 0.9742 - 660ms/epoch - 2ms/step\nEpoch 6/20\n375/375 - 1s - loss: 0.1068 - accuracy: 0.9685 - val_loss: 0.0872 - val_accuracy: 0.9760 - 648ms/epoch - 2ms/step\nEpoch 7/20\n375/375 - 1s - loss: 0.0947 - accuracy: 0.9719 - val_loss: 0.0857 - val_accuracy: 0.9758 - 657ms/epoch - 2ms/step\nEpoch 8/20\n375/375 - 1s - loss: 0.0871 - accuracy: 0.9737 - val_loss: 0.0829 - val_accuracy: 0.9778 - 650ms/epoch - 2ms/step\nEpoch 9/20\n375/375 - 1s - loss: 0.0818 - accuracy: 0.9754 - val_loss: 0.0814 - val_accuracy: 0.9783 - 667ms/epoch - 2ms/step\nEpoch 10/20\n375/375 - 1s - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.0840 - val_accuracy: 0.9783 - 645ms/epoch - 2ms/step\nEpoch 11/20\n375/375 - 1s - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.0808 - val_accuracy: 0.9795 - 656ms/epoch - 2ms/step\nEpoch 12/20\n375/375 - 1s - loss: 0.0715 - accuracy: 0.9793 - val_loss: 0.0872 - val_accuracy: 0.9783 - 662ms/epoch - 2ms/step\nEpoch 13/20\n375/375 - 1s - loss: 0.0686 - accuracy: 0.9792 - val_loss: 0.0788 - val_accuracy: 0.9786 - 637ms/epoch - 2ms/step\nEpoch 14/20\n375/375 - 1s - loss: 0.0657 - accuracy: 0.9801 - val_loss: 0.0784 - val_accuracy: 0.9802 - 713ms/epoch - 2ms/step\nEpoch 15/20\n375/375 - 1s - loss: 0.0639 - accuracy: 0.9799 - val_loss: 0.0851 - val_accuracy: 0.9777 - 644ms/epoch - 2ms/step\nEpoch 16/20\n375/375 - 1s - loss: 0.0585 - accuracy: 0.9818 - val_loss: 0.0863 - val_accuracy: 0.9795 - 640ms/epoch - 2ms/step\nEpoch 17/20\n375/375 - 1s - loss: 0.0556 - accuracy: 0.9837 - val_loss: 0.0853 - val_accuracy: 0.9795 - 644ms/epoch - 2ms/step\nEpoch 18/20\n375/375 - 1s - loss: 0.0585 - accuracy: 0.9824 - val_loss: 0.0860 - val_accuracy: 0.9798 - 636ms/epoch - 2ms/step\nEpoch 19/20\n375/375 - 1s - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0878 - val_accuracy: 0.9792 - 644ms/epoch - 2ms/step\nEpoch 20/20\n375/375 - 1s - loss: 0.0543 - accuracy: 0.9840 - val_loss: 0.0888 - val_accuracy: 0.9803 - 638ms/epoch - 2ms/step\n\n\n\n\nCode\nplot(history)\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel %&gt;% evaluate(x_test, y_test)\n\n\n313/313 - 0s - loss: 0.0773 - accuracy: 0.9810 - 121ms/epoch - 388us/step\n\n\n      loss   accuracy \n0.07734758 0.98100001 \n\n\n\n\nCode\npredictions &lt;- predict(model, x_test)%&gt;% k_argmax() \n\n\n313/313 - 0s - 130ms/epoch - 416us/step\n\n\nCode\nhead(predictions)\n\n\ntf.Tensor([7 2 1 0 4 1], shape=(6), dtype=int64)\n\n\n\n\n4 resource:\nhttps://cran.r-project.org/web/packages/keras/vignettes/\nhttps://tensorflow.rstudio.com/guides/keras/training_with_built_in_methods\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "resample.html",
    "href": "resample.html",
    "title": "resample",
    "section": "",
    "text": "k-Fold Cross-Validation\n\n\nk_flod_resample&lt;- vfold_cv(data, v = 10)\nk_flod_resample\n\n\n\nMONTE CARLO CROSS-VALIDATION\nfor MCCV, this proportion of the data is randomly selected each time. This results in assessment sets that are not mutually exclusive\n\nmc_resample&lt;- mc_cv(data, prop = 9/10, times = 20)\nmc_resample\n\n\n\nThe Bootstrap\nA bootstrap sample of the training set is a sample that is the same size as the training set but is drawn with replacement\n\n\nbootstraps_resample&lt;- bootstraps(data, times = 1000)\nbootstraps_resample\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tensorflow dog vs cat/Level 0 picture recognition with tensorflow.html",
    "href": "tensorflow dog vs cat/Level 0 picture recognition with tensorflow.html",
    "title": "Level 0 Level 0 picture recognition with tensorflow",
    "section": "",
    "text": "1 install tensorflow\n\n\nCode\n# Requires the latest pip\npip install --upgrade pip\n\n\n\n\nCode\n# Requires the latest pip\npip install tensorflow\n\n\ncheck tensorflow version\n\n\nCode\nimport tensorflow as tf\n\nprint(tf.__version__)\n\n\n2.14.0\n\n\n\n\nCode\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n\n\n\nCode\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dropout(0.2),\n  tf.keras.layers.Dense(10)\n])\n\n\n\n\nCode\npredictions = model(x_train[:1]).numpy()\npredictions\n\n\narray([[ 0.00966743, -0.49575064,  0.30405563,  0.2072168 ,  0.55507463,\n         0.4276619 ,  0.24729648, -0.204224  , -0.84203595, -0.24444702]],\n      dtype=float32)\n\n\n\n\nCode\ntf.nn.softmax(predictions).numpy()\n\n\narray([[0.09357899, 0.05645184, 0.12561153, 0.11401787, 0.16145283,\n        0.14213827, 0.11868048, 0.07555904, 0.03992898, 0.07258014]],\n      dtype=float32)\n\n\n\n\nCode\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n\n\n\nCode\nloss_fn(y_train[:1], predictions).numpy()\n\n\n1.9509549\n\n\n\n\nCode\n\nmodel.compile(optimizer='adam',\n              loss=loss_fn,\n              metrics=['accuracy'])\n\n\n\n\nCode\nmodel.fit(x_train, y_train, epochs=5)\n\n\nEpoch 1/5\n\n   1/1875 [..............................] - ETA: 3:41 - loss: 2.2261 - accuracy: 0.1875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 103/1875 [&gt;.............................] - ETA: 0s - loss: 0.9372 - accuracy: 0.7345  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 210/1875 [==&gt;...........................] - ETA: 0s - loss: 0.6930 - accuracy: 0.8028\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 317/1875 [====&gt;.........................] - ETA: 0s - loss: 0.5860 - accuracy: 0.8331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 424/1875 [=====&gt;........................] - ETA: 0s - loss: 0.5225 - accuracy: 0.8508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 530/1875 [=======&gt;......................] - ETA: 0s - loss: 0.4763 - accuracy: 0.8639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 637/1875 [=========&gt;....................] - ETA: 0s - loss: 0.4470 - accuracy: 0.8723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 745/1875 [==========&gt;...................] - ETA: 0s - loss: 0.4245 - accuracy: 0.8785\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 852/1875 [============&gt;.................] - ETA: 0s - loss: 0.3999 - accuracy: 0.8859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 958/1875 [==============&gt;...............] - ETA: 0s - loss: 0.3820 - accuracy: 0.8909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1065/1875 [================&gt;.............] - ETA: 0s - loss: 0.3670 - accuracy: 0.8945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1172/1875 [=================&gt;............] - ETA: 0s - loss: 0.3533 - accuracy: 0.8983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1278/1875 [===================&gt;..........] - ETA: 0s - loss: 0.3423 - accuracy: 0.9016\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1384/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3330 - accuracy: 0.9042\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1491/1875 [======================&gt;.......] - ETA: 0s - loss: 0.3252 - accuracy: 0.9064\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1598/1875 [========================&gt;.....] - ETA: 0s - loss: 0.3157 - accuracy: 0.9092\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1706/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3073 - accuracy: 0.9115\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1814/1875 [============================&gt;.] - ETA: 0s - loss: 0.2989 - accuracy: 0.9140\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 473us/step - loss: 0.2946 - accuracy: 0.9152\nEpoch 2/5\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.2282 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 108/1875 [&gt;.............................] - ETA: 0s - loss: 0.1672 - accuracy: 0.9459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 216/1875 [==&gt;...........................] - ETA: 0s - loss: 0.1559 - accuracy: 0.9520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 324/1875 [====&gt;.........................] - ETA: 0s - loss: 0.1588 - accuracy: 0.9535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 431/1875 [=====&gt;........................] - ETA: 0s - loss: 0.1597 - accuracy: 0.9533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 536/1875 [=======&gt;......................] - ETA: 0s - loss: 0.1558 - accuracy: 0.9538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 643/1875 [=========&gt;....................] - ETA: 0s - loss: 0.1562 - accuracy: 0.9534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 750/1875 [===========&gt;..................] - ETA: 0s - loss: 0.1557 - accuracy: 0.9538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 856/1875 [============&gt;.................] - ETA: 0s - loss: 0.1555 - accuracy: 0.9538\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 961/1875 [==============&gt;...............] - ETA: 0s - loss: 0.1548 - accuracy: 0.9539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1066/1875 [================&gt;.............] - ETA: 0s - loss: 0.1529 - accuracy: 0.9539\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1173/1875 [=================&gt;............] - ETA: 0s - loss: 0.1527 - accuracy: 0.9545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1279/1875 [===================&gt;..........] - ETA: 0s - loss: 0.1510 - accuracy: 0.9548\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1383/1875 [=====================&gt;........] - ETA: 0s - loss: 0.1491 - accuracy: 0.9551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1490/1875 [======================&gt;.......] - ETA: 0s - loss: 0.1479 - accuracy: 0.9553\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1596/1875 [========================&gt;.....] - ETA: 0s - loss: 0.1468 - accuracy: 0.9559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1703/1875 [==========================&gt;...] - ETA: 0s - loss: 0.1454 - accuracy: 0.9563\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1810/1875 [===========================&gt;..] - ETA: 0s - loss: 0.1442 - accuracy: 0.9566\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 473us/step - loss: 0.1436 - accuracy: 0.9569\nEpoch 3/5\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.0717 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 108/1875 [&gt;.............................] - ETA: 0s - loss: 0.1030 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 216/1875 [==&gt;...........................] - ETA: 0s - loss: 0.1086 - accuracy: 0.9666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 322/1875 [====&gt;.........................] - ETA: 0s - loss: 0.1083 - accuracy: 0.9671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 430/1875 [=====&gt;........................] - ETA: 0s - loss: 0.1121 - accuracy: 0.9664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 537/1875 [=======&gt;......................] - ETA: 0s - loss: 0.1117 - accuracy: 0.9664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 632/1875 [=========&gt;....................] - ETA: 0s - loss: 0.1139 - accuracy: 0.9657\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 723/1875 [==========&gt;...................] - ETA: 0s - loss: 0.1163 - accuracy: 0.9649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 827/1875 [============&gt;.................] - ETA: 0s - loss: 0.1147 - accuracy: 0.9652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 933/1875 [=============&gt;................] - ETA: 0s - loss: 0.1142 - accuracy: 0.9655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1039/1875 [===============&gt;..............] - ETA: 0s - loss: 0.1146 - accuracy: 0.9657\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1146/1875 [=================&gt;............] - ETA: 0s - loss: 0.1137 - accuracy: 0.9659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1253/1875 [===================&gt;..........] - ETA: 0s - loss: 0.1127 - accuracy: 0.9660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1360/1875 [====================&gt;.........] - ETA: 0s - loss: 0.1117 - accuracy: 0.9660\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1467/1875 [======================&gt;.......] - ETA: 0s - loss: 0.1109 - accuracy: 0.9663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1572/1875 [========================&gt;.....] - ETA: 0s - loss: 0.1112 - accuracy: 0.9662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1678/1875 [=========================&gt;....] - ETA: 0s - loss: 0.1108 - accuracy: 0.9663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1785/1875 [===========================&gt;..] - ETA: 0s - loss: 0.1109 - accuracy: 0.9663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 478us/step - loss: 0.1099 - accuracy: 0.9667\nEpoch 4/5\n\n   1/1875 [..............................] - ETA: 1s - loss: 0.0411 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 108/1875 [&gt;.............................] - ETA: 0s - loss: 0.0769 - accuracy: 0.9754\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 215/1875 [==&gt;...........................] - ETA: 0s - loss: 0.0848 - accuracy: 0.9719\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 322/1875 [====&gt;.........................] - ETA: 0s - loss: 0.0909 - accuracy: 0.9702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 429/1875 [=====&gt;........................] - ETA: 0s - loss: 0.0885 - accuracy: 0.9710\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 537/1875 [=======&gt;......................] - ETA: 0s - loss: 0.0886 - accuracy: 0.9715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 644/1875 [=========&gt;....................] - ETA: 0s - loss: 0.0906 - accuracy: 0.9715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 750/1875 [===========&gt;..................] - ETA: 0s - loss: 0.0919 - accuracy: 0.9713\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 856/1875 [============&gt;.................] - ETA: 0s - loss: 0.0918 - accuracy: 0.9715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 962/1875 [==============&gt;...............] - ETA: 0s - loss: 0.0886 - accuracy: 0.9724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1069/1875 [================&gt;.............] - ETA: 0s - loss: 0.0868 - accuracy: 0.9729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1176/1875 [=================&gt;............] - ETA: 0s - loss: 0.0872 - accuracy: 0.9729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1244/1875 [==================&gt;...........] - ETA: 0s - loss: 0.0880 - accuracy: 0.9726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1343/1875 [====================&gt;.........] - ETA: 0s - loss: 0.0876 - accuracy: 0.9728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1445/1875 [======================&gt;.......] - ETA: 0s - loss: 0.0883 - accuracy: 0.9728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1550/1875 [=======================&gt;......] - ETA: 0s - loss: 0.0888 - accuracy: 0.9726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1655/1875 [=========================&gt;....] - ETA: 0s - loss: 0.0885 - accuracy: 0.9726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1758/1875 [===========================&gt;..] - ETA: 0s - loss: 0.0890 - accuracy: 0.9727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1863/1875 [============================&gt;.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 486us/step - loss: 0.0903 - accuracy: 0.9721\nEpoch 5/5\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 107/1875 [&gt;.............................] - ETA: 0s - loss: 0.0715 - accuracy: 0.9772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 213/1875 [==&gt;...........................] - ETA: 0s - loss: 0.0722 - accuracy: 0.9780\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 320/1875 [====&gt;.........................] - ETA: 0s - loss: 0.0727 - accuracy: 0.9781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 427/1875 [=====&gt;........................] - ETA: 0s - loss: 0.0728 - accuracy: 0.9769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 534/1875 [=======&gt;......................] - ETA: 0s - loss: 0.0730 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 639/1875 [=========&gt;....................] - ETA: 0s - loss: 0.0726 - accuracy: 0.9771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 745/1875 [==========&gt;...................] - ETA: 0s - loss: 0.0746 - accuracy: 0.9763\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 849/1875 [============&gt;.................] - ETA: 0s - loss: 0.0739 - accuracy: 0.9762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 955/1875 [==============&gt;...............] - ETA: 0s - loss: 0.0733 - accuracy: 0.9764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1062/1875 [===============&gt;..............] - ETA: 0s - loss: 0.0748 - accuracy: 0.9761\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1169/1875 [=================&gt;............] - ETA: 0s - loss: 0.0754 - accuracy: 0.9759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1276/1875 [===================&gt;..........] - ETA: 0s - loss: 0.0757 - accuracy: 0.9759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1383/1875 [=====================&gt;........] - ETA: 0s - loss: 0.0763 - accuracy: 0.9758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1490/1875 [======================&gt;.......] - ETA: 0s - loss: 0.0761 - accuracy: 0.9759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1597/1875 [========================&gt;.....] - ETA: 0s - loss: 0.0756 - accuracy: 0.9762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1704/1875 [==========================&gt;...] - ETA: 0s - loss: 0.0765 - accuracy: 0.9759\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1811/1875 [===========================&gt;..] - ETA: 0s - loss: 0.0757 - accuracy: 0.9761\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 472us/step - loss: 0.0756 - accuracy: 0.9760\n&lt;keras.src.callbacks.History object at 0x28a3485d0&gt;\n\n\n\n\nCode\nmodel.evaluate(x_test,  y_test, verbose=2)\n\n\n313/313 - 0s - loss: 0.0762 - accuracy: 0.9775 - 137ms/epoch - 438us/step\n[0.07622810453176498, 0.9775000214576721]\n\n\n\n\nCode\nprobability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])\n\n\n\n\nCode\nprobability_model(x_test[:5])\n\n\n&lt;tf.Tensor: shape=(5, 10), dtype=float32, numpy=\narray([[1.6884792e-08, 6.2359740e-09, 2.2839263e-06, 3.0109071e-04,\n        1.4157997e-11, 4.7969461e-08, 1.9358855e-14, 9.9968910e-01,\n        8.0746659e-08, 7.2519715e-06],\n       [2.4315270e-09, 3.8297239e-05, 9.9993598e-01, 2.5221627e-05,\n        1.6726798e-17, 4.7619244e-07, 2.2213504e-08, 5.4046335e-15,\n        1.3750172e-09, 1.6255697e-14],\n       [3.0869202e-07, 9.9876785e-01, 1.5246472e-05, 5.9393237e-06,\n        9.5862815e-06, 3.2575456e-06, 1.8949711e-05, 9.4002305e-04,\n        2.3831373e-04, 6.6376680e-07],\n       [9.9944800e-01, 6.7377753e-10, 1.2596110e-05, 5.7803149e-08,\n        1.3485007e-07, 7.6757260e-06, 5.3057430e-04, 6.4588119e-07,\n        2.9488630e-08, 2.8083522e-07],\n       [1.4407695e-07, 8.3753454e-10, 1.0728088e-05, 1.1517051e-06,\n        9.9814761e-01, 7.2193728e-08, 6.0818097e-06, 4.8544935e-05,\n        1.8324789e-06, 1.7838343e-03]], dtype=float32)&gt;\n\n\n\n\n2 resource:\nhttps://tensorflow.rstudio.com/examples/image_classification_from_scratch.html\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tensorflow/Level 0 picture recognition with tensorflow.html",
    "href": "tensorflow/Level 0 picture recognition with tensorflow.html",
    "title": "Level 0 picture recognition with tensorflow",
    "section": "",
    "text": "1 resource:\nML Zero to Hero: https://www.youtube.com/watch?v=bemDFpNooA8\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tensorflow",
      "Level 0 picture recognition with tensorflow"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 picture recognition with tensorflow.html",
    "href": "tensorflow/Level 1 picture recognition with tensorflow.html",
    "title": "Level 1 picture recognition with tensorflow",
    "section": "",
    "text": "Code\n# TensorFlow and tf.keras\nimport tensorflow as tf\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n\n\n2.14.0\n\n\n\n1 data\n\n\nCode\nfashion_mnist = tf.keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n\n\n\nCode\ntrain_images.shape\n\n\n(60000, 28, 28)\n\n\n\n\nCode\ntrain_labels.shape\n\n\n(60000,)\n\n\n\n\nCode\ntest_images.shape\n\n\n(10000, 28, 28)\n\n\n\n\nCode\ntest_labels.shape\n\n\n(10000,)\n\n\nBoth train and test have 10 calss 0-9\n\n\nCode\nset(train_labels)\n\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\n\nCode\nset(test_labels)\n\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\n\nCode\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\n\n\nCode\nplt.figure()\nplt.imshow(train_images[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()\n\n\n\n\n\n\n\n\n\nScale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It’s important that the training set and the testing set be preprocessed in the same way:\nall of the values in the number are between 0 and 255. If you are training a neural network especially in image processing, for various reasons it will usually learn better if you scale all values to between 0 and 1. It’s a process called normalization\n\n\nCode\ntrain_images = train_images / 255.0\n\ntest_images = test_images / 255.0\n\n\n\n\nCode\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n2 model\n\n\nCode\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10)\n])\n\n\n\n\n3 Compile the model\n\n\nCode\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n\n\n4 call back\n\n\nCode\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    '''\n    Halts the training when the loss falls below 0.3\n\n    Args:\n      epoch (integer) - index of epoch (required but unused in the function definition below)\n      logs (dict) - metric results from the training epoch\n    '''\n\n    # Check the loss\n    if(logs.get('loss') &lt; 0.3):\n\n      # Stop if threshold is met\n      print(\"\\nLoss is lower than 0.3 so cancelling training!\")\n      self.model.stop_training = True\n\n# Instantiate class\ncallbacks = myCallback()\n\n\n\n\n5 training\n\n\nCode\nhistory=model.fit(train_images, train_labels, epochs=10,callbacks=[callbacks])\n\n\nEpoch 1/10\n   1/1875 [..............................] - ETA: 3:36 - loss: 2.6772 - accuracy: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  97/1875 [&gt;.............................] - ETA: 0s - loss: 1.0649 - accuracy: 0.6366  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 196/1875 [==&gt;...........................] - ETA: 0s - loss: 0.8781 - accuracy: 0.7006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 296/1875 [===&gt;..........................] - ETA: 0s - loss: 0.7963 - accuracy: 0.7275\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 397/1875 [=====&gt;........................] - ETA: 0s - loss: 0.7391 - accuracy: 0.7467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 498/1875 [======&gt;.......................] - ETA: 0s - loss: 0.6974 - accuracy: 0.7601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 599/1875 [========&gt;.....................] - ETA: 0s - loss: 0.6646 - accuracy: 0.7705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 699/1875 [==========&gt;...................] - ETA: 0s - loss: 0.6427 - accuracy: 0.7778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 800/1875 [===========&gt;..................] - ETA: 0s - loss: 0.6265 - accuracy: 0.7828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 901/1875 [=============&gt;................] - ETA: 0s - loss: 0.6139 - accuracy: 0.7859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1002/1875 [===============&gt;..............] - ETA: 0s - loss: 0.6016 - accuracy: 0.7900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1104/1875 [================&gt;.............] - ETA: 0s - loss: 0.5911 - accuracy: 0.7945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1205/1875 [==================&gt;...........] - ETA: 0s - loss: 0.5816 - accuracy: 0.7970\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1306/1875 [===================&gt;..........] - ETA: 0s - loss: 0.5712 - accuracy: 0.8005\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1407/1875 [=====================&gt;........] - ETA: 0s - loss: 0.5628 - accuracy: 0.8030\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1508/1875 [=======================&gt;......] - ETA: 0s - loss: 0.5551 - accuracy: 0.8050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1609/1875 [========================&gt;.....] - ETA: 0s - loss: 0.5487 - accuracy: 0.8068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1708/1875 [==========================&gt;...] - ETA: 0s - loss: 0.5428 - accuracy: 0.8088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1808/1875 [===========================&gt;..] - ETA: 0s - loss: 0.5379 - accuracy: 0.8105\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 501us/step - loss: 0.5327 - accuracy: 0.8120\nEpoch 2/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.5916 - accuracy: 0.7188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 102/1875 [&gt;.............................] - ETA: 0s - loss: 0.4148 - accuracy: 0.8490\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 203/1875 [==&gt;...........................] - ETA: 0s - loss: 0.4153 - accuracy: 0.8464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 305/1875 [===&gt;..........................] - ETA: 0s - loss: 0.4060 - accuracy: 0.8496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 406/1875 [=====&gt;........................] - ETA: 0s - loss: 0.4041 - accuracy: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 506/1875 [=======&gt;......................] - ETA: 0s - loss: 0.4094 - accuracy: 0.8502\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 608/1875 [========&gt;.....................] - ETA: 0s - loss: 0.4086 - accuracy: 0.8517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 710/1875 [==========&gt;...................] - ETA: 0s - loss: 0.4088 - accuracy: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 811/1875 [===========&gt;..................] - ETA: 0s - loss: 0.4062 - accuracy: 0.8534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 912/1875 [=============&gt;................] - ETA: 0s - loss: 0.4055 - accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1014/1875 [===============&gt;..............] - ETA: 0s - loss: 0.4050 - accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1115/1875 [================&gt;.............] - ETA: 0s - loss: 0.4051 - accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1217/1875 [==================&gt;...........] - ETA: 0s - loss: 0.4036 - accuracy: 0.8541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1320/1875 [====================&gt;.........] - ETA: 0s - loss: 0.4033 - accuracy: 0.8542\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1420/1875 [=====================&gt;........] - ETA: 0s - loss: 0.4033 - accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1521/1875 [=======================&gt;......] - ETA: 0s - loss: 0.4033 - accuracy: 0.8537\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1623/1875 [========================&gt;.....] - ETA: 0s - loss: 0.4012 - accuracy: 0.8542\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1724/1875 [==========================&gt;...] - ETA: 0s - loss: 0.4002 - accuracy: 0.8543\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1826/1875 [============================&gt;.] - ETA: 0s - loss: 0.3985 - accuracy: 0.8546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 496us/step - loss: 0.3989 - accuracy: 0.8545\nEpoch 3/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.5280 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 104/1875 [&gt;.............................] - ETA: 0s - loss: 0.3491 - accuracy: 0.8699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 206/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3605 - accuracy: 0.8653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 308/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3690 - accuracy: 0.8628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 410/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3723 - accuracy: 0.8633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 512/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3694 - accuracy: 0.8652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 612/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3711 - accuracy: 0.8649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 713/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3698 - accuracy: 0.8658\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 815/1875 [============&gt;.................] - ETA: 0s - loss: 0.3721 - accuracy: 0.8656\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 916/1875 [=============&gt;................] - ETA: 0s - loss: 0.3701 - accuracy: 0.8665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1021/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3691 - accuracy: 0.8662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1123/1875 [================&gt;.............] - ETA: 0s - loss: 0.3674 - accuracy: 0.8670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1225/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3669 - accuracy: 0.8670\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1326/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3668 - accuracy: 0.8671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1427/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3669 - accuracy: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1529/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3672 - accuracy: 0.8668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1629/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3670 - accuracy: 0.8668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1731/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3667 - accuracy: 0.8667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1832/1875 [============================&gt;.] - ETA: 0s - loss: 0.3665 - accuracy: 0.8664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 495us/step - loss: 0.3666 - accuracy: 0.8664\nEpoch 4/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.5138 - accuracy: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 102/1875 [&gt;.............................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 203/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8708\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 304/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3402 - accuracy: 0.8718\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 405/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3413 - accuracy: 0.8715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 507/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3421 - accuracy: 0.8705\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 609/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3449 - accuracy: 0.8704\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 708/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8715\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 810/1875 [===========&gt;..................] - ETA: 0s - loss: 0.3426 - accuracy: 0.8726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 912/1875 [=============&gt;................] - ETA: 0s - loss: 0.3430 - accuracy: 0.8729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1014/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3415 - accuracy: 0.8735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1115/1875 [================&gt;.............] - ETA: 0s - loss: 0.3423 - accuracy: 0.8731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1217/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3437 - accuracy: 0.8730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1318/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3441 - accuracy: 0.8732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1420/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3436 - accuracy: 0.8734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1521/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3441 - accuracy: 0.8731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1623/1875 [========================&gt;.....] - ETA: 0s - loss: 0.3437 - accuracy: 0.8734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1724/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3455 - accuracy: 0.8730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1826/1875 [============================&gt;.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 496us/step - loss: 0.3455 - accuracy: 0.8725\nEpoch 5/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.2302 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 103/1875 [&gt;.............................] - ETA: 0s - loss: 0.3202 - accuracy: 0.8850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 205/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3213 - accuracy: 0.8837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 308/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3190 - accuracy: 0.8852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 410/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 511/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3317 - accuracy: 0.8804\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 615/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3348 - accuracy: 0.8783\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 716/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3353 - accuracy: 0.8782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 816/1875 [============&gt;.................] - ETA: 0s - loss: 0.3322 - accuracy: 0.8796\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 917/1875 [=============&gt;................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8795\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1019/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3307 - accuracy: 0.8790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1121/1875 [================&gt;.............] - ETA: 0s - loss: 0.3300 - accuracy: 0.8792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1224/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3315 - accuracy: 0.8783\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1328/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3320 - accuracy: 0.8778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1432/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3338 - accuracy: 0.8772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1533/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3325 - accuracy: 0.8776\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1634/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3320 - accuracy: 0.8779\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1735/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3324 - accuracy: 0.8778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1837/1875 [============================&gt;.] - ETA: 0s - loss: 0.3323 - accuracy: 0.8777\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 493us/step - loss: 0.3321 - accuracy: 0.8777\nEpoch 6/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.4587 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 101/1875 [&gt;.............................] - ETA: 0s - loss: 0.3326 - accuracy: 0.8735\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 203/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3227 - accuracy: 0.8802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 305/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3239 - accuracy: 0.8798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 408/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3195 - accuracy: 0.8807\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 511/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3121 - accuracy: 0.8844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 613/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3091 - accuracy: 0.8855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 715/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 816/1875 [============&gt;.................] - ETA: 0s - loss: 0.3110 - accuracy: 0.8845\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 917/1875 [=============&gt;................] - ETA: 0s - loss: 0.3123 - accuracy: 0.8844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1018/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3143 - accuracy: 0.8844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1122/1875 [================&gt;.............] - ETA: 0s - loss: 0.3156 - accuracy: 0.8834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1223/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3178 - accuracy: 0.8832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1322/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3180 - accuracy: 0.8832\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1423/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3163 - accuracy: 0.8839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1524/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3164 - accuracy: 0.8836\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1626/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3167 - accuracy: 0.8840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1727/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3185 - accuracy: 0.8834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1829/1875 [============================&gt;.] - ETA: 0s - loss: 0.3195 - accuracy: 0.8831\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 495us/step - loss: 0.3196 - accuracy: 0.8830\nEpoch 7/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.6619 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  99/1875 [&gt;.............................] - ETA: 0s - loss: 0.2899 - accuracy: 0.8952\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 197/1875 [==&gt;...........................] - ETA: 0s - loss: 0.2926 - accuracy: 0.8934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 298/1875 [===&gt;..........................] - ETA: 0s - loss: 0.2916 - accuracy: 0.8932\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 399/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 500/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3046 - accuracy: 0.8870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 601/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3085 - accuracy: 0.8856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 703/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3108 - accuracy: 0.8847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 804/1875 [===========&gt;..................] - ETA: 0s - loss: 0.3097 - accuracy: 0.8855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 904/1875 [=============&gt;................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8855\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1005/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3075 - accuracy: 0.8859\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1106/1875 [================&gt;.............] - ETA: 0s - loss: 0.3097 - accuracy: 0.8854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1208/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3086 - accuracy: 0.8860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1311/1875 [===================&gt;..........] - ETA: 0s - loss: 0.3080 - accuracy: 0.8865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1415/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3071 - accuracy: 0.8871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1519/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3077 - accuracy: 0.8865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1620/1875 [========================&gt;.....] - ETA: 0s - loss: 0.3071 - accuracy: 0.8866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1721/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3074 - accuracy: 0.8865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1821/1875 [============================&gt;.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 497us/step - loss: 0.3083 - accuracy: 0.8861\nEpoch 8/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.4540 - accuracy: 0.8125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 102/1875 [&gt;.............................] - ETA: 0s - loss: 0.2868 - accuracy: 0.8922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 203/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3058 - accuracy: 0.8841\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 305/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3052 - accuracy: 0.8857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 407/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3035 - accuracy: 0.8872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 509/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3007 - accuracy: 0.8876\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 611/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3038 - accuracy: 0.8861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 713/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3034 - accuracy: 0.8863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 814/1875 [============&gt;.................] - ETA: 0s - loss: 0.3011 - accuracy: 0.8871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 915/1875 [=============&gt;................] - ETA: 0s - loss: 0.3019 - accuracy: 0.8877\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1016/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3017 - accuracy: 0.8884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1117/1875 [================&gt;.............] - ETA: 0s - loss: 0.3010 - accuracy: 0.8890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1219/1875 [==================&gt;...........] - ETA: 0s - loss: 0.2993 - accuracy: 0.8893\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1315/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3002 - accuracy: 0.8889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1415/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3008 - accuracy: 0.8884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1516/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3014 - accuracy: 0.8878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1616/1875 [========================&gt;.....] - ETA: 0s - loss: 0.3014 - accuracy: 0.8880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1717/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3016 - accuracy: 0.8882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1818/1875 [============================&gt;.] - ETA: 0s - loss: 0.3007 - accuracy: 0.8887\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 498us/step - loss: 0.3009 - accuracy: 0.8884\nEpoch 9/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.2241 - accuracy: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 102/1875 [&gt;.............................] - ETA: 0s - loss: 0.2921 - accuracy: 0.8866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 204/1875 [==&gt;...........................] - ETA: 0s - loss: 0.2947 - accuracy: 0.8857\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 307/1875 [===&gt;..........................] - ETA: 0s - loss: 0.2992 - accuracy: 0.8878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 408/1875 [=====&gt;........................] - ETA: 0s - loss: 0.2997 - accuracy: 0.8879\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 509/1875 [=======&gt;......................] - ETA: 0s - loss: 0.2968 - accuracy: 0.8903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 610/1875 [========&gt;.....................] - ETA: 0s - loss: 0.2928 - accuracy: 0.8927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 711/1875 [==========&gt;...................] - ETA: 0s - loss: 0.2919 - accuracy: 0.8925\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 814/1875 [============&gt;.................] - ETA: 0s - loss: 0.2925 - accuracy: 0.8922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 915/1875 [=============&gt;................] - ETA: 0s - loss: 0.2912 - accuracy: 0.8915\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1018/1875 [===============&gt;..............] - ETA: 0s - loss: 0.2943 - accuracy: 0.8902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1120/1875 [================&gt;.............] - ETA: 0s - loss: 0.2927 - accuracy: 0.8911\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1221/1875 [==================&gt;...........] - ETA: 0s - loss: 0.2927 - accuracy: 0.8911\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1323/1875 [====================&gt;.........] - ETA: 0s - loss: 0.2897 - accuracy: 0.8920\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1424/1875 [=====================&gt;........] - ETA: 0s - loss: 0.2889 - accuracy: 0.8922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1525/1875 [=======================&gt;......] - ETA: 0s - loss: 0.2900 - accuracy: 0.8919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1625/1875 [=========================&gt;....] - ETA: 0s - loss: 0.2900 - accuracy: 0.8922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1726/1875 [==========================&gt;...] - ETA: 0s - loss: 0.2911 - accuracy: 0.8918\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1827/1875 [============================&gt;.] - ETA: 0s - loss: 0.2914 - accuracy: 0.8916\nLoss is lower than 0.3 so cancelling training!\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 496us/step - loss: 0.2918 - accuracy: 0.8913\n\n\n\n\nCode\nprint(f\"Your model was trained for {len(history.epoch)} epochs\")\n\n\nYour model was trained for 9 epochs\n\n\n\n\n6 Evaluate\n\n\nCode\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)\n\n\n313/313 - 0s - loss: 0.3401 - accuracy: 0.8806 - 145ms/epoch - 465us/step\n\nTest accuracy: 0.8805999755859375\n\n\n\n\n7 Make predictions\n\n\nCode\nprobability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])\n\n\n\n\nCode\npredictions = probability_model.predict(test_images)\n\n\n  1/313 [..............................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b167/313 [===============&gt;..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b313/313 [==============================] - 0s 295us/step\n\n\n\n\nCode\npredictions[0]\n\n\narray([2.1628241e-06, 1.8279518e-10, 1.7441415e-09, 1.2995643e-09,\n       2.2349051e-09, 1.8804809e-02, 5.4445149e-08, 5.9717121e-03,\n       5.7994153e-08, 9.7522122e-01], dtype=float32)\n\n\n\n\nCode\nnp.argmax(predictions[0])\n\n\n9\n\n\n\n\nCode\ntest_labels[0]\n\n\n9\n\n\n\n\n8 Use the trained model\n\n\nCode\n# Grab an image from the test dataset.\nimg = test_images[1]\n\nprint(img.shape)\n\n\n(28, 28)\n\n\n\n\nCode\n# Add the image to a batch where it's the only member.\nimg = (np.expand_dims(img,0))\n\nprint(img.shape)\n\n\n(1, 28, 28)\n\n\n\n\nCode\npredictions_single = probability_model.predict(img)\n\nprint(predictions_single)\n\n\n1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 8ms/step\n[[5.3414024e-06 4.1603829e-14 9.9569571e-01 8.8006262e-11 3.5118531e-03\n  4.0887243e-14 7.8704773e-04 1.3665034e-18 8.9623996e-11 6.3567139e-14]]\n\n\n\n\nCode\nnp.argmax(predictions_single[0])\n\n\n2\n\n\n\n\nCode\ntest_labels[1]\n\n\n2\n\n\n\n\n9 resource:\nhttps://github.com/https-deeplearning-ai/tensorflow-1-public\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tensorflow",
      "Level 1 picture recognition with tensorflow"
    ]
  },
  {
    "objectID": "tensorflow/Level 2 picture recognition with tensorflow.html",
    "href": "tensorflow/Level 2 picture recognition with tensorflow.html",
    "title": "Level 1 picture recognition with tensorflow",
    "section": "",
    "text": "Code\n# TensorFlow and tf.keras\nimport tensorflow as tf\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n\n\n2.14.0\n\n\n\n1 data\n\n\nCode\nfashion_mnist = tf.keras.datasets.fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n\n\n\nCode\ntrain_images.shape\n\n\n(60000, 28, 28)\n\n\n\n\nCode\ntrain_labels.shape\n\n\n(60000,)\n\n\n\n\nCode\ntest_images.shape\n\n\n(10000, 28, 28)\n\n\n\n\nCode\ntest_labels.shape\n\n\n(10000,)\n\n\nBoth train and test have 10 calss 0-9\n\n\nCode\nset(train_labels)\n\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\n\nCode\nset(test_labels)\n\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\n\nCode\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\n\n\nCode\nplt.figure()\nplt.imshow(train_images[0])\nplt.colorbar()\nplt.grid(False)\nplt.show()\n\n\n\n\n\n\n\n\n\nScale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It’s important that the training set and the testing set be preprocessed in the same way:\nall of the values in the number are between 0 and 255. If you are training a neural network especially in image processing, for various reasons it will usually learn better if you scale all values to between 0 and 1. It’s a process called normalization\n\n\nCode\ntrain_images = train_images / 255.0\n\ntest_images = test_images / 255.0\n\n\n\n\nCode\nplt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n2 model\n\n\nCode\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(128, activation='relu'),\n      tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10)\n])\n\n\n\n\n3 Compile the model\n\n\nCode\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n\n\n4 call back\n\n\nCode\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    '''\n    Halts the training when the loss falls below 0.3\n\n    Args:\n      epoch (integer) - index of epoch (required but unused in the function definition below)\n      logs (dict) - metric results from the training epoch\n    '''\n\n    # Check the loss\n    if(logs.get('loss') &lt; 0.3):\n\n      # Stop if threshold is met\n      print(\"\\nLoss is lower than 0.3 so cancelling training!\")\n      self.model.stop_training = True\n\n# Instantiate class\ncallbacks = myCallback()\n\n\n\n\n5 training\n\n\nCode\nhistory=model.fit(train_images, train_labels, epochs=10,callbacks=[callbacks])\n\n\nEpoch 1/10\n   1/1875 [..............................] - ETA: 4:04 - loss: 2.5952 - accuracy: 0.0312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  95/1875 [&gt;.............................] - ETA: 0s - loss: 1.0687 - accuracy: 0.6316  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 173/1875 [=&gt;............................] - ETA: 1s - loss: 0.8939 - accuracy: 0.6884\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 240/1875 [==&gt;...........................] - ETA: 1s - loss: 0.8226 - accuracy: 0.7145\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 321/1875 [====&gt;.........................] - ETA: 1s - loss: 0.7648 - accuracy: 0.7345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 411/1875 [=====&gt;........................] - ETA: 0s - loss: 0.7257 - accuracy: 0.7485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 490/1875 [======&gt;.......................] - ETA: 0s - loss: 0.6970 - accuracy: 0.7586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 574/1875 [========&gt;.....................] - ETA: 0s - loss: 0.6775 - accuracy: 0.7655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 664/1875 [=========&gt;....................] - ETA: 0s - loss: 0.6558 - accuracy: 0.7732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 758/1875 [===========&gt;..................] - ETA: 0s - loss: 0.6388 - accuracy: 0.7794\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 848/1875 [============&gt;.................] - ETA: 0s - loss: 0.6230 - accuracy: 0.7839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 928/1875 [=============&gt;................] - ETA: 0s - loss: 0.6121 - accuracy: 0.7875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1009/1875 [===============&gt;..............] - ETA: 0s - loss: 0.6019 - accuracy: 0.7902\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1092/1875 [================&gt;.............] - ETA: 0s - loss: 0.5925 - accuracy: 0.7928\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1178/1875 [=================&gt;............] - ETA: 0s - loss: 0.5823 - accuracy: 0.7967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1264/1875 [===================&gt;..........] - ETA: 0s - loss: 0.5732 - accuracy: 0.7995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1349/1875 [====================&gt;.........] - ETA: 0s - loss: 0.5656 - accuracy: 0.8019\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1431/1875 [=====================&gt;........] - ETA: 0s - loss: 0.5587 - accuracy: 0.8043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1513/1875 [=======================&gt;......] - ETA: 0s - loss: 0.5539 - accuracy: 0.8062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1592/1875 [========================&gt;.....] - ETA: 0s - loss: 0.5466 - accuracy: 0.8088\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1668/1875 [=========================&gt;....] - ETA: 0s - loss: 0.5425 - accuracy: 0.8097\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1749/1875 [==========================&gt;...] - ETA: 0s - loss: 0.5377 - accuracy: 0.8109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1835/1875 [============================&gt;.] - ETA: 0s - loss: 0.5337 - accuracy: 0.8120\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 614us/step - loss: 0.5326 - accuracy: 0.8123\nEpoch 2/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.5925 - accuracy: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  91/1875 [&gt;.............................] - ETA: 1s - loss: 0.4194 - accuracy: 0.8510\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 178/1875 [=&gt;............................] - ETA: 0s - loss: 0.4115 - accuracy: 0.8509\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 270/1875 [===&gt;..........................] - ETA: 0s - loss: 0.4146 - accuracy: 0.8503\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 360/1875 [====&gt;.........................] - ETA: 0s - loss: 0.4117 - accuracy: 0.8498\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 454/1875 [======&gt;.......................] - ETA: 0s - loss: 0.4145 - accuracy: 0.8489\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 549/1875 [=======&gt;......................] - ETA: 0s - loss: 0.4131 - accuracy: 0.8505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 648/1875 [=========&gt;....................] - ETA: 0s - loss: 0.4087 - accuracy: 0.8520\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 741/1875 [==========&gt;...................] - ETA: 0s - loss: 0.4058 - accuracy: 0.8531\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 821/1875 [============&gt;.................] - ETA: 0s - loss: 0.4035 - accuracy: 0.8535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 888/1875 [=============&gt;................] - ETA: 0s - loss: 0.4044 - accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 947/1875 [==============&gt;...............] - ETA: 0s - loss: 0.4023 - accuracy: 0.8548\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1033/1875 [===============&gt;..............] - ETA: 0s - loss: 0.4024 - accuracy: 0.8546\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1129/1875 [=================&gt;............] - ETA: 0s - loss: 0.4013 - accuracy: 0.8554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1222/1875 [==================&gt;...........] - ETA: 0s - loss: 0.4012 - accuracy: 0.8554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1319/1875 [====================&gt;.........] - ETA: 0s - loss: 0.4018 - accuracy: 0.8552\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1415/1875 [=====================&gt;........] - ETA: 0s - loss: 0.4012 - accuracy: 0.8550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1509/1875 [=======================&gt;......] - ETA: 0s - loss: 0.4008 - accuracy: 0.8554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1588/1875 [========================&gt;.....] - ETA: 0s - loss: 0.4012 - accuracy: 0.8554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1688/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3993 - accuracy: 0.8560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1789/1875 [===========================&gt;..] - ETA: 0s - loss: 0.3986 - accuracy: 0.8560\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 569us/step - loss: 0.3987 - accuracy: 0.8560\nEpoch 3/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.4048 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 104/1875 [&gt;.............................] - ETA: 0s - loss: 0.3708 - accuracy: 0.8582\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 206/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3587 - accuracy: 0.8665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 309/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3664 - accuracy: 0.8648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 412/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3664 - accuracy: 0.8650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 510/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3703 - accuracy: 0.8635\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 614/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3680 - accuracy: 0.8655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 719/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3680 - accuracy: 0.8653\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 822/1875 [============&gt;.................] - ETA: 0s - loss: 0.3688 - accuracy: 0.8651\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 924/1875 [=============&gt;................] - ETA: 0s - loss: 0.3656 - accuracy: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1029/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3672 - accuracy: 0.8662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1133/1875 [=================&gt;............] - ETA: 0s - loss: 0.3656 - accuracy: 0.8668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1236/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3663 - accuracy: 0.8667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1338/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3669 - accuracy: 0.8664\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1440/1875 [======================&gt;.......] - ETA: 0s - loss: 0.3664 - accuracy: 0.8665\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1542/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3666 - accuracy: 0.8661\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1645/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3661 - accuracy: 0.8662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1748/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3647 - accuracy: 0.8669\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1850/1875 [============================&gt;.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 489us/step - loss: 0.3641 - accuracy: 0.8670\nEpoch 4/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.4339 - accuracy: 0.7812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 103/1875 [&gt;.............................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 204/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3430 - accuracy: 0.8703\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 306/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3462 - accuracy: 0.8702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 407/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3482 - accuracy: 0.8714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 509/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3505 - accuracy: 0.8709\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 611/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3480 - accuracy: 0.8721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 713/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3466 - accuracy: 0.8721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 816/1875 [============&gt;.................] - ETA: 0s - loss: 0.3463 - accuracy: 0.8722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 918/1875 [=============&gt;................] - ETA: 0s - loss: 0.3468 - accuracy: 0.8724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1020/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3459 - accuracy: 0.8729\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1122/1875 [================&gt;.............] - ETA: 0s - loss: 0.3456 - accuracy: 0.8731\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1224/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3463 - accuracy: 0.8727\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1325/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3480 - accuracy: 0.8718\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1427/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3466 - accuracy: 0.8724\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1529/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3466 - accuracy: 0.8728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1630/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3447 - accuracy: 0.8734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1733/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3448 - accuracy: 0.8732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1835/1875 [============================&gt;.] - ETA: 0s - loss: 0.3429 - accuracy: 0.8741\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 494us/step - loss: 0.3430 - accuracy: 0.8738\nEpoch 5/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.1300 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 103/1875 [&gt;.............................] - ETA: 0s - loss: 0.3300 - accuracy: 0.8799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 204/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3236 - accuracy: 0.8847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 303/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8808\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 404/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3268 - accuracy: 0.8813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 506/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3275 - accuracy: 0.8806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 607/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3250 - accuracy: 0.8814\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 708/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3255 - accuracy: 0.8810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 809/1875 [===========&gt;..................] - ETA: 0s - loss: 0.3258 - accuracy: 0.8804\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 910/1875 [=============&gt;................] - ETA: 0s - loss: 0.3266 - accuracy: 0.8799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1008/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3264 - accuracy: 0.8797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1105/1875 [================&gt;.............] - ETA: 0s - loss: 0.3261 - accuracy: 0.8798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1207/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3243 - accuracy: 0.8806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1309/1875 [===================&gt;..........] - ETA: 0s - loss: 0.3238 - accuracy: 0.8805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1412/1875 [=====================&gt;........] - ETA: 0s - loss: 0.3248 - accuracy: 0.8796\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1513/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3257 - accuracy: 0.8795\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1615/1875 [========================&gt;.....] - ETA: 0s - loss: 0.3261 - accuracy: 0.8796\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1718/1875 [==========================&gt;...] - ETA: 0s - loss: 0.3256 - accuracy: 0.8797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1819/1875 [============================&gt;.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 498us/step - loss: 0.3285 - accuracy: 0.8783\nEpoch 6/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.1747 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 104/1875 [&gt;.............................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8822\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 206/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 309/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3212 - accuracy: 0.8805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 414/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3196 - accuracy: 0.8802\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 517/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3168 - accuracy: 0.8824\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 620/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3176 - accuracy: 0.8814\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 725/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3188 - accuracy: 0.8819\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 828/1875 [============&gt;.................] - ETA: 0s - loss: 0.3162 - accuracy: 0.8833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 936/1875 [=============&gt;................] - ETA: 0s - loss: 0.3172 - accuracy: 0.8838\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1042/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3159 - accuracy: 0.8838\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1146/1875 [=================&gt;............] - ETA: 0s - loss: 0.3155 - accuracy: 0.8837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1250/1875 [===================&gt;..........] - ETA: 0s - loss: 0.3138 - accuracy: 0.8848\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1353/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3152 - accuracy: 0.8842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1457/1875 [======================&gt;.......] - ETA: 0s - loss: 0.3170 - accuracy: 0.8833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1562/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3182 - accuracy: 0.8830\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1664/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3167 - accuracy: 0.8836\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1767/1875 [===========================&gt;..] - ETA: 0s - loss: 0.3158 - accuracy: 0.8839\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1870/1875 [============================&gt;.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 485us/step - loss: 0.3156 - accuracy: 0.8842\nEpoch 7/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.1908 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 104/1875 [&gt;.............................] - ETA: 0s - loss: 0.3159 - accuracy: 0.8825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 206/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3119 - accuracy: 0.8853\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 309/1875 [===&gt;..........................] - ETA: 0s - loss: 0.3064 - accuracy: 0.8863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 411/1875 [=====&gt;........................] - ETA: 0s - loss: 0.3087 - accuracy: 0.8853\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 513/1875 [=======&gt;......................] - ETA: 0s - loss: 0.3040 - accuracy: 0.8872\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 618/1875 [========&gt;.....................] - ETA: 0s - loss: 0.3025 - accuracy: 0.8882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 722/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3010 - accuracy: 0.8881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 827/1875 [============&gt;.................] - ETA: 0s - loss: 0.3031 - accuracy: 0.8878\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 932/1875 [=============&gt;................] - ETA: 0s - loss: 0.3041 - accuracy: 0.8877\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1038/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3043 - accuracy: 0.8876\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1142/1875 [=================&gt;............] - ETA: 0s - loss: 0.3054 - accuracy: 0.8868\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1247/1875 [==================&gt;...........] - ETA: 0s - loss: 0.3032 - accuracy: 0.8871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1352/1875 [====================&gt;.........] - ETA: 0s - loss: 0.3039 - accuracy: 0.8870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1455/1875 [======================&gt;.......] - ETA: 0s - loss: 0.3037 - accuracy: 0.8868\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1559/1875 [=======================&gt;......] - ETA: 0s - loss: 0.3052 - accuracy: 0.8864\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1663/1875 [=========================&gt;....] - ETA: 0s - loss: 0.3060 - accuracy: 0.8860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1768/1875 [===========================&gt;..] - ETA: 0s - loss: 0.3071 - accuracy: 0.8852\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1872/1875 [============================&gt;.] - ETA: 0s - loss: 0.3069 - accuracy: 0.8854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 484us/step - loss: 0.3069 - accuracy: 0.8854\nEpoch 8/10\n   1/1875 [..............................] - ETA: 1s - loss: 0.2811 - accuracy: 0.9062\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 102/1875 [&gt;.............................] - ETA: 0s - loss: 0.3048 - accuracy: 0.8922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 205/1875 [==&gt;...........................] - ETA: 0s - loss: 0.3028 - accuracy: 0.8924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 307/1875 [===&gt;..........................] - ETA: 0s - loss: 0.2995 - accuracy: 0.8914\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 379/1875 [=====&gt;........................] - ETA: 0s - loss: 0.2996 - accuracy: 0.8922\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 461/1875 [======&gt;.......................] - ETA: 0s - loss: 0.2981 - accuracy: 0.8926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 557/1875 [=======&gt;......................] - ETA: 0s - loss: 0.2955 - accuracy: 0.8926\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 654/1875 [=========&gt;....................] - ETA: 0s - loss: 0.2994 - accuracy: 0.8900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 753/1875 [===========&gt;..................] - ETA: 0s - loss: 0.2996 - accuracy: 0.8895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 852/1875 [============&gt;.................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8885\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 955/1875 [==============&gt;...............] - ETA: 0s - loss: 0.3007 - accuracy: 0.8886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 980/1875 [==============&gt;...............] - ETA: 0s - loss: 0.3004 - accuracy: 0.8889\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1025/1875 [===============&gt;..............] - ETA: 0s - loss: 0.2994 - accuracy: 0.8895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1123/1875 [================&gt;.............] - ETA: 0s - loss: 0.2989 - accuracy: 0.8894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1221/1875 [==================&gt;...........] - ETA: 0s - loss: 0.2989 - accuracy: 0.8891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1318/1875 [====================&gt;.........] - ETA: 0s - loss: 0.2981 - accuracy: 0.8895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1416/1875 [=====================&gt;........] - ETA: 0s - loss: 0.2986 - accuracy: 0.8892\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1514/1875 [=======================&gt;......] - ETA: 0s - loss: 0.2975 - accuracy: 0.8896\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1600/1875 [========================&gt;.....] - ETA: 0s - loss: 0.2969 - accuracy: 0.8898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1696/1875 [==========================&gt;...] - ETA: 0s - loss: 0.2967 - accuracy: 0.8898\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1791/1875 [===========================&gt;..] - ETA: 0s - loss: 0.2975 - accuracy: 0.8894\nLoss is lower than 0.3 so cancelling training!\n\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1875/1875 [==============================] - 1s 567us/step - loss: 0.2974 - accuracy: 0.8893\n\n\n\n\nCode\nprint(f\"Your model was trained for {len(history.epoch)} epochs\")\n\n\nYour model was trained for 8 epochs\n\n\n\n\n6 Evaluate\n\n\nCode\ntest_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n\nprint('\\nTest accuracy:', test_acc)\n\n\n313/313 - 0s - loss: 0.3564 - accuracy: 0.8746 - 156ms/epoch - 497us/step\n\nTest accuracy: 0.8745999932289124\n\n\n\n\n7 Make predictions\n\n\nCode\nprobability_model = tf.keras.Sequential([model, \n                                         tf.keras.layers.Softmax()])\n\n\n\n\nCode\npredictions = probability_model.predict(test_images)\n\n\n  1/313 [..............................] - ETA: 8s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b162/313 [==============&gt;...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b313/313 [==============================] - 0s 298us/step\n\n\n\n\nCode\npredictions[0]\n\n\narray([1.1355811e-08, 1.0960215e-12, 7.1256334e-11, 5.7601024e-10,\n       8.2441071e-10, 4.7945324e-04, 3.1974807e-09, 1.6840933e-02,\n       1.6669144e-07, 9.8267949e-01], dtype=float32)\n\n\n\n\nCode\nnp.argmax(predictions[0])\n\n\n9\n\n\n\n\nCode\ntest_labels[0]\n\n\n9\n\n\n\n\n8 Use the trained model\n\n\nCode\n# Grab an image from the test dataset.\nimg = test_images[1]\n\nprint(img.shape)\n\n\n(28, 28)\n\n\n\n\nCode\n# Add the image to a batch where it's the only member.\nimg = (np.expand_dims(img,0))\n\nprint(img.shape)\n\n\n(1, 28, 28)\n\n\n\n\nCode\npredictions_single = probability_model.predict(img)\n\nprint(predictions_single)\n\n\n1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 0s 8ms/step\n[[2.1064245e-06 1.4731624e-14 9.9986446e-01 9.2522940e-13 7.1792601e-05\n  1.0558498e-15 6.1599618e-05 2.1143049e-18 1.1180190e-12 1.4141482e-18]]\n\n\n\n\nCode\nnp.argmax(predictions_single[0])\n\n\n2\n\n\n\n\nCode\ntest_labels[1]\n\n\n2\n\n\n\n\n9 resource:\nhttps://github.com/https-deeplearning-ai/tensorflow-1-public\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tensorflow",
      "Level 2 picture recognition with tensorflow"
    ]
  },
  {
    "objectID": "tensorflow/Level 1  picture recognition with tensorflow.html",
    "href": "tensorflow/Level 1  picture recognition with tensorflow.html",
    "title": "Level 0 picture recognition with tensorflow",
    "section": "",
    "text": "1 install tensorflow\n\n\nCode\n# Requires the latest pip\n#pip install --upgrade pip\n\n\n\n\nCode\n# Requires the latest pip\n#pip install tensorflow\n\n\ncheck tensorflow version\n\n\nCode\nimport tensorflow as tf\n\nprint(tf.__version__)\n\n\n2.14.0\n\n\n\n\n2 load data\n\n\nCode\nmnist = tf.keras.datasets.mnist\n\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n\ntraining with 60000 picture with 28* 28 pixels\n\n\nCode\nx_train.shape\n\n\n(60000, 28, 28)\n\n\ntraining with 60000 label\n\n\nCode\ny_train.shape\n\n\n(60000,)\n\n\ntraining with 10000 picture with 28* 28 pixels\n\n\nCode\nx_test.shape\n\n\n(10000, 28, 28)\n\n\ntraining with 10000 label\n\n\nCode\ny_test.shape\n\n\n(10000,)\n\n\nBoth train and test have 10 calss 0-9\n\n\nCode\nset(y_train)\n\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\n\nCode\nset(y_test)\n\n\n{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n\n\n\n\nCode\nimport pandas as pd\npd.value_counts(y_test)\n\n\n1    1135\n2    1032\n7    1028\n3    1010\n9    1009\n4     982\n0     980\n8     974\n6     958\n5     892\nName: count, dtype: int64\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nplt.imshow(x_test[0], cmap='gray_r')\n\n\n\n\n\n\n\n\n\n\n\n3 define model\n\n\nCode\nmodel = tf.keras.models.Sequential([\n                                    tf.keras.layers.Flatten(input_shape=(28, 28)),\n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n                                    ])\n\n\n\n\n4 model.compile\n\n\nCode\nmodel.compile(\n  optimizer = tf.keras.optimizers.legacy.Adam(),\n  #optimizer = tf.keras.optimizers.Adam(),\n              loss = 'sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n\n\n5 training\n\n\nCode\nmodel.fit(x_train, y_train, epochs=5)\n\n\nEpoch 1/5\n\n   1/1875 [..............................] - ETA: 3:29 - loss: 2.2527 - accuracy: 0.1875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 107/1875 [&gt;.............................] - ETA: 0s - loss: 0.8191 - accuracy: 0.7880  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 215/1875 [==&gt;...........................] - ETA: 0s - loss: 0.6013 - accuracy: 0.8387\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 326/1875 [====&gt;.........................] - ETA: 0s - loss: 0.5060 - accuracy: 0.8610\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 373/1875 [====&gt;.........................] - ETA: 0s - loss: 0.4831 - accuracy: 0.8668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 455/1875 [======&gt;.......................] - ETA: 0s - loss: 0.4477 - accuracy: 0.8752\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 542/1875 [=======&gt;......................] - ETA: 0s - loss: 0.4180 - accuracy: 0.8838\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 639/1875 [=========&gt;....................] - ETA: 0s - loss: 0.3933 - accuracy: 0.8904\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 744/1875 [==========&gt;...................] - ETA: 0s - loss: 0.3721 - accuracy: 0.8956\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 835/1875 [============&gt;.................] - ETA: 0s - loss: 0.3554 - accuracy: 0.8997\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 936/1875 [=============&gt;................] - ETA: 0s - loss: 0.3385 - accuracy: 0.9044\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1039/1875 [===============&gt;..............] - ETA: 0s - loss: 0.3261 - accuracy: 0.9079\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1145/1875 [=================&gt;............] - ETA: 0s - loss: 0.3151 - accuracy: 0.9109\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1252/1875 [===================&gt;..........] - ETA: 0s - loss: 0.3024 - accuracy: 0.9146\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1366/1875 [====================&gt;.........] - ETA: 0s - loss: 0.2920 - accuracy: 0.9175\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1468/1875 [======================&gt;.......] - ETA: 0s - loss: 0.2846 - accuracy: 0.9194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1546/1875 [=======================&gt;......] - ETA: 0s - loss: 0.2782 - accuracy: 0.9210\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1653/1875 [=========================&gt;....] - ETA: 0s - loss: 0.2708 - accuracy: 0.9230\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1762/1875 [===========================&gt;..] - ETA: 0s - loss: 0.2647 - accuracy: 0.9248\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1867/1875 [============================&gt;.] - ETA: 0s - loss: 0.2583 - accuracy: 0.9266\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 513us/step - loss: 0.2577 - accuracy: 0.9267\nEpoch 2/5\n\n   1/1875 [..............................] - ETA: 1s - loss: 0.4581 - accuracy: 0.9375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 106/1875 [&gt;.............................] - ETA: 0s - loss: 0.1360 - accuracy: 0.9614\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 211/1875 [==&gt;...........................] - ETA: 0s - loss: 0.1306 - accuracy: 0.9618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 314/1875 [====&gt;.........................] - ETA: 0s - loss: 0.1289 - accuracy: 0.9616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 410/1875 [=====&gt;........................] - ETA: 0s - loss: 0.1294 - accuracy: 0.9615\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 507/1875 [=======&gt;......................] - ETA: 0s - loss: 0.1284 - accuracy: 0.9618\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 598/1875 [========&gt;.....................] - ETA: 0s - loss: 0.1249 - accuracy: 0.9626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 700/1875 [==========&gt;...................] - ETA: 0s - loss: 0.1247 - accuracy: 0.9626\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 802/1875 [===========&gt;..................] - ETA: 0s - loss: 0.1224 - accuracy: 0.9637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 903/1875 [=============&gt;................] - ETA: 0s - loss: 0.1227 - accuracy: 0.9640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 996/1875 [==============&gt;...............] - ETA: 0s - loss: 0.1229 - accuracy: 0.9637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1085/1875 [================&gt;.............] - ETA: 0s - loss: 0.1218 - accuracy: 0.9642\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1192/1875 [==================&gt;...........] - ETA: 0s - loss: 0.1206 - accuracy: 0.9643\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1299/1875 [===================&gt;..........] - ETA: 0s - loss: 0.1192 - accuracy: 0.9648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1403/1875 [=====================&gt;........] - ETA: 0s - loss: 0.1174 - accuracy: 0.9652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1509/1875 [=======================&gt;......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1611/1875 [========================&gt;.....] - ETA: 0s - loss: 0.1139 - accuracy: 0.9659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1715/1875 [==========================&gt;...] - ETA: 0s - loss: 0.1143 - accuracy: 0.9658\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1819/1875 [============================&gt;.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 497us/step - loss: 0.1132 - accuracy: 0.9662\nEpoch 3/5\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.0373 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 103/1875 [&gt;.............................] - ETA: 0s - loss: 0.0782 - accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 160/1875 [=&gt;............................] - ETA: 1s - loss: 0.0794 - accuracy: 0.9787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 252/1875 [===&gt;..........................] - ETA: 0s - loss: 0.0816 - accuracy: 0.9764\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 362/1875 [====&gt;.........................] - ETA: 0s - loss: 0.0789 - accuracy: 0.9768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 466/1875 [======&gt;.......................] - ETA: 0s - loss: 0.0800 - accuracy: 0.9769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 578/1875 [========&gt;.....................] - ETA: 0s - loss: 0.0797 - accuracy: 0.9771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 690/1875 [==========&gt;...................] - ETA: 0s - loss: 0.0784 - accuracy: 0.9771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 802/1875 [===========&gt;..................] - ETA: 0s - loss: 0.0786 - accuracy: 0.9770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 912/1875 [=============&gt;................] - ETA: 0s - loss: 0.0779 - accuracy: 0.9769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1023/1875 [===============&gt;..............] - ETA: 0s - loss: 0.0791 - accuracy: 0.9768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1127/1875 [=================&gt;............] - ETA: 0s - loss: 0.0782 - accuracy: 0.9769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1218/1875 [==================&gt;...........] - ETA: 0s - loss: 0.0789 - accuracy: 0.9768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1311/1875 [===================&gt;..........] - ETA: 0s - loss: 0.0788 - accuracy: 0.9767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1421/1875 [=====================&gt;........] - ETA: 0s - loss: 0.0781 - accuracy: 0.9767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1533/1875 [=======================&gt;......] - ETA: 0s - loss: 0.0778 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1638/1875 [=========================&gt;....] - ETA: 0s - loss: 0.0780 - accuracy: 0.9765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1747/1875 [==========================&gt;...] - ETA: 0s - loss: 0.0779 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1858/1875 [============================&gt;.] - ETA: 0s - loss: 0.0777 - accuracy: 0.9766\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 488us/step - loss: 0.0776 - accuracy: 0.9766\nEpoch 4/5\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.0526 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 113/1875 [&gt;.............................] - ETA: 0s - loss: 0.0542 - accuracy: 0.9837\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 226/1875 [==&gt;...........................] - ETA: 0s - loss: 0.0532 - accuracy: 0.9844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 338/1875 [====&gt;.........................] - ETA: 0s - loss: 0.0559 - accuracy: 0.9833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 452/1875 [======&gt;.......................] - ETA: 0s - loss: 0.0597 - accuracy: 0.9820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 568/1875 [========&gt;.....................] - ETA: 0s - loss: 0.0595 - accuracy: 0.9827\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 683/1875 [=========&gt;....................] - ETA: 0s - loss: 0.0585 - accuracy: 0.9828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 798/1875 [===========&gt;..................] - ETA: 0s - loss: 0.0592 - accuracy: 0.9825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 910/1875 [=============&gt;................] - ETA: 0s - loss: 0.0591 - accuracy: 0.9825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1015/1875 [===============&gt;..............] - ETA: 0s - loss: 0.0584 - accuracy: 0.9826\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1116/1875 [================&gt;.............] - ETA: 0s - loss: 0.0586 - accuracy: 0.9826\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1230/1875 [==================&gt;...........] - ETA: 0s - loss: 0.0592 - accuracy: 0.9823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1341/1875 [====================&gt;.........] - ETA: 0s - loss: 0.0596 - accuracy: 0.9820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1453/1875 [======================&gt;.......] - ETA: 0s - loss: 0.0594 - accuracy: 0.9820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1568/1875 [========================&gt;.....] - ETA: 0s - loss: 0.0594 - accuracy: 0.9820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1678/1875 [=========================&gt;....] - ETA: 0s - loss: 0.0594 - accuracy: 0.9819\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1785/1875 [===========================&gt;..] - ETA: 0s - loss: 0.0592 - accuracy: 0.9820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 452us/step - loss: 0.0595 - accuracy: 0.9820\nEpoch 5/5\n\n   1/1875 [..............................] - ETA: 0s - loss: 0.0969 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 107/1875 [&gt;.............................] - ETA: 0s - loss: 0.0451 - accuracy: 0.9869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 186/1875 [=&gt;............................] - ETA: 0s - loss: 0.0411 - accuracy: 0.9886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 289/1875 [===&gt;..........................] - ETA: 0s - loss: 0.0415 - accuracy: 0.9882\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 389/1875 [=====&gt;........................] - ETA: 0s - loss: 0.0417 - accuracy: 0.9883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 493/1875 [======&gt;.......................] - ETA: 0s - loss: 0.0429 - accuracy: 0.9877\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 597/1875 [========&gt;.....................] - ETA: 0s - loss: 0.0435 - accuracy: 0.9873\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 707/1875 [==========&gt;...................] - ETA: 0s - loss: 0.0457 - accuracy: 0.9866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 815/1875 [============&gt;.................] - ETA: 0s - loss: 0.0454 - accuracy: 0.9867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n 925/1875 [=============&gt;................] - ETA: 0s - loss: 0.0464 - accuracy: 0.9862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1029/1875 [===============&gt;..............] - ETA: 0s - loss: 0.0456 - accuracy: 0.9863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1136/1875 [=================&gt;............] - ETA: 0s - loss: 0.0455 - accuracy: 0.9864\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1249/1875 [==================&gt;...........] - ETA: 0s - loss: 0.0452 - accuracy: 0.9864\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1353/1875 [====================&gt;.........] - ETA: 0s - loss: 0.0451 - accuracy: 0.9864\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1455/1875 [======================&gt;.......] - ETA: 0s - loss: 0.0448 - accuracy: 0.9865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1552/1875 [=======================&gt;......] - ETA: 0s - loss: 0.0458 - accuracy: 0.9863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1661/1875 [=========================&gt;....] - ETA: 0s - loss: 0.0461 - accuracy: 0.9861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1770/1875 [===========================&gt;..] - ETA: 0s - loss: 0.0456 - accuracy: 0.9862\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1870/1875 [============================&gt;.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9861\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n1875/1875 [==============================] - 1s 485us/step - loss: 0.0457 - accuracy: 0.9862\n&lt;keras.src.callbacks.History object at 0x2ceb604d0&gt;\n\n\n\n\n6 evaluation with test data\n\n\nCode\nmodel.evaluate(x_test,  y_test, verbose=2)\n\n\n313/313 - 0s - loss: 0.0827 - accuracy: 0.9739 - 137ms/epoch - 438us/step\n[0.08269048482179642, 0.9739000201225281]\n\n\n\n\n7 prediction\n\n\nCode\nprobability_model = tf.keras.Sequential([\n  model,\n  tf.keras.layers.Softmax()\n])\n\n\n\n\nCode\nprediction=probability_model(x_test[:5])\nprediction\n\n\n&lt;tf.Tensor: shape=(5, 10), dtype=float32, numpy=\narray([[0.08533699, 0.08533699, 0.08533702, 0.08533819, 0.08533699,\n        0.08533701, 0.08533699, 0.23196526, 0.08533699, 0.08533747],\n       [0.0853681 , 0.08552412, 0.2314732 , 0.08541308, 0.08536805,\n        0.08536811, 0.08536806, 0.08536805, 0.08538112, 0.08536805],\n       [0.08538935, 0.23113708, 0.08539245, 0.08539321, 0.085435  ,\n        0.08538999, 0.08539075, 0.08543161, 0.0856489 , 0.08539164],\n       [0.23194827, 0.08533806, 0.08533976, 0.08533806, 0.08533808,\n        0.08533811, 0.08534495, 0.08533841, 0.08533806, 0.08533815],\n       [0.08534767, 0.08534767, 0.08534767, 0.08534767, 0.23179632,\n        0.08534767, 0.08534767, 0.08534775, 0.08534767, 0.08542223]],\n      dtype=float32)&gt;\n\n\n\n\nCode\nimport numpy as np\nnp.argmax(prediction, axis=1) \n\n\narray([7, 2, 1, 0, 4])\n\n\n\n\n8 resource:\nhttps://www.tensorflow.org/tutorials\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tensorflow",
      "Level 0 picture recognition with tensorflow"
    ]
  },
  {
    "objectID": "tensorflow/Level 3 picture recognition with tensorflow.html",
    "href": "tensorflow/Level 3 picture recognition with tensorflow.html",
    "title": "Level 2 picture recognition with tensorflow",
    "section": "",
    "text": "Code\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport random\nimport pickle\nimport time\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\n\n\n2.14.0\n\n\n\n1 data\n\n\n2 resource:\nhttps://www.tensorflow.org/tutorials\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Tensorflow",
      "Level 2 picture recognition with tensorflow"
    ]
  },
  {
    "objectID": "house price regression model/Level 4 Regression Tidy Modeling.html#training",
    "href": "house price regression model/Level 4 Regression Tidy Modeling.html#training",
    "title": "Level 4 Regression Tidy Modeling",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\n\n\nCode\nlasso_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 200 × 7\n    penalty .metric .estimator      mean     n   std_err .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model001\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model001\n 3 1.26e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model002\n 4 1.26e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model002\n 5 1.59e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model003\n 6 1.59e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model003\n 7 2.01e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model004\n 8 2.01e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model004\n 9 2.54e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model005\n10 2.54e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model005\n# ℹ 190 more rows",
    "crumbs": [
      "house price regression model",
      "Level 4 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html",
    "title": "Level 2 classification Tidy Modeling",
    "section": "",
    "text": "Level 2 classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#read-data",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#data-split",
    "title": "Level 2 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children)%&gt;% sample_n(50000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    10",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#prep-the-recipe",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 35000    23\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 5758   23\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 5758   23\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2879\n2 none            32121\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2879\n2 none             2879\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2879\n2 none             2879",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#model",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#model",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#trainning",
    "title": "Level 2 classification Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2612018\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5758 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 5758 2879 children (0.5000000 0.5000000)  \n  2) adr&gt;=0.2991205 1878  365 children (0.8056443 0.1943557) *\n  3) adr&lt; 0.2991205 3880 1366 none (0.3520619 0.6479381)  \n    6) total_of_special_requests&gt;=0.6645634 773  290 children (0.6248383 0.3751617) *\n    7) total_of_special_requests&lt; 0.6645634 3107  883 none (0.2841970 0.7158030) *",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#evaluate",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,test_proc) \n\npredictions_probability &lt;- predict(tree_fit,test_proc,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      280 1173\n  none          131 3416\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.739\n2 kap      binary         0.198\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.739\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.681\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.744\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.739\n2 sens     binary         0.681\n3 spec     binary         0.744\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.739\n 2 kap                  binary         0.198\n 3 sens                 binary         0.681\n 4 spec                 binary         0.744\n 5 ppv                  binary         0.193\n 6 npv                  binary         0.963\n 7 mcc                  binary         0.257\n 8 j_index              binary         0.426\n 9 bal_accuracy         binary         0.713\n10 detection_prevalence binary         0.291\n11 precision            binary         0.193\n12 recall               binary         0.681\n13 f_meas               binary         0.300\n\n\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_children)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.731\n\n\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_children) %&gt;% \n  autoplot()",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#save-model",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n1.16 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 2 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/Level 2 classification Tidy Modeling.html#make-predication",
    "title": "Level 2 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 children   \n4 children   \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      507 2327\n  none          269 6897\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.740\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          776\n2 none             9224\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2834\n2 none         7166\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      507 2327\n  none          269 6897",
    "crumbs": [
      "hotel classification model",
      "Level 2 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html",
    "title": "Level 1 classification Tidy Modeling",
    "section": "",
    "text": "Level 1 classification Tidy Modeling with 2 model and no recipe:\n*using basic Tidymodel package.\nNo recipe\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#read-data",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.1 read data",
    "text": "3.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#data-split",
    "title": "Level 1 classification Tidy Modeling",
    "section": "3.2 data split",
    "text": "3.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(10000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 7000   10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 1000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 2000   10",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#recipe",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.1 recipe",
    "text": "4.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#model",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#model",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.2 model",
    "text": "4.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#trainning",
    "title": "Level 1 classification Tidy Modeling",
    "section": "4.3 trainning",
    "text": "4.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.08742857\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 7000 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 7000 564 none (0.08057143 0.91942857)  \n  2) adr&gt;=154.05 862 249 none (0.28886311 0.71113689)  \n    4) adr&gt;=221.75 161  80 children (0.50310559 0.49689441)  \n      8) hotel=City Hotel 61  19 children (0.68852459 0.31147541) *\n      9) hotel=Resort Hotel 100  39 none (0.39000000 0.61000000) *\n    5) adr&lt; 221.75 701 168 none (0.23965763 0.76034237) *\n  3) adr&lt; 154.05 6138 315 none (0.05131965 0.94868035) *",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#evaluate",
    "title": "Level 1 classification Tidy Modeling",
    "section": "5.1 Evaluate",
    "text": "5.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children        2    1\n  none           95  902\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.904 \n2 kap      binary        0.0344\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.904\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary        0.0206\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.999\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary        0.904 \n2 sens     binary        0.0206\n3 spec     binary        0.999 \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary        0.904 \n 2 kap                  binary        0.0344\n 3 sens                 binary        0.0206\n 4 spec                 binary        0.999 \n 5 ppv                  binary        0.667 \n 6 npv                  binary        0.905 \n 7 mcc                  binary        0.106 \n 8 j_index              binary        0.0195\n 9 bal_accuracy         binary        0.510 \n10 detection_prevalence binary        0.003 \n11 precision            binary        0.667 \n12 recall               binary        0.0206\n13 f_meas               binary        0.04  \n\n\nROC:receiver operating characteristic curve\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\nAUC:Area under ROC Curve\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_children)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.665",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#save-model",
    "title": "Level 1 classification Tidy Modeling",
    "section": "5.2 save model",
    "text": "5.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n543.76 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 1 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/Level 1 classification Tidy Modeling.html#make-predication",
    "title": "Level 1 classification Tidy Modeling",
    "section": "5.3 make predication",
    "text": "5.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none",
    "crumbs": [
      "hotel classification model",
      "Level 1 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html",
    "title": "Level 3 classification Tidy Modeling",
    "section": "",
    "text": "Level 3 classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#read-data",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#data-split",
    "title": "Level 3 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(50000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    10",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#prep-the-recipe",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 35000    23\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 5672   23\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 5672   23\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2836\n2 none            32164\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2836\n2 none             2836\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2836\n2 none             2836",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          398\n2 none             4602\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          784\n2 none             9216\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#model",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#model",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#trainning",
    "title": "Level 3 classification Tidy Modeling",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2642807\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5672 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 5672 2836 children (0.5000000 0.5000000)  \n   2) adr&gt;=-0.03293739 2507  682 children (0.7279617 0.2720383) *\n   3) adr&lt; -0.03293739 3165 1011 none (0.3194313 0.6805687)  \n     6) total_of_special_requests&gt;=0.6366706 593  252 children (0.5750422 0.4249578) *\n     7) total_of_special_requests&lt; 0.6366706 2572  670 none (0.2604977 0.7395023)  \n      14) adults&lt; -2.851161 46    7 children (0.8478261 0.1521739) *\n      15) adults&gt;=-2.851161 2526  631 none (0.2498021 0.7501979) *",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#evaluate",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits             id        \n   &lt;list&gt;             &lt;chr&gt;     \n 1 &lt;split [5104/568]&gt; Resample01\n 2 &lt;split [5104/568]&gt; Resample02\n 3 &lt;split [5104/568]&gt; Resample03\n 4 &lt;split [5104/568]&gt; Resample04\n 5 &lt;split [5104/568]&gt; Resample05\n 6 &lt;split [5104/568]&gt; Resample06\n 7 &lt;split [5104/568]&gt; Resample07\n 8 &lt;split [5104/568]&gt; Resample08\n 9 &lt;split [5104/568]&gt; Resample09\n10 &lt;split [5104/568]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.73     25 0.00381 Preprocessor1_Model1\n2 roc_auc  binary     0.797    25 0.00348 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.719    25 0.00438 Preprocessor1_Model1\n2 roc_auc  binary     0.736    25 0.00534 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_children) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#save-model",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n1.14 MB\n\n\nCode\nobj_size(knn_fit)\n\n\n1.09 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 3 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/Level 3 classification Tidy Modeling.html#make-predication",
    "title": "Level 3 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 children   \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      555 2393\n  none          229 6823\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.738\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          784\n2 none             9216\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2948\n2 none         7052\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      555 2393\n  none          229 6823",
    "crumbs": [
      "hotel classification model",
      "Level 3 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 0 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 0 classification Tidy Modeling.html",
    "title": "Level 0 classification Tidy Modeling",
    "section": "",
    "text": "Look at the hotel booking data.The target variable is whether have children",
    "crumbs": [
      "hotel classification model",
      "Level 0 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 0 classification Tidy Modeling.html#measurement",
    "href": "hotel classification model/Level 0 classification Tidy Modeling.html#measurement",
    "title": "Level 0 classification Tidy Modeling",
    "section": "4.1 Measurement:",
    "text": "4.1 Measurement:\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nSpecificity=TN/(TN+FP)\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)\n\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nF1 score=2/(1/Precision+1/Recall)",
    "crumbs": [
      "hotel classification model",
      "Level 0 classification Tidy Modeling"
    ]
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html",
    "title": "Level 4 classification Tidy Modeling",
    "section": "",
    "text": "Level 4 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth) with tune_grid()"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#read-data",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#data-split",
    "title": "Level 4 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train,v=10)"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#recipe",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#model",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#model",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#workflow",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#workflow",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl,\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits               id     .metrics          .notes           .predictions\n   &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [31500/3500]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [31500/3500]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [31500/3500]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [31500/3500]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [31500/3500]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [31500/3500]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [31500/3500]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [31500/3500]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [31500/3500]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [31500/3500]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.765    10 0.00851 Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 3    0.0000000178          1 accuracy binary     0.765    10 0.00851 Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 5    0.00000316            1 accuracy binary     0.765    10 0.00851 Preproces…\n 6    0.00000316            1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 7    0.000562              1 accuracy binary     0.765    10 0.00851 Preproces…\n 8    0.000562              1 roc_auc  binary     0.704    10 0.00310 Preproces…\n 9    0.1                   1 accuracy binary     0.765    10 0.00851 Preproces…\n10    0.1                   1 roc_auc  binary     0.704    10 0.00310 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.000562             11 accuracy binary     0.767    10 0.00661 Preprocess…\n2    0.0000000001          1 accuracy binary     0.765    10 0.00851 Preprocess…\n3    0.0000000178          1 accuracy binary     0.765    10 0.00851 Preprocess…\n4    0.00000316            1 accuracy binary     0.765    10 0.00851 Preprocess…\n5    0.000562              1 accuracy binary     0.765    10 0.00851 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1        0.000562         11 Preprocessor1_Model19\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 0.000562341325190349\n  tree_depth = 11\n\nComputational engine: rpart"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#last-fit",
    "title": "Level 4 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#evaluate",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.762 Preprocessor1_Model1\n2 roc_auc  binary         0.800 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5726 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5726 2863 children (0.50000000 0.50000000)  \n     2) adr&gt;=0.1697088 2113  477 children (0.77425461 0.22574539)  \n       4) adr&gt;=0.8986797 1033  128 children (0.87608906 0.12391094)  \n         8) adults&lt; 1.261466 880   77 children (0.91250000 0.08750000) *\n         9) adults&gt;=1.261466 153   51 children (0.66666667 0.33333333)  \n          18) adr&gt;=1.784047 58    5 children (0.91379310 0.08620690) *\n          19) adr&lt; 1.784047 95   46 children (0.51578947 0.48421053)  \n            38) total_of_special_requests&lt; 0.648806 76   32 children (0.57894737 0.42105263)  \n              76) adr&gt;=1.118784 55   19 children (0.65454545 0.34545455) *\n              77) adr&lt; 1.118784 21    8 none (0.38095238 0.61904762)  \n               154) adr&lt; 1.021625 11    4 children (0.63636364 0.36363636) *\n               155) adr&gt;=1.021625 10    1 none (0.10000000 0.90000000) *\n            39) total_of_special_requests&gt;=0.648806 19    5 none (0.26315789 0.73684211) *\n       5) adr&lt; 0.8986797 1080  349 children (0.67685185 0.32314815)  \n        10) adults&lt; 1.261466 979  276 children (0.71807967 0.28192033)  \n          20) adults&gt;=-0.7987603 916  233 children (0.74563319 0.25436681)  \n            40) meal_SC&lt; 1.874245 876  210 children (0.76027397 0.23972603)  \n              80) total_of_special_requests&gt;=0.648806 311   48 children (0.84565916 0.15434084) *\n              81) total_of_special_requests&lt; 0.648806 565  162 children (0.71327434 0.28672566)  \n               162) arrival_date_month_September&lt; 1.714139 508  136 children (0.73228346 0.26771654) *\n               163) arrival_date_month_September&gt;=1.714139 57   26 children (0.54385965 0.45614035)  \n                 326) stays_in_weekend_nights&gt;=0.527525 16    4 children (0.75000000 0.25000000) *\n                 327) stays_in_weekend_nights&lt; 0.527525 41   19 none (0.46341463 0.53658537)  \n                   654) total_of_special_requests&gt;=-0.4298999 24   10 children (0.58333333 0.41666667)  \n                    1308) adr&gt;=0.3102977 17    4 children (0.76470588 0.23529412) *\n                    1309) adr&lt; 0.3102977 7    1 none (0.14285714 0.85714286) *\n                   655) total_of_special_requests&lt; -0.4298999 17    5 none (0.29411765 0.70588235) *\n            41) meal_SC&gt;=1.874245 40   17 none (0.42500000 0.57500000)  \n              82) adr&gt;=0.4268564 24   10 children (0.58333333 0.41666667)  \n               164) adr&lt; 0.5513986 16    3 children (0.81250000 0.18750000) *\n               165) adr&gt;=0.5513986 8    1 none (0.12500000 0.87500000) *\n              83) adr&lt; 0.4268564 16    3 none (0.18750000 0.81250000) *\n          21) adults&lt; -0.7987603 63   20 none (0.31746032 0.68253968)  \n            42) stays_in_week_nights&gt;=-0.02165468 13    5 children (0.61538462 0.38461538) *\n            43) stays_in_week_nights&lt; -0.02165468 50   12 none (0.24000000 0.76000000) *\n        11) adults&gt;=1.261466 101   28 none (0.27722772 0.72277228)  \n          22) hotel_Resort.Hotel&gt;=0.2012867 32   10 children (0.68750000 0.31250000) *\n          23) hotel_Resort.Hotel&lt; 0.2012867 69    6 none (0.08695652 0.91304348) *\n     3) adr&lt; 0.1697088 3613 1227 none (0.33960697 0.66039303)  \n       6) total_of_special_requests&gt;=0.648806 713  282 children (0.60448808 0.39551192)  \n        12) meal_SC&lt; 1.874245 658  238 children (0.63829787 0.36170213)  \n          24) adr&gt;=-0.4024668 331   92 children (0.72205438 0.27794562)  \n            48) adults&lt; 1.261466 322   84 children (0.73913043 0.26086957)  \n              96) arrival_date_month_July&gt;=1.014446 63    7 children (0.88888889 0.11111111) *\n              97) arrival_date_month_July&lt; 1.014446 259   77 children (0.70270270 0.29729730)  \n\n...\nand 86 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#save-model",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.50 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')"
  },
  {
    "objectID": "hotel classification model/Level 4 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/Level 4 classification Tidy Modeling.html#make-predication",
    "title": "Level 4 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 children   \n5 none       \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      605 2196\n  none          200 6999\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.760\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          805\n2 none             9195\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2801\n2 none         7199\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      605 2196\n  none          200 6999"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html",
    "title": "Level 5 classification Tidy Modeling",
    "section": "",
    "text": "Level 5 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#read-data",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#data-split",
    "title": "Level 5 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#recipe",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#model",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#model",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      &lt;int&gt; 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#workflow",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#workflow",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 96 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.00000000437         11 accuracy binary     0.747    10 0.00458 Preproces…\n 2   0.00000000437         11 roc_auc  binary     0.820    10 0.00526 Preproces…\n 3   0.000000134           15 accuracy binary     0.749    10 0.00502 Preproces…\n 4   0.000000134           15 roc_auc  binary     0.818    10 0.00489 Preproces…\n 5   0.00000708            12 accuracy binary     0.755    10 0.00470 Preproces…\n 6   0.00000708            12 roc_auc  binary     0.819    10 0.00504 Preproces…\n 7   0.00000327            12 accuracy binary     0.755    10 0.00470 Preproces…\n 8   0.00000327            12 roc_auc  binary     0.819    10 0.00504 Preproces…\n 9   0.0000750             13 accuracy binary     0.754    10 0.00539 Preproces…\n10   0.0000750             13 roc_auc  binary     0.818    10 0.00517 Preproces…\n# ℹ 86 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1        4.37e- 9         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n2        4.32e- 5         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n3        1.09e-10         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n4        1.45e- 9         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n5        7.52e- 8         11 roc_auc binary     0.820    10 0.00526 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1   0.00000000437         11 Preprocessor1_Model008\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 4.37354062320283e-09\n  tree_depth = 11\n\nComputational engine: rpart"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#last-fit",
    "title": "Level 5 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#evaluate",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.741 Preprocessor1_Model1\n2 roc_auc  binary         0.817 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.741\n2 recall    binary         0.767\n3 precision binary         0.212\n4 f_meas    binary         0.333\n5 kap       binary         0.231\n6 sens      binary         0.767\n7 spec      binary         0.738\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5740 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5740 2870 children (0.50000000 0.50000000)  \n     2) adr&gt;=0.284338 1897  389 children (0.79493938 0.20506062)  \n       4) adr&gt;=0.7947756 1158  162 children (0.86010363 0.13989637)  \n         8) adults&lt; 1.283198 1031  121 children (0.88263822 0.11736178)  \n          16) adr&gt;=1.920987 227    9 children (0.96035242 0.03964758) *\n          17) adr&lt; 1.920987 804  112 children (0.86069652 0.13930348)  \n            34) hotel_Resort.Hotel&lt; 0.2015155 447   40 children (0.91051454 0.08948546)  \n              68) arrival_date_month_July&gt;=1.001495 84    0 children (1.00000000 0.00000000) *\n              69) arrival_date_month_July&lt; 1.001495 363   40 children (0.88980716 0.11019284)  \n               138) adr&gt;=1.056165 232   17 children (0.92672414 0.07327586)  \n                 276) arrival_date_month_May&lt; 1.621817 199   10 children (0.94974874 0.05025126) *\n                 277) arrival_date_month_May&gt;=1.621817 33    7 children (0.78787879 0.21212121)  \n                   554) stays_in_weekend_nights&lt; 0.5718426 24    2 children (0.91666667 0.08333333) *\n                   555) stays_in_weekend_nights&gt;=0.5718426 9    4 none (0.44444444 0.55555556) *\n               139) adr&lt; 1.056165 131   23 children (0.82442748 0.17557252)  \n                 278) adr&lt; 1.035544 119   18 children (0.84873950 0.15126050)  \n                   556) adr&gt;=0.9905588 24    0 children (1.00000000 0.00000000) *\n                   557) adr&lt; 0.9905588 95   18 children (0.81052632 0.18947368)  \n                    1114) adr&lt; 0.9722464 84   11 children (0.86904762 0.13095238) *\n                    1115) adr&gt;=0.9722464 11    4 none (0.36363636 0.63636364) *\n                 279) adr&gt;=1.035544 12    5 children (0.58333333 0.41666667) *\n            35) hotel_Resort.Hotel&gt;=0.2015155 357   72 children (0.79831933 0.20168067)  \n              70) stays_in_week_nights&gt;=0.5693529 165   20 children (0.87878788 0.12121212) *\n              71) stays_in_week_nights&lt; 0.5693529 192   52 children (0.72916667 0.27083333)  \n               142) required_car_parking_spaces_parking&gt;=1.065734 67   10 children (0.85074627 0.14925373) *\n               143) required_car_parking_spaces_parking&lt; 1.065734 125   42 children (0.66400000 0.33600000)  \n                 286) stays_in_weekend_nights&gt;=-0.4695205 70   16 children (0.77142857 0.22857143)  \n                   572) adr&lt; 1.125593 25    1 children (0.96000000 0.04000000) *\n                   573) adr&gt;=1.125593 45   15 children (0.66666667 0.33333333)  \n                    1146) adr&gt;=1.199957 37   10 children (0.72972973 0.27027027) *\n                    1147) adr&lt; 1.199957 8    3 none (0.37500000 0.62500000) *\n                 287) stays_in_weekend_nights&lt; -0.4695205 55   26 children (0.52727273 0.47272727)  \n                   574) total_of_special_requests&lt; -0.4165399 20    6 children (0.70000000 0.30000000) *\n                   575) total_of_special_requests&gt;=-0.4165399 35   15 none (0.42857143 0.57142857)  \n                    1150) adr&lt; 1.225674 19    9 children (0.52631579 0.47368421) *\n                    1151) adr&gt;=1.225674 16    5 none (0.31250000 0.68750000) *\n         9) adults&gt;=1.283198 127   41 children (0.67716535 0.32283465)  \n          18) adr&gt;=1.597176 62   10 children (0.83870968 0.16129032) *\n          19) adr&lt; 1.597176 65   31 children (0.52307692 0.47692308)  \n            38) hotel_Resort.Hotel&gt;=0.2015155 21    4 children (0.80952381 0.19047619) *\n            39) hotel_Resort.Hotel&lt; 0.2015155 44   17 none (0.38636364 0.61363636)  \n              78) adr&lt; 1.218269 29   14 none (0.48275862 0.51724138)  \n               156) stays_in_week_nights&gt;=0.007439962 13    5 children (0.61538462 0.38461538) *\n               157) stays_in_week_nights&lt; 0.007439962 16    6 none (0.37500000 0.62500000) *\n              79) adr&gt;=1.218269 15    3 none (0.20000000 0.80000000) *\n\n...\nand 208 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#save-model",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.54 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')"
  },
  {
    "objectID": "hotel classification model/Level 5 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/Level 5 classification Tidy Modeling.html#make-predication",
    "title": "Level 5 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 children   \n3 none       \n4 children   \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      612 2402\n  none          184 6802\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.741\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          796\n2 none             9204\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     3014\n2 none         6986\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      612 2402\n  none          184 6802"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html",
    "title": "Level 6 classification Tidy Modeling",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:\nlogistic glm model\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\nKNN model with knn engine(knn_spec)\ntuning XG boost model (tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)\ntuning light gbm boost model(tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#read-data",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#data-split",
    "title": "Level 6 classification Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#recipe",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#model",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#model",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          2   3.42e- 6       8.02e- 9    32       0.734     3\n2          7   4.05e- 5       2.42e- 1    25       0.393     7\n3         14   4.98e- 4       5.17e-10     4       0.465     3\n4         12   4.33e- 8       8.46e- 7     8       0.485     9\n5         10   4.00e-10       2.81e- 5    14       0.387     9\n6          7   7.24e- 5       8.03e- 2     9       0.105    11\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         10   1.14e-10       1.09e- 3    13       0.682     1\n2          6   1.25e- 5       1.81e+ 1    19       0.265     6\n3          2   3.59e- 6       1.55e- 5    18       0.860     8\n4          3   5.01e- 8       2.34e-10    20       0.108     6\n5         15   2.98e- 2       2.05e- 6    21       0.341     5\n6         13   2.28e- 3       2.52e- 7    34       0.124     4"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#workflow-set",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#workflow-set",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#training-and-tunning",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_xgb\nPreprocessor1_Model19\naccuracy\n0.7737143\n0.002532689\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model19\nroc_auc\n0.8374165\n0.003095749\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model17\naccuracy\n0.7728000\n0.002728468\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_lightgbm\nPreprocessor1_Model17\nroc_auc\n0.8343130\n0.002166861\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\naccuracy\n0.7511429\n0.005013361\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model02\nroc_auc\n0.8151031\n0.004443499\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7633429\n0.002970467\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.8041016\n0.004391708\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7349429\n0.002423262\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7905486\n0.005938270\n10\nrecipe\nnearest_neighbor\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#last-fit",
    "title": "Level 6 classification Tidy Modeling",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#evaluate",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.766 Preprocessor1_Model1\n2 roc_auc  binary         0.855 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.766\n2 recall    binary         0.763\n3 precision binary         0.223\n4 f_meas    binary         0.345\n5 kap       binary         0.252\n6 sens      binary         0.763\n7 spec      binary         0.766\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 69.6 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.116616325671592, max_depth = 13L, \n    gamma = 0.0148245372418564, colsample_bytree = 1, colsample_bynode = 0.954545454545455, \n    min_child_weight = 8L, subsample = 0.915680007706396), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.116616325671592\", max_depth = \"13\", gamma = \"0.0148245372418564\", colsample_bytree = \"1\", colsample_bynode = \"0.954545454545455\", min_child_weight = \"8\", subsample = \"0.915680007706396\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 22 \nniter: 10\nnfeatures : 22 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6541358\n        2        0.6233505\n---                       \n        9        0.4999397\n       10        0.4906805\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#save-model",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.50 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')"
  },
  {
    "objectID": "hotel classification model/Level 6 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/Level 6 classification Tidy Modeling.html#make-predication",
    "title": "Level 6 classification Tidy Modeling",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 children   \n4 children   \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      589 2063\n  none          199 7149\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.774\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          788\n2 none             9212\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2652\n2 none         7348\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      589 2063\n  none          199 7149"
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning\nadd quick tuning\nadd workflow set and setting different tuning grid for different model",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#read-data",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#data-split",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#recipe",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\n\nCode\ntrained_data_rec &lt;- prep(data_rec, training = data_train)\n\n\n\n\nCode\ntrained_data_rec %&gt;%check_missing(\"LotFrontage\")",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#model",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#model",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 50)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\n3.2.2 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec =\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"regression\")\n\n\n\n\nCode\ntune_spec %&gt;% extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid = \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.3 lightGBM Boost tree\n\n\nCode\nlightgbm_spec = boost_tree(\n  trees = 100,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"regression\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth    learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          7 0.00953             2.79e- 1    40       0.256    13\n2          6 0.00130             1.47e- 3    16       0.732     4\n3          9 0.0000453           2.17e- 7    36       0.446    25\n4          3 0.0199              2.13e- 8    26       0.773    35\n5         13 0.0793              8.96e- 9    30       0.219    12\n6         10 0.00000000238       1.09e-10    21       0.699    21\n\n\n\n\n3.2.4 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(\n  mtry = tune(), trees = tune(), min_n = tune()\n  )%&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n\nComputational engine: ranger \n\n\n\n\nCode\nrf_grid &lt;- \n  grid_latin_hypercube(\n    min_n(), \n    mtry(range = c(4, 9)), \n    trees(), \n    size = 80)\n\nhead(rf_grid)\n\n\n# A tibble: 6 × 3\n  min_n  mtry trees\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    33     7  1713\n2    29     5  1343\n3    12     6   545\n4    21     6   843\n5    27     5  1485\n6    13     9    48",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#workflow",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nworkflow_set =\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(\n                  lasso=lasso_tune_spec,\n                  tree  = tune_spec,\n                  lightgbm=lightgbm_spec,\n                  random_forest=rf_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = lasso_grid, id = \"recipe_lasso\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\")  %&gt;% \n  option_add(grid = rf_grid, id = \"recipe_rf\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id             info             option    result    \n  &lt;chr&gt;                &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_lasso         &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n2 recipe_tree          &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_lightgbm      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n4 recipe_random_forest &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;\n\n\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#training",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#training",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 50,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"rmse\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_lightgbm\nPreprocessor1_Model46\nrmse\n2.898681e+04\n3.152131e+03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model46\nrsq\n8.704013e-01\n1.884946e-02\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_random_forest\nPreprocessor1_Model31\nrmse\n2.918897e+04\n3.074054e+03\n10\nrecipe\nrand_forest\n2\n\n\nrecipe_random_forest\nPreprocessor1_Model31\nrsq\n8.693925e-01\n1.953458e-02\n10\nrecipe\nrand_forest\n2\n\n\nrecipe_lasso\nPreprocessor1_Model01\nrmse\n3.878538e+04\n5.169415e+03\n10\nrecipe\nlinear_reg\n3\n\n\nrecipe_lasso\nPreprocessor1_Model01\nrsq\n7.769664e-01\n4.331088e-02\n10\nrecipe\nlinear_reg\n3\n\n\nrecipe_tree\nPreprocessor1_Model06\nrmse\n3.923049e+04\n2.064970e+03\n10\nrecipe\ndecision_tree\n4\n\n\nrecipe_tree\nPreprocessor1_Model06\nrsq\n7.674437e-01\n1.574068e-02\n10\nrecipe\ndecision_tree\n4\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_lightgbm')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_random_forest\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"rmse\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#last-fit",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "4.1 last fit",
    "text": "4.1 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)\n\n\n\n\nCode\noptions(scipen=10000)\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   28019.    Preprocessor1_Model1\n2 rsq     standard       0.876 Preprocessor1_Model1\n\n\n\n\nCode\n(final_fit%&gt;%collect_predictions()) %&gt;% ggplot(aes(target_variable, .pred))+ geom_abline(lty = 2, color = \"gray80\", size = 1.5) +geom_point(alpha = 0.5)+labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )+scale_x_continuous(labels = scales::comma) +scale_y_continuous(labels = scales::comma) \n\n\n\n\n\n\n\n\n\nmanual calculate RMSE on testing data\n\n\nCode\nfinal_data=final_fit%&gt;%collect_predictions()\n\nfinal_data2=final_data %&gt;% mutate(diff=target_variable-.pred)%&gt;% mutate(diff2=diff^2)\n\na=sum(final_data2$diff2)/nrow(final_data2)\n\nsqrt(a)\n\n\n[1] 28018.9\n\n\nCode\n#glimpse(final_data2)",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 6 Regression Tidy Modeling.html#resample-with-tuned-model",
    "href": "house price regression model/Level 6 Regression Tidy Modeling.html#resample-with-tuned-model",
    "title": "Level 6 Regression Tidy Modeling",
    "section": "4.2 resample with tuned model",
    "text": "4.2 resample with tuned model",
    "crumbs": [
      "house price regression model",
      "Level 6 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning\nadd quick tunning",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#read-data",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#data-split",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#recipe",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(),-all_outcomes())",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#model",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#model",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 50)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#workflow",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(lasso_tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#training",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#training",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nlasso_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 100 × 7\n    penalty .metric .estimator      mean     n   std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model01\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model01\n 3 1.60e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model02\n 4 1.60e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model02\n 5 2.56e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model03\n 6 2.56e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model03\n 7 4.09e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model04\n 8 4.09e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model04\n 9 6.55e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model05\n10 6.55e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model05\n# ℹ 90 more rows",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#evaluate",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nautoplot(lasso_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nglimpse(lasso_res)\n\n\nRows: 10\nColumns: 6\n$ splits       &lt;list&gt; [&lt;vfold_split[919 x 102 x 1021 x 38]&gt;], [&lt;vfold_split[91…\n$ id           &lt;chr&gt; \"Fold02\", \"Fold05\", \"Fold10\", \"Fold09\", \"Fold03\", \"Fold04…\n$ .order       &lt;int&gt; 3, 2, 1, 4, 5, 6, 7, 8, 9, 10\n$ .metrics     &lt;list&gt; [&lt;tbl_df[100 x 5]&gt;], [&lt;tbl_df[100 x 5]&gt;], [&lt;tbl_df[100 x …\n$ .notes       &lt;list&gt; [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;],…\n$ .predictions &lt;list&gt; [&lt;tbl_df[5100 x 5]&gt;], [&lt;tbl_df[5100 x 5]&gt;], [&lt;tbl_df[510…\n\n\n\n\nCode\nlasso_res %&gt;% plot_race()\n\n\n\n\n\n\n\n\n\nuse best tune model for final fit\n\n\nCode\nlowest_rmse &lt;- lasso_res %&gt;%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n\n\n# A tibble: 1 × 2\n       penalty .config              \n         &lt;dbl&gt; &lt;chr&gt;                \n1 0.0000000001 Preprocessor1_Model01\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#last-fit",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "4.2 last fit",
    "text": "4.2 last fit\n\n\nCode\nfinal_res &lt;- \n  final_wf %&gt;%\n  last_fit(data_split) \n\n\n\n\nCode\noptions(scipen=10000)\nfinal_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "house price regression model/Level 5 Regression Tidy Modeling.html#resample-with-tuned-model",
    "href": "house price regression model/Level 5 Regression Tidy Modeling.html#resample-with-tuned-model",
    "title": "Level 5 Regression Tidy Modeling",
    "section": "4.3 resample with tuned model",
    "text": "4.3 resample with tuned model",
    "crumbs": [
      "house price regression model",
      "Level 5 Regression Tidy Modeling"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html",
    "href": "tensorflow/Level 1 Regression tensorflow.html",
    "title": "Level 1 Regression Tensorflow model",
    "section": "",
    "text": "Code\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n\n\nCode\nprint(\"TensorFlow v\" + tf.__version__)\nprint(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n\n\nTensorFlow v2.16.1\nTensorFlow Decision Forests v1.9.0",
    "crumbs": [
      "Tensorflow",
      "Level 1 Regression Tensorflow model"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#read-data",
    "href": "tensorflow/Level 1 Regression tensorflow.html#read-data",
    "title": "Level 1 Regression Tensorflow model",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\ntrain_file_path = \"data/train.csv\"\ndataset_df = pd.read_csv(train_file_path)\nprint(\"Full train dataset shape is {}\".format(dataset_df.shape))\n\n\nFull train dataset shape is (1460, 81)\n\n\n\n\nCode\ndataset_df.head(3)\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n\n\n3 rows × 81 columns\n\n\n\n\n\n\nCode\ndataset_df = dataset_df.drop('Id', axis=1)\ndataset_df.head(3)\n\n\n\n\n\n\n\n\n\n\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\nLotConfig\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\nInside\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\nFR2\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\nInside\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n\n\n3 rows × 80 columns\n\n\n\n\n\n\nCode\ndataset_df.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 80 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   MSSubClass     1460 non-null   int64  \n 1   MSZoning       1460 non-null   object \n 2   LotFrontage    1201 non-null   float64\n 3   LotArea        1460 non-null   int64  \n 4   Street         1460 non-null   object \n 5   Alley          91 non-null     object \n 6   LotShape       1460 non-null   object \n 7   LandContour    1460 non-null   object \n 8   Utilities      1460 non-null   object \n 9   LotConfig      1460 non-null   object \n 10  LandSlope      1460 non-null   object \n 11  Neighborhood   1460 non-null   object \n 12  Condition1     1460 non-null   object \n 13  Condition2     1460 non-null   object \n 14  BldgType       1460 non-null   object \n 15  HouseStyle     1460 non-null   object \n 16  OverallQual    1460 non-null   int64  \n 17  OverallCond    1460 non-null   int64  \n 18  YearBuilt      1460 non-null   int64  \n 19  YearRemodAdd   1460 non-null   int64  \n 20  RoofStyle      1460 non-null   object \n 21  RoofMatl       1460 non-null   object \n 22  Exterior1st    1460 non-null   object \n 23  Exterior2nd    1460 non-null   object \n 24  MasVnrType     588 non-null    object \n 25  MasVnrArea     1452 non-null   float64\n 26  ExterQual      1460 non-null   object \n 27  ExterCond      1460 non-null   object \n 28  Foundation     1460 non-null   object \n 29  BsmtQual       1423 non-null   object \n 30  BsmtCond       1423 non-null   object \n 31  BsmtExposure   1422 non-null   object \n 32  BsmtFinType1   1423 non-null   object \n 33  BsmtFinSF1     1460 non-null   int64  \n 34  BsmtFinType2   1422 non-null   object \n 35  BsmtFinSF2     1460 non-null   int64  \n 36  BsmtUnfSF      1460 non-null   int64  \n 37  TotalBsmtSF    1460 non-null   int64  \n 38  Heating        1460 non-null   object \n 39  HeatingQC      1460 non-null   object \n 40  CentralAir     1460 non-null   object \n 41  Electrical     1459 non-null   object \n 42  1stFlrSF       1460 non-null   int64  \n 43  2ndFlrSF       1460 non-null   int64  \n 44  LowQualFinSF   1460 non-null   int64  \n 45  GrLivArea      1460 non-null   int64  \n 46  BsmtFullBath   1460 non-null   int64  \n 47  BsmtHalfBath   1460 non-null   int64  \n 48  FullBath       1460 non-null   int64  \n 49  HalfBath       1460 non-null   int64  \n 50  BedroomAbvGr   1460 non-null   int64  \n 51  KitchenAbvGr   1460 non-null   int64  \n 52  KitchenQual    1460 non-null   object \n 53  TotRmsAbvGrd   1460 non-null   int64  \n 54  Functional     1460 non-null   object \n 55  Fireplaces     1460 non-null   int64  \n 56  FireplaceQu    770 non-null    object \n 57  GarageType     1379 non-null   object \n 58  GarageYrBlt    1379 non-null   float64\n 59  GarageFinish   1379 non-null   object \n 60  GarageCars     1460 non-null   int64  \n 61  GarageArea     1460 non-null   int64  \n 62  GarageQual     1379 non-null   object \n 63  GarageCond     1379 non-null   object \n 64  PavedDrive     1460 non-null   object \n 65  WoodDeckSF     1460 non-null   int64  \n 66  OpenPorchSF    1460 non-null   int64  \n 67  EnclosedPorch  1460 non-null   int64  \n 68  3SsnPorch      1460 non-null   int64  \n 69  ScreenPorch    1460 non-null   int64  \n 70  PoolArea       1460 non-null   int64  \n 71  PoolQC         7 non-null      object \n 72  Fence          281 non-null    object \n 73  MiscFeature    54 non-null     object \n 74  MiscVal        1460 non-null   int64  \n 75  MoSold         1460 non-null   int64  \n 76  YrSold         1460 non-null   int64  \n 77  SaleType       1460 non-null   object \n 78  SaleCondition  1460 non-null   object \n 79  SalePrice      1460 non-null   int64  \ndtypes: float64(3), int64(34), object(43)\nmemory usage: 912.6+ KB",
    "crumbs": [
      "Tensorflow",
      "Level 1 Regression Tensorflow model"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#data-pre",
    "href": "tensorflow/Level 1 Regression tensorflow.html#data-pre",
    "title": "Level 1 Regression Tensorflow model",
    "section": "2.2 data pre",
    "text": "2.2 data pre\n\n\nCode\nimport numpy as np\ndef split_dataset(dataset, test_ratio=0.30):\n  test_indices = np.random.rand(len(dataset)) &lt; test_ratio\n  return dataset[~test_indices], dataset[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_dataset(dataset_df)\nprint(\"{} examples in training, {} examples in testing.\".format(\n    len(train_ds_pd), len(valid_ds_pd)))\n\n\n1012 examples in training, 448 examples in testing.\n\n\n\n\nCode\nlabel = 'SalePrice'\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)",
    "crumbs": [
      "Tensorflow",
      "Level 1 Regression Tensorflow model"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#define-model-keras-random-forest",
    "href": "tensorflow/Level 1 Regression tensorflow.html#define-model-keras-random-forest",
    "title": "Level 1 Regression Tensorflow model",
    "section": "3.1 define model Keras random forest",
    "text": "3.1 define model Keras random forest\n\n\nCode\ntfdf.keras.get_all_models()\n\n\n[tensorflow_decision_forests.keras.RandomForestModel,\n tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n tensorflow_decision_forests.keras.CartModel,\n tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]\n\n\n\n\nCode\nrf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\nrf.compile(metrics=[\"mse\"]) # Optional, you can use this to include a list of eval metrics\n\n\nUse /var/folders/v3/pzt9c47n1nbcsmybsg_w0lhw0000gn/T/tmpfvd0haib as temporary training directory",
    "crumbs": [
      "Tensorflow",
      "Level 1 Regression Tensorflow model"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#train-model",
    "href": "tensorflow/Level 1 Regression tensorflow.html#train-model",
    "title": "Level 1 Regression Tensorflow model",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nrf.fit(x=train_ds)\n\n\nReading training dataset...\nTraining dataset read in 0:00:01.592298. Found 1012 examples.\nTraining model...\nModel trained in 0:00:00.488444\nCompiling model...\nModel compiled.\n\n\n&lt;tf_keras.src.callbacks.History at 0x10572d850&gt;\n\n\n\n\nCode\ntfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=3)\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nlogs = rf.make_inspector().training_logs()\nplt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"RMSE (out-of-bag)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ninspector = rf.make_inspector()\ninspector.evaluation()\n\n\nEvaluation(num_examples=1012, accuracy=None, loss=None, rmse=29144.798502788246, ndcg=None, aucs=None, auuc=None, qini=None)\n\n\n\n\nCode\nevaluation = rf.evaluate(x=valid_ds,return_dict=True)\n\nfor name, value in evaluation.items():\n  print(f\"{name}: {value:.4f}\")\n\n\n1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - mse: 912837952.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - mse: 912837952.0000\nloss: 0.0000\nmse: 912837952.0000\n\n\n\n\nCode\nfor name, value in evaluation.items():\n  mse=value\n\n\nRMSE\n\n\nCode\nimport math\nmath.sqrt(mse)\n\n\n30213.208237458002",
    "crumbs": [
      "Tensorflow",
      "Level 1 Regression Tensorflow model"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#variable-importances",
    "href": "tensorflow/Level 1 Regression tensorflow.html#variable-importances",
    "title": "Level 1 Regression Tensorflow model",
    "section": "3.3 Variable importances",
    "text": "3.3 Variable importances\n\n\nCode\nprint(f\"Available variable importances:\")\nfor importance in inspector.variable_importances().keys():\n  print(\"\\t\", importance)\n\n\nAvailable variable importances:\n     INV_MEAN_MIN_DEPTH\n     NUM_NODES\n     NUM_AS_ROOT\n     SUM_SCORE",
    "crumbs": [
      "Tensorflow",
      "Level 1 Regression Tensorflow model"
    ]
  },
  {
    "objectID": "index/1 index.html",
    "href": "index/1 index.html",
    "title": "tidymodeling",
    "section": "",
    "text": "This is tidymodel Project.\n\n\n\nhotel classification model\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitanic classification model\n\n\n\n\n\n\n\n\n\n\n\n\n\nhouse price regression model\n\n\n\n\n\n\n\n\n\n\n\ntensorflow model\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Index",
      "tidymodeling"
    ]
  },
  {
    "objectID": "index/3 resample.html",
    "href": "index/3 resample.html",
    "title": "resample",
    "section": "",
    "text": "k-Fold Cross-Validation\n\n\nk_flod_resample&lt;- vfold_cv(data, v = 10)\nk_flod_resample\n\n\n\nMONTE CARLO CROSS-VALIDATION\nfor MCCV, this proportion of the data is randomly selected each time. This results in assessment sets that are not mutually exclusive\n\nmc_resample&lt;- mc_cv(data, prop = 9/10, times = 20)\nmc_resample\n\n\n\nThe Bootstrap\nA bootstrap sample of the training set is a sample that is the same size as the training set but is drawn with replacement\n\n\nbootstraps_resample&lt;- bootstraps(data, times = 1000)\nbootstraps_resample\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Index",
      "resample"
    ]
  },
  {
    "objectID": "index/4 recipe.html",
    "href": "index/4 recipe.html",
    "title": "recipe",
    "section": "",
    "text": "create recipe step_xxx\n\ntree_rec &lt;- recipe(legal_status ~ ., data = trees_train) %&gt;%\n  \n # update the role for tree_id, since this is a variable we might like to keep around for convenience as an identifier for rows but is not a predictor or outcome. \n  update_role(tree_id, new_role = \"ID\") %&gt;%\n  \n# step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step, there were 300+ species!\n  step_other(species, caretaker, threshold = 0.01) %&gt;%\n  \n# create dummy for nominal data exclude outcome\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  \n# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date, given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.  \n  step_date(date, features = c(\"year\")) %&gt;%step_rm(date) %&gt;%\n  \n# There are many more DPW maintained trees than not, so let’s downsample the data for training.  \n  step_downsample(legal_status)%&gt;%\n\n# will remove all. predictor variables that contain only a single value\n    step_zv(all_numeric(all_predictors())) %&gt;% \n  \n#  normalize all numeric data\n  step_normalize(all_numeric()) %&gt;% \n\n# use KNN to impute all predictors\nstep_impute_knn(all_predictors()) \n\n\n\ncheck recipe check_xxx\n\n#&gt; [1] \"check_class\"      \"check_cols\"       \"check_missing\"   \n#&gt; [4] \"check_name\"       \"check_new_data\"   \"check_new_values\"\n#&gt; [7] \"check_range\"      \"check_type\"\n\n\n\nroles to select variables\nIn most cases, the right approach for users will be use to use the predictor-specific selectors such as all_numeric_predictors() and all_nominal_predictors().\n\nhas_role(match = \"predictor\")\n\nhas_type(match = \"numeric\")\n\nall_outcomes()\n\nall_predictors()\n\nall_date()\n\nall_date_predictors()\n\nall_datetime()\n\nall_datetime_predictors()\n\nall_double()\n\nall_double_predictors()\n\nall_factor()\n\nall_factor_predictors()\n\nall_integer()\n\nall_integer_predictors()\n\nall_logical()\n\nall_logical_predictors()\n\nall_nominal()\n\nall_nominal_predictors()\n\nall_numeric()\n\nall_numeric_predictors()\n\nall_ordered()\n\nall_ordered_predictors()\n\nall_string()\n\nall_string_predictors()\n\nall_unordered()\n\nall_unordered_predictors()\n\ncurrent_info()\n\n\n\nreference:\nhttps://recipes.tidymodels.org/reference/has_role.html\n\n\n\n\n Back to top",
    "crumbs": [
      "Index",
      "recipe"
    ]
  },
  {
    "objectID": "index/2 about.html",
    "href": "index/2 about.html",
    "title": "About",
    "section": "",
    "text": "About this site:\nlink:https://tonyfly3000.github.io/tidymodeling/\n\nhttps://www.tidymodels.org/\n\nModeling process\n\n\n\nresource\ntidymodels website: https://www.tidymodels.org/\ntidymodels book: https://www.tmwr.org/\n\n\n\n\n Back to top",
    "crumbs": [
      "Index",
      "About"
    ]
  },
  {
    "objectID": "intro/3 resample.html",
    "href": "intro/3 resample.html",
    "title": "resample",
    "section": "",
    "text": "k-Fold Cross-Validation\n\n\nk_flod_resample&lt;- vfold_cv(data, v = 10)\nk_flod_resample\n\n\n\nMONTE CARLO CROSS-VALIDATION\nfor MCCV, this proportion of the data is randomly selected each time. This results in assessment sets that are not mutually exclusive\n\nmc_resample&lt;- mc_cv(data, prop = 9/10, times = 20)\nmc_resample\n\n\n\nThe Bootstrap\nA bootstrap sample of the training set is a sample that is the same size as the training set but is drawn with replacement\n\n\nbootstraps_resample&lt;- bootstraps(data, times = 1000)\nbootstraps_resample\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "resample"
    ]
  },
  {
    "objectID": "intro/2 about.html",
    "href": "intro/2 about.html",
    "title": "About",
    "section": "",
    "text": "About this site:\nlink:https://tonyfly3000.github.io/tidymodeling/\n\nhttps://www.tidymodels.org/\n\nModeling process\n\n\n\nresource\ntidymodels website: https://www.tidymodels.org/\ntidymodels book: https://www.tmwr.org/\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "About"
    ]
  },
  {
    "objectID": "intro/4 recipe.html",
    "href": "intro/4 recipe.html",
    "title": "recipe",
    "section": "",
    "text": "create recipe step_xxx\n\ntree_rec &lt;- recipe(legal_status ~ ., data = trees_train) %&gt;%\n  \n # update the role for tree_id, since this is a variable we might like to keep around for convenience as an identifier for rows but is not a predictor or outcome. \n  update_role(tree_id, new_role = \"ID\") %&gt;%\n  \n# step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step, there were 300+ species!\n  step_other(species, caretaker, threshold = 0.01) %&gt;%\n  \n# create dummy for nominal data exclude outcome\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  \n# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date, given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.  \n  step_date(date, features = c(\"year\")) %&gt;%step_rm(date) %&gt;%\n  \n# There are many more DPW maintained trees than not, so let’s downsample the data for training.  \n  step_downsample(legal_status)%&gt;%\n\n# will remove all. predictor variables that contain only a single value\n    step_zv(all_numeric(all_predictors())) %&gt;% \n  \n#  normalize all numeric data\n  step_normalize(all_numeric()) %&gt;% \n\n# use KNN to impute all predictors\nstep_impute_knn(all_predictors()) \n\n\n\ncheck recipe check_xxx\n\n#&gt; [1] \"check_class\"      \"check_cols\"       \"check_missing\"   \n#&gt; [4] \"check_name\"       \"check_new_data\"   \"check_new_values\"\n#&gt; [7] \"check_range\"      \"check_type\"\n\n\n\nroles to select variables\nIn most cases, the right approach for users will be use to use the predictor-specific selectors such as all_numeric_predictors() and all_nominal_predictors().\n\nhas_role(match = \"predictor\")\n\nhas_type(match = \"numeric\")\n\nall_outcomes()\n\nall_predictors()\n\nall_date()\n\nall_date_predictors()\n\nall_datetime()\n\nall_datetime_predictors()\n\nall_double()\n\nall_double_predictors()\n\nall_factor()\n\nall_factor_predictors()\n\nall_integer()\n\nall_integer_predictors()\n\nall_logical()\n\nall_logical_predictors()\n\nall_nominal()\n\nall_nominal_predictors()\n\nall_numeric()\n\nall_numeric_predictors()\n\nall_ordered()\n\nall_ordered_predictors()\n\nall_string()\n\nall_string_predictors()\n\nall_unordered()\n\nall_unordered_predictors()\n\ncurrent_info()\n\n\n\nreference:\nhttps://recipes.tidymodels.org/reference/has_role.html\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "recipe"
    ]
  },
  {
    "objectID": "intro/1 index.html",
    "href": "intro/1 index.html",
    "title": "tidymodeling",
    "section": "",
    "text": "This is tidymodel Project.\n\n\n\nhotel classification model\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitanic classification model\n\n\n\n\n\n\n\n\n\n\n\n\n\nhouse price regression model\n\n\n\n\n\n\n\n\n\n\n\ntensorflow model\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "tidymodeling"
    ]
  },
  {
    "objectID": "intro/5 data analytic in R book.html",
    "href": "intro/5 data analytic in R book.html",
    "title": "Data analytic in R book",
    "section": "",
    "text": "R for Data Science\nby Garrett Grolemund, Hadley Wickham\n\n\n\nHands on programming with R\nby Garrett Grolemund, Hadley Wickham\n\n\n\nDeep Learning with R\nby François Chollet,J. J. Allaire\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "Data analytic in R book"
    ]
  },
  {
    "objectID": "intro/5 R boook.html",
    "href": "intro/5 R boook.html",
    "title": "R book",
    "section": "",
    "text": "The Art of R Programming\nby Norman Matloff 2011\n\n\n\nThe book of R\nby Tilman M. Davie 2016\n\n\n\nR in action\nby Robert I. Kabacoff 2011\n\n\n\nR Packages\nby Hadley Wickham Jennifer Bryan\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "R book"
    ]
  },
  {
    "objectID": "intro/6 data analytic in R book.html",
    "href": "intro/6 data analytic in R book.html",
    "title": "Data analytic in R book",
    "section": "",
    "text": "R for Data Science\nby Garrett Grolemund, Hadley Wickham 2017\n\n\n\nHands on programming with R\nby Garrett Grolemund, Hadley Wickham\n\n\n\nTidy Modeling with R\nby Max Kuhn and Julia Silge\n\n(https://www.tmwr.org/)\n\n\nDeep Learning with R\nby François Chollet,J. J. Allaire\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "Data analytic in R book"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html",
    "href": "titanic classification model/3 classification Tidy Modeling.html",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "",
    "text": "Level 4 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/3 classification Tidy Modeling.html#read-data",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/3 classification Tidy Modeling.html#eda",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/3 classification Tidy Modeling.html#plotting",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/3 classification Tidy Modeling.html#data-split",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/3 classification Tidy Modeling.html#recipe",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#model",
    "href": "titanic classification model/3 classification Tidy Modeling.html#model",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#workflow",
    "href": "titanic classification model/3 classification Tidy Modeling.html#workflow",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/3 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits           id     .metrics          .notes           .predictions\n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [560/63]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [560/63]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [560/63]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [561/62]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [561/62]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [561/62]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [561/62]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [561/62]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [561/62]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [561/62]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.774    10  0.0144 Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 3    0.0000000178          1 accuracy binary     0.774    10  0.0144 Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 5    0.00000316            1 accuracy binary     0.774    10  0.0144 Preproces…\n 6    0.00000316            1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 7    0.000562              1 accuracy binary     0.774    10  0.0144 Preproces…\n 8    0.000562              1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 9    0.1                   1 accuracy binary     0.774    10  0.0144 Preproces…\n10    0.1                   1 roc_auc  binary     0.751    10  0.0161 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.0000000001          4 accuracy binary     0.788    10  0.0179 Preprocess…\n2    0.0000000178          4 accuracy binary     0.788    10  0.0179 Preprocess…\n3    0.00000316            4 accuracy binary     0.788    10  0.0179 Preprocess…\n4    0.000562              4 accuracy binary     0.788    10  0.0179 Preprocess…\n5    0.0000000001          1 accuracy binary     0.774    10  0.0144 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          4 Preprocessor1_Model06\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 4\n\nComputational engine: rpart",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/3 classification Tidy Modeling.html#last-fit",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/3 classification Tidy Modeling.html#evaluate",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.844 Preprocessor1_Model1\n2 roc_auc  binary         0.861 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 623 244 0 (0.60834671 0.39165329)  \n   2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n     4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237) *\n     5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n   3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n     6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n      12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n      13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n        26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143) *\n        27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970) *\n     7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/3 classification Tidy Modeling.html#save-model",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.14 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/3 classification Tidy Modeling.html#make-predication",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.764\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              62\n2 1              27\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html",
    "href": "titanic classification model/4 classification Tidy Modeling.html",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "",
    "text": "Level 5 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/4 classification Tidy Modeling.html#read-data",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/4 classification Tidy Modeling.html#eda",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/4 classification Tidy Modeling.html#plotting",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/4 classification Tidy Modeling.html#data-split",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/4 classification Tidy Modeling.html#recipe",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#model",
    "href": "titanic classification model/4 classification Tidy Modeling.html#model",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.604226e-02, 1.240402e-07, 2.627129e-08, 9.554920e-09, 4.573048e-07, 4.382004e-07, 7.226307e-10, 5.853203e-03, 3.898687e-03, 6.021893e-02, 2.083316e-02, 1.088783e-05, 5.4962…\n$ tree_depth      &lt;int&gt; 8, 7, 6, 4, 12, 4, 11, 5, 3, 11, 15, 1, 5, 13, 8, 12, 10, 11, 9, 4, 7, 10, 3, 6, 15, 4, 9, 10, 4, 2, 1, 4, 14, 4, 11, 8, 12, 6, 10, 12, 13, 13, 7, 7, 2, 12, 4, 3, 2, 8, 13, 3…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    13\n 4          4    15\n 5          5    14\n 6          6    15\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    15\n13         13    14\n14         14    14\n15         15     7",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#workflow",
    "href": "titanic classification model/4 classification Tidy Modeling.html#workflow",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 352 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.0160                 8 accuracy binary     0.774    10  0.0160 Preproces…\n 2   0.0160                 8 roc_auc  binary     0.799    10  0.0139 Preproces…\n 3   0.000000124            7 accuracy binary     0.772    10  0.0137 Preproces…\n 4   0.000000124            7 roc_auc  binary     0.821    10  0.0177 Preproces…\n 5   0.00000000955          4 accuracy binary     0.788    10  0.0179 Preproces…\n 6   0.00000000955          4 roc_auc  binary     0.818    10  0.0150 Preproces…\n 7   0.000000457           12 accuracy binary     0.771    10  0.0136 Preproces…\n 8   0.000000457           12 roc_auc  binary     0.817    10  0.0202 Preproces…\n 9   0.000000438            4 accuracy binary     0.785    10  0.0164 Preproces…\n10   0.000000438            4 roc_auc  binary     0.817    10  0.0149 Preproces…\n# ℹ 342 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1        2.38e- 8         12 roc_auc binary     0.829    10  0.0144 Preprocesso…\n2        5.87e- 7         12 roc_auc binary     0.827    10  0.0156 Preprocesso…\n3        1.61e- 6         12 roc_auc binary     0.827    10  0.0154 Preprocesso…\n4        1.50e- 5         15 roc_auc binary     0.826    10  0.0151 Preprocesso…\n5        8.95e-10         13 roc_auc binary     0.826    10  0.0164 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1    0.0000000238         12 Preprocessor1_Model040\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 2.37513046201816e-08\n  tree_depth = 12\n\nComputational engine: rpart",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/4 classification Tidy Modeling.html#last-fit",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/4 classification Tidy Modeling.html#evaluate",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.816 Preprocessor1_Model1\n2 roc_auc  binary         0.885 Preprocessor1_Model1\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.816\n2 recall    binary         0.903\n3 precision binary         0.823\n4 f_meas    binary         0.861\n5 kap       binary         0.590\n6 sens      binary         0.903\n7 spec      binary         0.667\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 623 244 0 (0.60834671 0.39165329)  \n     2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n       4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237)  \n         8) Pclass&gt;=-0.9236371 305  39 0 (0.87213115 0.12786885)  \n          16) Fare&lt; 0.4362002 295  35 0 (0.88135593 0.11864407)  \n            32) Cabin_E121&gt;=1.925855 26   0 0 (1.00000000 0.00000000) *\n            33) Cabin_E121&lt; 1.925855 269  35 0 (0.86988848 0.13011152)  \n              66) Age&gt;=-0.6289231 209  23 0 (0.88995215 0.11004785) *\n              67) Age&lt; -0.6289231 60  12 0 (0.80000000 0.20000000)  \n               134) Embarked_S&gt;=-0.4915368 49   7 0 (0.85714286 0.14285714)  \n                 268) PassengerId&gt;=0.8547689 16   0 0 (1.00000000 0.00000000) *\n                 269) PassengerId&lt; 0.8547689 33   7 0 (0.78787879 0.21212121)  \n                   538) Fare&lt; -0.543308 8   0 0 (1.00000000 0.00000000) *\n                   539) Fare&gt;=-0.543308 25   7 0 (0.72000000 0.28000000)  \n                    1078) Fare&gt;=-0.5171166 18   3 0 (0.83333333 0.16666667) *\n                    1079) Fare&lt; -0.5171166 7   3 1 (0.42857143 0.57142857) *\n               135) Embarked_S&lt; -0.4915368 11   5 0 (0.54545455 0.45454545) *\n          17) Fare&gt;=0.4362002 10   4 0 (0.60000000 0.40000000) *\n         9) Pclass&lt; -0.9236371 83  31 0 (0.62650602 0.37349398)  \n          18) PassengerId&lt; -1.024023 15   1 0 (0.93333333 0.06666667) *\n          19) PassengerId&gt;=-1.024023 68  30 0 (0.55882353 0.44117647)  \n            38) Age&gt;=0.4276941 48  17 0 (0.64583333 0.35416667)  \n              76) SibSp&lt; -0.03494193 34   9 0 (0.73529412 0.26470588)  \n               152) Fare&gt;=0.01793593 7   0 0 (1.00000000 0.00000000) *\n               153) Fare&lt; 0.01793593 27   9 0 (0.66666667 0.33333333)  \n                 306) Fare&lt; -0.05252826 20   5 0 (0.75000000 0.25000000) *\n                 307) Fare&gt;=-0.05252826 7   3 1 (0.42857143 0.57142857) *\n              77) SibSp&gt;=-0.03494193 14   6 1 (0.42857143 0.57142857) *\n            39) Age&lt; 0.4276941 20   7 1 (0.35000000 0.65000000) *\n       5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n     3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n       6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n        12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n        13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n          26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n            52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n            53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n             106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609)  \n               212) PassengerId&lt; 0.1220595 14   3 0 (0.78571429 0.21428571) *\n               213) PassengerId&gt;=0.1220595 9   4 1 (0.44444444 0.55555556) *\n             107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n          27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970)  \n            54) Cabin_G6&lt; 1.120627 13   6 0 (0.53846154 0.46153846) *\n            55) Cabin_G6&gt;=1.120627 20   3 1 (0.15000000 0.85000000) *\n       7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *\n\n...\nand 0 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/4 classification Tidy Modeling.html#save-model",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.14 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/4 classification Tidy Modeling.html#make-predication",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 47 13\n         1 10 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.742\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              60\n2 1              29\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 47 13\n         1 10 19",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html",
    "href": "titanic classification model/2 classification Tidy Modeling.html",
    "title": "Classification model with Recipe",
    "section": "",
    "text": "Level 3 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/2 classification Tidy Modeling.html#read-data",
    "title": "Classification model with Recipe",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/2 classification Tidy Modeling.html#eda",
    "title": "Classification model with Recipe",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/2 classification Tidy Modeling.html#plotting",
    "title": "Classification model with Recipe",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/2 classification Tidy Modeling.html#data-split",
    "title": "Classification model with Recipe",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#recipe",
    "title": "Classification model with Recipe",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#prep-the-recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Classification model with Recipe",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Classification model with Recipe",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 623 128\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Classification model with Recipe",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 113\n2 1                  66\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#model",
    "href": "titanic classification model/2 classification Tidy Modeling.html#model",
    "title": "Classification model with Recipe",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/2 classification Tidy Modeling.html#trainning",
    "title": "Classification model with Recipe",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2536116\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n      4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237) *\n      5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n    3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/2 classification Tidy Modeling.html#evaluate",
    "title": "Classification model with Recipe",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits           id        \n   &lt;list&gt;           &lt;chr&gt;     \n 1 &lt;split [560/63]&gt; Resample01\n 2 &lt;split [560/63]&gt; Resample02\n 3 &lt;split [560/63]&gt; Resample03\n 4 &lt;split [560/63]&gt; Resample04\n 5 &lt;split [560/63]&gt; Resample05\n 6 &lt;split [560/63]&gt; Resample06\n 7 &lt;split [560/63]&gt; Resample07\n 8 &lt;split [560/63]&gt; Resample08\n 9 &lt;split [560/63]&gt; Resample09\n10 &lt;split [560/63]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.726    25 0.0118  Preprocessor1_Model1\n2 roc_auc  binary     0.773    25 0.00998 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.788    25  0.0115 Preprocessor1_Model1\n2 roc_auc  binary     0.815    25  0.0117 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_0) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/2 classification Tidy Modeling.html#save-model",
    "title": "Classification model with Recipe",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n847.94 kB\n\n\nCode\nobj_size(knn_fit)\n\n\n817.13 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/2 classification Tidy Modeling.html#make-predication",
    "title": "Classification model with Recipe",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 0          \n3 1          \n4 0          \n5 1          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.730\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              53\n2 1              36\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html",
    "href": "titanic classification model/5 classification Tidy Modeling.html",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/5 classification Tidy Modeling.html#read-data",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/5 classification Tidy Modeling.html#data-split",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/5 classification Tidy Modeling.html#recipe",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#model",
    "href": "titanic classification model/5 classification Tidy Modeling.html#model",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          6   3.33e- 5       2.32e+ 1    34       0.746     2\n2          6   6.19e- 4       2.32e- 2    22       0.580     5\n3          5   3.66e- 2       4.50e-10    24       0.949     1\n4          9   9.47e-10       2.06e- 5     2       0.340    11\n5          9   9.81e- 2       5.39e- 8     7       0.787     3\n6         12   2.50e- 6       6.99e- 3    16       0.151     5\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth   learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;        &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         12 0.00000156         6.09e-10    14       0.917     6\n2          3 0.0134             5.25e- 6    22       0.151     1\n3          2 0.0000000634       1.79e-10    15       0.132     5\n4          6 0.0206             1.84e- 5    19       0.863     9\n5          6 0.00000358         4.57e- 1    38       0.818     8\n6          4 0.00384            3.55e- 4    15       0.552     4",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#workflow-set",
    "href": "titanic classification model/5 classification Tidy Modeling.html#workflow-set",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_lightgbm\nPreprocessor1_Model11\naccuracy\n0.7301587\nNA\n1\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model11\nroc_auc\n0.8858093\nNA\n1\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model09\naccuracy\n0.7704813\n0.01220734\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_xgb\nPreprocessor1_Model09\nroc_auc\n0.8316034\n0.01125249\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model20\naccuracy\n0.7721710\n0.01523136\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model20\nroc_auc\n0.8284261\n0.01503274\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7063236\n0.01911126\n10\nrecipe\nnearest_neighbor\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7420401\n0.01885929\n10\nrecipe\nnearest_neighbor\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7398105\n0.01844242\n10\nrecipe\nlogistic_reg\n5\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7301929\n0.03339075\n10\nrecipe\nlogistic_reg\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\n\n\nCode\nxgb_model_set_res=model_set_res %&gt;% extract_workflow_set_result(id= 'recipe_xgb')\n\n\n\n\nCode\nglimpse(xgb_model_set_res)\n\n\nRows: 10\nColumns: 5\n$ splits       &lt;list&gt; [&lt;vfold_split[560 x 63 x 623 x 11]&gt;], [&lt;vfold_split[560 …\n$ id           &lt;chr&gt; \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     &lt;list&gt; [&lt;tbl_df[40 x 10]&gt;], [&lt;tbl_df[40 x 10]&gt;], [&lt;tbl_df[40 x …\n$ .notes       &lt;list&gt; [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;],…\n$ .predictions &lt;list&gt; [&lt;tbl_df[1260 x 12]&gt;], [&lt;tbl_df[1260 x 12]&gt;], [&lt;tbl_df[1…\n\n\n\n\nCode\n#xgb_model_set_res %&gt;% plot_race()\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/5 classification Tidy Modeling.html#last-fit",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/5 classification Tidy Modeling.html#evaluate",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.827 Preprocessor1_Model1\n2 roc_auc  binary         0.915 Preprocessor1_Model1\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.827\n2 recall    binary         0.982\n3 precision binary         0.793\n4 f_meas    binary         0.877\n5 kap       binary         0.593\n6 sens      binary         0.982\n7 spec      binary         0.561\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 14.8 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.080098505877286, max_depth = 12L, \n    gamma = 5.39858008778608e-07, colsample_bytree = 1, colsample_bynode = 0.645669291338583, \n    min_child_weight = 9L, subsample = 0.771166819442296), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.080098505877286\", max_depth = \"12\", gamma = \"5.39858008778608e-07\", colsample_bytree = \"1\", colsample_bynode = \"0.645669291338583\", min_child_weight = \"9\", subsample = \"0.771166819442296\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 127 \nniter: 10\nnfeatures : 127 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6633661\n        2        0.6379807\n---                       \n        9        0.5294025\n       10        0.5201621\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/5 classification Tidy Modeling.html#save-model",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.04 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/5 classification Tidy Modeling.html#make-predication",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 0          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 53 14\n         1  4 18\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.798\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              67\n2 1              22\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 53 14\n         1  4 18",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html",
    "href": "titanic classification model/1 classification Tidy Modeling.html",
    "title": "Classification model",
    "section": "",
    "text": "Level 1 classification Tidy Modeling: using basic Tidymodel package.",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/1 classification Tidy Modeling.html#read-data",
    "title": "Classification model",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/1 classification Tidy Modeling.html#eda",
    "title": "Classification model",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/1 classification Tidy Modeling.html#plotting",
    "title": "Classification model",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/1 classification Tidy Modeling.html#data-split",
    "title": "Classification model",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name,-Ticket) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 10",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/1 classification Tidy Modeling.html#recipe",
    "title": "Classification model",
    "section": "3.1 recipe",
    "text": "3.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#model",
    "href": "titanic classification model/1 classification Tidy Modeling.html#model",
    "title": "Classification model",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/1 classification Tidy Modeling.html#trainning",
    "title": "Classification model",
    "section": "3.3 trainning",
    "text": "3.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.3684211\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex=male 406  84 0 (0.79310345 0.20689655)  \n      4) Cabin=A14,A19,A32,A5,B102,B19,B22,B30,B37,B38,B51 B53 B55,B71,B94,C118,C123,C124,C128,C23 C25 C27,C30,C46,C65,C68,C82,C83,C86,C87,C95,D,D26,D30,D48,E38,E58,E63,E67,F G63,F G73,F38,T 288  36 0 (0.87500000 0.12500000) *\n      5) Cabin=A20,A23,A31,A34,B20,B41,B49,B50,B96 B98,C104,C106,C126,C148,C22 C26,C47,C52,C70,C92,C93,D10 D12,D33,D35,D49,D56,E10,E12,E121,E24,E25,E50,F2,F4 118  48 0 (0.59322034 0.40677966)  \n       10) Pclass&gt;=1.5 88  20 0 (0.77272727 0.22727273)  \n         20) Age&gt;=6.5 75  10 0 (0.86666667 0.13333333) *\n         21) Age&lt; 6.5 13   3 1 (0.23076923 0.76923077) *\n       11) Pclass&lt; 1.5 30   2 1 (0.06666667 0.93333333) *\n    3) Sex=female 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=2.5 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=24.80835 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; 24.80835 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked=S 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=17.35 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; 17.35 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; 11.375 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=11.375 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked=C,Q 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 2.5 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/1 classification Tidy Modeling.html#evaluate",
    "title": "Classification model",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   0   1\n         0 105  19\n         1   8  47\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 kap      binary         0.664\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.929\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.712\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 sens     binary         0.929\n3 spec     binary         0.712\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.849\n 2 kap                  binary         0.664\n 3 sens                 binary         0.929\n 4 spec                 binary         0.712\n 5 ppv                  binary         0.847\n 6 npv                  binary         0.855\n 7 mcc                  binary         0.671\n 8 j_index              binary         0.641\n 9 bal_accuracy         binary         0.821\n10 detection_prevalence binary         0.693\n11 precision            binary         0.847\n12 recall               binary         0.929\n13 f_meas               binary         0.886\n\n\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_0)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.881\n\n\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_0) %&gt;% \n  autoplot()",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/1 classification Tidy Modeling.html#save-model",
    "title": "Classification model",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n130.17 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/1 classification Tidy Modeling.html#make-predication",
    "title": "Classification model",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/0 classification Tidy Modeling.html",
    "href": "titanic classification model/0 classification Tidy Modeling.html",
    "title": "Titanic data",
    "section": "",
    "text": "data download form kaggle\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\nData have 891 record and 12 variable\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;% group_by(Survived) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   Survived [2]\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342\n\n\n\n\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nSpecificity=TN/(TN+FP)\n\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)",
    "crumbs": [
      "titanic classification model",
      "Titanic data"
    ]
  },
  {
    "objectID": "titanic classification model/0 classification Tidy Modeling.html#measurement",
    "href": "titanic classification model/0 classification Tidy Modeling.html#measurement",
    "title": "Titanic data",
    "section": "",
    "text": "Accuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nSpecificity=TN/(TN+FP)\n\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)",
    "crumbs": [
      "titanic classification model",
      "Titanic data"
    ]
  },
  {
    "objectID": "house price regression model/0 Regression Tidy Modeling.html",
    "href": "house price regression model/0 Regression Tidy Modeling.html",
    "title": "House price data",
    "section": "",
    "text": "1 house price data\n\ndata download form kaggle\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\nData have 1460 record and 81 variable\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n2 Measurement:\n\nMean absolute error (MAE)\n\nThe MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. The equation is given in the library references. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n\nRoot Mean Squared Error (RMSE)\n\n\nThe RMSE is a quadratic scoring rule which measures the average magnitude of the error. The equation for the RMSE is given in both of the references. Expressing the formula in words, the difference between forecast and corresponding observed values are each squared and then averaged over the sample. Finally, the square root of the average is taken. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\nBoth the MAE and RMSE can range from 0 to ∞. They are negatively-oriented scores: Lower values are better.\n\nR^2 (Coefficient of determination): is between 0 to 1. bigger the better.\n\n\nresidual sum of squares(RSS):\n\ntotal sum of squares(TOT):\n\n\n\n3 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\n\n\n4 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n5 EDA\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "house price regression model",
      "House price data"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html",
    "href": "house price regression model/5 Regression Tidy Modeling.html",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning\nadd quick tunning",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/5 Regression Tidy Modeling.html#read-data",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/5 Regression Tidy Modeling.html#data-split",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/5 Regression Tidy Modeling.html#recipe",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(),-all_outcomes())",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#model",
    "href": "house price regression model/5 Regression Tidy Modeling.html#model",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 50)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/5 Regression Tidy Modeling.html#workflow",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(lasso_tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#training",
    "href": "house price regression model/5 Regression Tidy Modeling.html#training",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nlasso_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 100 × 7\n    penalty .metric .estimator      mean     n   std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model01\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model01\n 3 1.60e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model02\n 4 1.60e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model02\n 5 2.56e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model03\n 6 2.56e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model03\n 7 4.09e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model04\n 8 4.09e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model04\n 9 6.55e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model05\n10 6.55e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model05\n# ℹ 90 more rows",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/5 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nautoplot(lasso_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nglimpse(lasso_res)\n\n\nRows: 10\nColumns: 6\n$ splits       &lt;list&gt; [&lt;vfold_split[919 x 102 x 1021 x 38]&gt;], [&lt;vfold_split[91…\n$ id           &lt;chr&gt; \"Fold02\", \"Fold05\", \"Fold10\", \"Fold09\", \"Fold03\", \"Fold04…\n$ .order       &lt;int&gt; 3, 2, 1, 4, 5, 6, 7, 8, 9, 10\n$ .metrics     &lt;list&gt; [&lt;tbl_df[100 x 5]&gt;], [&lt;tbl_df[100 x 5]&gt;], [&lt;tbl_df[100 x …\n$ .notes       &lt;list&gt; [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;],…\n$ .predictions &lt;list&gt; [&lt;tbl_df[5100 x 5]&gt;], [&lt;tbl_df[5100 x 5]&gt;], [&lt;tbl_df[510…\n\n\n\n\nCode\nlasso_res %&gt;% plot_race()\n\n\n\n\n\n\n\n\n\nuse best tune model for final fit\n\n\nCode\nlowest_rmse &lt;- lasso_res %&gt;%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n\n\n# A tibble: 1 × 2\n       penalty .config              \n         &lt;dbl&gt; &lt;chr&gt;                \n1 0.0000000001 Preprocessor1_Model01\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/5 Regression Tidy Modeling.html#last-fit",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "4.2 last fit",
    "text": "4.2 last fit\n\n\nCode\nfinal_res &lt;- \n  final_wf %&gt;%\n  last_fit(data_split) \n\n\n\n\nCode\noptions(scipen=10000)\nfinal_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html",
    "href": "house price regression model/4 Regression Tidy Modeling.html",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tuning",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/4 Regression Tidy Modeling.html#read-data",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/4 Regression Tidy Modeling.html#data-split",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/4 Regression Tidy Modeling.html#recipe",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\n\nCode\ndata_rec %&gt;% summary()\n\n\n# A tibble: 38 × 4\n   variable     type      role      source  \n   &lt;chr&gt;        &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 Id           &lt;chr [2]&gt; predictor original\n 2 MSSubClass   &lt;chr [2]&gt; predictor original\n 3 LotFrontage  &lt;chr [2]&gt; predictor original\n 4 LotArea      &lt;chr [2]&gt; predictor original\n 5 OverallQual  &lt;chr [2]&gt; predictor original\n 6 OverallCond  &lt;chr [2]&gt; predictor original\n 7 YearBuilt    &lt;chr [2]&gt; predictor original\n 8 YearRemodAdd &lt;chr [2]&gt; predictor original\n 9 MasVnrArea   &lt;chr [2]&gt; predictor original\n10 BsmtFinSF1   &lt;chr [2]&gt; predictor original\n# ℹ 28 more rows",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#model",
    "href": "house price regression model/4 Regression Tidy Modeling.html#model",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 100)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/4 Regression Tidy Modeling.html#workflow",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(lasso_tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#training",
    "href": "house price regression model/4 Regression Tidy Modeling.html#training",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\n\n\nCode\nlasso_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 200 × 7\n    penalty .metric .estimator      mean     n   std_err .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model001\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model001\n 3 1.26e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model002\n 4 1.26e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model002\n 5 1.59e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model003\n 6 1.59e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model003\n 7 2.01e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model004\n 8 2.01e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model004\n 9 2.54e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model005\n10 2.54e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model005\n# ℹ 190 more rows",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/4 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nautoplot(lasso_res)\n\n\n\n\n\n\n\n\n\nuse best tune model for final fit\n\n\nCode\nlowest_rmse &lt;- lasso_res %&gt;%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n\n\n# A tibble: 1 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/4 Regression Tidy Modeling.html#last-fit",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "4.2 last fit",
    "text": "4.2 last fit\n\n\nCode\nfinal_res &lt;- \n  final_wf %&gt;%\n  last_fit(data_split) \n\n\n\n\nCode\nfinal_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html",
    "href": "house price regression model/1 Regression Tidy Modeling.html",
    "title": "Regression model",
    "section": "",
    "text": "Load Pacakges & Set Options\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/1 Regression Tidy Modeling.html#read-data",
    "title": "Regression model",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/1 Regression Tidy Modeling.html#data-split",
    "title": "Regression model",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/1 Regression Tidy Modeling.html#recipe",
    "title": "Regression model",
    "section": "3.1 recipe",
    "text": "3.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#model",
    "href": "house price regression model/1 Regression Tidy Modeling.html#model",
    "title": "Regression model",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.2.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.2.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/1 Regression Tidy Modeling.html#trainning",
    "title": "Regression model",
    "section": "3.3 trainning",
    "text": "3.3 trainning\n\n3.3.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    6.786e+05      1.851e+00     -1.899e+02      2.506e+01      1.804e-01  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n    1.890e+04      4.588e+03      2.974e+02      1.226e+02      3.001e+01  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n    1.411e+01      8.770e+00      6.529e+00             NA      4.605e+01  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n    4.830e+01      6.035e-01             NA      9.801e+03      4.500e+03  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n    3.766e+03     -1.734e+03     -8.997e+03     -1.285e+04      3.689e+03  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n    4.535e+03     -1.615e+01      1.789e+04      2.146e+00      2.358e+01  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n   -2.548e+01     -5.078e+00      3.999e+01      4.278e+01     -5.265e+01  \n      MiscVal         MoSold         YrSold  \n   -2.539e-01     -2.339e+02     -7.699e+02  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term           estimate   std.error statistic  p.value\n   &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)  678634.    1808073.        0.375 7.07e- 1\n 2 Id                1.85        2.81      0.659 5.10e- 1\n 3 MSSubClass     -190.         33.7      -5.63  2.29e- 8\n 4 LotFrontage      25.1        35.2       0.712 4.77e- 1\n 5 LotArea           0.180       0.146     1.23  2.18e- 1\n 6 OverallQual   18904.       1515.       12.5   2.69e-33\n 7 OverallCond    4588.       1332.        3.44  5.98e- 4\n 8 YearBuilt       297.         77.4       3.84  1.30e- 4\n 9 YearRemodAdd    123.         84.7       1.45  1.48e- 1\n10 MasVnrArea       30.0         7.28      4.12  4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.3.2 train lm model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00  63480\n2   1 10.62  57840\n3   1 19.45  52700\n4   1 26.77  48020\n5   2 32.89  43760\n6   2 39.26  39870\n7   2 44.56  36330\n8   2 48.95  33100\n9   3 52.79  30160\n10  4 56.28  27480\n11  5 59.43  25040\n12  5 62.05  22810\n13  5 64.22  20790\n14  5 66.03  18940\n15  5 67.53  17260\n16  5 68.77  15720\n17  5 69.80  14330\n18  7 70.71  13060\n19  9 71.66  11900\n20 10 72.51  10840\n21 10 73.26   9876\n22 10 73.87   8998\n23 11 74.40   8199\n24 11 74.86   7471\n25 13 75.37   6807\n26 13 75.86   6202\n27 13 76.28   5651\n28 13 76.64   5149\n29 13 76.95   4692\n30 13 77.21   4275\n31 13 77.42   3895\n32 14 77.60   3549\n33 14 77.75   3234\n34 15 77.88   2947\n35 15 77.99   2685\n36 16 78.09   2446\n37 17 78.27   2229\n38 19 78.44   2031\n39 20 78.62   1851\n40 21 78.76   1686\n41 22 78.90   1536\n42 23 79.03   1400\n43 24 79.14   1275\n44 25 79.24   1162\n45 25 79.32   1059\n46 25 79.39    965\n47 26 79.45    879\n48 26 79.50    801\n49 27 79.54    730\n50 28 79.59    665\n51 29 79.62    606\n52 30 79.65    552\n53 30 79.68    503\n54 31 79.70    458\n55 31 79.72    418\n56 31 79.73    381\n57 32 79.74    347\n58 33 79.75    316\n59 33 79.76    288\n60 34 79.77    262\n61 34 79.78    239\n62 33 79.78    218\n63 33 79.79    198\n64 33 79.79    181\n65 33 79.79    165\n66 33 79.80    150\n67 34 79.80    137\n68 35 79.80    125\n69 35 79.80    114\n70 35 79.80    104\n71 35 79.81     94\n72 35 79.81     86\n73 35 79.81     78\n74 35 79.81     71\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term           estimate penalty\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)  528464.        0.1\n 2 Id                1.65      0.1\n 3 MSSubClass     -187.        0.1\n 4 LotFrontage      24.0       0.1\n 5 LotArea           0.177     0.1\n 6 OverallQual   18970.        0.1\n 7 OverallCond    4464.        0.1\n 8 YearBuilt       290.        0.1\n 9 YearRemodAdd    125.        0.1\n10 MasVnrArea       29.9       0.1\n# ℹ 28 more rows\n\n\n\n\n3.3.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       959255491 \nR squared (OOB):                  0.8511865",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/1 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = data_train) %&gt;%\n  mutate(\n    truth = data_train$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = data_train) %&gt;%\n    mutate(\n      truth = data_train$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = data_train) %&gt;%\n    mutate(\n      truth = data_train$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = data_test) %&gt;%\n  mutate(\n    truth = data_test$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = data_test) %&gt;%\n    mutate(\n      truth = data_test$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = data_test) %&gt;%\n    mutate(\n      truth = data_test$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      36059.\n2 lm    rmse    standard      36055.\n3 rf    rmse    standard      13542.\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      31122.\n2 lm    rmse    standard      31139.\n3 rf    rmse    standard      28428.\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/1 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Regression model",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46227.        1      NA Preprocessor1_Model1\n2 rsq     standard       0.830     1      NA Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html",
    "href": "house price regression model/6 Regression Tidy Modeling.html",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning\nadd quick tuning\nadd workflow set and setting different tuning grid for different model",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/6 Regression Tidy Modeling.html#read-data",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/6 Regression Tidy Modeling.html#data-split",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/6 Regression Tidy Modeling.html#recipe",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\n\nCode\ntrained_data_rec &lt;- prep(data_rec, training = data_train)\n\n\n\n\nCode\ntrained_data_rec %&gt;%check_missing(\"LotFrontage\")",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#model",
    "href": "house price regression model/6 Regression Tidy Modeling.html#model",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 50)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\n3.2.2 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec =\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"regression\")\n\n\n\n\nCode\ntune_spec %&gt;% extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid = \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.3 lightGBM Boost tree\n\n\nCode\nlightgbm_spec = boost_tree(\n  trees = 100,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"regression\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth    learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          7 0.00953             2.79e- 1    40       0.256    13\n2          6 0.00130             1.47e- 3    16       0.732     4\n3          9 0.0000453           2.17e- 7    36       0.446    25\n4          3 0.0199              2.13e- 8    26       0.773    35\n5         13 0.0793              8.96e- 9    30       0.219    12\n6         10 0.00000000238       1.09e-10    21       0.699    21\n\n\n\n\n3.2.4 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(\n  mtry = tune(), trees = tune(), min_n = tune()\n  )%&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n\nComputational engine: ranger \n\n\n\n\nCode\nrf_grid &lt;- \n  grid_latin_hypercube(\n    min_n(), \n    mtry(range = c(4, 9)), \n    trees(), \n    size = 80)\n\nhead(rf_grid)\n\n\n# A tibble: 6 × 3\n  min_n  mtry trees\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    33     7  1713\n2    29     5  1343\n3    12     6   545\n4    21     6   843\n5    27     5  1485\n6    13     9    48",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/6 Regression Tidy Modeling.html#workflow",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nworkflow_set =\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(\n                  lasso=lasso_tune_spec,\n                  tree  = tune_spec,\n                  lightgbm=lightgbm_spec,\n                  random_forest=rf_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = lasso_grid, id = \"recipe_lasso\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\")  %&gt;% \n  option_add(grid = rf_grid, id = \"recipe_rf\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id             info             option    result    \n  &lt;chr&gt;                &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_lasso         &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n2 recipe_tree          &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_lightgbm      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n4 recipe_random_forest &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;\n\n\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#training",
    "href": "house price regression model/6 Regression Tidy Modeling.html#training",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 50,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"rmse\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_lightgbm\nPreprocessor1_Model46\nrmse\n2.898681e+04\n3.152131e+03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model46\nrsq\n8.704013e-01\n1.884946e-02\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_random_forest\nPreprocessor1_Model31\nrmse\n2.918897e+04\n3.074054e+03\n10\nrecipe\nrand_forest\n2\n\n\nrecipe_random_forest\nPreprocessor1_Model31\nrsq\n8.693925e-01\n1.953458e-02\n10\nrecipe\nrand_forest\n2\n\n\nrecipe_lasso\nPreprocessor1_Model01\nrmse\n3.878538e+04\n5.169415e+03\n10\nrecipe\nlinear_reg\n3\n\n\nrecipe_lasso\nPreprocessor1_Model01\nrsq\n7.769664e-01\n4.331088e-02\n10\nrecipe\nlinear_reg\n3\n\n\nrecipe_tree\nPreprocessor1_Model06\nrmse\n3.923049e+04\n2.064970e+03\n10\nrecipe\ndecision_tree\n4\n\n\nrecipe_tree\nPreprocessor1_Model06\nrsq\n7.674437e-01\n1.574068e-02\n10\nrecipe\ndecision_tree\n4\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_lightgbm')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_random_forest\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"rmse\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/6 Regression Tidy Modeling.html#last-fit",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "4.1 last fit",
    "text": "4.1 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)\n\n\n\n\nCode\noptions(scipen=10000)\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   28019.    Preprocessor1_Model1\n2 rsq     standard       0.876 Preprocessor1_Model1\n\n\n\n\nCode\n(final_fit%&gt;%collect_predictions()) %&gt;% ggplot(aes(target_variable, .pred))+ geom_abline(lty = 2, color = \"gray80\", size = 1.5) +geom_point(alpha = 0.5)+labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )+scale_x_continuous(labels = scales::comma) +scale_y_continuous(labels = scales::comma) \n\n\n\n\n\n\n\n\n\nmanual calculate RMSE on testing data\n\n\nCode\nfinal_data=final_fit%&gt;%collect_predictions()\n\nfinal_data2=final_data %&gt;% mutate(diff=target_variable-.pred)%&gt;% mutate(diff2=diff^2)\n\na=sum(final_data2$diff2)/nrow(final_data2)\n\nsqrt(a)\n\n\n[1] 28018.9\n\n\nCode\n#glimpse(final_data2)",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html",
    "href": "house price regression model/3 Regression Tidy Modeling.html",
    "title": "Regression model with Recipe",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/3 Regression Tidy Modeling.html#read-data",
    "title": "Regression model with Recipe",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/3 Regression Tidy Modeling.html#data-split",
    "title": "Regression model with Recipe",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\nglimpse(train_df)\n\n\nRows: 1,460\nColumns: 38\n$ Id              &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ MSSubClass      &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 2…\n$ LotFrontage     &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, 0, 51, 50, 70, 85, 0, 91, …\n$ LotArea         &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 6…\n$ OverallQual     &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, …\n$ OverallCond     &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, …\n$ YearBuilt       &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, …\n$ YearRemodAdd    &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, …\n$ MasVnrArea      &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306…\n$ BsmtFinSF1      &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, …\n$ BsmtFinSF2      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF       &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, …\n$ TotalBsmtSF     &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, …\n$ `1stFlrSF`      &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077…\n$ `2ndFlrSF`      &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, …\n$ LowQualFinSF    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ GrLivArea       &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, …\n$ BsmtFullBath    &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, …\n$ BsmtHalfBath    &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FullBath        &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, …\n$ HalfBath        &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ BedroomAbvGr    &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, …\n$ KitchenAbvGr    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, …\n$ TotRmsAbvGrd    &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6,…\n$ Fireplaces      &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, …\n$ GarageYrBlt     &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, …\n$ GarageCars      &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, …\n$ GarageArea      &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384,…\n$ WoodDeckSF      &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 1…\n$ OpenPorchSF     &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 21…\n$ EnclosedPorch   &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0…\n$ `3SsnPorch`     &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ScreenPorch     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0…\n$ PoolArea        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ MiscVal         &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 70…\n$ MoSold          &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, …\n$ YrSold          &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, …\n$ target_variable &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000…\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#recipe",
    "title": "Regression model with Recipe",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#prep-the-recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#prep-the-recipe",
    "title": "Regression model with Recipe",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Regression model with Recipe",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Regression model with Recipe",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#model",
    "href": "house price regression model/3 Regression Tidy Modeling.html#model",
    "title": "Regression model with Recipe",
    "section": "3.5 model",
    "text": "3.5 model\n\n3.5.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.5.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.5.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/3 Regression Tidy Modeling.html#trainning",
    "title": "Regression model with Recipe",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n3.6.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    180421.70         767.46       -8094.25         903.70        1599.01  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n     26128.59        5018.48        8945.07        2525.17        5672.04  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n      6631.92        1406.69        2868.07             NA       18015.90  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n     20898.31          28.81             NA        5099.47        1079.56  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n      2064.26        -865.84       -7429.07       -2969.90        6013.58  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n      2906.10       -7470.78       13312.87         454.85        2970.22  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n     -1630.78        -296.59        1206.28        2450.60       -2053.73  \n      MiscVal         MoSold         YrSold  \n      -145.90        -645.51       -1011.23  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term         estimate std.error statistic  p.value\n   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)   180422.     1149.   157.    0       \n 2 Id               767.     1165.     0.659 5.10e- 1\n 3 MSSubClass     -8094.     1437.    -5.63  2.29e- 8\n 4 LotFrontage      904.     1270.     0.712 4.77e- 1\n 5 LotArea         1599.     1297.     1.23  2.18e- 1\n 6 OverallQual    26129.     2093.    12.5   2.69e-33\n 7 OverallCond     5018.     1457.     3.44  5.98e- 4\n 8 YearBuilt       8945.     2329.     3.84  1.30e- 4\n 9 YearRemodAdd    2525.     1745.     1.45  1.48e- 1\n10 MasVnrArea      5672.     1375.     4.12  4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.6.2 train lasso model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00  63480\n2   1 10.62  57840\n3   1 19.45  52700\n4   1 26.77  48020\n5   2 32.89  43760\n6   2 39.26  39870\n7   2 44.56  36330\n8   2 48.95  33100\n9   3 52.79  30160\n10  4 56.28  27480\n11  5 59.43  25040\n12  5 62.05  22810\n13  5 64.22  20790\n14  5 66.03  18940\n15  5 67.53  17260\n16  5 68.77  15720\n17  5 69.80  14330\n18  7 70.71  13060\n19  9 71.66  11900\n20 10 72.51  10840\n21 10 73.26   9876\n22 10 73.87   8998\n23 11 74.40   8199\n24 11 74.86   7471\n25 13 75.37   6807\n26 13 75.86   6202\n27 13 76.28   5651\n28 13 76.64   5149\n29 13 76.95   4692\n30 13 77.21   4275\n31 13 77.42   3895\n32 14 77.60   3549\n33 14 77.75   3234\n34 15 77.88   2947\n35 15 77.99   2685\n36 16 78.09   2446\n37 17 78.27   2229\n38 19 78.44   2031\n39 20 78.62   1851\n40 21 78.76   1686\n41 22 78.90   1536\n42 23 79.03   1400\n43 24 79.14   1275\n44 25 79.24   1162\n45 25 79.32   1059\n46 25 79.39    965\n47 26 79.45    879\n48 26 79.50    801\n49 27 79.54    730\n50 28 79.59    665\n51 29 79.62    606\n52 30 79.65    552\n53 30 79.68    503\n54 31 79.70    458\n55 31 79.72    418\n56 31 79.73    381\n57 32 79.74    347\n58 33 79.75    316\n59 33 79.76    288\n60 34 79.77    262\n61 34 79.78    239\n62 33 79.78    218\n63 33 79.79    198\n64 33 79.79    181\n65 33 79.79    165\n66 33 79.80    150\n67 34 79.80    137\n68 35 79.80    125\n69 35 79.80    114\n70 35 79.80    104\n71 35 79.81     94\n72 35 79.81     86\n73 35 79.81     78\n74 35 79.81     71\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term         estimate penalty\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)   180422.     0.1\n 2 Id               684.     0.1\n 3 MSSubClass     -7967.     0.1\n 4 LotFrontage      867.     0.1\n 5 LotArea         1564.     0.1\n 6 OverallQual    26220.     0.1\n 7 OverallCond     4883.     0.1\n 8 YearBuilt       8728.     0.1\n 9 YearRemodAdd    2583.     0.1\n10 MasVnrArea      5657.     0.1\n# ℹ 28 more rows\n\n\n\n\n3.6.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1006353699 \nR squared (OOB):                  0.8438799",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/3 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model with Recipe",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = train_juice) %&gt;%\n  mutate(\n    truth = train_juice$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = test_proc) %&gt;%\n  mutate(\n    truth = test_proc$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      36059.\n2 lm    rmse    standard      36055.\n3 rf    rmse    standard      13540.\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      31122.\n2 lm    rmse    standard      31139.\n3 rf    rmse    standard      28348.\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/3 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Regression model with Recipe",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- rf_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   30645.       10 2324.     Preprocessor1_Model1\n2 rsq     standard       0.859    10    0.0218 Preprocessor1_Model1\n\n\n\n\nCode\nlasso_res &lt;- lasso_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nlasso_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   39201.       10 4620.     Preprocessor1_Model1\n2 rsq     standard       0.769    10    0.0422 Preprocessor1_Model1\n\n\n\n\nCode\nlm_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nlm_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46227.        1      NA Preprocessor1_Model1\n2 rsq     standard       0.830     1      NA Preprocessor1_Model1\n\n\nShow all resample result:\n\n\nCode\nrf_res %&gt;%\n  unnest(.predictions) %&gt;%\n  ggplot(aes(target_variable, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  labs(\n    x = \"Truth\",\n    y = \"Prediction\",\n    color = NULL\n  )\n\n\n\n\n\n\n\n\n\nShow each resample result:\n\n\nCode\nlibrary(gganimate)\n\np=rf_res %&gt;%\n  unnest(.predictions) %&gt;%\n  ggplot(aes(target_variable, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  labs(\n    x = \"Truth\",\n    y = \"Prediction\",\n    color = NULL\n  )+transition_states(id)\n\np",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html",
    "href": "hotel classification model/6 classification Tidy Modeling.html",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:\nlogistic glm model\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\nKNN model with knn engine(knn_spec)\ntuning XG boost model (tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)\ntuning light gbm boost model(tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/6 classification Tidy Modeling.html#read-data",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/6 classification Tidy Modeling.html#data-split",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/6 classification Tidy Modeling.html#recipe",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#model",
    "href": "hotel classification model/6 classification Tidy Modeling.html#model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          2   3.42e- 6       8.02e- 9    32       0.734     3\n2          7   4.05e- 5       2.42e- 1    25       0.393     7\n3         14   4.98e- 4       5.17e-10     4       0.465     3\n4         12   4.33e- 8       8.46e- 7     8       0.485     9\n5         10   4.00e-10       2.81e- 5    14       0.387     9\n6          7   7.24e- 5       8.03e- 2     9       0.105    11\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         10   1.14e-10       1.09e- 3    13       0.682     1\n2          6   1.25e- 5       1.81e+ 1    19       0.265     6\n3          2   3.59e- 6       1.55e- 5    18       0.860     8\n4          3   5.01e- 8       2.34e-10    20       0.108     6\n5         15   2.98e- 2       2.05e- 6    21       0.341     5\n6         13   2.28e- 3       2.52e- 7    34       0.124     4",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#workflow-set",
    "href": "hotel classification model/6 classification Tidy Modeling.html#workflow-set",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/6 classification Tidy Modeling.html#training-and-tunning",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_xgb\nPreprocessor1_Model19\naccuracy\n0.7659429\n0.002672714\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model19\nroc_auc\n0.8351222\n0.003292009\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\naccuracy\n0.7679429\n0.003942857\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nroc_auc\n0.8328707\n0.003144983\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\naccuracy\n0.7465143\n0.007227285\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model02\nroc_auc\n0.8179011\n0.004984221\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7581714\n0.001141428\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7979514\n0.004063108\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7366857\n0.001567354\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7849985\n0.004460053\n10\nrecipe\nnearest_neighbor\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/6 classification Tidy Modeling.html#last-fit",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/6 classification Tidy Modeling.html#evaluate",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.754 Preprocessor1_Model1\n2 roc_auc  binary         0.774 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.754\n2 recall    binary         0.690\n3 precision binary         0.201\n4 f_meas    binary         0.311\n5 kap       binary         0.213\n6 sens      binary         0.690\n7 spec      binary         0.760\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 11.6 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.00470774296245284, max_depth = 1L, \n    gamma = 5.1538567202903, colsample_bytree = 1, colsample_bynode = 0.454545454545455, \n    min_child_weight = 18L, subsample = 0.133142875451595), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.00470774296245284\", max_depth = \"1\", gamma = \"5.1538567202903\", colsample_bytree = \"1\", colsample_bynode = \"0.454545454545455\", min_child_weight = \"18\", subsample = \"0.133142875451595\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 22 \nniter: 10\nnfeatures : 22 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6924354\n        2        0.6924197\n---                       \n        9        0.6891105\n       10        0.6889369\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/6 classification Tidy Modeling.html#save-model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.44 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/6 classification Tidy Modeling.html#make-predication",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 children   \n3 children   \n4 none       \n5 children   \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      541 2217\n  none          244 6998\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.754\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          785\n2 none             9215\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2758\n2 none         7242\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      541 2217\n  none          244 6998",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html",
    "href": "hotel classification model/3 classification Tidy Modeling.html",
    "title": "Classification Model with recipe",
    "section": "",
    "text": "Level 3 classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/3 classification Tidy Modeling.html#read-data",
    "title": "Classification Model with recipe",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/3 classification Tidy Modeling.html#data-split",
    "title": "Classification Model with recipe",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(50000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    10",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#recipe",
    "title": "Classification Model with recipe",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#prep-the-recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Classification Model with recipe",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Classification Model with recipe",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 35000    23\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 5728   23\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 5728   23\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2864\n2 none            32136\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2864\n2 none             2864\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2864\n2 none             2864",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Classification Model with recipe",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          393\n2 none             4607\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          820\n2 none             9180\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#model",
    "href": "hotel classification model/3 classification Tidy Modeling.html#model",
    "title": "Classification Model with recipe",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/3 classification Tidy Modeling.html#trainning",
    "title": "Classification Model with recipe",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2616969\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5728 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 5728 2864 children (0.5000000 0.5000000)  \n   2) adr&gt;=0.3221018 1817  355 children (0.8046230 0.1953770) *\n   3) adr&lt; 0.3221018 3911 1402 none (0.3584761 0.6415239)  \n     6) total_of_special_requests&gt;=0.6520526 839  353 children (0.5792610 0.4207390)  \n      12) meal_SC&lt; 1.940923 781  307 children (0.6069142 0.3930858) *\n      13) meal_SC&gt;=1.940923 58   12 none (0.2068966 0.7931034) *\n     7) total_of_special_requests&lt; 0.6520526 3072  916 none (0.2981771 0.7018229) *",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/3 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model with recipe",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits             id        \n   &lt;list&gt;             &lt;chr&gt;     \n 1 &lt;split [5154/574]&gt; Resample01\n 2 &lt;split [5154/574]&gt; Resample02\n 3 &lt;split [5154/574]&gt; Resample03\n 4 &lt;split [5154/574]&gt; Resample04\n 5 &lt;split [5154/574]&gt; Resample05\n 6 &lt;split [5154/574]&gt; Resample06\n 7 &lt;split [5154/574]&gt; Resample07\n 8 &lt;split [5154/574]&gt; Resample08\n 9 &lt;split [5154/574]&gt; Resample09\n10 &lt;split [5154/574]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 3 × 6\n  .metric     .estimator  mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.739    25 0.00385 Preprocessor1_Model1\n2 brier_class binary     0.197    25 0.00244 Preprocessor1_Model1\n3 roc_auc     binary     0.801    25 0.00342 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 3 × 6\n  .metric     .estimator  mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.726    25 0.00365 Preprocessor1_Model1\n2 brier_class binary     0.194    25 0.00187 Preprocessor1_Model1\n3 roc_auc     binary     0.748    25 0.00492 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_children) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/3 classification Tidy Modeling.html#save-model",
    "title": "Classification Model with recipe",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n1.15 MB\n\n\nCode\nobj_size(knn_fit)\n\n\n1.10 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/3 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model with recipe",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 children   \n3 none       \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      578 2399\n  none          242 6781\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.736\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          820\n2 none             9180\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2977\n2 none         7023\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      578 2399\n  none          242 6781",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/0 classification Tidy Modeling.html",
    "href": "hotel classification model/0 classification Tidy Modeling.html",
    "title": "Hotel booking data",
    "section": "",
    "text": "Look at the hotel booking data.The target variable is whether have children.\n8590 booking with children.110800 bookings with no children.\nOnly 7% booking with children.Its imbalanced data.Why it causes problems?\nThe model cannot learn to predict the minority class well because of class imbalance.\nModel is only able to learn a simple heuristic (e.g. always predict the dominate class) and it gets stuck in a sub optimal solution.\nAn accuracy of over 90% can be misleading because the model may not have predictive power on the rare class.\nSo in the latter this chapter will introduce downsample method to overcome the this problem.",
    "crumbs": [
      "hotel classification model",
      "Hotel booking data"
    ]
  },
  {
    "objectID": "hotel classification model/0 classification Tidy Modeling.html#measurement",
    "href": "hotel classification model/0 classification Tidy Modeling.html#measurement",
    "title": "Hotel booking data",
    "section": "4.1 Measurement:",
    "text": "4.1 Measurement:\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nSpecificity=TN/(TN+FP)\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)\n\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nF1 score=2/(1/Precision+1/Recall)",
    "crumbs": [
      "hotel classification model",
      "Hotel booking data"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html",
    "href": "hotel classification model/5 classification Tidy Modeling.html",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "",
    "text": "Level 5 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/5 classification Tidy Modeling.html#read-data",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/5 classification Tidy Modeling.html#data-split",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/5 classification Tidy Modeling.html#recipe",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#model",
    "href": "hotel classification model/5 classification Tidy Modeling.html#model",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      &lt;int&gt; 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#workflow",
    "href": "hotel classification model/5 classification Tidy Modeling.html#workflow",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 220 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.000000126            7 accuracy binary     0.754    10 0.00567 Preproces…\n 2   0.000000126            7 roc_auc  binary     0.806    10 0.00583 Preproces…\n 3   0.000104              10 accuracy binary     0.762    10 0.00753 Preproces…\n 4   0.000104              10 roc_auc  binary     0.815    10 0.00545 Preproces…\n 5   0.000369               6 accuracy binary     0.745    10 0.00758 Preproces…\n 6   0.000369               6 roc_auc  binary     0.804    10 0.00577 Preproces…\n 7   0.00000000437         11 accuracy binary     0.756    10 0.00610 Preproces…\n 8   0.00000000437         11 roc_auc  binary     0.817    10 0.00538 Preproces…\n 9   0.000000134           15 accuracy binary     0.751    10 0.00305 Preproces…\n10   0.000000134           15 roc_auc  binary     0.815    10 0.00499 Preproces…\n# ℹ 210 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1        4.37e- 9         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n2        4.32e- 5         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n3        1.09e-10         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n4        1.45e- 9         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n5        7.52e- 8         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1   0.00000000437         11 Preprocessor1_Model008\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 4.37354062320283e-09\n  tree_depth = 11\n\nComputational engine: rpart",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/5 classification Tidy Modeling.html#last-fit",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/5 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.765 Preprocessor1_Model1\n2 roc_auc  binary         0.811 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.765\n2 recall    binary         0.701\n3 precision binary         0.208\n4 f_meas    binary         0.320\n5 kap       binary         0.226\n6 sens      binary         0.701\n7 spec      binary         0.770\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5708 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5708 2854 children (0.500000000 0.500000000)  \n     2) adr&gt;=0.1217285 2186  515 children (0.764409881 0.235590119)  \n       4) adr&gt;=0.795892 1118  149 children (0.866726297 0.133273703)  \n         8) adults&lt; 1.258765 992  110 children (0.889112903 0.110887097)  \n          16) hotel_Resort.Hotel&lt; 0.2015753 489   29 children (0.940695297 0.059304703)  \n            32) arrival_date_month_September&lt; 1.809553 451   20 children (0.955654102 0.044345898)  \n              64) adr&gt;=1.310769 220    2 children (0.990909091 0.009090909) *\n              65) adr&lt; 1.310769 231   18 children (0.922077922 0.077922078)  \n               130) adr&lt; 1.227981 210   12 children (0.942857143 0.057142857) *\n               131) adr&gt;=1.227981 21    6 children (0.714285714 0.285714286)  \n                 262) arrival_date_month_August&gt;=0.8845497 10    0 children (1.000000000 0.000000000) *\n                 263) arrival_date_month_August&lt; 0.8845497 11    5 none (0.454545455 0.545454545) *\n            33) arrival_date_month_September&gt;=1.809553 38    9 children (0.763157895 0.236842105)  \n              66) total_of_special_requests&gt;=-0.4338162 29    3 children (0.896551724 0.103448276) *\n              67) total_of_special_requests&lt; -0.4338162 9    3 none (0.333333333 0.666666667) *\n          17) hotel_Resort.Hotel&gt;=0.2015753 503   81 children (0.838966203 0.161033797)  \n            34) adr&gt;=1.806699 184   13 children (0.929347826 0.070652174) *\n            35) adr&lt; 1.806699 319   68 children (0.786833856 0.213166144)  \n              70) arrival_date_month_August&lt; 0.8845497 189   28 children (0.851851852 0.148148148)  \n               140) arrival_date_month_July&lt; 1.00281 69    4 children (0.942028986 0.057971014) *\n               141) arrival_date_month_July&gt;=1.00281 120   24 children (0.800000000 0.200000000)  \n                 282) adr&gt;=1.003498 96   16 children (0.833333333 0.166666667) *\n                 283) adr&lt; 1.003498 24    8 children (0.666666667 0.333333333)  \n                   566) adr&lt; 0.8813067 9    0 children (1.000000000 0.000000000) *\n                   567) adr&gt;=0.8813067 15    7 none (0.466666667 0.533333333) *\n              71) arrival_date_month_August&gt;=0.8845497 130   40 children (0.692307692 0.307692308)  \n               142) required_car_parking_spaces_parking&gt;=1.047041 45    9 children (0.800000000 0.200000000) *\n               143) required_car_parking_spaces_parking&lt; 1.047041 85   31 children (0.635294118 0.364705882)  \n                 286) stays_in_weekend_nights&gt;=0.53872 54   16 children (0.703703704 0.296296296)  \n                   572) adr&gt;=0.9636965 40    9 children (0.775000000 0.225000000)  \n                    1144) stays_in_week_nights&lt; 1.62789 33    5 children (0.848484848 0.151515152) *\n                    1145) stays_in_week_nights&gt;=1.62789 7    3 none (0.428571429 0.571428571) *\n                   573) adr&lt; 0.9636965 14    7 children (0.500000000 0.500000000) *\n                 287) stays_in_weekend_nights&lt; 0.53872 31   15 children (0.516129032 0.483870968)  \n                   574) adr&gt;=1.17385 21    8 children (0.619047619 0.380952381)  \n                    1148) adr&lt; 1.37684 7    0 children (1.000000000 0.000000000) *\n                    1149) adr&gt;=1.37684 14    6 none (0.428571429 0.571428571) *\n                   575) adr&lt; 1.17385 10    3 none (0.300000000 0.700000000) *\n         9) adults&gt;=1.258765 126   39 children (0.690476190 0.309523810)  \n          18) adr&gt;=1.235145 83   14 children (0.831325301 0.168674699)  \n            36) adr&gt;=1.476344 62    7 children (0.887096774 0.112903226)  \n              72) arrival_date_month_August&lt; 0.8845497 40    2 children (0.950000000 0.050000000) *\n              73) arrival_date_month_August&gt;=0.8845497 22    5 children (0.772727273 0.227272727)  \n               146) stays_in_week_nights&lt; 0.5290259 13    0 children (1.000000000 0.000000000) *\n               147) stays_in_week_nights&gt;=0.5290259 9    4 none (0.444444444 0.555555556) *\n\n...\nand 200 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/5 classification Tidy Modeling.html#save-model",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.53 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/5 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      574 2043\n  none          247 7136\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.771\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          821\n2 none             9179\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2617\n2 none         7383\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      574 2043\n  none          247 7136",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "intro/2 basic R.html",
    "href": "intro/2 basic R.html",
    "title": "Basic R",
    "section": "",
    "text": "Code\nx &lt;- -5\nif(x &gt; 0){\nprint(\"Non-negative number\")\n} else {\nprint(\"Negative number\")\n}\n\n\n[1] \"Negative number\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 about.html",
    "href": "intro/1 about.html",
    "title": "About",
    "section": "",
    "text": "About this site:\nlink:https://tonyfly3000.github.io/tidymodeling/\n\nhttps://www.tidymodels.org/\n\nModeling process\n\n\n\nresource\ntidymodels website: https://www.tidymodels.org/\ntidymodels book: https://www.tmwr.org/\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "About"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html",
    "href": "hotel classification model/1 classification Tidy Modeling.html",
    "title": "Classification Model",
    "section": "",
    "text": "Level 1 classification Tidy Modeling with 2 model and no recipe:\n*using basic Tidymodel package.\nNo recipe\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/1 classification Tidy Modeling.html#read-data",
    "title": "Classification Model",
    "section": "3.1 read data",
    "text": "3.1 read data\n\n\nCode\nlibrary(tidyverse)\n\n#hotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotels &lt;- readr::read_csv(\"./data/hotels.csv\")\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/1 classification Tidy Modeling.html#data-split",
    "title": "Classification Model",
    "section": "3.2 data split",
    "text": "3.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(10000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 7000   10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 1000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 2000   10",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/1 classification Tidy Modeling.html#recipe",
    "title": "Classification Model",
    "section": "4.1 recipe",
    "text": "4.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#model",
    "href": "hotel classification model/1 classification Tidy Modeling.html#model",
    "title": "Classification Model",
    "section": "4.2 model",
    "text": "4.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/1 classification Tidy Modeling.html#trainning",
    "title": "Classification Model",
    "section": "4.3 trainning",
    "text": "4.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.081\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 7000 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7000 568 none (0.08114286 0.91885714)  \n   2) adr&gt;=171.07 571 193 none (0.33800350 0.66199650)  \n     4) adr&gt;=221.09 164  80 children (0.51219512 0.48780488)  \n       8) hotel=City Hotel 49  14 children (0.71428571 0.28571429) *\n       9) hotel=Resort Hotel 115  49 none (0.42608696 0.57391304)  \n        18) adr&gt;=273.25 31  10 children (0.67741935 0.32258065) *\n        19) adr&lt; 273.25 84  28 none (0.33333333 0.66666667) *\n     5) adr&lt; 221.09 407 109 none (0.26781327 0.73218673) *\n   3) adr&lt; 171.07 6429 375 none (0.05832944 0.94167056) *",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/1 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model",
    "section": "5.1 Evaluate",
    "text": "5.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children       10    5\n  none           84  901\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.911\n2 kap      binary         0.162\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.911\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.106\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.994\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.911\n2 sens     binary         0.106\n3 spec     binary         0.994\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.911\n 2 kap                  binary         0.162\n 3 sens                 binary         0.106\n 4 spec                 binary         0.994\n 5 ppv                  binary         0.667\n 6 npv                  binary         0.915\n 7 mcc                  binary         0.242\n 8 j_index              binary         0.101\n 9 bal_accuracy         binary         0.550\n10 detection_prevalence binary         0.015\n11 precision            binary         0.667\n12 recall               binary         0.106\n13 f_meas               binary         0.183\n\n\nROC:receiver operating characteristic curve\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\nAUC:Area under ROC Curve\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_children)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.654",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/1 classification Tidy Modeling.html#save-model",
    "title": "Classification Model",
    "section": "5.2 save model",
    "text": "5.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n544.50 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/1 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model",
    "section": "5.3 make predication",
    "text": "5.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction %&gt;% count(.pred_class)\n\n\n# A tibble: 2 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children       24\n2 none         1976\n\n\n\n\nCode\ndata_valid %&gt;% count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          154\n2 none             1846",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html",
    "href": "hotel classification model/4 classification Tidy Modeling.html",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "",
    "text": "Level 4 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth) with tune_grid()",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/4 classification Tidy Modeling.html#read-data",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/4 classification Tidy Modeling.html#data-split",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train,v=10)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/4 classification Tidy Modeling.html#recipe",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#model",
    "href": "hotel classification model/4 classification Tidy Modeling.html#model",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#workflow",
    "href": "hotel classification model/4 classification Tidy Modeling.html#workflow",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl,\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits               id     .metrics          .notes           .predictions\n   &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [31500/3500]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [31500/3500]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [31500/3500]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [31500/3500]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [31500/3500]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [31500/3500]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [31500/3500]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [31500/3500]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [31500/3500]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [31500/3500]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.806    10 0.0108  Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 3    0.0000000178          1 accuracy binary     0.806    10 0.0108  Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 5    0.00000316            1 accuracy binary     0.806    10 0.0108  Preproces…\n 6    0.00000316            1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 7    0.000562              1 accuracy binary     0.806    10 0.0108  Preproces…\n 8    0.000562              1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 9    0.1                   1 accuracy binary     0.806    10 0.0108  Preproces…\n10    0.1                   1 roc_auc  binary     0.686    10 0.00390 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.0000000001          1 accuracy binary     0.806    10  0.0108 Preprocess…\n2    0.0000000178          1 accuracy binary     0.806    10  0.0108 Preprocess…\n3    0.00000316            1 accuracy binary     0.806    10  0.0108 Preprocess…\n4    0.000562              1 accuracy binary     0.806    10  0.0108 Preprocess…\n5    0.1                   1 accuracy binary     0.806    10  0.0108 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          1 Preprocessor1_Model01\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 1\n\nComputational engine: rpart",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/4 classification Tidy Modeling.html#last-fit",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/4 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.789 Preprocessor1_Model1\n2 roc_auc  binary         0.701 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5754 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 5754 2877 children (0.5000000 0.5000000)  \n  2) adr&gt;=0.1165396 2235  553 children (0.7525727 0.2474273) *\n  3) adr&lt; 0.1165396 3519 1195 none (0.3395851 0.6604149) *\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/4 classification Tidy Modeling.html#save-model",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.48 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/4 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 children   \n2 none       \n3 none       \n4 none       \n5 children   \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      467 1879\n  none          288 7366\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.783\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          755\n2 none             9245\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2346\n2 none         7654\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      467 1879\n  none          288 7366",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "data manipulation/5 recipe.html",
    "href": "data manipulation/5 recipe.html",
    "title": "recipe",
    "section": "",
    "text": "1 create recipe step_xxx\n\n\nCode\ntree_rec &lt;- recipe(legal_status ~ ., data = trees_train) %&gt;%\n  \n # update the role for tree_id, since this is a variable we might like to keep around for convenience as an identifier for rows but is not a predictor or outcome. \n  update_role(tree_id, new_role = \"ID\") %&gt;%\n  \n# step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step, there were 300+ species!\n  step_other(species, caretaker, threshold = 0.01) %&gt;%\n  \n# create dummy for nominal data exclude outcome\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  \n# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date, given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.  \n  step_date(date, features = c(\"year\")) %&gt;%step_rm(date) %&gt;%\n  \n# There are many more DPW maintained trees than not, so let’s downsample the data for training.  \n  step_downsample(legal_status)%&gt;%\n\n# will remove all. predictor variables that contain only a single value\n    step_zv(all_numeric(all_predictors())) %&gt;% \n  \n#  normalize all numeric data\n  step_normalize(all_numeric()) %&gt;% \n\n# use KNN to impute all predictors\nstep_impute_knn(all_predictors()) \n\n\n\n\n2 check recipe check_xxx\n\n\nCode\n#&gt; [1] \"check_class\"      \"check_cols\"       \"check_missing\"   \n#&gt; [4] \"check_name\"       \"check_new_data\"   \"check_new_values\"\n#&gt; [7] \"check_range\"      \"check_type\"\n\n\n\n\n3 roles to select variables\nIn most cases, the right approach for users will be use to use the predictor-specific selectors such as all_numeric_predictors() and all_nominal_predictors().\n\n\nCode\nhas_role(match = \"predictor\")\n\nhas_type(match = \"numeric\")\n\nall_outcomes()\n\nall_predictors()\n\nall_date()\n\nall_date_predictors()\n\nall_datetime()\n\nall_datetime_predictors()\n\nall_double()\n\nall_double_predictors()\n\nall_factor()\n\nall_factor_predictors()\n\nall_integer()\n\nall_integer_predictors()\n\nall_logical()\n\nall_logical_predictors()\n\nall_nominal()\n\nall_nominal_predictors()\n\nall_numeric()\n\nall_numeric_predictors()\n\nall_ordered()\n\nall_ordered_predictors()\n\nall_string()\n\nall_string_predictors()\n\nall_unordered()\n\nall_unordered_predictors()\n\ncurrent_info()\n\n\n\n\n4 reference:\nhttps://recipes.tidymodels.org/reference/has_role.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "data manipulation",
      "recipe"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#for-loop",
    "href": "intro/2 basic R.html#for-loop",
    "title": "Basic R",
    "section": "2.1 for Loop",
    "text": "2.1 for Loop",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#while-loop",
    "href": "intro/2 basic R.html#while-loop",
    "title": "Basic R",
    "section": "2.2 while Loop",
    "text": "2.2 while Loop\nwith break statement",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#without-arguments",
    "href": "intro/2 basic R.html#without-arguments",
    "title": "Basic R",
    "section": "3.1 without Arguments",
    "text": "3.1 without Arguments",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#return-result",
    "href": "intro/2 basic R.html#return-result",
    "title": "Basic R",
    "section": "3.2 return result",
    "text": "3.2 return result",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#check-python-version",
    "href": "intro/2 basic R.html#check-python-version",
    "title": "Basic R",
    "section": "4.1 check python version",
    "text": "4.1 check python version",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#install-package",
    "href": "intro/2 basic R.html#install-package",
    "title": "Basic R",
    "section": "4.2 install package",
    "text": "4.2 install package",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#check-one-package-version",
    "href": "intro/2 basic R.html#check-one-package-version",
    "title": "Basic R",
    "section": "4.3 check one package version",
    "text": "4.3 check one package version",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/2 basic R.html#check-all-package-version",
    "href": "intro/2 basic R.html#check-all-package-version",
    "title": "Basic R",
    "section": "4.4 check all package version",
    "text": "4.4 check all package version",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "data manipulation/4 resample.html",
    "href": "data manipulation/4 resample.html",
    "title": "resample",
    "section": "",
    "text": "1 k-Fold Cross-Validation\n\n\n\nCode\nk_flod_resample&lt;- vfold_cv(data, v = 10)\nk_flod_resample\n\n\n\n\n2 MONTE CARLO CROSS-VALIDATION\nfor MCCV, this proportion of the data is randomly selected each time. This results in assessment sets that are not mutually exclusive\n\n\nCode\nmc_resample&lt;- mc_cv(data, prop = 9/10, times = 20)\nmc_resample\n\n\n\n\n3 The Bootstrap\nA bootstrap sample of the training set is a sample that is the same size as the training set but is drawn with replacement\n\n\n\nCode\nbootstraps_resample&lt;- bootstraps(data, times = 1000)\nbootstraps_resample\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "data manipulation",
      "resample"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html",
    "href": "data manipulation/1 input ouput.html",
    "title": "input & ouput in R",
    "section": "",
    "text": "Data input and ouput in R\nCode\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(readxl)",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html",
    "href": "data manipulation/2 data structure in R.html",
    "title": "Data structure in R",
    "section": "",
    "text": "1 vector\nA vector is an ordered collection of basic data types of a given length. The only key thing here is all the elements of a vector must be same data type e.g homogeneous data structures. Vectors are one-dimensional data structures.\n\n\nCode\na = c(1, 2, 3, 4)\na\n\n\n[1] 1 2 3 4\n\n\n\n\nCode\nclass(a)\n\n\n[1] \"numeric\"\n\n\n\n\nCode\nb =  c(\"Debi\", \"Sandeep\", \"Subham\", \"Shiba\")\nb\n\n\n[1] \"Debi\"    \"Sandeep\" \"Subham\"  \"Shiba\"  \n\n\n\n\nCode\nclass(b)\n\n\n[1] \"character\"\n\n\n\n\n2 Dataframe\nDataframes are generic data objects of R which are used to store the tabular data. Dataframes are the foremost popular data objects in R programming because we are comfortable in seeing the data within the tabular form. They are two-dimensional, heterogeneous data structures\n\n\nCode\n# A vector which is a character vector\nName = c(\"Amiya\", \"Raj\", \"Asish\")\n\n# A vector which is a character vector\nLanguage = c(\"R\", \"Python\", \"Java\")\n\n# A vector which is a numeric vector\nAge = c(22, 25, 45)\n\n# To create dataframe use data.frame command\n# and then pass each of the vectors \n# we have created as arguments\n# to the function data.frame()\ndf = data.frame(Name, Language, Age)\n\ndf\n\n\n   Name Language Age\n1 Amiya        R  22\n2   Raj   Python  25\n3 Asish     Java  45\n\n\n\n\nCode\nclass(df)\n\n\n[1] \"data.frame\"\n\n\n\n\n3 Matrices\nA matrix is a rectangular arrangement of numbers in rows and columns. In a matrix, as we know rows are the ones that run horizontally and columns are the ones that run vertically. Matrices are two-dimensional, homogeneous data structures.\n\n\nCode\nA = matrix(\n    # Taking sequence of elements\n    c(1, 2, 3, 4, 5, 6, 7, 8, 9), \n    \n    # No of rows and columns\n    nrow = 3, ncol = 3,  \n\n    # By default matrices are \n    # in column-wise order \n    # So this parameter decides\n    # how to arrange the matrix          \n    byrow = TRUE                             \n)\n\nA\n\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n\n\nCode\nclass(A)\n\n\n[1] \"matrix\" \"array\" \n\n\n\n\nCode\nmatrix002=A+A\n\nmatrix002\n\n\n     [,1] [,2] [,3]\n[1,]    2    4    6\n[2,]    8   10   12\n[3,]   14   16   18\n\n\n\n\nCode\nmatrix003=A*A\n\nmatrix003\n\n\n     [,1] [,2] [,3]\n[1,]    1    4    9\n[2,]   16   25   36\n[3,]   49   64   81\n\n\n\n\n4 Lists\nA list is a generic object consisting of an ordered collection of objects. Lists are heterogeneous data structures. These are also one-dimensional data structures. A list can be a list of vectors, list of matrices, a list of characters and a list of functions and so on.\n\n\nCode\nempId = c(1, 2, 3, 4)\n\n# The second attribute is the employee name \n# which is created using this line of code here\n# which is the character vector \nempName = c(\"Debi\", \"Sandeep\", \"Subham\", \"Shiba\")\n\n# The third attribute is the number of employees\n# which is a single numeric variable.\nnumberOfEmp = 4\n\n# We can combine all these three different\n# data types into a list\n# containing the details of employees\n# which can be done using a list command\nempList = list(empId, empName, numberOfEmp)\n\nempList\n\n\n[[1]]\n[1] 1 2 3 4\n\n[[2]]\n[1] \"Debi\"    \"Sandeep\" \"Subham\"  \"Shiba\"  \n\n[[3]]\n[1] 4\n\n\n\n\nCode\nclass(empList)\n\n\n[1] \"list\"\n\n\n\n\n5 Arrays\n3D arrays\n\n\nCode\nA = array(\n    # Taking sequence of elements\n    c(1, 2, 3, 4, 5, 6, 7, 8),\n\n    # Creating two rectangular matrices \n    # each with two rows and two columns\n    dim = c(2, 2, 2)                        \n)\n\nA\n\n\n, , 1\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n, , 2\n\n     [,1] [,2]\n[1,]    5    7\n[2,]    6    8\n\n\n\n\nCode\nclass(A)\n\n\n[1] \"array\"\n\n\n\n\n6 Reference:\nhttps://www.geeksforgeeks.org/data-structures-in-r-programming/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html",
    "href": "data manipulation/3 data manipulation with tidyverse.html",
    "title": "Data manipulation with tidyverse",
    "section": "",
    "text": "The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\ndplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges.",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-csv",
    "href": "data manipulation/1 input ouput.html#read-csv",
    "title": "input & ouput in R",
    "section": "1.1 read CSV",
    "text": "1.1 read CSV\n\n\nCode\ndata001=read_csv('data/Book3.csv')\nhead(data001)\n\n\n# A tibble: 2 × 2\n      a b    \n  &lt;dbl&gt; &lt;chr&gt;\n1  1241 rhth \n2 35235 rjyyj\n\n\nread CSV online\n\n\nCode\nurl='https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv'\ndata001=read_csv(url)\nhead(data001)\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_year arrival_date_month\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;             \n1 Resort Hotel           0       342              2015 July              \n2 Resort Hotel           0       737              2015 July              \n3 Resort Hotel           0         7              2015 July              \n4 Resort Hotel           0        13              2015 July              \n5 Resort Hotel           0        14              2015 July              \n6 Resort Hotel           0        14              2015 July              \n# ℹ 27 more variables: arrival_date_week_number &lt;dbl&gt;,\n#   arrival_date_day_of_month &lt;dbl&gt;, stays_in_weekend_nights &lt;dbl&gt;,\n#   stays_in_week_nights &lt;dbl&gt;, adults &lt;dbl&gt;, children &lt;dbl&gt;, babies &lt;dbl&gt;,\n#   meal &lt;chr&gt;, country &lt;chr&gt;, market_segment &lt;chr&gt;,\n#   distribution_channel &lt;chr&gt;, is_repeated_guest &lt;dbl&gt;,\n#   previous_cancellations &lt;dbl&gt;, previous_bookings_not_canceled &lt;dbl&gt;,\n#   reserved_room_type &lt;chr&gt;, assigned_room_type &lt;chr&gt;, …",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-excel",
    "href": "data manipulation/1 input ouput.html#read-excel",
    "title": "input & ouput in R",
    "section": "1.2 read excel",
    "text": "1.2 read excel\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\ndata001=read_excel('data/Book1.xlsx')\nhead(data001)\n\n\n# A tibble: 2 × 2\n      a b    \n  &lt;dbl&gt; &lt;chr&gt;\n1  1241 rhth \n2 35235 rjyyj",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-parquet",
    "href": "data manipulation/1 input ouput.html#read-parquet",
    "title": "input & ouput in R",
    "section": "1.3 read parquet",
    "text": "1.3 read parquet\nmust install in this way,otherwise will report error.\n\n\nCode\ninstall.packages(\"arrow\", repos = c(\"https://apache.r-universe.dev\"))\n\n\n\n\nCode\nlibrary(arrow)\narrow_info()\n\n\nArrow package version: 15.0.1\n\nCapabilities:\n               \nacero      TRUE\ndataset    TRUE\nsubstrait FALSE\nparquet    TRUE\njson       TRUE\ns3         TRUE\ngcs        TRUE\nutf8proc   TRUE\nre2        TRUE\nsnappy     TRUE\ngzip       TRUE\nbrotli     TRUE\nzstd       TRUE\nlz4        TRUE\nlz4_frame  TRUE\nlzo       FALSE\nbz2        TRUE\njemalloc   TRUE\nmimalloc   TRUE\n\nMemory:\n                  \nAllocator mimalloc\nCurrent    0 bytes\nMax        0 bytes\n\nRuntime:\n                        \nSIMD Level          none\nDetected SIMD Level none\n\nBuild:\n                                                             \nC++ Library Version                                    15.0.1\nC++ Compiler                                       AppleClang\nC++ Compiler Version                          15.0.0.15000100\nGit ID               5ce6ff434c1e7daaa2d7f134349f3ce4c22683da\n\n\n\n\nCode\ndata001=read_parquet('data/df.parquet')\nhead(data001)\n\n\n# A tibble: 6 × 62\n  FlightDate          Airline Origin Dest  Cancelled Diverted CRSDepTime DepTime\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt;     &lt;lgl&gt;         &lt;int&gt;   &lt;dbl&gt;\n1 2022-04-04 00:00:00 Commut… GJT    DEN   FALSE     FALSE          1133    1123\n2 2022-04-04 00:00:00 Commut… HRL    IAH   FALSE     FALSE           732     728\n3 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1529    1514\n4 2022-04-04 00:00:00 Commut… IAH    GPT   FALSE     FALSE          1435    1430\n5 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1135    1135\n6 2022-04-04 00:00:00 Commut… DEN    TUL   FALSE     FALSE           955     952\n# ℹ 54 more variables: DepDelayMinutes &lt;dbl&gt;, DepDelay &lt;dbl&gt;, ArrTime &lt;dbl&gt;,\n#   ArrDelayMinutes &lt;dbl&gt;, AirTime &lt;dbl&gt;, CRSElapsedTime &lt;dbl&gt;,\n#   ActualElapsedTime &lt;dbl&gt;, Distance &lt;dbl&gt;, Year &lt;int&gt;, Quarter &lt;int&gt;,\n#   Month &lt;int&gt;, DayofMonth &lt;int&gt;, DayOfWeek &lt;int&gt;,\n#   Marketing_Airline_Network &lt;chr&gt;,\n#   Operated_or_Branded_Code_Share_Partners &lt;chr&gt;,\n#   DOT_ID_Marketing_Airline &lt;int&gt;, IATA_Code_Marketing_Airline &lt;chr&gt;, …\n\n\nread parquet zip\n\n\nCode\ndata001=read_parquet('data/df.parquet.gzip')\nhead(data001)\n\n\n# A tibble: 6 × 62\n  FlightDate          Airline Origin Dest  Cancelled Diverted CRSDepTime DepTime\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt;     &lt;lgl&gt;         &lt;int&gt;   &lt;dbl&gt;\n1 2022-04-04 00:00:00 Commut… GJT    DEN   FALSE     FALSE          1133    1123\n2 2022-04-04 00:00:00 Commut… HRL    IAH   FALSE     FALSE           732     728\n3 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1529    1514\n4 2022-04-04 00:00:00 Commut… IAH    GPT   FALSE     FALSE          1435    1430\n5 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1135    1135\n6 2022-04-04 00:00:00 Commut… DEN    TUL   FALSE     FALSE           955     952\n# ℹ 54 more variables: DepDelayMinutes &lt;dbl&gt;, DepDelay &lt;dbl&gt;, ArrTime &lt;dbl&gt;,\n#   ArrDelayMinutes &lt;dbl&gt;, AirTime &lt;dbl&gt;, CRSElapsedTime &lt;dbl&gt;,\n#   ActualElapsedTime &lt;dbl&gt;, Distance &lt;dbl&gt;, Year &lt;int&gt;, Quarter &lt;int&gt;,\n#   Month &lt;int&gt;, DayofMonth &lt;int&gt;, DayOfWeek &lt;int&gt;,\n#   Marketing_Airline_Network &lt;chr&gt;,\n#   Operated_or_Branded_Code_Share_Partners &lt;chr&gt;,\n#   DOT_ID_Marketing_Airline &lt;int&gt;, IATA_Code_Marketing_Airline &lt;chr&gt;, …",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-feather",
    "href": "data manipulation/1 input ouput.html#read-feather",
    "title": "input & ouput in R",
    "section": "1.4 read feather",
    "text": "1.4 read feather\n\n\nCode\nlibrary(feather)\n\ndata001=read_feather('data/feather_file.feather')\nhead(data001)\n\n\n# A tibble: 6 × 62\n  FlightDate          Airline Origin Dest  Cancelled Diverted CRSDepTime DepTime\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt;     &lt;lgl&gt;         &lt;int&gt;   &lt;dbl&gt;\n1 2022-04-04 00:00:00 Commut… GJT    DEN   FALSE     FALSE          1133    1123\n2 2022-04-04 00:00:00 Commut… HRL    IAH   FALSE     FALSE           732     728\n3 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1529    1514\n4 2022-04-04 00:00:00 Commut… IAH    GPT   FALSE     FALSE          1435    1430\n5 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1135    1135\n6 2022-04-04 00:00:00 Commut… DEN    TUL   FALSE     FALSE           955     952\n# ℹ 54 more variables: DepDelayMinutes &lt;dbl&gt;, DepDelay &lt;dbl&gt;, ArrTime &lt;dbl&gt;,\n#   ArrDelayMinutes &lt;dbl&gt;, AirTime &lt;dbl&gt;, CRSElapsedTime &lt;dbl&gt;,\n#   ActualElapsedTime &lt;dbl&gt;, Distance &lt;dbl&gt;, Year &lt;int&gt;, Quarter &lt;int&gt;,\n#   Month &lt;int&gt;, DayofMonth &lt;int&gt;, DayOfWeek &lt;int&gt;,\n#   Marketing_Airline_Network &lt;chr&gt;,\n#   Operated_or_Branded_Code_Share_Partners &lt;chr&gt;,\n#   DOT_ID_Marketing_Airline &lt;int&gt;, IATA_Code_Marketing_Airline &lt;chr&gt;, …",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-csv",
    "href": "data manipulation/1 input ouput.html#write-csv",
    "title": "input & ouput in R",
    "section": "2.1 write csv",
    "text": "2.1 write csv\n\n\nCode\nwrite.csv(data001,'data001 csv output data.csv')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-excel",
    "href": "data manipulation/1 input ouput.html#write-excel",
    "title": "input & ouput in R",
    "section": "2.2 write excel",
    "text": "2.2 write excel\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nwrite.xlsx(data001,'data001 excel output data.xlsx')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-parquet",
    "href": "data manipulation/1 input ouput.html#write-parquet",
    "title": "input & ouput in R",
    "section": "2.3 write parquet",
    "text": "2.3 write parquet\n\n\nCode\nlibrary(arrow)\nwrite_parquet(data001,'data/df.parquet')\n\n\noutput to zip format\n\n\nCode\nwrite_parquet(data001,'data/df.parquet.gzip',compression='gzip')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-feather",
    "href": "data manipulation/1 input ouput.html#write-feather",
    "title": "input & ouput in R",
    "section": "2.4 write feather",
    "text": "2.4 write feather\n\n\nCode\nlibrary(feather)\nwrite_feather(data001,'data/feather_file.feather')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html",
    "href": "intro/1 basic R.html",
    "title": "Basic R",
    "section": "",
    "text": "Code\ngetwd()\n\n\n\n\n\n\n\nCode\nlist.files()\n\n\n[1] \"1 basic R.qmd\"                 \"1 basic R.rmarkdown\"          \n[3] \"1-basic-R.rmarkdown\"           \"5 R boook.qmd\"                \n[5] \"6 data analytic in R book.qmd\" \"hotels.csv\"                   \n[7] \"images\"                       \n\n\n\n\n\n\n\nCode\nfile.info(\"1 about.qmd\" )\n\n\n            size isdir mode mtime ctime atime uid gid uname grname\n1 about.qmd   NA    NA &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  NA  NA  &lt;NA&gt;   &lt;NA&gt;\n\n\n\n\n\n\n\nCode\ndir.create('testing_folder')\n\n\n\n\n\n\n\nCode\nfile.remove('testing_folder')\n\n\n\n\n\n\n\nCode\nlibrary(fs)\nfile_copy('test.csv', 'test2.csv')\n\n\n\n\n\n\n\nCode\nurl=\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n\ndownload.file(url = url, destfile = \"hotels.csv\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-current-directory",
    "href": "intro/1 basic R.html#get-current-directory",
    "title": "Basic R",
    "section": "1.1 get current directory",
    "text": "1.1 get current directory\n\n\nCode\ngetwd()",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-all-file-name-under-current-directory",
    "href": "intro/1 basic R.html#get-all-file-name-under-current-directory",
    "title": "Basic R",
    "section": "1.2 get all file name under current directory",
    "text": "1.2 get all file name under current directory\n\n\nCode\nlist.files()\n\n\n[1] \"1 basic R_files\"               \"1 basic R.qmd\"                \n[3] \"1 basic R.rmarkdown\"           \"1-basic-R.rmarkdown\"          \n[5] \"5 R boook.qmd\"                 \"6 data analytic in R book.qmd\"\n[7] \"hotels.csv\"                    \"images\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-file-info",
    "href": "intro/1 basic R.html#get-file-info",
    "title": "Basic R",
    "section": "1.4 get file info",
    "text": "1.4 get file info\n\n\nCode\nfile.info(\"6 data analytic in R book.qmd\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#create-folder",
    "href": "intro/1 basic R.html#create-folder",
    "title": "Basic R",
    "section": "1.5 create folder",
    "text": "1.5 create folder\n\n\nCode\ndir.create('testing_folder')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#delete-folderfile",
    "href": "intro/1 basic R.html#delete-folderfile",
    "title": "Basic R",
    "section": "1.6 delete folder/file",
    "text": "1.6 delete folder/file\n\n\nCode\nfile.remove('testing_folder')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#copy-file",
    "href": "intro/1 basic R.html#copy-file",
    "title": "Basic R",
    "section": "1.7 copy file",
    "text": "1.7 copy file\n\n\nCode\nlibrary(fs)\nfile_copy('test.csv', 'test2.csv')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#download-file-from-internet",
    "href": "intro/1 basic R.html#download-file-from-internet",
    "title": "Basic R",
    "section": "1.8 download file from internet",
    "text": "1.8 download file from internet\n\n\nCode\nurl=\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n\ndownload.file(url = url, destfile = \"hotels.csv\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#for-loop",
    "href": "intro/1 basic R.html#for-loop",
    "title": "Basic R",
    "section": "3.1 for Loop",
    "text": "3.1 for Loop\n\n\nCode\nfor (x in 1:4) {\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\nwith break statement\n\n\nCode\nfor (x in 1:6) {\n  if (x == 4) {break}\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n\n\nwith next statement\n\n\nCode\nfor (x in 1:6) {\n  if (x == 4) {next}\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 5\n[1] 6",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#while-loop",
    "href": "intro/1 basic R.html#while-loop",
    "title": "Basic R",
    "section": "3.3 while Loop",
    "text": "3.3 while Loop\n\n\nCode\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nwith break statement\n\n\nCode\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n  if (i == 4) {break}\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n\n\nwith next statement\n\n\nCode\ni =1\n\nwhile (i &lt; 6) {\n  i &lt;- i + 1\n  if (i == 4){next}\n  print(i)\n}\n\n\n[1] 2\n[1] 3\n[1] 5\n[1] 6",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#without-arguments",
    "href": "intro/1 basic R.html#without-arguments",
    "title": "Basic R",
    "section": "4.1 without Arguments",
    "text": "4.1 without Arguments\n\n\nCode\nmy_function &lt;- function() { \n  print(\"Hello World!\")\n}\n\nmy_function()\n\n\n[1] \"Hello World!\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#return-result",
    "href": "intro/1 basic R.html#return-result",
    "title": "Basic R",
    "section": "4.2 return result",
    "text": "4.2 return result\n\n\nCode\nadding_ten &lt;- function(x) { \n  a=x+10\n  return(a)\n}\n\nadding_ten(5)\n\n\n[1] 15",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-r-version",
    "href": "intro/1 basic R.html#check-r-version",
    "title": "Basic R",
    "section": "6.1 check R version",
    "text": "6.1 check R version\n\n\nCode\nversion\n\n\n               _                           \nplatform       aarch64-apple-darwin20      \narch           aarch64                     \nos             darwin20                    \nsystem         aarch64, darwin20           \nstatus                                     \nmajor          4                           \nminor          3.1                         \nyear           2023                        \nmonth          06                          \nday            16                          \nsvn rev        84548                       \nlanguage       R                           \nversion.string R version 4.3.1 (2023-06-16)\nnickname       Beagle Scouts",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#install-r-package",
    "href": "intro/1 basic R.html#install-r-package",
    "title": "Basic R",
    "section": "6.2 install R package",
    "text": "6.2 install R package\n\n6.2.1 install from Cran\n99% of the time will install pacakge from The Comprehensive R Archive Network(cran).https://cran.r-project.org/\n\n\n\nCode\ninstall.packages('tidyverse')\n\n\n\n\n6.2.2 install from Github\n\n\nCode\npak::pkg_install(\"tidymodels/learntidymodels\")\n\n\n\n\n6.2.3 install from Bioconductor\n\n\nCode\npak::pkg_install(\"text2vec\")\n\n\n\n\n6.2.4 install from local\n\n\nCode\npak::local_install(\"cli\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-one-package-version",
    "href": "intro/1 basic R.html#check-one-package-version",
    "title": "Basic R",
    "section": "6.3 check one package version",
    "text": "6.3 check one package version\n\n\nCode\npackageVersion(\"tidyverse\")\n\n\n[1] '2.0.0'",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-all-package-version",
    "href": "intro/1 basic R.html#check-all-package-version",
    "title": "Basic R",
    "section": "6.7 check all package version",
    "text": "6.7 check all package version\n\n\nCode\nip = as.data.frame(installed.packages()[,c(1,3:4)])\nip = ip[is.na(ip$Priority),1:2,drop=FALSE]\nhead(ip)\n\n\n                Package  Version\nabind             abind    1.4-5\nanytime         anytime    0.3.9\napplicable   applicable    0.1.0\narchive         archive    1.1.7\narrow             arrow   15.0.1\nAsioHeaders AsioHeaders 1.22.1-2",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-package-install-loaciton",
    "href": "intro/1 basic R.html#check-package-install-loaciton",
    "title": "Basic R",
    "section": "6.8 check package install loaciton",
    "text": "6.8 check package install loaciton\n\n\nCode\n.libPaths()\n\n\n[1] \"/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#create-database-file-pythonsqlite.db-and-copy-mtcars-data-and-iris-data-into-database",
    "href": "data manipulation/5 SQL database.html#create-database-file-pythonsqlite.db-and-copy-mtcars-data-and-iris-data-into-database",
    "title": "SQL database with R",
    "section": "1.1 create database file pythonsqlite.db and copy mtcars data and iris data into database",
    "text": "1.1 create database file pythonsqlite.db and copy mtcars data and iris data into database\n\n\nCode\nmtcars=cbind(newColName = rownames(mtcars), mtcars)\n\n\n\n\nCode\n# Create an ephemeral in-memory RSQLite database\ncon &lt;- dbConnect(RSQLite::SQLite(), \"my_sql_database\")\n\n#dbListTables(con)\ndbWriteTable(con, \"mtcars\", mtcars,overwrite=TRUE)\ndbWriteTable(con, \"iris\", iris,overwrite=TRUE)",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#check-all-table-in-database",
    "href": "data manipulation/5 SQL database.html#check-all-table-in-database",
    "title": "SQL database with R",
    "section": "1.2 check all table in database",
    "text": "1.2 check all table in database\n\n\nCode\ncon &lt;- dbConnect(RSQLite::SQLite(), \"my_sql_database\")\ndbListTables(con)\n\n\n[1] \"iris\"   \"mtcars\"",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#select",
    "href": "data manipulation/5 SQL database.html#select",
    "title": "SQL database with R",
    "section": "2.1 select",
    "text": "2.1 select\n\n\nCode\nsql =\"SELECT * FROM mtcars LIMIT 3\"\ntable=dbGetQuery(con,sql)\ntable\n\n\n     newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1     Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2 Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3    Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#renaming-column",
    "href": "data manipulation/5 SQL database.html#renaming-column",
    "title": "SQL database with R",
    "section": "2.2 Renaming column",
    "text": "2.2 Renaming column\n\n\nCode\nsql=\"select mpg as new_mpg from mtcars\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n  new_mpg\n1    21.0\n2    21.0\n3    22.8\n4    21.4\n5    18.7\n6    18.1",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#create-column",
    "href": "data manipulation/5 SQL database.html#create-column",
    "title": "SQL database with R",
    "section": "2.3 create column",
    "text": "2.3 create column\n\n\nCode\nsql=\"select mpg+1 as new_mpg,mpg from mtcars\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n  new_mpg  mpg\n1    22.0 21.0\n2    22.0 21.0\n3    23.8 22.8\n4    22.4 21.4\n5    19.7 18.7\n6    19.1 18.1",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#filter-rows",
    "href": "data manipulation/5 SQL database.html#filter-rows",
    "title": "SQL database with R",
    "section": "2.4 Filter rows",
    "text": "2.4 Filter rows\n\n\nCode\nsql=\"select * from mtcars where hp&gt;100\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n4 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n5           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n6        Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\n\n\n\n2.4.1 Filters with AND conditions\n\n\nCode\nsql=\"select * from mtcars where hp&gt;100 and drat&lt;3\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n          newColName  mpg cyl disp  hp drat   wt  qsec vs am gear carb\n1            Valiant 18.1   6  225 105 2.76 3.46 20.22  1  0    3    1\n2 Cadillac Fleetwood 10.4   8  472 205 2.93 5.25 17.98  0  0    3    4\n3   Dodge Challenger 15.5   8  318 150 2.76 3.52 16.87  0  0    3    2\n\n\n\n\n2.4.2 Filters with or conditions\n\n\nCode\nsql=\"select * from mtcars where hp&gt;100 or drat&lt;3\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n4 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n5           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n6        Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#append",
    "href": "data manipulation/5 SQL database.html#append",
    "title": "SQL database with R",
    "section": "2.5 Append",
    "text": "2.5 Append\n\n2.5.1 append by row\n\n\nCode\nsql=\"select * from mtcars union all select * from mtcars \"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n6           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n\n\n2.5.2 append by column\n\n\n2.5.3 Dropping NA values\n\n\n2.5.4 keep NA values",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#group-by",
    "href": "data manipulation/5 SQL database.html#group-by",
    "title": "SQL database with R",
    "section": "2.6 group by",
    "text": "2.6 group by\n\n2.6.1 average,min,max,sum\n\n\nCode\nsql=\"select AVG(hp),min(hp),max(hp),sum(hp) from mtcars\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n   AVG(hp) min(hp) max(hp) sum(hp)\n1 146.6875      52     335    4694\n\n\n\n\n2.6.2 count record and count distinct record\n\n\nCode\nsql=\"select vs, count(*),count(distinct cyl) from mtcars group by vs\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n  vs count(*) count(distinct cyl)\n1  0       18                   3\n2  1       14                   2",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#order-rows",
    "href": "data manipulation/5 SQL database.html#order-rows",
    "title": "SQL database with R",
    "section": "2.7 order rows",
    "text": "2.7 order rows\n\n\nCode\nsql=\"select * from mtcars order by mpg\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n           newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1  Cadillac Fleetwood 10.4   8  472 205 2.93 5.250 17.98  0  0    3    4\n2 Lincoln Continental 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4\n3          Camaro Z28 13.3   8  350 245 3.73 3.840 15.41  0  0    3    4\n4          Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\n5   Chrysler Imperial 14.7   8  440 230 3.23 5.345 17.42  0  0    3    4\n6       Maserati Bora 15.0   8  301 335 3.54 3.570 14.60  0  1    5    8\n\n\n\n2.7.1 Sort in descending order\n\n\nCode\nsql=\"select * from mtcars order by mpg desc\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n      newColName  mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n1 Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n2       Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n3    Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n4   Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n5      Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n6  Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n\n\n\n\n2.7.2 Arrange by multiple variables\n\n\nCode\nsql=\"select * from mtcars order by mpg ,cyl\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n           newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1  Cadillac Fleetwood 10.4   8  472 205 2.93 5.250 17.98  0  0    3    4\n2 Lincoln Continental 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4\n3          Camaro Z28 13.3   8  350 245 3.73 3.840 15.41  0  0    3    4\n4          Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\n5   Chrysler Imperial 14.7   8  440 230 3.23 5.345 17.42  0  0    3    4\n6       Maserati Bora 15.0   8  301 335 3.54 3.570 14.60  0  1    5    8",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#join",
    "href": "data manipulation/5 SQL database.html#join",
    "title": "SQL database with R",
    "section": "2.8 join",
    "text": "2.8 join\n\n2.8.1 inner_join\n\n\nCode\nsql=\"select a.newColName,a.mpg,b.mpg as new_mpg from mtcars a left join mtcars b on a.newColName=b.newColName\"\n\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg new_mpg\n1         Mazda RX4 21.0    21.0\n2     Mazda RX4 Wag 21.0    21.0\n3        Datsun 710 22.8    22.8\n4    Hornet 4 Drive 21.4    21.4\n5 Hornet Sportabout 18.7    18.7\n6           Valiant 18.1    18.1\n\n\n\n\n2.8.2 full join\n\n\n2.8.3 left join\n\n\n2.8.4 anti join",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#reshape-tables",
    "href": "data manipulation/5 SQL database.html#reshape-tables",
    "title": "SQL database with R",
    "section": "2.9 Reshape tables",
    "text": "2.9 Reshape tables\n\n2.9.1 Gather data long(wide to long)\n\n\n2.9.2 Spread data wide (long to wide)",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#string",
    "href": "data manipulation/5 SQL database.html#string",
    "title": "SQL database with R",
    "section": "2.10 string",
    "text": "2.10 string\n\n2.10.1 upper case\n\n\n2.10.2 lower case\n\n\n2.10.3 match\n\n\n2.10.4 concatenation\n\n\n2.10.5 replace\n\n\n2.10.6 extract",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#date",
    "href": "data manipulation/5 SQL database.html#date",
    "title": "SQL database with R",
    "section": "2.11 date",
    "text": "2.11 date",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#create-table-into-database",
    "href": "data manipulation/5 SQL database.html#create-table-into-database",
    "title": "SQL database with R",
    "section": "2.12 create table into database",
    "text": "2.12 create table into database\n\n\nCode\nsql=\"create table if not exists new_mtcars as select * from mtcars order by mpg ,cyl\"\ndbSendQuery(con,sql)\n\n\n&lt;SQLiteResult&gt;\n  SQL  create table if not exists new_mtcars as select * from mtcars order by mpg ,cyl\n  ROWS Fetched: 0 [complete]\n       Changed: 0\n\n\nCode\ndbListTables(con)\n\n\n[1] \"iris\"       \"mtcars\"     \"new_mtcars\"",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#delete-table-in-database",
    "href": "data manipulation/5 SQL database.html#delete-table-in-database",
    "title": "SQL database with R",
    "section": "2.13 delete table in database",
    "text": "2.13 delete table in database\n\n\nCode\nsql=\"drop table if  exists  new_mtcars\"\ndbSendQuery(con,sql)\n\n\n&lt;SQLiteResult&gt;\n  SQL  drop table if  exists  new_mtcars\n  ROWS Fetched: 0 [complete]\n       Changed: 0\n\n\nCode\ndbListTables(con)\n\n\n[1] \"iris\"   \"mtcars\"",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#edit-table-in-database",
    "href": "data manipulation/5 SQL database.html#edit-table-in-database",
    "title": "SQL database with R",
    "section": "2.14 edit table in database",
    "text": "2.14 edit table in database",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-current-loaded-package",
    "href": "intro/1 basic R.html#check-current-loaded-package",
    "title": "Basic R",
    "section": "6.6 check current loaded package",
    "text": "6.6 check current loaded package\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     R6_2.5.1          fastmap_1.1.1     xfun_0.43        \n [5] knitr_1.45        htmltools_0.5.8.1 rmarkdown_2.26    ps_1.7.6         \n [9] cli_3.6.2         processx_3.8.4    callr_3.7.6       pak_0.7.2        \n[13] compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1       evaluate_0.23    \n[17] yaml_2.3.8        rlang_1.1.3       jsonlite_1.8.8    htmlwidgets_1.6.4",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#get-current-directory",
    "href": "Plot/1 basic R.html#get-current-directory",
    "title": "Basic R",
    "section": "1.1 get current directory",
    "text": "1.1 get current directory\n\n\nCode\ngetwd()",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#get-all-file-name-under-current-directory",
    "href": "Plot/1 basic R.html#get-all-file-name-under-current-directory",
    "title": "Basic R",
    "section": "1.2 get all file name under current directory",
    "text": "1.2 get all file name under current directory\n\n\nCode\nlist.files()\n\n\n[1] \"1 basic R.qmd\"       \"1 basic R.rmarkdown\" \"1-basic-R.rmarkdown\"",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#get-file-info",
    "href": "Plot/1 basic R.html#get-file-info",
    "title": "Basic R",
    "section": "1.3 get file info",
    "text": "1.3 get file info\n\n\nCode\nfile.info(\"1 about.qmd\" )\n\n\n            size isdir mode mtime ctime atime uid gid uname grname\n1 about.qmd   NA    NA &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  NA  NA  &lt;NA&gt;   &lt;NA&gt;",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#create-folder",
    "href": "Plot/1 basic R.html#create-folder",
    "title": "Basic R",
    "section": "1.4 create folder",
    "text": "1.4 create folder\n\n\nCode\ndir.create('testing_folder')",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#delete-folderfile",
    "href": "Plot/1 basic R.html#delete-folderfile",
    "title": "Basic R",
    "section": "1.5 delete folder/file",
    "text": "1.5 delete folder/file\n\n\nCode\nfile.remove('testing_folder')",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#copy-file",
    "href": "Plot/1 basic R.html#copy-file",
    "title": "Basic R",
    "section": "1.6 copy file",
    "text": "1.6 copy file\n\n\nCode\nlibrary(fs)\nfile_copy('test.csv', 'test2.csv')",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#download-file-from-internet",
    "href": "Plot/1 basic R.html#download-file-from-internet",
    "title": "Basic R",
    "section": "1.7 download file from internet",
    "text": "1.7 download file from internet\n\n\nCode\nurl=\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n\ndownload.file(url = url, destfile = \"hotels.csv\")",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#for-loop",
    "href": "Plot/1 basic R.html#for-loop",
    "title": "Basic R",
    "section": "3.1 for Loop",
    "text": "3.1 for Loop\n\n\nCode\nfor (x in 1:4) {\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#while-loop",
    "href": "Plot/1 basic R.html#while-loop",
    "title": "Basic R",
    "section": "3.2 while Loop",
    "text": "3.2 while Loop\n\n\nCode\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nwith break statement\n\n\nCode\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n  if (i == 4) {break}\n}\n\n\n[1] 1\n[1] 2\n[1] 3",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#without-arguments",
    "href": "Plot/1 basic R.html#without-arguments",
    "title": "Basic R",
    "section": "4.1 without Arguments",
    "text": "4.1 without Arguments\n\n\nCode\nmy_function &lt;- function() { \n  print(\"Hello World!\")\n}\n\nmy_function()\n\n\n[1] \"Hello World!\"",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#return-result",
    "href": "Plot/1 basic R.html#return-result",
    "title": "Basic R",
    "section": "4.2 return result",
    "text": "4.2 return result\n\n\nCode\nadding_ten &lt;- function(x) { \n  a=x+10\n  return(a)\n}\n\nadding_ten(5)\n\n\n[1] 15",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#check-r-version",
    "href": "Plot/1 basic R.html#check-r-version",
    "title": "Basic R",
    "section": "5.1 check R version",
    "text": "5.1 check R version\n\n\nCode\nversion\n\n\n               _                           \nplatform       aarch64-apple-darwin20      \narch           aarch64                     \nos             darwin20                    \nsystem         aarch64, darwin20           \nstatus                                     \nmajor          4                           \nminor          3.1                         \nyear           2023                        \nmonth          06                          \nday            16                          \nsvn rev        84548                       \nlanguage       R                           \nversion.string R version 4.3.1 (2023-06-16)\nnickname       Beagle Scouts",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#install-r-package",
    "href": "Plot/1 basic R.html#install-r-package",
    "title": "Basic R",
    "section": "5.2 install R package",
    "text": "5.2 install R package\nfrom The Comprehensive R Archive Network(cran).https://cran.r-project.org/\n\n\n\nCode\ninstall.packages('tidyverse')",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#check-one-package-version",
    "href": "Plot/1 basic R.html#check-one-package-version",
    "title": "Basic R",
    "section": "5.3 check one package version",
    "text": "5.3 check one package version\n\n\nCode\npackageVersion(\"tidyverse\")\n\n\n[1] '2.0.0'",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#check-current-loaded-package",
    "href": "Plot/1 basic R.html#check-current-loaded-package",
    "title": "Basic R",
    "section": "5.4 check current loaded package",
    "text": "5.4 check current loaded package\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.7   rstudioapi_0.15.0 yaml_2.3.8       \n [9] rmarkdown_2.25    knitr_1.45        jsonlite_1.8.8    xfun_0.42        \n[13] digest_0.6.35     rlang_1.1.3       evaluate_0.23",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#check-all-package-version",
    "href": "Plot/1 basic R.html#check-all-package-version",
    "title": "Basic R",
    "section": "5.5 check all package version",
    "text": "5.5 check all package version\n\n\nCode\nip = as.data.frame(installed.packages()[,c(1,3:4)])\nip = ip[is.na(ip$Priority),1:2,drop=FALSE]\nhead(ip)\n\n\n              Package Version\nabind           abind   1.4-5\nanytime       anytime   0.3.9\narchive       archive   1.1.7\narrow           arrow  15.0.1\naskpass       askpass   1.2.0\nassertthat assertthat   0.2.1",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 basic R.html#check-package-install-loaciton",
    "href": "Plot/1 basic R.html#check-package-install-loaciton",
    "title": "Basic R",
    "section": "5.6 check package install loaciton",
    "text": "5.6 check package install loaciton\n\n\nCode\n.libPaths()\n\n\n[1] \"/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\"",
    "crumbs": [
      "Plot",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html",
    "href": "Plot/1 ggplot.html",
    "title": "GGplot in R",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\npackageVersion(\"ggplot2\")\n\n\n[1] '3.5.0'",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#color-by-group",
    "href": "Plot/1 ggplot.html#color-by-group",
    "title": "GGplot in R",
    "section": "1.1 color by group",
    "text": "1.1 color by group",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#size-by-group",
    "href": "Plot/1 ggplot.html#size-by-group",
    "title": "GGplot in R",
    "section": "1.2 size by group",
    "text": "1.2 size by group",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#line-plot",
    "href": "Plot/1 ggplot.html#line-plot",
    "title": "GGplot in R",
    "section": "1.3 line Plot",
    "text": "1.3 line Plot",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#color-by-group-1",
    "href": "Plot/1 ggplot.html#color-by-group-1",
    "title": "GGplot in R",
    "section": "1.4 color by group",
    "text": "1.4 color by group",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#color-by-group-2",
    "href": "Plot/1 ggplot.html#color-by-group-2",
    "title": "GGplot in R",
    "section": "2.1 color by group",
    "text": "2.1 color by group",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#color-by-group-3",
    "href": "Plot/1 ggplot.html#color-by-group-3",
    "title": "GGplot in R",
    "section": "4.1 color by group",
    "text": "4.1 color by group",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#color-by-group-4",
    "href": "Plot/1 ggplot.html#color-by-group-4",
    "title": "GGplot in R",
    "section": "5.1 color by group",
    "text": "5.1 color by group",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#add-title",
    "href": "Plot/1 ggplot.html#add-title",
    "title": "GGplot in R",
    "section": "7.1 add title",
    "text": "7.1 add title",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#adjust-size",
    "href": "Plot/1 ggplot.html#adjust-size",
    "title": "GGplot in R",
    "section": "7.2 adjust size",
    "text": "7.2 adjust size",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot.html#change-x-y-name",
    "href": "Plot/1 ggplot.html#change-x-y-name",
    "title": "GGplot in R",
    "section": "7.3 change x y name",
    "text": "7.3 change x y name",
    "crumbs": [
      "Plot",
      "GGplot in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html",
    "href": "Plot/2 plotly.html",
    "title": "Plotly in R",
    "section": "",
    "text": "Code\nlibrary(gapminder)\nlibrary(plotly)\npackageVersion(\"plotly\")\n\n\n[1] '4.10.4'",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group",
    "href": "Plot/2 plotly.html#color-by-group",
    "title": "Plotly in R",
    "section": "1.1 color by group",
    "text": "1.1 color by group\n\n\nCode\nfig &lt;- plot_ly(data = tips, x = ~total_bill, y = ~tip,color=~sex)\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#size-by-group",
    "href": "Plot/2 plotly.html#size-by-group",
    "title": "Plotly in R",
    "section": "1.2 size by group",
    "text": "1.2 size by group\n\n\nCode\nfig &lt;- plot_ly(data = tips, x = ~total_bill, y = ~tip,color=~sex,size=~size)\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#line-plot",
    "href": "Plot/2 plotly.html#line-plot",
    "title": "Plotly in R",
    "section": "1.3 line Plot",
    "text": "1.3 line Plot\n\n\nCode\ndata001=gapminder\ndata002= data001 %&gt;% group_by(continent,year) %&gt;% summarise(pop=sum(pop))\n\n\n\n\nCode\nfig &lt;- plot_ly(data = data002 %&gt;%filter(continent=='Asia'), x = ~year, y = ~pop,mode = 'lines')\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-1",
    "href": "Plot/2 plotly.html#color-by-group-1",
    "title": "Plotly in R",
    "section": "1.4 color by group",
    "text": "1.4 color by group\n\n\nCode\nfig &lt;- plot_ly(data = data002, x = ~year, y = ~pop,color = ~continent,mode = 'lines')\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-2",
    "href": "Plot/2 plotly.html#color-by-group-2",
    "title": "Plotly in R",
    "section": "2.2 color by group",
    "text": "2.2 color by group\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\")\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-3",
    "href": "Plot/2 plotly.html#color-by-group-3",
    "title": "Plotly in R",
    "section": "4.1 color by group",
    "text": "4.1 color by group\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~sex,y=~total_bill,color=~sex, type = \"box\")\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-4",
    "href": "Plot/2 plotly.html#color-by-group-4",
    "title": "Plotly in R",
    "section": "5.1 color by group",
    "text": "5.1 color by group\n\n\nCode\np=ggplot(tips, aes(day,tip,color=sex)) + geom_jitter(position=position_jitterdodge())\nggplotly(p)",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#add-title",
    "href": "Plot/2 plotly.html#add-title",
    "title": "Plotly in R",
    "section": "7.1 add title",
    "text": "7.1 add title\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\") %&gt;% layout(title = 'new title')\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#adjust-size",
    "href": "Plot/2 plotly.html#adjust-size",
    "title": "Plotly in R",
    "section": "7.2 adjust size",
    "text": "7.2 adjust size\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\"\n               ,width = 500, height = 200)\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#change-x-y-name",
    "href": "Plot/2 plotly.html#change-x-y-name",
    "title": "Plotly in R",
    "section": "7.3 change x y name",
    "text": "7.3 change x y name\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\") %&gt;% layout(title = 'new title'\n                                                                                   ,xaxis = list(title = 'new x')\n                                                                                  ,yaxis = list(title = 'new y') \n                                                                                    )\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html",
    "href": "Plot/1 ggplot2.html",
    "title": "ggplot2 in R",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(ggpubr)\nlibrary(ggthemr)\n\nlibrary(ggplot2)\nlibrary(plotly)\npackageVersion(\"ggplot2\")\n\n\n[1] '3.5.1'\nCode\nlibrary(reshape2)\ntips=tips\nhead(tips)\n\n\n  total_bill  tip    sex smoker day   time size\n1      16.99 1.01 Female     No Sun Dinner    2\n2      10.34 1.66   Male     No Sun Dinner    3\n3      21.01 3.50   Male     No Sun Dinner    3\n4      23.68 3.31   Male     No Sun Dinner    2\n5      24.59 3.61 Female     No Sun Dinner    4\n6      25.29 4.71   Male     No Sun Dinner    4\nCode\ndata001=gapminder\nhead(data001)\n\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group",
    "href": "Plot/1 ggplot2.html#color-by-group",
    "title": "ggplot2 in R",
    "section": "1.1 color by group",
    "text": "1.1 color by group\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#size-by-group",
    "href": "Plot/1 ggplot2.html#size-by-group",
    "title": "ggplot2 in R",
    "section": "1.2 size by group",
    "text": "1.2 size by group\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,colour = sex,size=size)) + geom_point()\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#line-plot",
    "href": "Plot/1 ggplot2.html#line-plot",
    "title": "ggplot2 in R",
    "section": "1.3 line Plot",
    "text": "1.3 line Plot\n\n\nCode\ndata002= data001 %&gt;% group_by(continent,year) %&gt;% summarise(pop=sum(pop))\n\n\n\n\nCode\np=ggplot(data002 %&gt;%filter(continent=='Asia'), aes(year, pop)) + geom_line()\np\n\n\n\n\n\n\n\n\n\n\n1.3.1 change line size\n\n\nCode\np=ggplot(data002 %&gt;%filter(continent=='Asia'), aes(year, pop)) + geom_line(size=5)\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-1",
    "href": "Plot/1 ggplot2.html#color-by-group-1",
    "title": "ggplot2 in R",
    "section": "1.4 color by group",
    "text": "1.4 color by group\n\n\nCode\np=ggplot(data002, aes(year, pop,colour = continent)) + geom_line()\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-2",
    "href": "Plot/1 ggplot2.html#color-by-group-2",
    "title": "ggplot2 in R",
    "section": "2.1 color by group",
    "text": "2.1 color by group\n\n\nCode\nggplot(data002, aes(gdpPercap,,fill = continent)) +geom_histogram(position = 'dodge')",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-3",
    "href": "Plot/1 ggplot2.html#color-by-group-3",
    "title": "ggplot2 in R",
    "section": "3.8 color by group",
    "text": "3.8 color by group",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-4",
    "href": "Plot/1 ggplot2.html#color-by-group-4",
    "title": "ggplot2 in R",
    "section": "5.1 color by group",
    "text": "5.1 color by group\n\n\nCode\np=ggplot(tips, aes(day,tip,color=sex)) + geom_jitter(position=position_jitterdodge())\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-title",
    "href": "Plot/1 ggplot2.html#add-title",
    "title": "ggplot2 in R",
    "section": "7.1 add title",
    "text": "7.1 add title\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#adjust-size",
    "href": "Plot/1 ggplot2.html#adjust-size",
    "title": "ggplot2 in R",
    "section": "7.3 adjust size",
    "text": "7.3 adjust size\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+theme(\n  plot.margin = margin(2, 2, 5, 5, \"cm\"))\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#change-x-y-name",
    "href": "Plot/1 ggplot2.html#change-x-y-name",
    "title": "ggplot2 in R",
    "section": "7.6 change x y name",
    "text": "7.6 change x y name\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+xlab(\"new x name\") + ylab(\"new y name\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#theme_bw",
    "href": "Plot/1 ggplot2.html#theme_bw",
    "title": "ggplot2 in R",
    "section": "8.1 theme_bw()",
    "text": "8.1 theme_bw()\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\np+ theme_bw()",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#theme_light",
    "href": "Plot/1 ggplot2.html#theme_light",
    "title": "ggplot2 in R",
    "section": "8.2 theme_light()",
    "text": "8.2 theme_light()\n\n\nCode\np+ theme_light()",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#theme_economist",
    "href": "Plot/1 ggplot2.html#theme_economist",
    "title": "ggplot2 in R",
    "section": "8.3 theme_economist()",
    "text": "8.3 theme_economist()\n\n\nCode\nlibrary(\"ggthemes\")\np+ theme_economist()",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#set-bin-number",
    "href": "Plot/2 plotly.html#set-bin-number",
    "title": "Plotly in R",
    "section": "2.1 set bin number",
    "text": "2.1 set bin number\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill, type = \"histogram\",nbinsx = 5 )\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/3 shiny.html",
    "href": "Plot/3 shiny.html",
    "title": "Shiny in R",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/weightshiny/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#legend",
    "href": "Plot/2 plotly.html#legend",
    "title": "Plotly in R",
    "section": "7.5 legend",
    "text": "7.5 legend\n\n7.5.1 hide legend\n\n\nCode\nfig &lt;- plot_ly(data = data002, x = ~year, y = ~pop,color = ~continent,mode = 'lines') %&gt;% layout(showlegend = FALSE)\nfig\n\n\n\n\n\n\n\n\n7.5.2 show legend and change legend name\n\n\nCode\nfig &lt;- plot_ly(data = data002 %&gt;% filter(continent=='Asia'), x = ~year, y = ~pop,color = ~continent,mode = 'lines',name='Asia pop') %&gt;% layout(showlegend = TRUE)\nfig\n\n\n\n\n\n\n\n\n7.5.3 change legend and change legend Position\n\n\nCode\nfig &lt;- plot_ly(data = data002, x = ~year, y = ~pop,color = ~continent,mode = 'lines') %&gt;% layout(legend = list(orientation = 'h'))\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html",
    "href": "clustering/4 Principal component analysis .html",
    "title": "Principal component analysis",
    "section": "",
    "text": "Principal component analysis (PCA) is a method of reducing the dimensionality of data and is used to improve data visualization and speed up machine learning model training.",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#download-data",
    "href": "clustering/4 Principal component analysis .html#download-data",
    "title": "Principal component analysis",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/datasets/shwetabh123/mall-customer",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#input-data",
    "href": "clustering/4 Principal component analysis .html#input-data",
    "title": "Principal component analysis",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# load dataset into Pandas DataFrame\ndf = read_csv(url,col_names = c('sepal_length','sepal_width','petal_length','petal_width','target'))\n\n# Showing overview of the train dataset\nhead(df)\n\n\n# A tibble: 6 × 5\n  sepal_length sepal_width petal_length petal_width target     \n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;      \n1          5.1         3.5          1.4         0.2 Iris-setosa\n2          4.9         3            1.4         0.2 Iris-setosa\n3          4.7         3.2          1.3         0.2 Iris-setosa\n4          4.6         3.1          1.5         0.2 Iris-setosa\n5          5           3.6          1.4         0.2 Iris-setosa\n6          5.4         3.9          1.7         0.4 Iris-setosa",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#standardize-the-data",
    "href": "clustering/4 Principal component analysis .html#standardize-the-data",
    "title": "Principal component analysis",
    "section": "2.3 STANDARDIZE THE DATA",
    "text": "2.3 STANDARDIZE THE DATA\nPCA is affected by scale, so you need to scale the features in your data before applying PCA. Use StandardScaler to help you standardize the data set’s features onto unit scale (mean = 0 and variance = 1), which is a requirement for the optimal performance of many machine learning algorithms. If you don’t scale your data, it can have a negative effect on your algorithm.\n\n\nCode\nnumerical_data=data.matrix(df[c('sepal_length','sepal_width','petal_length','petal_width')])\n\n\n\n\nCode\ndata_normalized &lt;- scale(numerical_data)\nhead(data_normalized)\n\n\n     sepal_length sepal_width petal_length petal_width\n[1,]   -0.8976739   1.0286113    -1.336794   -1.308593\n[2,]   -1.1392005  -0.1245404    -1.336794   -1.308593\n[3,]   -1.3807271   0.3367203    -1.393470   -1.308593\n[4,]   -1.5014904   0.1060900    -1.280118   -1.308593\n[5,]   -1.0184372   1.2592416    -1.336794   -1.308593\n[6,]   -0.5353840   1.9511326    -1.166767   -1.046525",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#before-standardize",
    "href": "clustering/4 Principal component analysis .html#before-standardize",
    "title": "Principal component analysis",
    "section": "2.4 Before STANDARDIZE",
    "text": "2.4 Before STANDARDIZE",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#after-standardize",
    "href": "clustering/4 Principal component analysis .html#after-standardize",
    "title": "Principal component analysis",
    "section": "2.5 After STANDARDIZE",
    "text": "2.5 After STANDARDIZE",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#inverse-standardize.for-testing-purpose-only-have-no-impact-on-pca.",
    "href": "clustering/4 Principal component analysis .html#inverse-standardize.for-testing-purpose-only-have-no-impact-on-pca.",
    "title": "Principal component analysis",
    "section": "2.6 inverse STANDARDIZE.for testing purpose only, have no impact on PCA.",
    "text": "2.6 inverse STANDARDIZE.for testing purpose only, have no impact on PCA.\nfor testing purpose only.",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/3 k mode Clustering.html",
    "href": "clustering/3 k mode Clustering.html",
    "title": "k mode Clustering",
    "section": "",
    "text": "Coming soon\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Clustering",
      "k mode Clustering"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#download-data",
    "href": "clustering/0 Mall Customers.html#download-data",
    "title": "Mall Customers Dataset",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/datasets/shwetabh123/mall-customer",
    "crumbs": [
      "Clustering",
      "Mall Customers Dataset"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#input-data",
    "href": "clustering/0 Mall Customers.html#input-data",
    "title": "Mall Customers Dataset",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\ndf_train=read.csv('./data/Mall_Customers.csv')\n\n\n\n\nCode\nhead(df_train)\n\n\n  CustomerID  Genre Age Annual.Income..k.. Spending.Score..1.100.\n1          1   Male  19                 15                     39\n2          2   Male  21                 15                     81\n3          3 Female  20                 16                      6\n4          4 Female  23                 16                     77\n5          5 Female  31                 17                     40\n6          6 Female  22                 17                     76",
    "crumbs": [
      "Clustering",
      "Mall Customers Dataset"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#data-eda",
    "href": "clustering/0 Mall Customers.html#data-eda",
    "title": "Mall Customers Dataset",
    "section": "2.3 data EDA",
    "text": "2.3 data EDA\n\n\nCode\nglimpse(df_train)\n\n\nRows: 200\nColumns: 5\n$ CustomerID             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ Genre                  &lt;chr&gt; \"Male\", \"Male\", \"Female\", \"Female\", \"Female\", \"…\n$ Age                    &lt;int&gt; 19, 21, 20, 23, 31, 22, 35, 23, 64, 30, 67, 35,…\n$ Annual.Income..k..     &lt;int&gt; 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 19,…\n$ Spending.Score..1.100. &lt;int&gt; 39, 81, 6, 77, 40, 76, 6, 94, 3, 72, 14, 99, 15…\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(df_train)\n\n\n\nData summary\n\n\nName\ndf_train\n\n\nNumber of rows\n200\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGenre\n0\n1\n4\n6\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCustomerID\n0\n1\n100.50\n57.88\n1\n50.75\n100.5\n150.25\n200\n▇▇▇▇▇\n\n\nAge\n0\n1\n38.85\n13.97\n18\n28.75\n36.0\n49.00\n70\n▆▇▅▃▂\n\n\nAnnual.Income..k..\n0\n1\n60.56\n26.26\n15\n41.50\n61.5\n78.00\n137\n▆▇▇▂▁\n\n\nSpending.Score..1.100.\n0\n1\n50.20\n25.82\n1\n34.75\n50.0\n73.00\n99\n▃▃▇▃▃",
    "crumbs": [
      "Clustering",
      "Mall Customers Dataset"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#feature",
    "href": "clustering/0 Mall Customers.html#feature",
    "title": "Mall Customers Dataset",
    "section": "2.4 feature",
    "text": "2.4 feature"
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#download-data",
    "href": "clustering/1 k mean Clustering.html#download-data",
    "title": "K mean Clustering",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/datasets/shwetabh123/mall-customer",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#input-data",
    "href": "clustering/1 k mean Clustering.html#input-data",
    "title": "K mean Clustering",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\ndf_train=read.csv('./data/Mall_Customers.csv')\n\n\n\n\nCode\nnames(df_train)\n\n\n[1] \"CustomerID\"             \"Genre\"                  \"Age\"                   \n[4] \"Annual.Income..k..\"     \"Spending.Score..1.100.\"\n\n\n\n\nCode\ndf_train=df_train %&gt;% clean_names()\n\n\n\n\nCode\nnames(df_train)\n\n\n[1] \"customer_id\"          \"genre\"                \"age\"                 \n[4] \"annual_income_k\"      \"spending_score_1_100\"",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#data-eda",
    "href": "clustering/1 k mean Clustering.html#data-eda",
    "title": "K mean Clustering",
    "section": "2.3 data EDA",
    "text": "2.3 data EDA",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#annual-income-k",
    "href": "clustering/1 k mean Clustering.html#annual-income-k",
    "title": "K mean Clustering",
    "section": "5.1 ‘Annual Income (k$)’",
    "text": "5.1 ‘Annual Income (k$)’\n\n\nCode\nfrom plotnine import *\n\np=(\n)\n\np\n\n\n()"
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#spending-score-1-100",
    "href": "clustering/1 k mean Clustering.html#spending-score-1-100",
    "title": "K mean Clustering",
    "section": "5.2 ‘Spending Score (1-100)’",
    "text": "5.2 ‘Spending Score (1-100)’"
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#age",
    "href": "clustering/1 k mean Clustering.html#age",
    "title": "K mean Clustering",
    "section": "6.3 Age",
    "text": "6.3 Age",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/2 Hierarchical Clustering.html",
    "href": "clustering/2 Hierarchical Clustering.html",
    "title": "Hierarchical Clustering",
    "section": "",
    "text": "Coming soon\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Clustering",
      "Hierarchical Clustering"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html",
    "href": "clustering/1.2 k mean Clustering.html",
    "title": "K mean Clustering with image",
    "section": "",
    "text": "Using K mean Clustering to replace colow on below picture",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#input-data",
    "href": "clustering/1.2 k mean Clustering.html#input-data",
    "title": "K mean Clustering with image",
    "section": "2.1 input data",
    "text": "2.1 input data\nAlpha channel image\n\n\nCode\nlibrary(jpeg)\n\nimg &lt;- readJPEG('python logo.jpg')\n\n\n\n\nCode\ndim(img)\n\n\n[1] 235 214   3\n\n\n\n\nCode\n# Obtain the dimension\nimgDm &lt;- dim(img)\n\n# Assign RGB channels to data frame\nimgRGB &lt;- data.frame(\n  x = rep(1:imgDm[2], each = imgDm[1]),\n  y = rep(imgDm[1]:1, imgDm[2]),\n  R = as.vector(img[,,1]),\n  G = as.vector(img[,,2]),\n  B = as.vector(img[,,3])\n  )\n\n\n\n\nCode\nimgRGB2=imgRGB %&gt;% select(R,G,B)\n\n\n\n\nCode\n# Plot the image\nggplot(data = imgRGB, aes(x = x, y = y)) + \n  geom_point(colour = rgb(imgRGB[c(\"R\", \"G\", \"B\")])) +\n  labs(title = \"Original Image: Colorful Bird\") +\n  xlab(\"x\") +\n  ylab(\"y\")",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#load-package",
    "href": "data manipulation/3 data manipulation with tidyverse.html#load-package",
    "title": "Data manipulation with tidyverse",
    "section": "0.1 load package",
    "text": "0.1 load package\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\nCode\npackageVersion(\"dplyr\")\n\n\n[1] '1.1.4'\n\n\n\n\nCode\ndata(mtcars)\nsmall_mtcars = mtcars %&gt;% select(cyl, mpg,hp) %&gt;% head()",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.1 select column",
    "text": "2.1 select column",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#drop-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#drop-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.6 drop column",
    "text": "2.6 drop column\n\n\nCode\nsmall_mtcars %&gt;% select(-cyl)\n\n\n           car_name  mpg  hp\n1         Mazda RX4 21.0 110\n2     Mazda RX4 Wag 21.0 110\n3        Datsun 710 22.8  93\n4    Hornet 4 Drive 21.4 110\n5 Hornet Sportabout 18.7 175\n6           Valiant 18.1 105",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#renaming-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#renaming-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.7 Renaming column",
    "text": "2.7 Renaming column\n\n\nCode\nsmall_mtcars %&gt;%rename(new_cyl=cyl)\n\n\n           car_name new_cyl  mpg  hp\n1         Mazda RX4       6 21.0 110\n2     Mazda RX4 Wag       6 21.0 110\n3        Datsun 710       4 22.8  93\n4    Hornet 4 Drive       6 21.4 110\n5 Hornet Sportabout       8 18.7 175\n6           Valiant       6 18.1 105",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#create-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#create-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.8 Create column",
    "text": "2.8 Create column\n\n2.8.1 Mutate\n\n\nCode\nsmall_mtcars %&gt;%mutate(new_cyl=cyl+1)\n\n\n           car_name cyl  mpg  hp new_cyl\n1         Mazda RX4   6 21.0 110       7\n2     Mazda RX4 Wag   6 21.0 110       7\n3        Datsun 710   4 22.8  93       5\n4    Hornet 4 Drive   6 21.4 110       7\n5 Hornet Sportabout   8 18.7 175       9\n6           Valiant   6 18.1 105       7\n\n\n\n\n2.8.2 if else\n\n\nCode\nsmall_mtcars %&gt;%mutate(new_cly_group=if_else(cyl&gt;6,'big','small'))\n\n\n           car_name cyl  mpg  hp new_cly_group\n1         Mazda RX4   6 21.0 110         small\n2     Mazda RX4 Wag   6 21.0 110         small\n3        Datsun 710   4 22.8  93         small\n4    Hornet 4 Drive   6 21.4 110         small\n5 Hornet Sportabout   8 18.7 175           big\n6           Valiant   6 18.1 105         small\n\n\n\n\n2.8.3 case when\n\n\nCode\nsmall_mtcars %&gt;%mutate(cly_group=case_when(\n    cyl &gt; 6 ~ \"very big\",\n    cyl &gt; 4 ~ \"big\",\n    TRUE ~ \"other\",\n  ))\n\n\n           car_name cyl  mpg  hp cly_group\n1         Mazda RX4   6 21.0 110       big\n2     Mazda RX4 Wag   6 21.0 110       big\n3        Datsun 710   4 22.8  93     other\n4    Hornet 4 Drive   6 21.4 110       big\n5 Hornet Sportabout   8 18.7 175  very big\n6           Valiant   6 18.1 105       big\n\n\n\n\n2.8.4 Transmute,create column and only keep this column\n\n\nCode\nsmall_mtcars %&gt;%transmute(new_cyl=cyl+1)\n\n\n  new_cyl\n1       7\n2       7\n3       5\n4       7\n5       9\n6       7",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#filter-rows",
    "href": "data manipulation/3 data manipulation with tidyverse.html#filter-rows",
    "title": "Data manipulation with tidyverse",
    "section": "2.9 Filter rows",
    "text": "2.9 Filter rows\n\n\nCode\nsmall_mtcars %&gt;%filter(cyl&gt;5)\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3    Hornet 4 Drive   6 21.4 110\n4 Hornet Sportabout   8 18.7 175\n5           Valiant   6 18.1 105\n\n\n\n2.9.1 Filters with AND conditions\n\n\nCode\nsmall_mtcars %&gt;%filter(cyl&gt;5,mpg&gt;20)\n\n\n        car_name cyl  mpg  hp\n1      Mazda RX4   6 21.0 110\n2  Mazda RX4 Wag   6 21.0 110\n3 Hornet 4 Drive   6 21.4 110\n\n\n\n\n2.9.2 Filters with OR conditions\n\n\nCode\nsmall_mtcars %&gt;%filter(cyl&gt;5|mpg&gt;20)\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175\n6           Valiant   6 18.1 105\n\n\n\n\n2.9.3 filter row with index\n\n2.9.3.1 5th rows\n\n\nCode\nsmall_mtcars %&gt;% slice(5)\n\n\n           car_name cyl  mpg  hp\n1 Hornet Sportabout   8 18.7 175\n\n\n\n\n2.9.3.2 1 and 5h rows\n\n\nCode\nsmall_mtcars %&gt;% slice(1:5)\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175\n\n\n\n\n2.9.3.3 get ramdon 5 rows\n\n\nCode\nsmall_mtcars %&gt;% sample_n(5)\n\n\n           car_name cyl  mpg  hp\n1 Hornet Sportabout   8 18.7 175\n2     Mazda RX4 Wag   6 21.0 110\n3         Mazda RX4   6 21.0 110\n4        Datsun 710   4 22.8  93\n5           Valiant   6 18.1 105",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#append",
    "href": "data manipulation/3 data manipulation with tidyverse.html#append",
    "title": "Data manipulation with tidyverse",
    "section": "2.10 Append",
    "text": "2.10 Append\n\n2.10.1 append by row\n\n\nCode\nsmall_mtcars %&gt;% rbind(small_mtcars)\n\n\n            car_name cyl  mpg  hp\n1          Mazda RX4   6 21.0 110\n2      Mazda RX4 Wag   6 21.0 110\n3         Datsun 710   4 22.8  93\n4     Hornet 4 Drive   6 21.4 110\n5  Hornet Sportabout   8 18.7 175\n6            Valiant   6 18.1 105\n7          Mazda RX4   6 21.0 110\n8      Mazda RX4 Wag   6 21.0 110\n9         Datsun 710   4 22.8  93\n10    Hornet 4 Drive   6 21.4 110\n11 Hornet Sportabout   8 18.7 175\n12           Valiant   6 18.1 105\n\n\n\n\n2.10.2 append by column\n\n\nCode\nsmall_mtcars %&gt;% cbind(small_mtcars)\n\n\n           car_name cyl  mpg  hp          car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175 Hornet Sportabout   8 18.7 175\n6           Valiant   6 18.1 105           Valiant   6 18.1 105\n\n\n\n\n2.10.3 Sepcial vales\n\n2.10.3.1 NAN\n\n\n2.10.3.2 NA\n\n\n2.10.3.3 NULL",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#group-by",
    "href": "data manipulation/3 data manipulation with tidyverse.html#group-by",
    "title": "Data manipulation with tidyverse",
    "section": "2.11 group by",
    "text": "2.11 group by\n\n2.11.1 average,min,max,sum\n\n\nCode\nsmall_mtcars %&gt;%group_by(cyl) %&gt;% summarise(avg_mpg=mean(mpg)\n                                            ,min_mpg=min(mpg)\n                                            ,max_mpg=max(mpg)\n                                            ,sum_mpg=sum(mpg))\n\n\n# A tibble: 3 × 5\n    cyl avg_mpg min_mpg max_mpg sum_mpg\n  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     4    22.8    22.8    22.8    22.8\n2     6    20.4    18.1    21.4    81.5\n3     8    18.7    18.7    18.7    18.7\n\n\n\n\n2.11.2 count record and count distinct record\n\n\nCode\nsmall_mtcars %&gt;%group_by(cyl) %&gt;% summarise(n_mpg=n()\n                                            ,distinct_n_mpg=n_distinct(mpg)\n                                            \n                                            )\n\n\n# A tibble: 3 × 3\n    cyl n_mpg distinct_n_mpg\n  &lt;dbl&gt; &lt;int&gt;          &lt;int&gt;\n1     4     1              1\n2     6     4              3\n3     8     1              1",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#order-rows",
    "href": "data manipulation/3 data manipulation with tidyverse.html#order-rows",
    "title": "Data manipulation with tidyverse",
    "section": "2.12 order rows",
    "text": "2.12 order rows\n\n\nCode\nsmall_mtcars %&gt;%arrange(cyl) \n\n\n           car_name cyl  mpg  hp\n1        Datsun 710   4 22.8  93\n2         Mazda RX4   6 21.0 110\n3     Mazda RX4 Wag   6 21.0 110\n4    Hornet 4 Drive   6 21.4 110\n5           Valiant   6 18.1 105\n6 Hornet Sportabout   8 18.7 175\n\n\n\n2.12.1 Sort in descending order\n\n\nCode\nsmall_mtcars %&gt;%arrange(desc(cyl) )\n\n\n           car_name cyl  mpg  hp\n1 Hornet Sportabout   8 18.7 175\n2         Mazda RX4   6 21.0 110\n3     Mazda RX4 Wag   6 21.0 110\n4    Hornet 4 Drive   6 21.4 110\n5           Valiant   6 18.1 105\n6        Datsun 710   4 22.8  93\n\n\n\n\n2.12.2 Arrange by multiple variables\n\n\nCode\nsmall_mtcars %&gt;%arrange(cyl,mpg)\n\n\n           car_name cyl  mpg  hp\n1        Datsun 710   4 22.8  93\n2           Valiant   6 18.1 105\n3         Mazda RX4   6 21.0 110\n4     Mazda RX4 Wag   6 21.0 110\n5    Hornet 4 Drive   6 21.4 110\n6 Hornet Sportabout   8 18.7 175",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#join",
    "href": "data manipulation/3 data manipulation with tidyverse.html#join",
    "title": "Data manipulation with tidyverse",
    "section": "2.13 join",
    "text": "2.13 join\n\n\nCode\nleft_data=small_mtcars %&gt;% slice(1:2)\nright_data=small_mtcars %&gt;% slice(2:4)\n\n\n\n\nCode\nleft_data\n\n\n       car_name cyl mpg  hp\n1     Mazda RX4   6  21 110\n2 Mazda RX4 Wag   6  21 110\n\n\n\n\nCode\nright_data\n\n\n        car_name cyl  mpg  hp\n1  Mazda RX4 Wag   6 21.0 110\n2     Datsun 710   4 22.8  93\n3 Hornet 4 Drive   6 21.4 110\n\n\n\n2.13.1 inner_join\n\n\nCode\ndata=left_data %&gt;% inner_join(right_data,join_by(car_name== car_name), suffix = c(\"_l\", \"._r\"))\ndata\n\n\n       car_name cyl_l mpg_l hp_l cyl._r mpg._r hp._r\n1 Mazda RX4 Wag     6    21  110      6     21   110\n\n\n\n\n2.13.2 left join\n\n\nCode\ndata=left_data %&gt;% left_join(right_data,join_by(car_name== car_name), suffix = c(\"_l\", \"._r\"))\ndata\n\n\n       car_name cyl_l mpg_l hp_l cyl._r mpg._r hp._r\n1     Mazda RX4     6    21  110     NA     NA    NA\n2 Mazda RX4 Wag     6    21  110      6     21   110\n\n\n\n\n2.13.3 full join\n\n\nCode\ndata=left_data %&gt;% full_join(right_data,join_by(car_name== car_name), suffix = c(\"_l\", \"._r\"))\ndata\n\n\n        car_name cyl_l mpg_l hp_l cyl._r mpg._r hp._r\n1      Mazda RX4     6    21  110     NA     NA    NA\n2  Mazda RX4 Wag     6    21  110      6   21.0   110\n3     Datsun 710    NA    NA   NA      4   22.8    93\n4 Hornet 4 Drive    NA    NA   NA      6   21.4   110\n\n\n\n\n2.13.4 anti join\nanti_join() return all rows from x without a match in y\n\n\nCode\ndata=left_data %&gt;% anti_join(right_data,join_by(car_name== car_name))\ndata\n\n\n   car_name cyl mpg  hp\n1 Mazda RX4   6  21 110",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#reshape-tables",
    "href": "data manipulation/3 data manipulation with tidyverse.html#reshape-tables",
    "title": "Data manipulation with tidyverse",
    "section": "2.14 Reshape tables",
    "text": "2.14 Reshape tables\n\n\nCode\nolddata_wide &lt;- read.table(header=TRUE, text='\n subject sex control cond1 cond2\n       1   M     7.9  12.3  10.7\n       2   F     6.3  10.6  11.1\n       3   F     9.5  13.1  13.8\n       4   M    11.5  13.4  12.9\n')\n\n\n\n\nCode\nolddata_wide\n\n\n  subject sex control cond1 cond2\n1       1   M     7.9  12.3  10.7\n2       2   F     6.3  10.6  11.1\n3       3   F     9.5  13.1  13.8\n4       4   M    11.5  13.4  12.9\n\n\n\n2.14.1 Gather data long(wide to long)\n\n\nCode\ndata_long=olddata_wide %&gt;%\n  pivot_longer(!c(subject,sex), names_to = 'income', values_to = 'DATA')\n\ndata_long\n\n\n# A tibble: 12 × 4\n   subject sex   income   DATA\n     &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1       1 M     control   7.9\n 2       1 M     cond1    12.3\n 3       1 M     cond2    10.7\n 4       2 F     control   6.3\n 5       2 F     cond1    10.6\n 6       2 F     cond2    11.1\n 7       3 F     control   9.5\n 8       3 F     cond1    13.1\n 9       3 F     cond2    13.8\n10       4 M     control  11.5\n11       4 M     cond1    13.4\n12       4 M     cond2    12.9\n\n\n\n\n2.14.2 Spread data wide (long to wide)\n\n\nCode\ndata_wide=data_long %&gt;%\n  pivot_wider(names_from = income, values_from = DATA)\n\ndata_wide\n\n\n# A tibble: 4 × 5\n  subject sex   control cond1 cond2\n    &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       1 M         7.9  12.3  10.7\n2       2 F         6.3  10.6  11.1\n3       3 F         9.5  13.1  13.8\n4       4 M        11.5  13.4  12.9",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#string",
    "href": "data manipulation/3 data manipulation with tidyverse.html#string",
    "title": "Data manipulation with tidyverse",
    "section": "0.13 string",
    "text": "0.13 string\nstringr is built on top of stringi, which uses the ICU C library to provide fast, correct implementations of common string manipulations.\n\n\n0.13.1 length\n\n\nCode\nx &lt;- \"I like horses.\"\nstr_length(x)\n\n\n[1] 14\n\n\n\n\n0.13.2 upper case\n\n\nCode\nx &lt;- \"I like horses.\"\n\nstr_to_upper(x)\n\n\n[1] \"I LIKE HORSES.\"\n\n\n\n\n0.13.3 lower case\n\n\nCode\nx &lt;- \"I like horses.\"\n\nstr_to_lower(x)\n\n\n[1] \"i like horses.\"\n\n\n\n\n0.13.4 match\n\n\n0.13.5 concatenation\n\n\nCode\na='aaaa'\nb='bbbb'\n\n\n\n\nCode\npaste(a,b)\n\n\n[1] \"aaaa bbbb\"\n\n\n\n\nCode\npaste0(a,b)\n\n\n[1] \"aaaabbbb\"\n\n\n\n\n0.13.6 replace\nstr_replace()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace('b','1')\n\n\n[1] \"a1cb\"\n\n\nstr_replace_all()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace_all('b','1')\n\n\n[1] \"a1c1\"\n\n\n\n\n0.13.7 extract\n\n\nCode\ndata001=mtcars\ndata001 &lt;- cbind(names = rownames(data001), data001)\n\n\n\n0.13.7.1 subset string by postion\nextract 2 to 4\n\n\nCode\ndata001$new_names=data001$names %&gt;% str_sub(2,4)\nhead(data001 %&gt;% select(new_names,names))\n\n\n                  new_names             names\nMazda RX4               azd         Mazda RX4\nMazda RX4 Wag           azd     Mazda RX4 Wag\nDatsun 710              ats        Datsun 710\nHornet 4 Drive          orn    Hornet 4 Drive\nHornet Sportabout       orn Hornet Sportabout\nValiant                 ali           Valiant\n\n\n\n\n0.13.7.2 extracting number from a string\n\n\nCode\nlibrary(stringr)\n\ntrx='abc1993 ccc'\n\nnum=str_extract(trx, \"(\\\\d)+\")\n\nnum\n\n\n[1] \"1993\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#date",
    "href": "data manipulation/3 data manipulation with tidyverse.html#date",
    "title": "Data manipulation with tidyverse",
    "section": "3.8 date",
    "text": "3.8 date\nusing lubridate package to handle date and time in R\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(nycflights13)\n\n\n\n3.8.1 date format\ninput as character\n\n\nCode\ndate1='2023-01-01'\nclass(date1)\n\n\n[1] \"character\"\n\n\n\n\nCode\ndate1\n\n\n[1] \"2023-01-01\"\n\n\nconvert into date type with as.Date()\n\n\nCode\ndate2=as.Date('2023-01-01')\nclass(date2)\n\n\n[1] \"Date\"\n\n\n\n\nCode\ndate2\n\n\n[1] \"2023-01-01\"\n\n\nconvert into date type with ymd()\n\n\nCode\ndate3=ymd('2023-01-01')\nclass(date3)\n\n\n[1] \"Date\"\n\n\n\n\nCode\ndate3\n\n\n[1] \"2023-01-01\"\n\n\nget today with today()\n\n\nCode\ntoday()\n\n\n[1] \"2024-04-12\"\n\n\nget local timezone\n\n\nCode\nSys.timezone()\n\n\n[1] \"Asia/Shanghai\"\n\n\n\n\n3.8.2 change date format\nmake multiple column character to date with make_date()\n\n\nCode\nflights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_date(year, month, day))\n\n\n# A tibble: 336,776 × 6\n    year month   day  hour minute departure \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;date&gt;    \n 1  2013     1     1     5     15 2013-01-01\n 2  2013     1     1     5     29 2013-01-01\n 3  2013     1     1     5     40 2013-01-01\n 4  2013     1     1     5     45 2013-01-01\n 5  2013     1     1     6      0 2013-01-01\n 6  2013     1     1     5     58 2013-01-01\n 7  2013     1     1     6      0 2013-01-01\n 8  2013     1     1     6      0 2013-01-01\n 9  2013     1     1     6      0 2013-01-01\n10  2013     1     1     6      0 2013-01-01\n# ℹ 336,766 more rows\n\n\n\n\nCode\nflights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n\n\n# A tibble: 336,776 × 6\n    year month   day  hour minute departure          \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n 1  2013     1     1     5     15 2013-01-01 05:15:00\n 2  2013     1     1     5     29 2013-01-01 05:29:00\n 3  2013     1     1     5     40 2013-01-01 05:40:00\n 4  2013     1     1     5     45 2013-01-01 05:45:00\n 5  2013     1     1     6      0 2013-01-01 06:00:00\n 6  2013     1     1     5     58 2013-01-01 05:58:00\n 7  2013     1     1     6      0 2013-01-01 06:00:00\n 8  2013     1     1     6      0 2013-01-01 06:00:00\n 9  2013     1     1     6      0 2013-01-01 06:00:00\n10  2013     1     1     6      0 2013-01-01 06:00:00\n# ℹ 336,766 more rows\n\n\n\n\n3.8.3 day differnce between two dates\n\n\nCode\nday1=ymd('2022-01-01')\nday2=ymd('2023-02-03')\n\ndiff=day2-day1\n\n\n\n\nCode\ndiff\n\n\nTime difference of 398 days\n\n\nusing interval() find two dates gap\n\n\nCode\ninterval(day1,day2) %&gt;% as.period()\n\n\n[1] \"1y 1m 2d 0H 0M 0S\"\n\n\nfind day gap\n\n\nCode\ninterval(day1,day2)%/% days(1)\n\n\n[1] 398\n\n\nfind month gap\n\n\nCode\ninterval(day1,day2)%/% months(1)\n\n\n[1] 13\n\n\nfind year gap\n\n\nCode\ninterval(day1,day2)%/% years(1)\n\n\n[1] 1\n\n\n\n\n3.8.4 day and time\n\n\nCode\nnow_time=now()\nnow_time\n\n\n[1] \"2024-04-12 15:53:44 CST\"\n\n\n\n3.8.4.1 get year\n\n\nCode\nyear(now_time)\n\n\n[1] 2024\n\n\n\n\n3.8.4.2 get month\n\n\nCode\nmonth(now_time)\n\n\n[1] 4\n\n\n\n\n3.8.4.3 get date of the month\n\n\nCode\nmday(now_time)\n\n\n[1] 12\n\n\n\n\n3.8.4.4 get date of the year\n\n\nCode\nyday(now_time)\n\n\n[1] 103\n\n\n\n\n3.8.4.5 get date of the week\n\n\nCode\nwday(now_time)\n\n\n[1] 6\n\n\n\n\n3.8.4.6 get hour\n\n\nCode\nhour(now_time)\n\n\n[1] 15\n\n\n\n\n3.8.4.7 get minute\n\n\nCode\nminute(now_time)\n\n\n[1] 53\n\n\n\n\n3.8.4.8 get second\n\n\nCode\nsecond(now_time)\n\n\n[1] 44.6701",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#dataframe-to-numpy-array",
    "href": "data manipulation/3 data manipulation with tidyverse.html#dataframe-to-numpy-array",
    "title": "Data manipulation with tidyverse",
    "section": "0.15 dataframe to numpy array",
    "text": "0.15 dataframe to numpy array",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-vector",
    "href": "data manipulation/2 data structure in R.html#create-vector",
    "title": "Data structure in R",
    "section": "1.1 create vector",
    "text": "1.1 create vector\n\n\nCode\nseq(from = 2, to = 14, by = 2) \n\n\n[1]  2  4  6  8 10 12 14\n\n\nother way:\n\n\nCode\nrep(x = 1.5, times = 4)  \n\n\n[1] 1.5 1.5 1.5 1.5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#append-vector",
    "href": "data manipulation/2 data structure in R.html#append-vector",
    "title": "Data structure in R",
    "section": "1.5 append vector",
    "text": "1.5 append vector\n\n\nCode\nx=c(1,2,3)\ny=c(4,5,6)\nz=c(x,y)\nz\n\n\n[1] 1 2 3 4 5 6",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#calculate-vector",
    "href": "data manipulation/2 data structure in R.html#calculate-vector",
    "title": "Data structure in R",
    "section": "1.9 calculate vector",
    "text": "1.9 calculate vector\n\n\nCode\nx=c(1,2,3,4,5)\n\nsum(x)\n\n\n[1] 15",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#select-vector-element",
    "href": "data manipulation/2 data structure in R.html#select-vector-element",
    "title": "Data structure in R",
    "section": "1.10 select vector element",
    "text": "1.10 select vector element\n\n\nCode\nx=c(1,2,3,6,9,10)\n\n\n\n1.10.1 select first\n\n\nCode\nx[1]\n\n\n[1] 1\n\n\n\n\n1.10.2 select last\n\n\n1.10.3 select first to 3th\n\n\nCode\nx[1:3]\n\n\n[1] 1 2 3",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#annual_income_k",
    "href": "clustering/1 k mean Clustering.html#annual_income_k",
    "title": "K mean Clustering",
    "section": "6.1 ‘annual_income_k’",
    "text": "6.1 ‘annual_income_k’\n\n\nCode\np=ggplot(df_train3, aes(cluster,annual_income_k,fill=cluster)) + geom_boxplot()\np",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#spending_score_1_100",
    "href": "clustering/1 k mean Clustering.html#spending_score_1_100",
    "title": "K mean Clustering",
    "section": "6.2 ‘spending_score_1_100’",
    "text": "6.2 ‘spending_score_1_100’\n\n\nCode\np=ggplot(df_train3, aes(cluster,spending_score_1_100,fill=cluster)) + geom_boxplot()\np",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "model type/2 random forest.html",
    "href": "model type/2 random forest.html",
    "title": "Random forest",
    "section": "",
    "text": "1 Pros\n\nEasier to interpret than Neural Network\nFast training and making inference\n\n\n\n2 Cons\n\nThe size & inference speed of the random forest can sometimes be an issue\nRandom forests cannot learn and reuse internal representations\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=w5gB8zyLx-8\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "model type",
      "Random forest"
    ]
  },
  {
    "objectID": "model type/3 gradient boosted trees.html",
    "href": "model type/3 gradient boosted trees.html",
    "title": "Gradient boosted trees",
    "section": "",
    "text": "1 Pros\n\nNative support for numerical and categorical features, and no necessary need for feature pre-processing.\nGBT are fast and light-weight and with great performance.\n\n\n\n2 Cons\n\nGBT can overfit.\nDecision tree trained sequentially -&gt; slower training.\nGBT cannot learn & reuse internal representations.Poor performance on image and long text.\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=w5gB8zyLx-8\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "model type",
      "Gradient boosted trees"
    ]
  },
  {
    "objectID": "model type/1 decision tree.html",
    "href": "model type/1 decision tree.html",
    "title": "Decision tree",
    "section": "",
    "text": "1 Pros\n\nEasier to interpret than Neural Network\nFast training and making inference\n\n\n\n2 Cons\n\nProne to overfitting\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=6DlWndLbk90\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "model type",
      "Decision tree"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#input-image",
    "href": "clustering/1.2 k mean Clustering.html#input-image",
    "title": "K mean Clustering with image",
    "section": "2.1 input image",
    "text": "2.1 input image\n\n\nCode\nimage &lt;- image_read('images/python logo.jpg')",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix",
    "href": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix",
    "title": "K mean Clustering with image",
    "section": "2.2 convert png to matrix",
    "text": "2.2 convert png to matrix\n\n\nCode\nimage_tiff &lt;- image_convert(image, \"tiff\")\nimage_array &lt;- as.integer(image_tiff[[1]])                \n\n\n\n\nCode\nmagick::image_read(image_array/ 255)\n\n\n\n\n\n\n\n\n\n235 * 214 pixcel and 3 channels\n\n\nCode\ndim(image_array)\n\n\n[1] 235 214   3\n\n\n\n\nCode\nclass(image_array)\n\n\n[1] \"array\"\n\n\nData Normalization\nSince the dataset contains a range of values from 0 to 255, the dataset has to be normalized. Data Normalization is an important preprocessing step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This fastens the process of covergence while training the model. Also Normalization makes sure no one particular parameter influences the output significantly.\n\n\nCode\nimage_array=image_array/255\n\n\n\n\nCode\nimage_array_old=image_array",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d",
    "href": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d",
    "title": "K mean Clustering with image",
    "section": "2.3 reshape from 3 D to 2 D",
    "text": "2.3 reshape from 3 D to 2 D\n\n\nCode\ndim(image_array) &lt;- c(dim(image_array)[1]*dim(image_array)[2],3)\n\n\n\n\nCode\ndim(image_array)\n\n\n[1] 50290     3",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters",
    "href": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters",
    "title": "K mean Clustering with image",
    "section": "2.4 Optimal number of k-clusters",
    "text": "2.4 Optimal number of k-clusters\n\n\nCode\nkclusts &lt;- \n  tibble(k = 1:9) %&gt;%\n  mutate(\n    kclust = map(k, ~kmeans(image_array, .x)),\n    tidied = map(kclust, tidy),\n    glanced = map(kclust, glance),\n    augmented = map(kclust, augment, image_array)\n  )\n\nkclusts\n\n\n# A tibble: 9 × 5\n      k kclust   tidied           glanced          augmented            \n  &lt;int&gt; &lt;list&gt;   &lt;list&gt;           &lt;list&gt;           &lt;list&gt;               \n1     1 &lt;kmeans&gt; &lt;tibble [1 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n2     2 &lt;kmeans&gt; &lt;tibble [2 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n3     3 &lt;kmeans&gt; &lt;tibble [3 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n4     4 &lt;kmeans&gt; &lt;tibble [4 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n5     5 &lt;kmeans&gt; &lt;tibble [5 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n6     6 &lt;kmeans&gt; &lt;tibble [6 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n7     7 &lt;kmeans&gt; &lt;tibble [7 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n8     8 &lt;kmeans&gt; &lt;tibble [8 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n9     9 &lt;kmeans&gt; &lt;tibble [9 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n\n\n\n\nCode\nclusters &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(tidied))\n\nassignments &lt;- \n  kclusts %&gt;% \n  unnest(cols = c(augmented))\n\nclusterings &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(glanced))\n\n\n\n\nCode\nlibrary(scales)\nggplot(clusterings, aes(k, tot.withinss)) +\n  geom_line() +\n  geom_point()+scale_x_continuous(breaks= pretty_breaks())+scale_y_continuous(labels = scales::comma)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#group-to-3",
    "href": "clustering/1.2 k mean Clustering.html#group-to-3",
    "title": "K mean Clustering with image",
    "section": "2.5 group to 3",
    "text": "2.5 group to 3\n\n\nCode\nkclust &lt;- kmeans(image_array, centers = 3)\n\n\n\n\nCode\nresult=augment(kclust, image_array) %&gt;% clean_names()\n\n\n\n\nCode\nresult %&gt;% count(cluster)\n\n\n# A tibble: 3 × 2\n  cluster     n\n  &lt;fct&gt;   &lt;int&gt;\n1 1       13560\n2 2       13631\n3 3       23099",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#change-2-color",
    "href": "clustering/1.2 k mean Clustering.html#change-2-color",
    "title": "K mean Clustering with image",
    "section": "2.6 change 2 color",
    "text": "2.6 change 2 color\n\n\nCode\n# black RGB code 0 0 0\n# red RGB code 255 0 0\n\nresult2=result %&gt;%mutate(x1=if_else(cluster==3,0,x1) \n                          ,x2=if_else(cluster==3,0,x2) \n                          ,x3=if_else(cluster==3,0,x3) \n                          )%&gt;%mutate(x1=if_else(cluster==1,255,x1) \n                          ,x2=if_else(cluster==1,0,x2) \n                          ,x3=if_else(cluster==1,0,x3)) %&gt;% select(-cluster)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-3-d",
    "href": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-3-d",
    "title": "K mean Clustering with image",
    "section": "2.7 convert 2 D back to 3 D",
    "text": "2.7 convert 2 D back to 3 D\n\n\nCode\nresult2arrary=array(unlist(result2),c(dim(image_array_old)[1],dim(image_array_old)[2],3))\n\n\n\n\nCode\ndim(result2arrary)\n\n\n[1] 235 214   3\n\n\nconvert from 0-1 back to 0-255\n\n\nCode\nresult2arrary=result2arrary*255\n\n\n\n\nCode\nmagick::image_read(result2arrary/ 255)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#input-image-1",
    "href": "clustering/1.2 k mean Clustering.html#input-image-1",
    "title": "K mean Clustering with image",
    "section": "3.1 input image",
    "text": "3.1 input image\n\n\nCode\nimage &lt;- image_read('images/R_logo.png')",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix-1",
    "href": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix-1",
    "title": "K mean Clustering with image",
    "section": "3.2 convert png to matrix",
    "text": "3.2 convert png to matrix\n\n\nCode\nimage_tiff &lt;- image_convert(image, \"tiff\")\nimage_array &lt;- as.integer(image_tiff[[1]])                \n\n\n\n\nCode\nmagick::image_read(image_array/ 255)\n\n\n\n\n\n\n\n\n\n561 * 724 pixcel and 4 channels\n\n\nCode\ndim(image_array)\n\n\n[1] 561 724   4\n\n\n\n\nCode\nclass(image_array)\n\n\n[1] \"array\"\n\n\n\n\nCode\nimage_array_old=image_array",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d-1",
    "href": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d-1",
    "title": "K mean Clustering with image",
    "section": "3.3 reshape from 3 D to 2 D",
    "text": "3.3 reshape from 3 D to 2 D\n\n\nCode\ndim(image_array) &lt;- c(dim(image_array)[1]*dim(image_array)[2],4)\n\n\n\n\nCode\ndim(image_array)\n\n\n[1] 406164      4\n\n\nData Normalization\nSince the dataset contains a range of values from 0 to 255, the dataset has to be normalized. Data Normalization is an important preprocessing step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This fastens the process of covergence while training the model. Also Normalization makes sure no one particular parameter influences the output significantly.\n\n\nCode\nimage_array=image_array/255",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters-1",
    "href": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters-1",
    "title": "K mean Clustering with image",
    "section": "3.4 Optimal number of k-clusters",
    "text": "3.4 Optimal number of k-clusters\n\n\nCode\nkclusts &lt;- \n  tibble(k = 1:9) %&gt;%\n  mutate(\n    kclust = map(k, ~kmeans(image_array, .x)),\n    tidied = map(kclust, tidy),\n    glanced = map(kclust, glance),\n    augmented = map(kclust, augment, image_array)\n  )\n\nkclusts\n\n\n# A tibble: 9 × 5\n      k kclust   tidied           glanced          augmented             \n  &lt;int&gt; &lt;list&gt;   &lt;list&gt;           &lt;list&gt;           &lt;list&gt;                \n1     1 &lt;kmeans&gt; &lt;tibble [1 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n2     2 &lt;kmeans&gt; &lt;tibble [2 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n3     3 &lt;kmeans&gt; &lt;tibble [3 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n4     4 &lt;kmeans&gt; &lt;tibble [4 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n5     5 &lt;kmeans&gt; &lt;tibble [5 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n6     6 &lt;kmeans&gt; &lt;tibble [6 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n7     7 &lt;kmeans&gt; &lt;tibble [7 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n8     8 &lt;kmeans&gt; &lt;tibble [8 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n9     9 &lt;kmeans&gt; &lt;tibble [9 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n\n\n\n\nCode\nclusters &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(tidied))\n\nassignments &lt;- \n  kclusts %&gt;% \n  unnest(cols = c(augmented))\n\nclusterings &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(glanced))\n\n\n\n\nCode\nlibrary(scales)\nggplot(clusterings, aes(k, tot.withinss)) +\n  geom_line() +\n  geom_point()+scale_x_continuous(breaks= pretty_breaks())+scale_y_continuous(labels = scales::comma)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#group-to-3-1",
    "href": "clustering/1.2 k mean Clustering.html#group-to-3-1",
    "title": "K mean Clustering with image",
    "section": "3.5 group to 3",
    "text": "3.5 group to 3\n\n\nCode\nkclust &lt;- kmeans(image_array, centers = 3)\n\n\n\n\nCode\nresult=augment(kclust, image_array) %&gt;% clean_names()\n\n\n\n\nCode\nresult %&gt;% count(cluster)\n\n\n# A tibble: 3 × 2\n  cluster      n\n  &lt;fct&gt;    &lt;int&gt;\n1 1       120865\n2 2       169342\n3 3       115957",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#change-2-color-1",
    "href": "clustering/1.2 k mean Clustering.html#change-2-color-1",
    "title": "K mean Clustering with image",
    "section": "3.6 change 2 color",
    "text": "3.6 change 2 color\n\n\nCode\n# black RGB code 0 0 0\n# red RGB code 255 0 0\n\nresult2=result %&gt;%mutate(x1=if_else(cluster==3,0,x1) \n                          ,x2=if_else(cluster==3,0,x2) \n                          ,x3=if_else(cluster==3,0,x3) \n                          )%&gt;%mutate(x1=if_else(cluster==1,255,x1) \n                          ,x2=if_else(cluster==1,0,x2) \n                          ,x3=if_else(cluster==1,0,x3)) %&gt;% select(-cluster)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-4-d",
    "href": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-4-d",
    "title": "K mean Clustering with image",
    "section": "3.7 convert 2 D back to 4 D",
    "text": "3.7 convert 2 D back to 4 D\n\n\nCode\nresult2arrary=array(unlist(result2),c(dim(image_array_old)[1],dim(image_array_old)[2],4))\n\n\n\n\nCode\ndim(result2arrary)\n\n\n[1] 561 724   4\n\n\nconvert from 0-1 back to 0-255\n\n\nCode\nresult2arrary=result2arrary*255\n\n\n\n\nCode\nmagick::image_read(result2arrary/ 255)\n\n\n\n\n\n\n\n\n\n\n\nCode\nimg &lt;- magick::image_read(result2arrary / 255)\n\nimage_write(img, path = \"final.png\", format = \"png\")",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#x-y-break-and-scales",
    "href": "Plot/1 ggplot2.html#x-y-break-and-scales",
    "title": "ggplot2 in R",
    "section": "7.4 x y break and scales",
    "text": "7.4 x y break and scales",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#make-rowname-into-one-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#make-rowname-into-one-column",
    "title": "Data manipulation with tidyverse",
    "section": "0.2 make rowname into one column",
    "text": "0.2 make rowname into one column\n\n\nCode\nlibrary(tibble)\nsmall_mtcars=rownames_to_column(small_mtcars, var=\"car_name\")\n\nsmall_mtcars %&gt;% head\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175\n6           Valiant   6 18.1 105",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#vector-to-other-data-format",
    "href": "data manipulation/2 data structure in R.html#vector-to-other-data-format",
    "title": "Data structure in R",
    "section": "1.12 vector to other data format",
    "text": "1.12 vector to other data format\n\n1.12.1 vector to dataframe\n\n\nCode\nName &lt;- c(\"Jhon\", \"Lee\", \"Suzan\", \"Abhinav\", \n          \"Brain\", \"Emma\", \"David\", \"Alice\") \n\n   \nMarks &lt;- c(56, 76, 86, 96, 73, 87, 47, 98) \n    \n\ndata&lt;- data.frame(Name,Marks) \ndata\n\n\n     Name Marks\n1    Jhon    56\n2     Lee    76\n3   Suzan    86\n4 Abhinav    96\n5   Brain    73\n6    Emma    87\n7   David    47\n8   Alice    98\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"data.frame\"\n\n\n\n\n1.12.2 verctor to matrix\n\n\nCode\nv1 &lt;- c(56, 76, 86, 96, 73, 87, 47, 98) \n\n\n\n\nCode\ndata&lt;-matrix(v1,nrow=4)\ndata\n\n\n     [,1] [,2]\n[1,]   56   73\n[2,]   76   87\n[3,]   86   47\n[4,]   96   98\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"matrix\" \"array\" \n\n\nother way:\n\n\nCode\ndata&lt;-matrix(c(v1,v1),ncol = 2)\ndata\n\n\n     [,1] [,2]\n[1,]   56   56\n[2,]   76   76\n[3,]   86   86\n[4,]   96   96\n[5,]   73   73\n[6,]   87   87\n[7,]   47   47\n[8,]   98   98\n\n\n\n\n1.12.3 verctor to list\n\n\nCode\ndata=list(v1)\ndata\n\n\n[[1]]\n[1] 56 76 86 96 73 87 47 98\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"list\"\n\n\neach element in vetor as a element in list\n\n\nCode\ndata=as.list(v1)\ndata\n\n\n[[1]]\n[1] 56\n\n[[2]]\n[1] 76\n\n[[3]]\n[1] 86\n\n[[4]]\n[1] 96\n\n[[5]]\n[1] 73\n\n[[6]]\n[1] 87\n\n[[7]]\n[1] 47\n\n[[8]]\n[1] 98\n\n\n\n\n1.12.4 verctor to array\n3D array\n\n\nCode\nvec1=c(1:5) \n \nvec2=c(6:10) \n \narr=array(c(vec1,vec2),dim=c(2,5,3)) \n \n# printing the array\nclass(arr)\n\n\n[1] \"array\"\n\n\n\n\nCode\narr\n\n\n, , 1\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10\n\n, , 2\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10\n\n, , 3\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#dataframe-to-other-data-format",
    "href": "data manipulation/3 data manipulation with tidyverse.html#dataframe-to-other-data-format",
    "title": "Data manipulation with tidyverse",
    "section": "4.5 dataframe to other data format",
    "text": "4.5 dataframe to other data format\n\n4.5.1 dataframe to vector\n\n\nCode\ndata=small_mtcars$cyl\ndata\n\n\n[1] 6 6 4 6 8 6\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"numeric\"\n\n\n\n\n4.5.2 dataframe to matrix\n\n\nCode\ndata=data.matrix(small_mtcars)\ndata\n\n\n     car_name cyl  mpg  hp\n[1,]        4   6 21.0 110\n[2,]        5   6 21.0 110\n[3,]        1   4 22.8  93\n[4,]        2   6 21.4 110\n[5,]        3   8 18.7 175\n[6,]        6   6 18.1 105\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"matrix\" \"array\" \n\n\n\n\n4.5.3 dataframe to list\n\n\nCode\ndata=as.list(small_mtcars)\ndata\n\n\n$car_name\n[1] \"Mazda RX4\"         \"Mazda RX4 Wag\"     \"Datsun 710\"       \n[4] \"Hornet 4 Drive\"    \"Hornet Sportabout\" \"Valiant\"          \n\n$cyl\n[1] 6 6 4 6 8 6\n\n$mpg\n[1] 21.0 21.0 22.8 21.4 18.7 18.1\n\n$hp\n[1] 110 110  93 110 175 105\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"list\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-pacakge-relationship",
    "href": "intro/1 basic R.html#check-pacakge-relationship",
    "title": "Basic R",
    "section": "6.4 check pacakge relationship",
    "text": "6.4 check pacakge relationship\n\n\nCode\npak::pkg_deps_explain(\"tibble\", \"rlang\")\n\n\ntibble -&gt; lifecycle -&gt; rlang\ntibble -&gt; pillar -&gt; lifecycle -&gt; rlang\ntibble -&gt; pillar -&gt; rlang\ntibble -&gt; pillar -&gt; vctrs -&gt; lifecycle -&gt; rlang\ntibble -&gt; pillar -&gt; vctrs -&gt; rlang\ntibble -&gt; rlang\ntibble -&gt; vctrs -&gt; lifecycle -&gt; rlang\ntibble -&gt; vctrs -&gt; rlang",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-pacakge-dependencies",
    "href": "intro/1 basic R.html#check-pacakge-dependencies",
    "title": "Basic R",
    "section": "6.5 check pacakge dependencies",
    "text": "6.5 check pacakge dependencies\n\n\nCode\npak::pkg_deps_tree(\"tibble\")\n\n\ntibble 3.2.1 ✨ ⬇ (684.10 kB)\n├─fansi 1.0.6 ✨ ⬇ (381.01 kB)\n├─lifecycle 1.0.4 ✨ ⬇ (124.48 kB)\n│ ├─cli 3.6.2 ✨ ⬇ (1.39 MB)\n│ ├─glue 1.7.0 ✨ ⬇ (159.26 kB)\n│ └─rlang 1.1.3 ✨ ⬇ (1.89 MB)\n├─magrittr 2.0.3 ✨ ⬇ (232.43 kB)\n├─pillar 1.9.0 ✨ ⬇ (648.86 kB)\n│ ├─cli\n│ ├─fansi\n│ ├─glue\n│ ├─lifecycle\n│ ├─rlang\n│ ├─utf8 1.2.4 ✨ ⬇ (206.92 kB)\n│ └─vctrs 0.6.5 ✨ ⬇ (1.88 MB)\n│   ├─cli\n│   ├─glue\n│   ├─lifecycle\n│   └─rlang\n├─pkgconfig 2.0.3 ✨ ⬇ (18.21 kB)\n├─rlang\n└─vctrs\n\nKey:  ✨ new |  ⬇ download",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html",
    "href": "Multiclass classification/3 multclass classification.html",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "",
    "text": "classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#read-data",
    "href": "Multiclass classification/3 multclass classification.html#read-data",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\n\n\n\n\nCode\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\ndf_test=df_test_raw\n\n\n\n\nCode\nglimpse(df_train)\n\n\nRows: 8,068\nColumns: 11\n$ ID              &lt;dbl&gt; 462809, 462643, 466315, 461735, 462669, 461319, 460156…\n$ Gender          &lt;chr&gt; \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", …\n$ Ever_Married    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"…\n$ Age             &lt;dbl&gt; 22, 38, 67, 67, 40, 56, 32, 33, 61, 55, 26, 19, 19, 70…\n$ Graduated       &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", …\n$ Profession      &lt;chr&gt; \"Healthcare\", \"Engineer\", \"Engineer\", \"Lawyer\", \"Enter…\n$ Work_Experience &lt;dbl&gt; 1, NA, 1, 0, NA, 0, 1, 1, 0, 1, 1, 4, 0, NA, 0, 1, 9, …\n$ Spending_Score  &lt;chr&gt; \"Low\", \"Average\", \"Low\", \"High\", \"High\", \"Average\", \"L…\n$ Family_Size     &lt;dbl&gt; 4, 3, 1, 2, 6, 2, 3, 3, 3, 4, 3, 4, NA, 1, 1, 2, 5, 6,…\n$ Var_1           &lt;chr&gt; \"Cat_4\", \"Cat_4\", \"Cat_6\", \"Cat_6\", \"Cat_6\", \"Cat_6\", …\n$ target_variable &lt;fct&gt; D, A, B, B, A, C, C, D, D, C, A, D, D, A, B, C, D, B, …",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#data-split",
    "href": "Multiclass classification/3 multclass classification.html#data-split",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 5647   11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 807  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 1614   11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#recipe",
    "href": "Multiclass classification/3 multclass classification.html#recipe",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #update_role(ID, new_role = \"ID\") %&gt;% \n  step_rm(ID) %&gt;% \n  #step_downsample(target_variable) %&gt;%\n  \n  step_impute_median(all_numeric(), -all_outcomes())%&gt;% \n  step_impute_mode(all_nominal(), -all_outcomes())%&gt;% \n  \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())\n\ndata_rec",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#model",
    "href": "Multiclass classification/3 multclass classification.html#model",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\n\n\n3.2.2 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\n\n\n\n3.2.3 xgb tuning model\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          2   1.79e-10     0.00740       10       0.484     2\n2         15   2.53e- 3     0.0000313     14       0.365     7\n3          5   4.69e- 8     1.51          16       0.697     7\n4          2   3.65e- 6     0.0000550     34       0.834     8\n5         14   6.92e- 7    10.4           30       0.714     6\n6         11   1.47e- 2     0.00000199    36       0.398     8\n\n\nworkflow\n\n\nCode\nknn_wf &lt;- workflow() %&gt;%add_recipe(data_rec) %&gt;% add_model(knn_spec) \n\ntree_wf &lt;- workflow() %&gt;%add_recipe(data_rec)%&gt;% add_model(tree_spec)\n\nxgb_wf &lt;- workflow() %&gt;%add_recipe(data_rec)%&gt;% add_model(xgb_spec)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#training-and-tunning",
    "href": "Multiclass classification/3 multclass classification.html#training-and-tunning",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.3 training and tunning",
    "text": "3.3 training and tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#evaluate",
    "href": "Multiclass classification/3 multclass classification.html#evaluate",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#save-model",
    "href": "Multiclass classification/3 multclass classification.html#save-model",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "4.2 save model",
    "text": "4.2 save model",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#make-predication",
    "href": "Multiclass classification/3 multclass classification.html#make-predication",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html",
    "href": "Multiclass classification/1 multclass classification.html",
    "title": "Classification Model",
    "section": "",
    "text": "Level 1 classification Tidy Modeling with 2 model and no recipe:\n*using basic Tidymodel package.\nNo recipe\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#read-data",
    "href": "Multiclass classification/1 multclass classification.html#read-data",
    "title": "Classification Model",
    "section": "3.1 read data",
    "text": "3.1 read data\n\n\nCode\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\n\n\n\n\nCode\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\ndf_test=df_test_raw\n\n\n\n\nCode\nglimpse(df_train)\n\n\nRows: 8,068\nColumns: 11\n$ ID              &lt;dbl&gt; 462809, 462643, 466315, 461735, 462669, 461319, 460156…\n$ Gender          &lt;chr&gt; \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", …\n$ Ever_Married    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"…\n$ Age             &lt;dbl&gt; 22, 38, 67, 67, 40, 56, 32, 33, 61, 55, 26, 19, 19, 70…\n$ Graduated       &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", …\n$ Profession      &lt;chr&gt; \"Healthcare\", \"Engineer\", \"Engineer\", \"Lawyer\", \"Enter…\n$ Work_Experience &lt;dbl&gt; 1, NA, 1, 0, NA, 0, 1, 1, 0, 1, 1, 4, 0, NA, 0, 1, 9, …\n$ Spending_Score  &lt;chr&gt; \"Low\", \"Average\", \"Low\", \"High\", \"High\", \"Average\", \"L…\n$ Family_Size     &lt;dbl&gt; 4, 3, 1, 2, 6, 2, 3, 3, 3, 4, 3, 4, NA, 1, 1, 2, 5, 6,…\n$ Var_1           &lt;chr&gt; \"Cat_4\", \"Cat_4\", \"Cat_6\", \"Cat_6\", \"Cat_6\", \"Cat_6\", …\n$ target_variable &lt;fct&gt; D, A, B, B, A, C, C, D, D, C, A, D, D, A, B, C, D, B, …",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#data-split",
    "href": "Multiclass classification/1 multclass classification.html#data-split",
    "title": "Classification Model",
    "section": "3.2 data split",
    "text": "3.2 data split\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 5647   11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 807  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 1614   11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#recipe",
    "href": "Multiclass classification/1 multclass classification.html#recipe",
    "title": "Classification Model",
    "section": "4.1 recipe",
    "text": "4.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#model",
    "href": "Multiclass classification/1 multclass classification.html#model",
    "title": "Classification Model",
    "section": "4.2 model",
    "text": "4.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#trainning",
    "href": "Multiclass classification/1 multclass classification.html#trainning",
    "title": "Classification Model",
    "section": "4.3 trainning",
    "text": "4.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.5423292\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5647 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 5647 4065 D (0.24508589 0.23339826 0.24136710 0.28014875)  \n   2) Age&gt;=34 3810 2653 C (0.26771654 0.29790026 0.30367454 0.13070866)  \n     4) Spending_Score=Low 1773 1108 A (0.37507050 0.26452341 0.15454033 0.20586576)  \n       8) Profession=Artist,Doctor 878  559 B (0.33485194 0.36332574 0.22209567 0.07972665) *\n       9) Profession=Engineer,Entertainment,Executive,Healthcare,Homemaker,Lawyer,Marketing 895  524 A (0.41452514 0.16759777 0.08826816 0.32960894)  \n        18) Profession=Engineer,Entertainment 433  198 A (0.54272517 0.18937644 0.06004619 0.20785219) *\n        19) Profession=Executive,Healthcare,Homemaker,Lawyer,Marketing 462  257 D (0.29437229 0.14718615 0.11471861 0.44372294) *\n     5) Spending_Score=Average,High 2037 1154 C (0.17427590 0.32695140 0.43348061 0.06529210)  \n      10) Profession=Doctor,Engineer,Entertainment,Executive,Healthcare,Homemaker,Lawyer,Marketing 1196  749 B (0.23076923 0.37374582 0.29598662 0.09949833) *\n      11) Profession=Artist 841  312 C (0.09393579 0.26040428 0.62901308 0.01664685) *\n   3) Age&lt; 34 1837  753 D (0.19814916 0.09961894 0.11213936 0.59009254) *",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#evaluate",
    "href": "Multiclass classification/1 multclass classification.html#evaluate",
    "title": "Classification Model",
    "section": "5.1 Evaluate",
    "text": "5.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   A   B   C   D\n         A  36  13   1  15\n         B  72  97  86  17\n         C  10  31  86   1\n         D  78  37  34 193\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.511\n2 kap      multiclass     0.345\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.511\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    macro          0.500\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    macro          0.837\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.511\n2 sens     macro          0.500\n3 spec     macro          0.837\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             multiclass     0.511\n 2 kap                  multiclass     0.345\n 3 sens                 macro          0.500\n 4 spec                 macro          0.837\n 5 ppv                  macro          0.537\n 6 npv                  macro          0.846\n 7 mcc                  multiclass     0.362\n 8 j_index              macro          0.336\n 9 bal_accuracy         macro          0.668\n10 detection_prevalence macro          0.25 \n11 precision            macro          0.537\n12 recall               macro          0.500\n13 f_meas               macro          0.475\n\n\nROC:receiver operating characteristic curve\n\n\nCode\n#roc_auc(\n#    truth = target_variable,\n#    .pred_A,\n #   .pred_B,\n #   .pred_C,\n #   .pred_D,\n #   estimator = \"macro_weighted\"\n # )",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#save-model",
    "href": "Multiclass classification/1 multclass classification.html#save-model",
    "title": "Classification Model",
    "section": "5.2 save model",
    "text": "5.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n591 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 multclass classification tree hotel model.RDS')",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#make-predication",
    "href": "Multiclass classification/1 multclass classification.html#make-predication",
    "title": "Classification Model",
    "section": "5.3 make predication",
    "text": "5.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 multclass classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 B          \n2 C          \n3 D          \n4 D          \n5 D          \n6 C          \n\n\n\n\nCode\nfinal_prediction %&gt;% count(.pred_class)\n\n\n# A tibble: 4 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 A             119\n2 B             538\n3 C             253\n4 D             704\n\n\n\n\nCode\ndata_valid %&gt;% count(target_variable)\n\n\n# A tibble: 4 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 A                 392\n2 B                 362\n3 C                 400\n4 D                 460",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html",
    "href": "Multiclass classification/6 multclass classification.html",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:\nlogistic glm model\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\nKNN model with knn engine(knn_spec)\ntuning XG boost model (tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)\ntuning light gbm boost model(tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#read-data",
    "href": "Multiclass classification/6 multclass classification.html#read-data",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\n\n\n\n\nCode\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\n#%&gt;% filter(target_variable %in% c('A','B'))\ndf_test=df_test_raw\n\n\n\n\nCode\nglimpse(df_train)\n\n\nRows: 8,068\nColumns: 11\n$ ID              &lt;dbl&gt; 462809, 462643, 466315, 461735, 462669, 461319, 460156…\n$ Gender          &lt;chr&gt; \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", …\n$ Ever_Married    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"…\n$ Age             &lt;dbl&gt; 22, 38, 67, 67, 40, 56, 32, 33, 61, 55, 26, 19, 19, 70…\n$ Graduated       &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", …\n$ Profession      &lt;chr&gt; \"Healthcare\", \"Engineer\", \"Engineer\", \"Lawyer\", \"Enter…\n$ Work_Experience &lt;dbl&gt; 1, NA, 1, 0, NA, 0, 1, 1, 0, 1, 1, 4, 0, NA, 0, 1, 9, …\n$ Spending_Score  &lt;chr&gt; \"Low\", \"Average\", \"Low\", \"High\", \"High\", \"Average\", \"L…\n$ Family_Size     &lt;dbl&gt; 4, 3, 1, 2, 6, 2, 3, 3, 3, 4, 3, 4, NA, 1, 1, 2, 5, 6,…\n$ Var_1           &lt;chr&gt; \"Cat_4\", \"Cat_4\", \"Cat_6\", \"Cat_6\", \"Cat_6\", \"Cat_6\", …\n$ target_variable &lt;fct&gt; D, A, B, B, A, C, C, D, D, C, A, D, D, A, B, C, D, B, …",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#data-split",
    "href": "Multiclass classification/6 multclass classification.html#data-split",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 5647   11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 807  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 1614   11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#recipe",
    "href": "Multiclass classification/6 multclass classification.html#recipe",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(ID) %&gt;% \n  #step_downsample(target_variable) %&gt;%\n  step_impute_median(all_numeric(), -all_outcomes())%&gt;% \n  step_impute_mode(all_nominal(), -all_outcomes())%&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#model",
    "href": "Multiclass classification/6 multclass classification.html#model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\nusing multinom_reg() since its multiclass classification\n\n\nCode\nglm_spec &lt;-\n  multinom_reg() |&gt;\n  set_engine(\"nnet\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=10)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          1   2.47e- 6       4.50e- 4    20       0.398    11\n2         15   1.41e- 7       1.35e-10     5       0.219     9\n3          7   1.51e- 8       1.89e- 3    27       0.942     2\n4         13   1.59e- 4       2.10e- 8    36       0.319     4\n5          8   2.73e- 2       5.16e- 1    33       0.183     6\n6          9   1.93e-10       5.17e- 5    10       0.905     3\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=10)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth    learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         13 0.00297         0.0000286       32       0.737     6\n2         11 0.00000110      0.0119          24       0.982     9\n3          5 0.00000671      0.0000000109    11       0.709     2\n4          4 0.00000000266   0.00140         34       0.619     9\n5          5 0.0000000602   24.2              6       0.432     4\n6          7 0.000112        0.000470         3       0.257     6",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#workflow-set",
    "href": "Multiclass classification/6 multclass classification.html#workflow-set",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;%\n  #option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#training-and-tunning",
    "href": "Multiclass classification/6 multclass classification.html#training-and-tunning",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 10,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"accuracy\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_xgb\nPreprocessor1_Model06\naccuracy\n0.5082270\n8.273046e-03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model06\nbrier_class\n0.3732666\n3.222901e-05\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model06\nroc_auc\n0.7630375\n3.825994e-03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_tree\nPreprocessor1_Model02\naccuracy\n0.5080500\n6.889790e-03\n10\nrecipe\ndecision_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\nbrier_class\n0.3078043\n2.744968e-03\n10\nrecipe\ndecision_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\nroc_auc\n0.7479156\n5.425592e-03\n10\nrecipe\ndecision_tree\n2\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.5032753\n8.839371e-03\n10\nrecipe\nmultinom_reg\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\nbrier_class\n0.3048293\n2.551260e-03\n10\nrecipe\nmultinom_reg\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7542779\n5.770592e-03\n10\nrecipe\nmultinom_reg\n3\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\naccuracy\n0.4779517\n9.344905e-03\n10\nrecipe\nboost_tree\n4\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nbrier_class\n0.3417080\n1.534749e-03\n10\nrecipe\nboost_tree\n4\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nroc_auc\n0.7263411\n6.250417e-03\n10\nrecipe\nboost_tree\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.4521041\n5.486483e-03\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nbrier_class\n0.3802044\n2.918211e-03\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7039305\n3.245546e-03\n10\nrecipe\nnearest_neighbor\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#last-fit",
    "href": "Multiclass classification/6 multclass classification.html#last-fit",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#evaluate",
    "href": "Multiclass classification/6 multclass classification.html#evaluate",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 3 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    multiclass     0.550 Preprocessor1_Model1\n2 roc_auc     hand_till      0.787 Preprocessor1_Model1\n3 brier_class multiclass     0.373 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  multiclass     0.550\n2 recall    macro          0.536\n3 precision macro          0.533\n4 f_meas    macro          0.530\n5 kap       multiclass     0.396\n6 sens      macro          0.536\n7 spec      macro          0.850\n\n\n\n\nCode\n#final_fit %&gt;%\n#  collect_predictions() %&gt;% \n # roc_curve(target_variable, .pred_children) %&gt;% \n # autoplot()\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_rm()\n• step_impute_median()\n• step_impute_mode()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 187.5 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.00188744903053763, max_depth = 14L, \n    gamma = 1.47066004807873, colsample_bytree = 1, colsample_bynode = 0.545454545454545, \n    min_child_weight = 5L, subsample = 0.300618941169232), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"multi:softprob\", num_class = 4L)\nparams (as set within xgb.train):\n  eta = \"0.00188744903053763\", max_depth = \"14\", gamma = \"1.47066004807873\", colsample_bytree = \"1\", colsample_bynode = \"0.545454545454545\", min_child_weight = \"5\", subsample = \"0.300618941169232\", nthread = \"1\", objective = \"multi:softprob\", num_class = \"4\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 22 \nniter: 10\nnfeatures : 22 \nevaluation_log:\n     iter training_mlogloss\n    &lt;num&gt;             &lt;num&gt;\n        1          1.385471\n        2          1.384689\n---                        \n        9          1.379286\n       10          1.378525\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#save-model",
    "href": "Multiclass classification/6 multclass classification.html#save-model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.84 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 multclass classification model.RDS')",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#make-predication",
    "href": "Multiclass classification/6 multclass classification.html#make-predication",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 multclass classification model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 B          \n2 C          \n3 D          \n4 D          \n5 D          \n6 C          \n\n\n\n\nCode\nfinal_prediction %&gt;%group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 4 × 2\n# Groups:   .pred_class [4]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 A             448\n2 B             229\n3 C             399\n4 D             538\n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   A   B   C   D\n         A 185 100  58 105\n         B  54  91  60  24\n         C  57 115 217  10\n         D  96  56  65 321\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.504\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 4 × 2\n# Groups:   target_variable [4]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 A                 392\n2 B                 362\n3 C                 400\n4 D                 460\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 4 × 2\n# Groups:   .pred_class [4]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 A             448\n2 B             229\n3 C             399\n4 D             538\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   A   B   C   D\n         A 185 100  58 105\n         B  54  91  60  24\n         C  57 115 217  10\n         D  96  56  65 321",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/0 multclass classification.html#measurement",
    "href": "Multiclass classification/0 multclass classification.html#measurement",
    "title": "Customer Segmentation Dataset",
    "section": "2.1 Measurement:",
    "text": "2.1 Measurement:\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nSpecificity=TN/(TN+FP)\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)\n\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nF1 score=2/(1/Precision+1/Recall)",
    "crumbs": [
      "Multiclass classification",
      "Customer Segmentation Dataset"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#read-data-1",
    "href": "Multiclass classification/3 multclass classification.html#read-data-1",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "4.1 read data",
    "text": "4.1 read data\nquarto-executable-code-5450563D\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\nquarto-executable-code-5450563D\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\ndf_test=df_test_raw\nquarto-executable-code-5450563D\nglimpse(df_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#data-split-1",
    "href": "Multiclass classification/3 multclass classification.html#data-split-1",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "4.2 data split",
    "text": "4.2 data split\nquarto-executable-code-5450563D\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\nquarto-executable-code-5450563D\ndim(data_train)\nquarto-executable-code-5450563D\ndim(data_test)\nquarto-executable-code-5450563D\ndim(data_valid)\n10 fold for tunning quarto-executable-code-5450563D\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#recipe-1",
    "href": "Multiclass classification/3 multclass classification.html#recipe-1",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "5.1 recipe",
    "text": "5.1 recipe\nbecasue the target class is not balance so using downsample quarto-executable-code-5450563D\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #update_role(ID, new_role = \"ID\") %&gt;% \n  step_rm(ID) %&gt;% \n  #step_downsample(target_variable) %&gt;%\n  \n  step_impute_median(all_numeric(), -all_outcomes())%&gt;% \n  step_impute_mode(all_nominal(), -all_outcomes())%&gt;% \n  \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())\n\ndata_rec",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#model-1",
    "href": "Multiclass classification/3 multclass classification.html#model-1",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "5.2 model",
    "text": "5.2 model\n\n5.2.1 tree model\nquarto-executable-code-5450563D\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\n5.2.2 KNN model\nquarto-executable-code-5450563D\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\n\n5.2.3 xgb tuning model\nquarto-executable-code-5450563D\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\nxgb tunning grid\nquarto-executable-code-5450563D\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\nworkflow\nquarto-executable-code-5450563D\nknn_wf &lt;- workflow() %&gt;%add_recipe(data_rec) %&gt;% add_model(knn_spec) \n\ntree_wf &lt;- workflow() %&gt;%add_recipe(data_rec)%&gt;% add_model(tree_spec)\n\nxgb_wf &lt;- workflow() %&gt;%add_recipe(data_rec)%&gt;% add_model(xgb_spec)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#training-and-tunning-1",
    "href": "Multiclass classification/3 multclass classification.html#training-and-tunning-1",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "5.3 training and tunning",
    "text": "5.3 training and tunning\nquarto-executable-code-5450563D\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)\n\n5.3.1 KNN\nquarto-executable-code-5450563D\nknn_wf_result= fit(knn_wf,data_train)\nquarto-executable-code-5450563D\nfuture_result_class=predict(knn_wf_result,data_test)\nquarto-executable-code-5450563D\nfuture_result_prob=predict(knn_wf_result,data_test,type=\"prob\")\nquarto-executable-code-5450563D\nall_future_result=cbind(data_test,future_result_class,future_result_prob)\nquarto-executable-code-5450563D\naccuracy(all_future_result, target_variable,  .pred_class)\nquarto-executable-code-5450563D\nroc_auc(all_future_result, target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D)\nquarto-executable-code-5450563D\nall_future_result %&gt;% roc_curve(target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D) %&gt;% \n  autoplot()\n\n\n5.3.2 tree\ntree_wf_result= fit(tree_wf,data_train)\n```\n\n\n:::",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#model-performance",
    "href": "Multiclass classification/3 multclass classification.html#model-performance",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.4 model performance:",
    "text": "3.4 model performance:\n\n3.4.1 KNN performance\n\n\nCode\nknn_wf_result= fit(knn_wf,data_train)\n\n\n\n\nCode\nfuture_result_class=predict(knn_wf_result,data_test)\n\n\n\n\nCode\nfuture_result_prob=predict(knn_wf_result,data_test,type=\"prob\")\n\n\n\n\nCode\nall_future_result=cbind(data_test,future_result_class,future_result_prob)\n\n\n\n\nCode\naccuracy(all_future_result, target_variable,  .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.475\n\n\n\n\nCode\nroc_auc(all_future_result, target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.711\n\n\n\n\nCode\nall_future_result %&gt;% roc_curve(target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Tree performance\n\n\nCode\ntree_wf_result= fit(tree_wf,data_train)\n\n\n\n\nCode\ntree_future_result_class=predict(tree_wf_result,data_test)\n\n\n\n\nCode\ntree_future_result_prob=predict(tree_wf_result,data_test,type=\"prob\")\n\n\n\n\nCode\ntree_all_future_result=cbind(data_test,tree_future_result_class,tree_future_result_prob)\n\n\n\n\nCode\naccuracy(tree_all_future_result, target_variable,  .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.525\n\n\n\n\nCode\nroc_auc(tree_all_future_result, target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.716\n\n\n\n\nCode\ntree_all_future_result %&gt;% roc_curve(target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D) %&gt;% \n  autoplot()",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#dataframe-to-other-data-format",
    "href": "data manipulation/2 data structure in R.html#dataframe-to-other-data-format",
    "title": "Data structure in R",
    "section": "2.1 dataframe to other data format",
    "text": "2.1 dataframe to other data format\n\n2.1.1 dataframe to matrix\n\n\nCode\nmat &lt;- as.matrix(df)\n\nclass(mat)\n\n\n[1] \"matrix\" \"array\" \n\n\n\n\nCode\nmat\n\n\n     Name    Language Age \n[1,] \"Amiya\" \"R\"      \"22\"\n[2,] \"Raj\"   \"Python\" \"25\"\n[3,] \"Asish\" \"Java\"   \"45\"\n\n\n\n\n2.1.2 dataframe to vector\n\n\nCode\nvec=df[['Name']]\n\nclass(vec)\n\n\n[1] \"character\"\n\n\n\n\nCode\nvec\n\n\n[1] \"Amiya\" \"Raj\"   \"Asish\"\n\n\n\n\n2.1.3 dataframe to list\n\n\nCode\nlist=as.list(df[['Name']])\n\nclass(list)\n\n\n[1] \"list\"\n\n\n\n\nCode\nlist\n\n\n[[1]]\n[1] \"Amiya\"\n\n[[2]]\n[1] \"Raj\"\n\n[[3]]\n[1] \"Asish\"",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#matrix-to-other-data-format",
    "href": "data manipulation/2 data structure in R.html#matrix-to-other-data-format",
    "title": "Data structure in R",
    "section": "3.1 matrix to other data format",
    "text": "3.1 matrix to other data format\n\n3.1.1 matrix to dataframe\n\n\nCode\ndf &lt;- as.data.frame(matrix003)\n\nclass(df)\n\n\n[1] \"data.frame\"\n\n\n\n\nCode\ndf\n\n\n  V1 V2 V3\n1  1  4  9\n2 16 25 36\n3 49 64 81\n\n\n\n\n3.1.2 matrix to vector\n\n\nCode\nvec=as.vector(matrix003)\n\nclass(vec)\n\n\n[1] \"numeric\"\n\n\n\n\nCode\nvec\n\n\n[1]  1 16 49  4 25 64  9 36 81\n\n\n\n\n3.1.3 matrix to list\n\n\nCode\nlist=as.list(matrix003)\n\nclass(list)\n\n\n[1] \"list\"\n\n\n\n\nCode\nlist\n\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 16\n\n[[3]]\n[1] 49\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 25\n\n[[6]]\n[1] 64\n\n[[7]]\n[1] 9\n\n[[8]]\n[1] 36\n\n[[9]]\n[1] 81",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#vector-converting-between-types",
    "href": "data manipulation/2 data structure in R.html#vector-converting-between-types",
    "title": "Data structure in R",
    "section": "1.11 vector Converting between types",
    "text": "1.11 vector Converting between types\n\n1.11.1 to factor\n\n\nCode\nx &lt;- c(\"a\", \"g\", \"b\")\ny=as.factor(x)\ny\n\n\n[1] a g b\nLevels: a b g\n\n\n\n\n1.11.2 to numeric\n\n\nCode\nx &lt;- c('123','44', '222')\ny=as.numeric(x)\ny\n\n\n[1] 123  44 222\n\n\n\n\n1.11.3 to character\n\n\nCode\nx &lt;- c(123123,111,5555)\ny=as.character(x)\ny\n\n\n[1] \"123123\" \"111\"    \"5555\"  \n\n\n\n\n1.11.4 to boolen\n\n\nCode\nx &lt;- c(1,0,1)\ny=as.logical(x)\ny\n\n\n[1]  TRUE FALSE  TRUE",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#get-column-names",
    "href": "data manipulation/3 data manipulation with tidyverse.html#get-column-names",
    "title": "Data manipulation with tidyverse",
    "section": "2.2 get column names",
    "text": "2.2 get column names\n\n\nCode\nnames(small_mtcars)\n\n\n[1] \"car_name\" \"cyl\"      \"mpg\"      \"hp\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-by-name",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-by-name",
    "title": "Data manipulation with tidyverse",
    "section": "2.3 select by name",
    "text": "2.3 select by name\n\n\nCode\nmtcars %&gt;% select(cyl, mpg,hp) \n\n\n                    cyl  mpg  hp\nMazda RX4             6 21.0 110\nMazda RX4 Wag         6 21.0 110\nDatsun 710            4 22.8  93\nHornet 4 Drive        6 21.4 110\nHornet Sportabout     8 18.7 175\nValiant               6 18.1 105\nDuster 360            8 14.3 245\nMerc 240D             4 24.4  62\nMerc 230              4 22.8  95\nMerc 280              6 19.2 123\nMerc 280C             6 17.8 123\nMerc 450SE            8 16.4 180\nMerc 450SL            8 17.3 180\nMerc 450SLC           8 15.2 180\nCadillac Fleetwood    8 10.4 205\nLincoln Continental   8 10.4 215\nChrysler Imperial     8 14.7 230\nFiat 128              4 32.4  66\nHonda Civic           4 30.4  52\nToyota Corolla        4 33.9  65\nToyota Corona         4 21.5  97\nDodge Challenger      8 15.5 150\nAMC Javelin           8 15.2 150\nCamaro Z28            8 13.3 245\nPontiac Firebird      8 19.2 175\nFiat X1-9             4 27.3  66\nPorsche 914-2         4 26.0  91\nLotus Europa          4 30.4 113\nFord Pantera L        8 15.8 264\nFerrari Dino          6 19.7 175\nMaserati Bora         8 15.0 335\nVolvo 142E            4 21.4 109",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-name-match-with-p",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-name-match-with-p",
    "title": "Data manipulation with tidyverse",
    "section": "2.4 select columns by name match with ‘p’",
    "text": "2.4 select columns by name match with ‘p’",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-index",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-index",
    "title": "Data manipulation with tidyverse",
    "section": "2.5 select columns by index",
    "text": "2.5 select columns by index\n\n2.5.1 select first and 3rd columns\n\n\n2.5.2 select first to 3rd columns",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#length",
    "href": "data manipulation/3 data manipulation with tidyverse.html#length",
    "title": "Data manipulation with tidyverse",
    "section": "3.1 length",
    "text": "3.1 length\n\n\nCode\nx &lt;- \"I like horses.\"\nstr_length(x)\n\n\n[1] 14",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#upper-case",
    "href": "data manipulation/3 data manipulation with tidyverse.html#upper-case",
    "title": "Data manipulation with tidyverse",
    "section": "3.2 upper case",
    "text": "3.2 upper case\n\n\nCode\nx &lt;- \"I like horses.\"\n\nstr_to_upper(x)\n\n\n[1] \"I LIKE HORSES.\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#lower-case",
    "href": "data manipulation/3 data manipulation with tidyverse.html#lower-case",
    "title": "Data manipulation with tidyverse",
    "section": "3.3 lower case",
    "text": "3.3 lower case\n\n\nCode\nx &lt;- \"I like horses.\"\n\nstr_to_lower(x)\n\n\n[1] \"i like horses.\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#match",
    "href": "data manipulation/3 data manipulation with tidyverse.html#match",
    "title": "Data manipulation with tidyverse",
    "section": "3.4 match",
    "text": "3.4 match\n\n\nCode\ntrx='abc1993'\n\nnum=str_match(trx, \"(\\\\d)+\")\n\nnum\n\n\n     [,1]   [,2]\n[1,] \"1993\" \"3\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#concatenation",
    "href": "data manipulation/3 data manipulation with tidyverse.html#concatenation",
    "title": "Data manipulation with tidyverse",
    "section": "3.5 concatenation",
    "text": "3.5 concatenation\n\n\nCode\na='aaaa'\nb='bbbb'\n\n\n\n\nCode\npaste(a,b)\n\n\n[1] \"aaaa bbbb\"\n\n\n\n\nCode\npaste0(a,b)\n\n\n[1] \"aaaabbbb\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#replace",
    "href": "data manipulation/3 data manipulation with tidyverse.html#replace",
    "title": "Data manipulation with tidyverse",
    "section": "3.6 replace",
    "text": "3.6 replace\nstr_replace()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace('b','1')\n\n\n[1] \"a1cb\"\n\n\nstr_replace_all()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace_all('b','1')\n\n\n[1] \"a1c1\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#extract",
    "href": "data manipulation/3 data manipulation with tidyverse.html#extract",
    "title": "Data manipulation with tidyverse",
    "section": "3.7 extract",
    "text": "3.7 extract\n\n\nCode\ndata001=mtcars\ndata001 &lt;- cbind(names = rownames(data001), data001)\n\n\n\n3.7.1 subset string by postion\nextract 2 to 4\n\n\nCode\ndata001$new_names=data001$names %&gt;% str_sub(2,4)\nhead(data001 %&gt;% select(new_names,names))\n\n\n                  new_names             names\nMazda RX4               azd         Mazda RX4\nMazda RX4 Wag           azd     Mazda RX4 Wag\nDatsun 710              ats        Datsun 710\nHornet 4 Drive          orn    Hornet 4 Drive\nHornet Sportabout       orn Hornet Sportabout\nValiant                 ali           Valiant\n\n\n\n\n3.7.2 extracting number from a string\n\n\nCode\ntrx='abc1993 ccc'\n\nnum=str_extract(trx, \"(\\\\d)+\")\n\nnum\n\n\n[1] \"1993\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#date-format",
    "href": "data manipulation/3 data manipulation with tidyverse.html#date-format",
    "title": "Data manipulation with tidyverse",
    "section": "4.1 date format",
    "text": "4.1 date format\ninput as character\n\n\nCode\ndate1='2023-01-01'\nclass(date1)\n\n\n[1] \"character\"\n\n\n\n\nCode\ndate1\n\n\n[1] \"2023-01-01\"\n\n\nconvert into date type with as.Date()\n\n\nCode\ndate2=as.Date('2023-01-01')\nclass(date2)\n\n\n[1] \"Date\"\n\n\n\n\nCode\ndate2\n\n\n[1] \"2023-01-01\"\n\n\nconvert into date type with ymd()\n\n\nCode\ndate3=ymd('2023-01-01')\nclass(date3)\n\n\n[1] \"Date\"\n\n\n\n\nCode\ndate3\n\n\n[1] \"2023-01-01\"\n\n\nget today with today()\n\n\nCode\ntoday()\n\n\n[1] \"2024-05-01\"\n\n\nget local timezone\n\n\nCode\nSys.timezone()\n\n\n[1] \"Asia/Shanghai\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#change-date-format",
    "href": "data manipulation/3 data manipulation with tidyverse.html#change-date-format",
    "title": "Data manipulation with tidyverse",
    "section": "4.2 change date format",
    "text": "4.2 change date format\nmake multiple column character to date with make_date()\n\n\nCode\nflights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_date(year, month, day))\n\n\n# A tibble: 336,776 × 6\n    year month   day  hour minute departure \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;date&gt;    \n 1  2013     1     1     5     15 2013-01-01\n 2  2013     1     1     5     29 2013-01-01\n 3  2013     1     1     5     40 2013-01-01\n 4  2013     1     1     5     45 2013-01-01\n 5  2013     1     1     6      0 2013-01-01\n 6  2013     1     1     5     58 2013-01-01\n 7  2013     1     1     6      0 2013-01-01\n 8  2013     1     1     6      0 2013-01-01\n 9  2013     1     1     6      0 2013-01-01\n10  2013     1     1     6      0 2013-01-01\n# ℹ 336,766 more rows\n\n\n\n\nCode\nflights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n\n\n# A tibble: 336,776 × 6\n    year month   day  hour minute departure          \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n 1  2013     1     1     5     15 2013-01-01 05:15:00\n 2  2013     1     1     5     29 2013-01-01 05:29:00\n 3  2013     1     1     5     40 2013-01-01 05:40:00\n 4  2013     1     1     5     45 2013-01-01 05:45:00\n 5  2013     1     1     6      0 2013-01-01 06:00:00\n 6  2013     1     1     5     58 2013-01-01 05:58:00\n 7  2013     1     1     6      0 2013-01-01 06:00:00\n 8  2013     1     1     6      0 2013-01-01 06:00:00\n 9  2013     1     1     6      0 2013-01-01 06:00:00\n10  2013     1     1     6      0 2013-01-01 06:00:00\n# ℹ 336,766 more rows",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#day-differnce-between-two-dates",
    "href": "data manipulation/3 data manipulation with tidyverse.html#day-differnce-between-two-dates",
    "title": "Data manipulation with tidyverse",
    "section": "4.3 day differnce between two dates",
    "text": "4.3 day differnce between two dates\n\n\nCode\nday1=ymd('2022-01-01')\nday2=ymd('2023-02-03')\n\ndiff=day2-day1\n\n\n\n\nCode\ndiff\n\n\nTime difference of 398 days\n\n\nusing interval() find two dates gap\n\n\nCode\ninterval(day1,day2) %&gt;% as.period()\n\n\n[1] \"1y 1m 2d 0H 0M 0S\"\n\n\nfind day gap\n\n\nCode\ninterval(day1,day2)%/% days(1)\n\n\n[1] 398\n\n\nfind month gap\n\n\nCode\ninterval(day1,day2)%/% months(1)\n\n\n[1] 13\n\n\nfind year gap\n\n\nCode\ninterval(day1,day2)%/% years(1)\n\n\n[1] 1",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#day-and-time",
    "href": "data manipulation/3 data manipulation with tidyverse.html#day-and-time",
    "title": "Data manipulation with tidyverse",
    "section": "4.4 day and time",
    "text": "4.4 day and time\n\n\nCode\nnow_time=now()\nnow_time\n\n\n[1] \"2024-05-01 16:44:20 CST\"\n\n\n\n4.4.1 get year\n\n\nCode\nyear(now_time)\n\n\n[1] 2024\n\n\n\n\n4.4.2 get month\n\n\nCode\nmonth(now_time)\n\n\n[1] 5\n\n\n\n\n4.4.3 get date of the month\n\n\nCode\nmday(now_time)\n\n\n[1] 1\n\n\n\n\n4.4.4 get date of the year\n\n\nCode\nyday(now_time)\n\n\n[1] 122\n\n\n\n\n4.4.5 get date of the week\n\n\nCode\nwday(now_time)\n\n\n[1] 4\n\n\n\n4.4.5.1 get hour\n\n\nCode\nhour(now_time)\n\n\n[1] 16\n\n\n\n\n\n4.4.6 get minute\n\n\nCode\nminute(now_time)\n\n\n[1] 44\n\n\n\n\n4.4.7 get second\n\n\nCode\nsecond(now_time)\n\n\n[1] 20.81399",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#return-result-with-default",
    "href": "intro/1 basic R.html#return-result-with-default",
    "title": "Basic R",
    "section": "4.3 return result with default",
    "text": "4.3 return result with default\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  return(a)\n}\n\nadding_ten(5)\n\n\n[1] 15\n\n\nif not define x, then x=10\n\n\nCode\nadding_ten()\n\n\n[1] 20",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-function-arguments",
    "href": "intro/1 basic R.html#check-function-arguments",
    "title": "Basic R",
    "section": "4.4 check function Arguments",
    "text": "4.4 check function Arguments\n\n\nCode\nargs(adding_ten)\n\n\nfunction (x = 10) \nNULL\n\n\nMany functions exhibit variadic behavior. That is, they can accept any num- ber of arguments, and it’s up to the user to decide how many arguments to provide. The functions c, data.frame, and list are all like this. When you call a function like data.frame, you can specify any number of members as arguments.\n\n\nCode\nargs(data.frame)\n\n\nfunction (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, \n    fix.empty.names = TRUE, stringsAsFactors = FALSE) \nNULL",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#warning-in-function",
    "href": "intro/1 basic R.html#warning-in-function",
    "title": "Basic R",
    "section": "4.5 warning in function",
    "text": "4.5 warning in function\nprint out warning\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  if(a&gt;50){\n    warning('its better than 50')\n  }\n  return(a)\n}\n\n\n\n\nCode\nadding_ten(100)\n\n\n[1] 110",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#stop-in-function",
    "href": "intro/1 basic R.html#stop-in-function",
    "title": "Basic R",
    "section": "4.6 stop in function",
    "text": "4.6 stop in function\nprint out stop error message\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  if(a&gt;50){\n    stop('its better than 50')\n  }\n  return(a)\n}\n\n\n\n\nCode\nadding_ten(100)",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#use-try-to-by-pass-error",
    "href": "intro/1 basic R.html#use-try-to-by-pass-error",
    "title": "Basic R",
    "section": "4.7 use try to by pass error",
    "text": "4.7 use try to by pass error\n\n\nCode\ntry(adding_ten(100))\n\n\n[1] 110\n\n\nCode\n5+10\n\n\n[1] 15",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#centrality-mean-median-mode",
    "href": "intro/1 basic R.html#centrality-mean-median-mode",
    "title": "Basic R",
    "section": "9.1 Centrality: Mean, Median, Mode",
    "text": "9.1 Centrality: Mean, Median, Mode",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#spread-variance-standard-deviation-and-the-interquartile-range",
    "href": "intro/1 basic R.html#spread-variance-standard-deviation-and-the-interquartile-range",
    "title": "Basic R",
    "section": "9.2 Spread: Variance, Standard Deviation, and the Interquartile Range",
    "text": "9.2 Spread: Variance, Standard Deviation, and the Interquartile Range",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#covariance-and-correlation",
    "href": "intro/1 basic R.html#covariance-and-correlation",
    "title": "Basic R",
    "section": "9.3 Covariance and Correlation",
    "text": "9.3 Covariance and Correlation\nWhen analyzing data, it’s often useful to be able to investigate the rela- tionship between two numeric variables to assess trends. For example, you might expect height and weight observations to have a noticeable positive relationship—taller people tend to weigh more. Conversely, you might imag- ine that handspan and length of hair would have less of an association. One of the simplest and most common ways such associations are quantified and compared is through the idea of correlation, for which you need the covariance. The covariance expresses how much two numeric variables “change together” and the nature of that relationship,",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#correlationpearsons-product-moment-correlation-coefficient",
    "href": "intro/1 basic R.html#correlationpearsons-product-moment-correlation-coefficient",
    "title": "Basic R",
    "section": "9.4 Correlation,Pearson’s product-moment correlation coefficient",
    "text": "9.4 Correlation,Pearson’s product-moment correlation coefficient\nPearson’s sample correlation coef- ficient ρxy is computed by dividing the sample covariance by the product of the standard deviation of each data set\n\nSome Correlation Example:",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#input-image-2",
    "href": "clustering/1.2 k mean Clustering.html#input-image-2",
    "title": "K mean Clustering with image",
    "section": "4.1 input image",
    "text": "4.1 input image\n\n\nCode\nimage &lt;- image_read('final.png')",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix-2",
    "href": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix-2",
    "title": "K mean Clustering with image",
    "section": "4.2 convert png to matrix",
    "text": "4.2 convert png to matrix\n\n\nCode\nimage_tiff &lt;- image_convert(image, \"tiff\")\nimage_array &lt;- as.integer(image_tiff[[1]])                \n\n\n\n\nCode\nmagick::image_read(image_array/ 255)\n\n\n\n\n\n\n\n\n\n561 * 724 pixcel and 4 channels\n\n\nCode\ndim(image_array)\n\n\n[1] 561 724   4\n\n\n\n\nCode\nclass(image_array)\n\n\n[1] \"array\"\n\n\n\n\nCode\nimage_array_old=image_array",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d-2",
    "href": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d-2",
    "title": "K mean Clustering with image",
    "section": "4.3 reshape from 3 D to 2 D",
    "text": "4.3 reshape from 3 D to 2 D\n\n\nCode\ndim(image_array) &lt;- c(dim(image_array)[1]*dim(image_array)[2],4)\n\n\n\n\nCode\ndim(image_array)\n\n\n[1] 406164      4\n\n\nData Normalization\nSince the dataset contains a range of values from 0 to 255, the dataset has to be normalized. Data Normalization is an important preprocessing step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This fastens the process of covergence while training the model. Also Normalization makes sure no one particular parameter influences the output significantly.\n\n\nCode\nimage_array=image_array/255",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters-2",
    "href": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters-2",
    "title": "K mean Clustering with image",
    "section": "4.4 Optimal number of k-clusters",
    "text": "4.4 Optimal number of k-clusters\n\n\nCode\nkclusts &lt;- \n  tibble(k = 1:9) %&gt;%\n  mutate(\n    kclust = map(k, ~kmeans(image_array, .x)),\n    tidied = map(kclust, tidy),\n    glanced = map(kclust, glance),\n    augmented = map(kclust, augment, image_array)\n  )\n\nkclusts\n\n\n# A tibble: 9 × 5\n      k kclust   tidied           glanced          augmented             \n  &lt;int&gt; &lt;list&gt;   &lt;list&gt;           &lt;list&gt;           &lt;list&gt;                \n1     1 &lt;kmeans&gt; &lt;tibble [1 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n2     2 &lt;kmeans&gt; &lt;tibble [2 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n3     3 &lt;kmeans&gt; &lt;tibble [3 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n4     4 &lt;kmeans&gt; &lt;tibble [4 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n5     5 &lt;kmeans&gt; &lt;tibble [5 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n6     6 &lt;kmeans&gt; &lt;tibble [6 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n7     7 &lt;kmeans&gt; &lt;tibble [7 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n8     8 &lt;kmeans&gt; &lt;tibble [8 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n9     9 &lt;kmeans&gt; &lt;tibble [9 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n\n\n\n\nCode\nclusters &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(tidied))\n\nassignments &lt;- \n  kclusts %&gt;% \n  unnest(cols = c(augmented))\n\nclusterings &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(glanced))\n\n\n\n\nCode\nlibrary(scales)\nggplot(clusterings, aes(k, tot.withinss)) +\n  geom_line() +\n  geom_point()+scale_x_continuous(breaks= pretty_breaks())+scale_y_continuous(labels = scales::comma)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#group-to-2",
    "href": "clustering/1.2 k mean Clustering.html#group-to-2",
    "title": "K mean Clustering with image",
    "section": "4.5 group to 2",
    "text": "4.5 group to 2\n\n\nCode\nkclust &lt;- kmeans(image_array, centers = 2)\n\n\n\n\nCode\nresult=augment(kclust, image_array) %&gt;% clean_names()\n\n\n\n\nCode\nresult %&gt;% count(cluster)\n\n\n# A tibble: 2 × 2\n  cluster      n\n  &lt;fct&gt;    &lt;int&gt;\n1 1       285299\n2 2       120865",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#change-2-color-2",
    "href": "clustering/1.2 k mean Clustering.html#change-2-color-2",
    "title": "K mean Clustering with image",
    "section": "4.6 change 2 color",
    "text": "4.6 change 2 color\n\n\nCode\n# black RGB code 0 0 0\n# red RGB code 255 0 0\n\nresult2=result %&gt;%mutate(x1=if_else(cluster==2,0,255) \n                          ,x2=if_else(cluster==2,255,0) \n                          ,x3=if_else(cluster==2,0,0) )",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-4-d-1",
    "href": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-4-d-1",
    "title": "K mean Clustering with image",
    "section": "4.7 convert 2 D back to 4 D",
    "text": "4.7 convert 2 D back to 4 D\n\n\nCode\nresult2arrary=array(unlist(result2),c(dim(image_array_old)[1],dim(image_array_old)[2],4))\n\n\n\n\nCode\ndim(result2arrary)\n\n\n[1] 561 724   4\n\n\nconvert from 0-1 back to 0-255\n\n\nCode\nresult2arrary=result2arrary*255\n\n\n\n\nCode\nmagick::image_read(result2arrary/ 255)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "other/Web scraping with rvest/2 web scraping with rvest on whiskynote.html",
    "href": "other/Web scraping with rvest/2 web scraping with rvest on whiskynote.html",
    "title": "Web scraping with rvest",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\nWeb scraping on www.whiskynotes.be\n\n1 review page\n\n\nCode\nreview_url='https://www.whiskynotes.be/2024/ardbeg/spheric-spirits-springbank-blended-malt-islay-malt/'\n\n\n\n\n\n2 read in html\n\n\nCode\nreview_page &lt;- read_html(review_url)\n\n\n\n\n3 bottle_name\n\n\nCode\nbottle_name=review_page  %&gt;% html_elements(\".product-main__name\") %&gt;% html_text2()\nbottle_name\n\n\n[1] \"Blended Malt 44 yo 1978 (59,8%, Spheric Spirits 2023, refill sherry butt #6, 331 btl.)\"   \n[2] \"Springbank 27 yo 1994 (47,1%, Spheric Spirits 2022, refill sherry hogshead #95, 241 btl.)\"\n[3] \"Islay Malt 25 yo (48,4%, Spheric Spirits 2022, 407 btl.)\"                                 \n\n\n\n\n4 bottle_review\n\n\nCode\nbottle_review=review_page  %&gt;% html_elements(\"p\") %&gt;% html_text2()\nbottle_review\n\n\n [1] \"Spheric Spirits is a young indie bottler from Germany, started by Benedict and Claudio. They have a slightly edgy / flashy branding (check the website) – I like the vibrant colours on the labels but apparently not everything agrees. Besides whisky, they’re also looking at armagnac and destilado de agave. They’re not just bottlers, by the way, they like to get involved at the beginning of production.\"\n [2] \"First up is a Blended Malt 1978, which is probably old Long John blending stock. It ended up forgotten due to a change of brand ownership in 1981. If this is true, then the peated component is probably 1970s Laphroaig.\"                                                                                                                                                                                        \n [3] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n [4] \"Nose: indeed you get this old school faded peat mixed with tropical fruits. Yellow plums, papaya, dried pineapple slices, peach and drizzles of honey. There’s a good dose of polished wood and light coconut (giving it an American touch) as well as paraffin, pine needles, buttery cake dough, walnuts and hints of old Amontillado. Quite stunning so far, you don’t get this profile often.\"                 \n [5] \"Mouth: peatier now, and more woody. Hints of plums and melons, as well as tangerines and overripe bananas. Something of the 1960s Ben Nevis waxiness, coconut, and some bitter herbs. Then a grassy sharpness, some cinnamon and ginger, as well as butter cookies, hazelnuts and pipe tobacco. Slightly astringent at times, but still it’s an uncommon, intruiging profile including nicely medicinal smoke.\"    \n [6] \"Finish: long, honeyed but also spicy, with peppery notes and a little fruit tea. Caramelized nuts and wood until the very end.\"                                                                                                                                                                                                                                                                                    \n [7] \"I remember hesitating to buy a bottle of this blended malt – honestly I thought it was too expensive at € 800+. However after trying it, I’m hesitating again because it’s such a unique profile. Almost sold out, I believe, but still seen at Whisky-Maniac for instance.\"                                                                                                                                       \n [8] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n [9] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[10] \"Nose: very mineral, you could almost think of mezcal here. Plenty of linseed or sunflower oil and waxed canvas, wax candles and some vegetal hints. Light orchard fruits in second row, maybe even a hint of green pineapple. Then a mossy note and a drop of seawater. Very clean, with virtually voiceless sherry (unless it was Fino).\"                                                                         \n[11] \"Mouth: a rather wonderful mix of minerals and waxes, with green fruits. Think kiwi and green apple. Then chalky notes and more vegetal oils, as well as grapefruit. Fresh herbs and a little eucalyptus. Light coastal touches. Just a hint of marshmallow sweetness in the background.\"                                                                                                                           \n[12] \"Finish: long, still lean and elegant, with lime and herbs, barley sweetness and aniseed.\"                                                                                                                                                                                                                                                                                                                          \n[13] \"Again, not a cheap whisky but very well chosen. Reminds me of the Whisky Sponge 60a, although this one is even more clean. Perhaps too clean for some. Still listed on the website of Hogshead Imports, but I believe we’ll be too late… Score: 91/100\"                                                                                                                                                            \n[14] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[15] \"We end this (already impressive) session with a secret Islay Malt, a mix of the 1993 and 1994 vintages. Spheric Spirits tell us that this is one of the unusual batches produced on site in the early 1990s by the team of a neighbouring brand, just to keep the distillery operational. Isn’t that the time when Allied Distillers made Laphroaig at Ardbeg?\"                                                    \n[16] \"Medicinal peat smoke is well integrated into its otherwise fruity and citrusy nose. Even hints of tropical nuances are detectable. On the pallet sweet peat shows up more present with a salty tang. Lovely old school earthy medicinal peatiness, no bonfire smoke. The mouthfeel is incredibly oily and lingering.\"                                                                                              \n[17] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[18] \"Nose: nice engine oil along with medicinal peat. Perhaps a little smokier / Laphroaigier than some other ‘Begs? Mentholated notes and subtle antiseptics. Then delicated earthy notes, big hints of lemons and just a hint of vanilla. Soft orange notes, malty sweetness and peaches. All in all quite mild.\"                                                                                                     \n[19] \"Mouth: more intensely peaty now, more clearly Ardbeg. Big medicinal notes, with some tar in the distance, as well as smoked meat. Then some lighter, fruitier notes, a little salt, and a hint of tea leaves. Towards the end it becomes more narrow again, with sour citrus and mineral notes that remind me of Caol Ila.\"                                                                                        \n[20] \"Finish: long, citrusy, with hints of charcoal, light pear and tarry ropes. Just a subtle touch of bitter herbs.\"                                                                                                                                                                                                                                                                                                   \n[21] \"Some beautiful old school notes in here again, although they may not be entirely Ardbeg if you know what I mean. Sold out. I apologize for not discovering Spheric Spirits sooner. Score: 90/100\"                                                                                                                                                                                                                  \n[22] \"Your email address will not be published. Required fields are marked *\"                                                                                                                                                                                                                                                                                                                                            \n[23] \"Comment *\"                                                                                                                                                                                                                                                                                                                                                                                                         \n[24] \"Name *\"                                                                                                                                                                                                                                                                                                                                                                                                            \n[25] \"Email *\"                                                                                                                                                                                                                                                                                                                                                                                                           \n[26] \"Website\"                                                                                                                                                                                                                                                                                                                                                                                                           \n[27] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                  \n[28] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                  \n[29] \"Δdocument.getElementById( \\\"ak_js_1\\\" ).setAttribute( \\\"value\\\", ( new Date() ).getTime() );\"                                                                                                                                                                                                                                                                                                                      \n[30] \"This site uses Akismet to reduce spam. Learn how your comment data is processed.\"                                                                                                                                                                                                                                                                                                                                  \n[31] \"Begin typing your search above and press return to search. Press Esc to cancel.\"                                                                                                                                                                                                                                                                                                                                   \n\n\n\n\n5 bottle_review_Nose\n\n\nCode\nbottle_review_Nose=bottle_review[bottle_review %&gt;% str_detect('Nose:')]\nbottle_review_Nose\n\n\n[1] \"Nose: indeed you get this old school faded peat mixed with tropical fruits. Yellow plums, papaya, dried pineapple slices, peach and drizzles of honey. There’s a good dose of polished wood and light coconut (giving it an American touch) as well as paraffin, pine needles, buttery cake dough, walnuts and hints of old Amontillado. Quite stunning so far, you don’t get this profile often.\"\n[2] \"Nose: very mineral, you could almost think of mezcal here. Plenty of linseed or sunflower oil and waxed canvas, wax candles and some vegetal hints. Light orchard fruits in second row, maybe even a hint of green pineapple. Then a mossy note and a drop of seawater. Very clean, with virtually voiceless sherry (unless it was Fino).\"                                                        \n[3] \"Nose: nice engine oil along with medicinal peat. Perhaps a little smokier / Laphroaigier than some other ‘Begs? Mentholated notes and subtle antiseptics. Then delicated earthy notes, big hints of lemons and just a hint of vanilla. Soft orange notes, malty sweetness and peaches. All in all quite mild.\"                                                                                    \n\n\n\n\nCode\nbottle_review_Mouth=bottle_review[bottle_review %&gt;% str_detect('Mouth:')]\nbottle_review_Mouth\n\n\n[1] \"Mouth: peatier now, and more woody. Hints of plums and melons, as well as tangerines and overripe bananas. Something of the 1960s Ben Nevis waxiness, coconut, and some bitter herbs. Then a grassy sharpness, some cinnamon and ginger, as well as butter cookies, hazelnuts and pipe tobacco. Slightly astringent at times, but still it’s an uncommon, intruiging profile including nicely medicinal smoke.\"\n[2] \"Mouth: a rather wonderful mix of minerals and waxes, with green fruits. Think kiwi and green apple. Then chalky notes and more vegetal oils, as well as grapefruit. Fresh herbs and a little eucalyptus. Light coastal touches. Just a hint of marshmallow sweetness in the background.\"                                                                                                                       \n[3] \"Mouth: more intensely peaty now, more clearly Ardbeg. Big medicinal notes, with some tar in the distance, as well as smoked meat. Then some lighter, fruitier notes, a little salt, and a hint of tea leaves. Towards the end it becomes more narrow again, with sour citrus and mineral notes that remind me of Caol Ila.\"                                                                                    \n\n\n\n\n6 bottle_review_Finish\n\n\nCode\nbottle_review_Finish=bottle_review[bottle_review %&gt;% str_detect('Finish:')]\nbottle_review_Finish\n\n\n[1] \"Finish: long, honeyed but also spicy, with peppery notes and a little fruit tea. Caramelized nuts and wood until the very end.\"\n[2] \"Finish: long, still lean and elegant, with lime and herbs, barley sweetness and aniseed.\"                                      \n[3] \"Finish: long, citrusy, with hints of charcoal, light pear and tarry ropes. Just a subtle touch of bitter herbs.\"               \n\n\n\n\n7 first score\n\n\nCode\nfirst_bottle_score=review_page  %&gt;% html_elements(\".entry-score\") %&gt;% html_text2()\nfirst_bottle_score=first_bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n\n\n\n\n8 all other score\n\n\nCode\nbottle_score=review_page  %&gt;% html_elements(\"strong\") %&gt;% html_text2()\n  \nbottle_score2=bottle_score %&gt;% str_match('[0-9][0-9]/100') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n\nbottle_score2=bottle_score2 %&gt;% mutate(V1=str_replace(V1,'/100',''))\n\n\n\n\n9 combine all score\n\n\nCode\n# move the last one to the first one\nif(identical(bottle_score, character(0))==TRUE|nrow(bottle_score2)==0){\n    all_page_score=first_bottle_score %&gt;% tibble()%&gt;% rename(all_page_score='.') \n  }else{\n  #bottle_score=bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  all_page_score=rbind(first_bottle_score,bottle_score2) %&gt;% rename(all_page_score=V1) \n  }\nall_page_score\n\n\n  all_page_score\n1             92\n2             91\n3             90\n\n\n\n\n10 page_published_date\n\n\nCode\npage_published_date=review_page  %&gt;% html_elements(\".published\") %&gt;% html_text2()\npage_published_date\n\n\n[1] \"16 April 2024\"\n\n\n\n\n11 page_class\n\n\nCode\npage_class=review_page  %&gt;% html_elements(\".cat-links a\") %&gt;% html_text2()\npage_class=str_flatten(page_class,collapse = \"--\")\npage_class\n\n\n[1] \"* Blends--Ardbeg--Springbank\"\n\n\n\n\n12 page_title\n\n\nCode\npage_title=review_page  %&gt;% html_elements(\".entry-title\") %&gt;% html_text2()\npage_title\n\n\n[1] \"Spheric Spirits: Springbank / Blended Malt / Islay Malt\"\n\n\n\n\n13 combine all one_page_review\n\n\nCode\none_page_review=data_frame(bottle_name,bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish,all_page_score,page_class,page_published_date,page_title,review_url)\none_page_review\n\n\n# A tibble: 3 × 9\n  bottle_name        bottle_review_Nose bottle_review_Mouth bottle_review_Finish\n  &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;               \n1 Blended Malt 44 y… Nose: indeed you … Mouth: peatier now… Finish: long, honey…\n2 Springbank 27 yo … Nose: very minera… Mouth: a rather wo… Finish: long, still…\n3 Islay Malt 25 yo … Nose: nice engine… Mouth: more intens… Finish: long, citru…\n# ℹ 5 more variables: all_page_score &lt;chr&gt;, page_class &lt;chr&gt;,\n#   page_published_date &lt;chr&gt;, page_title &lt;chr&gt;, review_url &lt;chr&gt;\n\n\n\n\n14 output\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(one_page_review,'one_page_review.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "Web scraping with rvest",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "other/Web scraping with rvest/2 web scraping with rvest copy.html",
    "href": "other/Web scraping with rvest/2 web scraping with rvest copy.html",
    "title": "Web scraping with rvest",
    "section": "",
    "text": "rvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nCode\npackageVersion(\"rvest\")\nWeb scraping on www.whiskynotes.be",
    "crumbs": [
      "Other",
      "Web scraping with rvest",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "other/Web scraping with rvest/2 web scraping with rvest copy.html#one-page-function",
    "href": "other/Web scraping with rvest/2 web scraping with rvest copy.html#one-page-function",
    "title": "Web scraping with rvest",
    "section": "6.1 one page function",
    "text": "6.1 one page function\n\n\nCode\none_page_function &lt;- function(review_url){\n  \n\n  \n     #review_url=\"https://www.whiskynotes.be/2023/linkwood/linkwood-2008-benrinnes-2000-glentauchers-2009-maltbarn/\"\n  \n  \n    tryCatch({\n\n    print(review_url)\n    review_page &lt;- read_html(review_url)\n    closeAllConnections()\n  }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n  \n\n  page_class=review_page  %&gt;% html_elements(\".cat-links a\") %&gt;% html_text2()\n  page_class=str_flatten(page_class,collapse = \"-\")\n  \n  bottle_name=review_page  %&gt;% html_elements(\".entry-content h2\") %&gt;% html_text2()\n  bottle_name=bottle_name[nzchar(bottle_name)]\n  \n  # remove ? mark non bottle name element\n  bottle_name=bottle_name[!bottle_name%&gt;% str_detect(\"\\\\?\")]\n  # remove Drams Delivered revisited  non bottle name element\n  bottle_name=bottle_name[ !bottle_name == 'Drams Delivered revisited']\n  print(bottle_name) \n  \n  bottle_review_raw=review_page  %&gt;% html_elements(\"p\") %&gt;% html_text()\n  bottle_review=unlist(strsplit(bottle_review_raw,\"(?= Nose: )\",perl = TRUE))\n  bottle_review=unlist(strsplit(bottle_review,\"(?= Mouth: )\",perl = TRUE))\n   bottle_review=unlist(strsplit(bottle_review,\"(?= Finish: )\",perl = TRUE))\n  \n  bottle_review_Nose=bottle_review[bottle_review %&gt;% str_detect('Nose:')]\n  bottle_review_Nose=bottle_review_Nose[nzchar(bottle_review_Nose)]\n\n  bottle_review_Mouth=bottle_review[bottle_review %&gt;% str_detect('Mouth:')]\n  bottle_review_Mouth=bottle_review_Mouth[nzchar(bottle_review_Mouth)]\n\n  bottle_review_Finish=bottle_review[bottle_review %&gt;% str_detect('Finish:')]\n  bottle_review_Finish=bottle_review_Finish[nzchar(bottle_review_Finish)]\n  \n  ########### add dummy score if there is no score review #########\n  # bottle_review_Finish_score=bottle_review[bottle_review %&gt;% str_detect('Finish:|Score:')][-1]\n \n  # # bottle_review_Finish_score2=bottle_review_Finish_score\n  \n  \n  # order=1\n  # for (word in bottle_review_Finish_score){\n  #   print(word)\n  #   print(order)\n  #   print(order%%2)\n  #   print(word %&gt;% str_detect('Score:'))\n  #   print(order%%2==0 & word %&gt;% str_detect('Score:')==FALSE)\n  #   if (order%%2==0 & word %&gt;% str_detect('Score:')==FALSE){\n  #     print('adding add dummy score if there is no score review ')\n  #     bottle_review_Finish_score2=append(bottle_review_Finish_score2,'Score:00/100',order-1)\n  #   }else{\n  #   }\n  #   order=order+1\n  #   }\n################################################\n    \n  \n  \n  first_bottle_score=review_page  %&gt;% html_elements(\".entry-score\") %&gt;% html_text2()\n\n  bottle_score=review_page  %&gt;% html_elements(\"strong\") %&gt;% html_text2()\n  \n  bottle_score2=bottle_score %&gt;% str_match('[0-9][0-9]/100') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  bottle_score2=bottle_score2 %&gt;% mutate(V1=str_replace(V1,'/100',''))\n\n\n  if(identical(bottle_score, character(0))==TRUE|nrow(bottle_score2)==0){\n    all_page_score=first_bottle_score %&gt;% tibble()%&gt;% rename(all_page_score='.') \n  }else{\n  #bottle_score=bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  all_page_score=rbind(first_bottle_score,bottle_score2) %&gt;% rename(all_page_score=V1) \n  }\n\n  page_published_date=review_page  %&gt;% html_elements(\".published\") %&gt;% html_text2()\n\n\n  page_title=review_page  %&gt;% html_elements(\".entry-title\") %&gt;% html_text2()\n  \n  if(nrow(all_page_score)!=length(bottle_name)){all_page_score=0}\n  if(length(bottle_review_Nose)!=length(bottle_name)){bottle_review_Nose='no comment'}\n  if(length(bottle_review_Mouth)!=length(bottle_name)){bottle_review_Mouth='no comment'}\n  if(length(bottle_review_Finish)!=length(bottle_name)){bottle_review_Finish='no comment'}\n  \n  \n  \n  one_page_review=tibble(bottle_name,bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish,all_page_score,page_class,page_published_date,page_title,review_url) \n  \n\n  Sys.sleep(runif(n=1, min=0.1, max=0.8))\n  #print(one_page_review)\n  print(dim(one_page_review))\n  #remove(review_page)\n  return(one_page_review)\n}\n\n\n\n\nCode\nlength(topic_link_list)\n\n\n\n\nCode\nnews=topic_link_list %&gt;% str_detect('/whisky-news/')\n\n\n\n\nCode\ntopic_link_list_exclude_news=topic_link_list[!news]\n\n\n\n\nCode\nlength(topic_link_list_exclude_news)\n\n\n\n\nCode\n#topic_link_list_exclude_news\n\nwhich(topic_link_list_exclude_news==\"https://www.whiskynotes.be/2023/world/paul-john-christmas-edition-2022/\")\n\n\n\n\nCode\ntopic_link_list_exclude_news_small=c('https://www.whiskynotes.be/2024/rum/9-rum-reviews-diamond-don-jose-tdl-fiji-enmore/','https://www.whiskynotes.be/2024/benriach/benriach-glenburgie-campbeltown-highland-milroys-soho/','https://www.whiskynotes.be/2024/rum/6-rums-black-tot-uitvlugt-clarendon-tdl-martinique/')\n\n\n\n\nCode\nall_page_review_list=data.frame()\n\nstart_time=Sys.time()\nprint(paste0(\"Start time: \", start_time))\n\nfor (i in topic_link_list_exclude_news){\n  \n   print(paste0(\"Running loop No.\",which(topic_link_list_exclude_news==i)))\n         \n   print(paste0(\"current time: \", Sys.time()))\n   a=one_page_function(i)\n   all_page_review_list=rbind(all_page_review_list,a)\n   print(paste0(\"Used time: \", Sys.time()-start_time))\n}\n\nend_time=Sys.time()\nprint(paste0(\"End time: \", end_time))\n\nprint(paste0(\"used time: \", end_time-start_time))\n\nlibrary(openxlsx)\nwrite.xlsx(all_page_review_list,'all_page_review_list.xlsx')\n\n\n\nall_page_review_list_final=all_page_review_list %&gt;% filter(all_page_score!=0& bottle_review_Mouth!='no comment')\n\nwrite.xlsx(all_page_review_list_final,'all_page_review_list_final.xlsx')",
    "crumbs": [
      "Other",
      "Web scraping with rvest",
      "Web scraping with rvest"
    ]
  },
  {
    "objectID": "other/Web scraping with other/1 whiskynote data.html",
    "href": "other/Web scraping with other/1 whiskynote data.html",
    "title": "Whiskynotes.be data",
    "section": "",
    "text": "1 whiskynotes.be data\nhttps://www.whiskynotes.be/\n\nWhiskyNotes is a personal collection of impressions, written while searching for the ultimate single malt whisky. A work in progress, and a continuous exercise for the senses.\nI started it in 2008 while living in Spain for a couple of years. I had discovered whisky a few years earlier but suddenly I was cut off from festivals, shops and whisky friends in my home country. A whisky blog seemed a good way of keeping in touch. It quickly gained a following, first in Belgium but now from all over the world.\n\n\n2 rvest package\nrvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "Web scraping with other",
      "Whiskynotes.be data"
    ]
  },
  {
    "objectID": "other/Web scraping with rvest/1 whiskynote data.html",
    "href": "other/Web scraping with rvest/1 whiskynote data.html",
    "title": "Whiskynotes.be data",
    "section": "",
    "text": "1 whiskynotes.be data\nhttps://www.whiskynotes.be/\n\nWhiskyNotes is a personal collection of impressions, written while searching for the ultimate single malt whisky. A work in progress, and a continuous exercise for the senses.\nI started it in 2008 while living in Spain for a couple of years. I had discovered whisky a few years earlier but suddenly I was cut off from festivals, shops and whisky friends in my home country. A whisky blog seemed a good way of keeping in touch. It quickly gained a following, first in Belgium but now from all over the world.\n\n\n2 rvest package\nrvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "Web scraping with rvest",
      "Whiskynotes.be data"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-sequence-vector",
    "href": "data manipulation/2 data structure in R.html#create-sequence-vector",
    "title": "Data structure in R",
    "section": "1.1 create sequence vector",
    "text": "1.1 create sequence vector\n\n\nCode\nseq(from = 2, to = 14, by = 2) \n\n\n[1]  2  4  6  8 10 12 14",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-repeat-vector",
    "href": "data manipulation/2 data structure in R.html#create-repeat-vector",
    "title": "Data structure in R",
    "section": "1.2 create repeat vector",
    "text": "1.2 create repeat vector\n\n\nCode\nrep(x = 1.5, times = 4)  \n\n\n[1] 1.5 1.5 1.5 1.5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-random-vector",
    "href": "data manipulation/2 data structure in R.html#create-random-vector",
    "title": "Data structure in R",
    "section": "1.3 create random vector",
    "text": "1.3 create random vector\ncreate 5 random number from 1 to 10 without replacement\n\n\nCode\nsample(1:10,5, replace=F) \n\n\n[1] 5 4 6 7 2\n\n\ncreate 5 random number from 1 to 10 with replacement\n\n\nCode\nsample(1:10,5, replace=T) \n\n\n[1]  1  1  7  9 10\n\n\ncreate 1 random number from 0 to 1 from random uniform distribution\n\n\nCode\nrunif(1, min=0, max=1)\n\n\n[1] 0.4916644\n\n\ngenerate 4 random number that follows the normal distribution with mean being 0 and standard deviation being 1\n\n\nCode\nsn1 &lt;- rnorm(4, mean=0, sd=1) # standard nromal\nsn1\n\n\n[1]  1.2887053 -0.4671360  0.7490033  0.5851018",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#sort-vector",
    "href": "data manipulation/2 data structure in R.html#sort-vector",
    "title": "Data structure in R",
    "section": "1.7 sort vector",
    "text": "1.7 sort vector\n\n\nCode\na=c(2,4,6,1,4)\n\n\n\n\nCode\nsort(a)\n\n\n[1] 1 2 4 4 6\n\n\n\n\nCode\nsort(a,decreasing=TRUE)\n\n\n[1] 6 4 4 2 1",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#vector-length",
    "href": "data manipulation/2 data structure in R.html#vector-length",
    "title": "Data structure in R",
    "section": "1.8 vector length",
    "text": "1.8 vector length\n\n\nCode\nlength(a)\n\n\n[1] 5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/4 whiskynote all year page.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/4 whiskynote all year page.html",
    "title": "All year page",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 loop all year page\n\n\nCode\nyear_list=seq(2010,2024)\nyear_list\n\n\n\n\nCode\nurl_list=paste0('https://www.whiskynotes.be/',year_list)\nurl_list\n\n\n\n\nCode\nbottle_list=c()\ntopic_list=c()\ntopic_link_list=c()\nall_year_list_topic=c()\nall_year_list_bottle=c()\n\nfor (i in url_list){\n  year=tail(unlist(strsplit(i, split = \"/\")),1)\n  print(year)\n  print(i)\n  year_ur=i\n  year_page &lt;- read_html(year_ur)\n  bottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\n  bottle003=unlist(strsplit(bottle001,\"\\n\"))\n  \n  \n  topic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\n  topic_link_001 &lt;- year_page %&gt;%\n    html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\n  year_list_topic=rep(year,length(topic001))\n  year_list_bottle=rep(year,length(bottle003))\n  \n  all_year_list_topic=c(all_year_list_topic,year_list_topic)\n  all_year_list_bottle=c(all_year_list_bottle,year_list_bottle)\n  \n  bottle_list=c(bottle_list,bottle003)\n  topic_list=c(topic_list,topic001)\n  topic_link_list=c(topic_link_list,topic_link_001)\n  \n  Sys.sleep(1)\n  }\n\n\n\n\n2 combine\n\n\nCode\ndata=tibble(topic_list,topic_link_list,all_year_list_topic)\n\n\n\n\nCode\n#bottle003=tibble(bottle_list,all_year_list_bottle)\n\n\n\n\n3 output\n\n\nCode\nlibrary(openxlsx)\nlist_of_datasets &lt;- list(\"topic\" = data)\n\nwrite.xlsx(list_of_datasets, file = \"./output/all year page.xlsx\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year page"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/2 whiskynote one page.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/2 whiskynote one page.html",
    "title": "One page reveiw",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\nWeb scraping on www.whiskynotes.be\n\n1 review page\n\n\nCode\nreview_url='https://www.whiskynotes.be/2024/ardbeg/spheric-spirits-springbank-blended-malt-islay-malt/'\n\n#review_url='https://www.whiskynotes.be/2011/port-ellen/port-ellen-10th-release-1978/'\n\n\n\n\n\n2 read in html\n\n\nCode\nreview_page &lt;- read_html(review_url)\n\n\n\n\n3 take picture of url\n\n\n4 bottle_name\n\n\nCode\nbottle_name=review_page  %&gt;% html_elements(\".entry-content h2\") %&gt;% html_text2()\n# remove empty element\nbottle_name=bottle_name[nzchar(bottle_name)]\n# remove space element\nbottle_name=bottle_name[nchar(bottle_name)&gt;2]\nbottle_name\n\n\n[1] \"Blended Malt 44 yo 1978 (59,8%, Spheric Spirits 2023, refill sherry butt #6, 331 btl.)\"   \n[2] \"Springbank 27 yo 1994 (47,1%, Spheric Spirits 2022, refill sherry hogshead #95, 241 btl.)\"\n[3] \"Islay Malt 25 yo (48,4%, Spheric Spirits 2022, 407 btl.)\"                                 \n\n\n\n\n5 bottle_review\n\n\nCode\nbottle_review=review_page  %&gt;% html_elements(\"p\") %&gt;% html_text2()\nbottle_review\n\n\n [1] \"Spheric Spirits is a young indie bottler from Germany, started by Benedict and Claudio. They have a slightly edgy / flashy branding (check the website) – I like the vibrant colours on the labels but apparently not everything agrees. Besides whisky, they’re also looking at armagnac and destilado de agave. They’re not just bottlers, by the way, they like to get involved at the beginning of production.\"\n [2] \"First up is a Blended Malt 1978, which is probably old Long John blending stock. It ended up forgotten due to a change of brand ownership in 1981. If this is true, then the peated component is probably 1970s Laphroaig.\"                                                                                                                                                                                        \n [3] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n [4] \"Nose: indeed you get this old school faded peat mixed with tropical fruits. Yellow plums, papaya, dried pineapple slices, peach and drizzles of honey. There’s a good dose of polished wood and light coconut (giving it an American touch) as well as paraffin, pine needles, buttery cake dough, walnuts and hints of old Amontillado. Quite stunning so far, you don’t get this profile often.\"                 \n [5] \"Mouth: peatier now, and more woody. Hints of plums and melons, as well as tangerines and overripe bananas. Something of the 1960s Ben Nevis waxiness, coconut, and some bitter herbs. Then a grassy sharpness, some cinnamon and ginger, as well as butter cookies, hazelnuts and pipe tobacco. Slightly astringent at times, but still it’s an uncommon, intruiging profile including nicely medicinal smoke.\"    \n [6] \"Finish: long, honeyed but also spicy, with peppery notes and a little fruit tea. Caramelized nuts and wood until the very end.\"                                                                                                                                                                                                                                                                                    \n [7] \"I remember hesitating to buy a bottle of this blended malt – honestly I thought it was too expensive at € 800+. However after trying it, I’m hesitating again because it’s such a unique profile. Almost sold out, I believe, but still seen at Whisky-Maniac for instance.\"                                                                                                                                       \n [8] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n [9] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[10] \"Nose: very mineral, you could almost think of mezcal here. Plenty of linseed or sunflower oil and waxed canvas, wax candles and some vegetal hints. Light orchard fruits in second row, maybe even a hint of green pineapple. Then a mossy note and a drop of seawater. Very clean, with virtually voiceless sherry (unless it was Fino).\"                                                                         \n[11] \"Mouth: a rather wonderful mix of minerals and waxes, with green fruits. Think kiwi and green apple. Then chalky notes and more vegetal oils, as well as grapefruit. Fresh herbs and a little eucalyptus. Light coastal touches. Just a hint of marshmallow sweetness in the background.\"                                                                                                                           \n[12] \"Finish: long, still lean and elegant, with lime and herbs, barley sweetness and aniseed.\"                                                                                                                                                                                                                                                                                                                          \n[13] \"Again, not a cheap whisky but very well chosen. Reminds me of the Whisky Sponge 60a, although this one is even more clean. Perhaps too clean for some. Still listed on the website of Hogshead Imports, but I believe we’ll be too late… Score: 91/100\"                                                                                                                                                            \n[14] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[15] \"We end this (already impressive) session with a secret Islay Malt, a mix of the 1993 and 1994 vintages. Spheric Spirits tell us that this is one of the unusual batches produced on site in the early 1990s by the team of a neighbouring brand, just to keep the distillery operational. Isn’t that the time when Allied Distillers made Laphroaig at Ardbeg?\"                                                    \n[16] \"Medicinal peat smoke is well integrated into its otherwise fruity and citrusy nose. Even hints of tropical nuances are detectable. On the pallet sweet peat shows up more present with a salty tang. Lovely old school earthy medicinal peatiness, no bonfire smoke. The mouthfeel is incredibly oily and lingering.\"                                                                                              \n[17] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[18] \"Nose: nice engine oil along with medicinal peat. Perhaps a little smokier / Laphroaigier than some other ‘Begs? Mentholated notes and subtle antiseptics. Then delicated earthy notes, big hints of lemons and just a hint of vanilla. Soft orange notes, malty sweetness and peaches. All in all quite mild.\"                                                                                                     \n[19] \"Mouth: more intensely peaty now, more clearly Ardbeg. Big medicinal notes, with some tar in the distance, as well as smoked meat. Then some lighter, fruitier notes, a little salt, and a hint of tea leaves. Towards the end it becomes more narrow again, with sour citrus and mineral notes that remind me of Caol Ila.\"                                                                                        \n[20] \"Finish: long, citrusy, with hints of charcoal, light pear and tarry ropes. Just a subtle touch of bitter herbs.\"                                                                                                                                                                                                                                                                                                   \n[21] \"Some beautiful old school notes in here again, although they may not be entirely Ardbeg if you know what I mean. Sold out. I apologize for not discovering Spheric Spirits sooner. Score: 90/100\"                                                                                                                                                                                                                  \n[22] \"Your email address will not be published. Required fields are marked *\"                                                                                                                                                                                                                                                                                                                                            \n[23] \"Comment *\"                                                                                                                                                                                                                                                                                                                                                                                                         \n[24] \"Name *\"                                                                                                                                                                                                                                                                                                                                                                                                            \n[25] \"Email *\"                                                                                                                                                                                                                                                                                                                                                                                                           \n[26] \"Website\"                                                                                                                                                                                                                                                                                                                                                                                                           \n[27] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                  \n[28] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                  \n[29] \"Δdocument.getElementById( \\\"ak_js_1\\\" ).setAttribute( \\\"value\\\", ( new Date() ).getTime() );\"                                                                                                                                                                                                                                                                                                                      \n[30] \"This site uses Akismet to reduce spam. Learn how your comment data is processed.\"                                                                                                                                                                                                                                                                                                                                  \n[31] \"Begin typing your search above and press return to search. Press Esc to cancel.\"                                                                                                                                                                                                                                                                                                                                   \n\n\n\n\n6 bottle_review_Nose\n\n\nCode\nbottle_review_Nose=bottle_review[bottle_review %&gt;% str_detect('Nose:')]\nbottle_review_Nose\n\n\n[1] \"Nose: indeed you get this old school faded peat mixed with tropical fruits. Yellow plums, papaya, dried pineapple slices, peach and drizzles of honey. There’s a good dose of polished wood and light coconut (giving it an American touch) as well as paraffin, pine needles, buttery cake dough, walnuts and hints of old Amontillado. Quite stunning so far, you don’t get this profile often.\"\n[2] \"Nose: very mineral, you could almost think of mezcal here. Plenty of linseed or sunflower oil and waxed canvas, wax candles and some vegetal hints. Light orchard fruits in second row, maybe even a hint of green pineapple. Then a mossy note and a drop of seawater. Very clean, with virtually voiceless sherry (unless it was Fino).\"                                                        \n[3] \"Nose: nice engine oil along with medicinal peat. Perhaps a little smokier / Laphroaigier than some other ‘Begs? Mentholated notes and subtle antiseptics. Then delicated earthy notes, big hints of lemons and just a hint of vanilla. Soft orange notes, malty sweetness and peaches. All in all quite mild.\"                                                                                    \n\n\n\n\n7 bottle_review_Mouth\n\n\nCode\nbottle_review_Mouth=bottle_review[bottle_review %&gt;% str_detect('Mouth:')]\nbottle_review_Mouth\n\n\n[1] \"Mouth: peatier now, and more woody. Hints of plums and melons, as well as tangerines and overripe bananas. Something of the 1960s Ben Nevis waxiness, coconut, and some bitter herbs. Then a grassy sharpness, some cinnamon and ginger, as well as butter cookies, hazelnuts and pipe tobacco. Slightly astringent at times, but still it’s an uncommon, intruiging profile including nicely medicinal smoke.\"\n[2] \"Mouth: a rather wonderful mix of minerals and waxes, with green fruits. Think kiwi and green apple. Then chalky notes and more vegetal oils, as well as grapefruit. Fresh herbs and a little eucalyptus. Light coastal touches. Just a hint of marshmallow sweetness in the background.\"                                                                                                                       \n[3] \"Mouth: more intensely peaty now, more clearly Ardbeg. Big medicinal notes, with some tar in the distance, as well as smoked meat. Then some lighter, fruitier notes, a little salt, and a hint of tea leaves. Towards the end it becomes more narrow again, with sour citrus and mineral notes that remind me of Caol Ila.\"                                                                                    \n\n\n\n\n8 bottle_review_Finish\n\n\nCode\nbottle_review_Finish=bottle_review[bottle_review %&gt;% str_detect('Finish:')]\nbottle_review_Finish\n\n\n[1] \"Finish: long, honeyed but also spicy, with peppery notes and a little fruit tea. Caramelized nuts and wood until the very end.\"\n[2] \"Finish: long, still lean and elegant, with lime and herbs, barley sweetness and aniseed.\"                                      \n[3] \"Finish: long, citrusy, with hints of charcoal, light pear and tarry ropes. Just a subtle touch of bitter herbs.\"               \n\n\n\n\n9 first score\n\n\nCode\nfirst_bottle_score=review_page  %&gt;% html_elements(\".entry-score\") %&gt;% html_text2()\nfirst_bottle_score=first_bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n\n\n\n\n10 all other score\n\n\nCode\nbottle_score=review_page  %&gt;% html_elements(\"strong\") %&gt;% html_text2()\n  \nbottle_score2=bottle_score %&gt;% str_match('[0-9][0-9]/100') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n\nbottle_score2=bottle_score2 %&gt;% mutate(V1=str_replace(V1,'/100',''))\n\n\n\n\n11 combine all score\n\n\nCode\n# move the last one to the first one\nif(identical(bottle_score, character(0))==TRUE|nrow(bottle_score2)==0){\n    all_page_score=first_bottle_score %&gt;% tibble()%&gt;% rename(all_page_score='.') \n  }else{\n  #bottle_score=bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  all_page_score=rbind(first_bottle_score,bottle_score2) %&gt;% rename(all_page_score=V1) \n  }\nall_page_score\n\n\n  all_page_score\n1             92\n2             91\n3             90\n\n\n\n\n12 page_published_date\n\n\nCode\npage_published_date=review_page  %&gt;% html_elements(\".published\") %&gt;% html_text2()\npage_published_date\n\n\n[1] \"16 April 2024\"\n\n\n\n\n13 page_class\n\n\nCode\npage_class=review_page  %&gt;% html_elements(\".cat-links a\") %&gt;% html_text2()\npage_class=str_flatten(page_class,collapse = \"--\")\npage_class\n\n\n[1] \"* Blends--Ardbeg--Springbank\"\n\n\n\n\n14 page_title\n\n\nCode\npage_title=review_page  %&gt;% html_elements(\".entry-title\") %&gt;% html_text2()\npage_title\n\n\n[1] \"Spheric Spirits: Springbank / Blended Malt / Islay Malt\"\n\n\n\n\n15 combine all one_page_review\n\n\nCode\none_page_review=data_frame(bottle_name,bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish,all_page_score,page_class,page_published_date,page_title,review_url)\none_page_review\n\n\n# A tibble: 3 × 9\n  bottle_name        bottle_review_Nose bottle_review_Mouth bottle_review_Finish\n  &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;               \n1 Blended Malt 44 y… Nose: indeed you … Mouth: peatier now… Finish: long, honey…\n2 Springbank 27 yo … Nose: very minera… Mouth: a rather wo… Finish: long, still…\n3 Islay Malt 25 yo … Nose: nice engine… Mouth: more intens… Finish: long, citru…\n# ℹ 5 more variables: all_page_score &lt;chr&gt;, page_class &lt;chr&gt;,\n#   page_published_date &lt;chr&gt;, page_title &lt;chr&gt;, review_url &lt;chr&gt;\n\n\n\n\n16 output\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(one_page_review,'one_page_review.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "One page reveiw"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/3 whiskynote one year page.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/3 whiskynote one year page.html",
    "title": "One year page review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\nWeb scraping on www.whiskynotes.be\n\n1 year page\n\n\nCode\nyear_ur='https://www.whiskynotes.be/2023'\n\n\n\n\n\n2 read in html\n\n\nCode\nyear_page &lt;- read_html(year_ur)\n\n\n\n\n3 review bottle name on one year\n\n\nCode\nbottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\nbottle001[length(bottle001)]\n\n\n\n\nCode\n# drop last one which is not bottle\nbottle002=bottle001[-length(bottle001)]\nhead(bottle002,3)\n\n\n\n\nCode\nlength(bottle002)\n\n\n\n\nCode\n# split to each bottle \nbottle003=unlist(strsplit(bottle002,\"\\n\"))\n\n\n\n\nCode\nhead(bottle003,5)\n\n\n\n\nCode\nlength(bottle003)\n\n\n\n\n4 review topic name on one year\n\n\nCode\ntopic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\nhead(topic001)\n\n\n\n\nCode\nlength(topic001)\n\n\n\n\n5 review topic link on one year\n\n\nCode\ntopic_link_list &lt;- year_page %&gt;%\n  html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\nhead(topic_link_list)\n\n\n\n\nCode\nlength(topic_link_list)\n\n\n\n\n6 combine\n\n\nCode\ndata=tibble(topic001,topic_link_list)\n\n\n\n\nCode\nbottle003=tibble(bottle003)\n\n\n\n\n7 output\n\n\nCode\nlibrary(openxlsx)\nlist_of_datasets &lt;- list(\"Name of DataSheet1\" = data, \"Name of Datasheet2\" = bottle003)\n\nwrite.xlsx(list_of_datasets, file = \"on year page.xlsx\")\n\n\n\n\n8 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "One year page review"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#sleep",
    "href": "intro/1 basic R.html#sleep",
    "title": "Basic R",
    "section": "6.9 sleep",
    "text": "6.9 sleep\nThe time interval to suspend execution for, in seconds.\n\n\nCode\nSys.sleep(3)",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/1 whiskynote data.html",
    "href": "other/2 Web scraping on whiskybase.com/1 whiskynote data.html",
    "title": "Whiskynotes.be data",
    "section": "",
    "text": "1 whiskynotes.be data\nhttps://www.whiskynotes.be/\n\nWhiskyNotes is a personal collection of impressions, written while searching for the ultimate single malt whisky. A work in progress, and a continuous exercise for the senses.\nI started it in 2008 while living in Spain for a couple of years. I had discovered whisky a few years earlier but suddenly I was cut off from festivals, shops and whisky friends in my home country. A whisky blog seemed a good way of keeping in touch. It quickly gained a following, first in Belgium but now from all over the world.\n\n\n2 rvest package\nrvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "Whiskynotes.be data"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/1 whiskynote data.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/1 whiskynote data.html",
    "title": "Whiskynotes.be data",
    "section": "",
    "text": "1 whiskynotes.be data\nhttps://www.whiskynotes.be/\n\nWhiskyNotes is a personal collection of impressions, written while searching for the ultimate single malt whisky. A work in progress, and a continuous exercise for the senses.\nI started it in 2008 while living in Spain for a couple of years. I had discovered whisky a few years earlier but suddenly I was cut off from festivals, shops and whisky friends in my home country. A whisky blog seemed a good way of keeping in touch. It quickly gained a following, first in Belgium but now from all over the world.\n\n\n2 rvest package\nrvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Whiskynotes.be data"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/5 web scraping with rvest all.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/5 web scraping with rvest all.html",
    "title": "Web scraping with rvest on all year all topic",
    "section": "",
    "text": "1 one page function\n\n\nCode\none_page_function &lt;- function(review_url){\n\n     #review_url=\"https://www.whiskynotes.be/2023/linkwood/linkwood-2008-benrinnes-2000-glentauchers-2009-maltbarn/\"\n  \n  \n    tryCatch({\n\n    print(review_url)\n    review_page &lt;- read_html(review_url)\n    closeAllConnections()\n  }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n  \n\n  page_class=review_page  %&gt;% html_elements(\".cat-links a\") %&gt;% html_text2()\n  page_class=str_flatten(page_class,collapse = \"-\")\n  \n  bottle_name=review_page  %&gt;% html_elements(\".entry-content h2\") %&gt;% html_text2()\n  bottle_name=bottle_name[nzchar(bottle_name)]\n  \n  # remove ? mark non bottle name element\n  bottle_name=bottle_name[!bottle_name%&gt;% str_detect(\"\\\\?\")]\n  # remove Drams Delivered revisited  non bottle name element\n  bottle_name=bottle_name[ !bottle_name == 'Drams Delivered revisited']\n  print(bottle_name) \n  \n  bottle_review_raw=review_page  %&gt;% html_elements(\"p\") %&gt;% html_text()\n  bottle_review=unlist(strsplit(bottle_review_raw,\"(?= Nose: )\",perl = TRUE))\n  bottle_review=unlist(strsplit(bottle_review,\"(?= Mouth: )\",perl = TRUE))\n   bottle_review=unlist(strsplit(bottle_review,\"(?= Finish: )\",perl = TRUE))\n  \n  bottle_review_Nose=bottle_review[bottle_review %&gt;% str_detect('Nose:')]\n  bottle_review_Nose=bottle_review_Nose[nzchar(bottle_review_Nose)]\n\n  bottle_review_Mouth=bottle_review[bottle_review %&gt;% str_detect('Mouth:')]\n  bottle_review_Mouth=bottle_review_Mouth[nzchar(bottle_review_Mouth)]\n\n  bottle_review_Finish=bottle_review[bottle_review %&gt;% str_detect('Finish:')]\n  bottle_review_Finish=bottle_review_Finish[nzchar(bottle_review_Finish)]\n  \n  ########### add dummy score if there is no score review #########\n  # bottle_review_Finish_score=bottle_review[bottle_review %&gt;% str_detect('Finish:|Score:')][-1]\n \n  # # bottle_review_Finish_score2=bottle_review_Finish_score\n  \n  \n  # order=1\n  # for (word in bottle_review_Finish_score){\n  #   print(word)\n  #   print(order)\n  #   print(order%%2)\n  #   print(word %&gt;% str_detect('Score:'))\n  #   print(order%%2==0 & word %&gt;% str_detect('Score:')==FALSE)\n  #   if (order%%2==0 & word %&gt;% str_detect('Score:')==FALSE){\n  #     print('adding add dummy score if there is no score review ')\n  #     bottle_review_Finish_score2=append(bottle_review_Finish_score2,'Score:00/100',order-1)\n  #   }else{\n  #   }\n  #   order=order+1\n  #   }\n################################################\n    \n  \n  \n  first_bottle_score=review_page  %&gt;% html_elements(\".entry-score\") %&gt;% html_text2()\n\n  bottle_score=review_page  %&gt;% html_elements(\"strong\") %&gt;% html_text2()\n  \n  bottle_score2=bottle_score %&gt;% str_match('[0-9][0-9]/100') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  bottle_score2=bottle_score2 %&gt;% mutate(V1=str_replace(V1,'/100',''))\n\n\n  if(identical(bottle_score, character(0))==TRUE|nrow(bottle_score2)==0){\n    all_page_score=first_bottle_score %&gt;% tibble()%&gt;% rename(all_page_score='.') \n  }else{\n  #bottle_score=bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  all_page_score=rbind(first_bottle_score,bottle_score2) %&gt;% rename(all_page_score=V1) \n  }\n\n  page_published_date=review_page  %&gt;% html_elements(\".published\") %&gt;% html_text2()\n\n\n  page_title=review_page  %&gt;% html_elements(\".entry-title\") %&gt;% html_text2()\n  \n  if(nrow(all_page_score)!=length(bottle_name)){all_page_score=0}\n  if(length(bottle_review_Nose)!=length(bottle_name)){bottle_review_Nose='no comment'}\n  if(length(bottle_review_Mouth)!=length(bottle_name)){bottle_review_Mouth='no comment'}\n  if(length(bottle_review_Finish)!=length(bottle_name)){bottle_review_Finish='no comment'}\n  \n  \n  \n  one_page_review=tibble(bottle_name,bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish,all_page_score,page_class,page_published_date,page_title,review_url) \n  \n\n  Sys.sleep(runif(n=1, min=0.1, max=0.8))\n  #print(one_page_review)\n  print(dim(one_page_review))\n  #remove(review_page)\n  return(one_page_review)\n}\n\n\n\n\n2 read in all link\n\n\nCode\nlibrary(readxl)\ntopic_link=read_excel('all year page.xlsx',sheet='topic')\n\n\n\n\nCode\nglimpse(topic_link)\n\n\nexclude news\n\n\nCode\nnews=topic_link$topic_link_list %&gt;% str_detect('/whisky-news/')\n\n\n\n\nCode\ntopic_link002=topic_link$topic_link_list[!news]\n\n\n\n\nCode\nlength(topic_link002)\n\n\n\n\nCode\ntopic_link_small=head(topic_link002,10)\n\n\n\n\n3 start downlaod all page\n\n\nCode\nlibrary(openxlsx)\n\npage=topic_link002\n\n\nall_page_review_list=data.frame()\n\nstart_time=Sys.time()\nprint(paste0(\"Start time: \", start_time))\n\nloop_num=0\n\nfor (i in page){\n   loop_num=loop_num+1\n   print(paste0(\"Running loop No.\",which(page==i)))\n         \n   print(paste0(\"current time: \", Sys.time()))\n   a=one_page_function(i)\n   all_page_review_list=rbind(all_page_review_list,a)\n   print(paste0(\"Used time: \", Sys.time()-start_time))\n   # ouput every 20 page\n   if (loop_num%%20==0){\n     print(paste0(\"output to excel: \", loop_num))\n     write.xlsx(all_page_review_list,'all_page_review_list.xlsx')\n     }\n}\n\nend_time=Sys.time()\nprint(paste0(\"End time: \", end_time))\nprint(paste0(\"total used time: \", end_time-start_time))\n\n\n\n\nall_page_review_list_final=all_page_review_list %&gt;% filter(all_page_score!=0& bottle_review_Mouth!='no comment')\n\nwrite.xlsx(all_page_review_list_final,'all_page_review_list_final.xlsx')\n\n\n\n\n4 output\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(all_page_review_list,'all_page_review_list.xlsx')\n\n\n\n\n5 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Web scraping with rvest on all year all topic"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#error-handling-on-for-loopprint-out-error",
    "href": "intro/1 basic R.html#error-handling-on-for-loopprint-out-error",
    "title": "Basic R",
    "section": "3.2 Error handling on for Loop:print out error",
    "text": "3.2 Error handling on for Loop:print out error\n\n\nCode\nstuff &lt;- list(12, 9, 2, \"cat\", 25, 10, \"bird\")\n#stuff\n\n\n\n\nCode\nloop_num=0\n\nfor (i in 1:6) {\n  loop_num=loop_num+1\n  tryCatch (print(1+i),\n           \n           error = function(e){\n           message(paste(\"An error occurred for loop num\", loop_num,\":\\n\"), e)\n             \n         })\n}\n\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/5 web scraping with rvest all first time.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/5 web scraping with rvest all first time.html",
    "title": "All year all topic first time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n1 one page function\n\n\nCode\nsource('one_page.r')\n\n\n\n\n2 read in all link\n\n\nCode\nlibrary(readxl)\ntopic_link=read_excel('./output/all year page2.xlsx',sheet='topic')\n\n\n\n\nCode\nglimpse(topic_link)\n\n\nexclude news\n\n\nCode\nnews=topic_link$topic_link_list %&gt;% str_detect('/whisky-news/')\n\n\n\n\nCode\ntopic_link002=topic_link$topic_link_list[!news]\n\n\n\n\nCode\nlength(topic_link002)\n\n\n\n\n3 start downlaod all page on first first try\n\n\nCode\n#test=one_page_function('https://www.whiskynotes.be/2020/irish-whiskey/teeling-1996-fill-your-own-teeling-chinkapin-oak-single-pot-still-distillery-exclusive/')%&gt;% mutate(loop_num=3)\n\n\n\n\nCode\nsink(\"log3.txt\", append=FALSE, split=TRUE)  # for screen and log\n\nlibrary(openxlsx)\n\npage=topic_link002\n\n\nall_page_review_list=data.frame()\n\nstart_time=Sys.time()\nprint(paste0(\"Start time: \", start_time))\n\nloop_num=0\n\nfor (i in page){\n   tryCatch({\n#############################     \n   loop_num=loop_num+1\n   print(paste0(\"################ Running loop No.\",which(page==i)))\n         \n   print(paste0(\"current time: \", Sys.time()))\n   \n   output=one_page_function(i) %&gt;% mutate(loop_num=loop_num)\n\n   all_page_review_list=rbind(all_page_review_list,output)\n   \n   print(paste0(\"Used time: \", Sys.time()-start_time))\n   # ouput every 20 page\n   if (loop_num%%20==0){\n      print(paste0(\"############################## output to excel: \", loop_num))\n      write.xlsx(all_page_review_list,'./output/all_page_bottle_list3.xlsx')\n     }\n    \n   \n#############################        \n    }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n}\n\nend_time=Sys.time()\nprint(paste0(\"End time: \", end_time))\nprint(paste0(\"total used time: \", end_time-start_time))\n\nwrite.xlsx(all_page_review_list,'./output/all_page_bottle_list3.xlsx')\n\nsink()\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year all topic first time"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/6 web scraping with rvest all second time.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/6 web scraping with rvest all second time.html",
    "title": "All year all topic second time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n1 one page function\n\n\nCode\nsource('one_page.r')\n\n\n\n\n2 read in all link\n\n\nCode\nlibrary(readxl)\ntopic_link=read_excel('./output/all year page.xlsx',sheet='topic')\n\n\n\n\nCode\nglimpse(topic_link)\n\n\nexclude news\n\n\nCode\nnews=topic_link$topic_link_list %&gt;% str_detect('whisky-news|whisky-bar')\n\n\n\n\nCode\ntopic_link002=topic_link$topic_link_list[!news]\n\n\nexclude no score page:\n\n\nCode\nno_score_page=c(\n\"https://www.whiskynotes.be/2011/blends/bloggers-blend-masterofmalt/\"         \n,\"https://www.whiskynotes.be/2012/glenfarclas/glenfarclas-1968-mytribute-5241/\"\n,\"https://www.whiskynotes.be/2012/ancnoc/ancnoc-distillery-visit/\"             \n,\"https://www.whiskynotes.be/2012/distillery-visits/old-pulteney/\"             \n,\"https://www.whiskynotes.be/2013/blends/cutty-sark-storm-appletiser/\"         \n,\"https://www.whiskynotes.be/2013/glenfarclas/glenfarclas-verticale/\"  \n)\n\n\n\n\n3 read in donload page:\n\n\nCode\nfinish_download=read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\nCode\nfinish_download_topic_link=unique(finish_download$review_url)\n\n\n\n\nCode\nlength(finish_download_topic_link)\n\n\n\n\nCode\nnon_finish_link=topic_link002 [! topic_link002 %in% c(finish_download_topic_link,no_score_page)]\n\n\n\n\nCode\nlength(non_finish_link)\n\n\n\n\n4 download non download page:\n\n\nCode\nlibrary(openxlsx)\npage=non_finish_link\n\nall_page_review_list=data.frame()\n\nstart_time=Sys.time()\nprint(paste0(\"Start time: \", start_time))\n\nloop_num=0\n\nfor (i in page){\n   tryCatch({\n#############################     \n   loop_num=loop_num+1\n   print(paste0(\"Running loop No.\",which(page==i)))\n         \n   print(paste0(\"current time: \", Sys.time()))\n   \n   output=one_page_function(i)\n\n   all_page_review_list=rbind(all_page_review_list,output)\n   \n   \n   print(paste0(\"Used time: \", Sys.time()-start_time))\n   # ouput every 20 page\n   if (loop_num%%20==0){\n      print(paste0(\"#########################. output to excel: \", loop_num))\n      all_page_review_list_total=rbind(finish_download,all_page_review_list)\n      write.xlsx(all_page_review_list_total,'./output/all_page_bottle_list_all.xlsx')\n     }\n    \n   \n#############################        \n    }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n}\n\nend_time=Sys.time()\nprint(paste0(\"End time: \", end_time))\nprint(paste0(\"total used time: \", end_time-start_time))\n\n\noutput=one_page_function(i)\n\nall_page_review_list_total=rbind(finish_download,all_page_review_list)\n   \nwrite.xlsx(all_page_review_list_total,'./output/all_page_bottle_list_all.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year all topic second time"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-unique-vector",
    "href": "data manipulation/2 data structure in R.html#create-unique-vector",
    "title": "Data structure in R",
    "section": "1.4 create unique vector",
    "text": "1.4 create unique vector\n\n\nCode\nv1=c(1,1,2,2,5,6)\nv1\n\n\n[1] 1 1 2 2 5 6\n\n\n\n\nCode\nunique(v1)\n\n\n[1] 1 2 5 6",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#remove-element-in-vector",
    "href": "data manipulation/2 data structure in R.html#remove-element-in-vector",
    "title": "Data structure in R",
    "section": "1.6 remove element in vector",
    "text": "1.6 remove element in vector\n\n\nCode\nx=c(1,2,3,4,5)\nx\n\n\n[1] 1 2 3 4 5\n\n\n\n1.6.1 remove first one\n\n\nCode\nx[-1]\n\n\n[1] 2 3 4 5\n\n\n\n\n1.6.2 remove last one\n\n\nCode\nx[-length(x)]\n\n\n[1] 1 2 3 4\n\n\n\n\n1.6.3 remove from last second\n\n\nCode\nx[1:(length(x)-2)]\n\n\n[1] 1 2 3\n\n\n\n\n1.6.4 remove from from another vector\n\n\nCode\nremove=c(2,4)\nx[-remove]\n\n\n[1] 1 3 5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/whiskybase data.html",
    "href": "other/2 Web scraping on whiskybase.com/whiskybase data.html",
    "title": "Whiskybase data",
    "section": "",
    "text": "1 whiskybase data\nhttps://www.whiskybase.com/\n\nFounded in the Netherlands in 2007, we’re the world’s premier provider of whisky data, shopping, and whisky-related services. We reach whisky enthusiasts and whisky professionals in nearly every country at all stages of their whisky journey.\nMillions of people use Whiskybase.com to look up their whisky bottles, organize a collection, plan a whisky event, or document their whisky experiences by adding ratings, reviews, and more to our whisky database, the world’s largest.\n\n\n2 rvest package\nrvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "Whiskybase data"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/2 whiskyfun one page.html",
    "href": "other/3 Web scraping on whiskyfun.com/2 whiskyfun one page.html",
    "title": "on page",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 review page\n\n\nCode\nreview_url='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\n\n#review_url='https://www.whiskynotes.be/2011/port-ellen/port-ellen-10th-release-1978/'\n\n\n\n\n2 read in html\n\n\nCode\nreview_page &lt;- read_html(review_url)\n\n\n\n\n3 bottle_review\n\n\nCode\nbottle_review=review_page  %&gt;% html_elements(\"p , .textegrandfoncegras , .textegrandfoncegras .TextenormalNEW , .Textenormal .textenormalgras , .Textenormal .TextenormalNEW , td.TextenormalNEW\") %&gt;% html_text2()\n# remove space element\n\nbottle_review1=bottle_review[bottle_review %&gt;% str_detect('SGP:')] \n\nbottle_review2=bottle_review1[bottle_review1 %&gt;% str_detect('Nose:')] \n\nbottle_review2=bottle_review2%&gt;% str_replace(\"Palate:\", \"Mouth\")%&gt;% str_replace(\"–\", \"-\")\n\n\nss=head(bottle_review2)\n\n\n\n\n4 bottle_name\n\n\nCode\nbottle_name=str_extract(bottle_review2, \n regex( \"[^)]+\")\n    )\nbottle_name=paste0(bottle_name,\")\")\nlength(bottle_name)\n\n\n\n\n5 bottle_score\n\n\nCode\nres &lt;- str_match(bottle_review2, \"SGP:\\\\s*(.*?)\\\\s*points\")\n\nbottle_score=paste(\"SGP:\",res[,2],\" points\")\n\nlength(bottle_score)\n\n\n\n\n6 bottle__final_score\n\n\nCode\nres &lt;- str_match(bottle_score, \" - \\\\s*(.*?)\\\\s*points\")\n\nbottle_final_score=res[,2]\n\nlength(bottle_final_score)\n\n\n\n\nCode\nbottle_score[91]\nbottle_final_score[91]\n\n\n\n\nCode\nbottle_score[92]\nbottle_final_score[92]\n\n\n\n\n7 Nose\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Nose:\\\\s*(.*?)\\\\s*Mouth\")\n\nbottle_name_nose=paste(\"Nose:\",res[,2])\n\nlength(bottle_name_nose)\n\n\n\n\n8 Mouth\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Mouth\\\\s*(.*?)\\\\s*Finish:\")\n\nbottle_name_mouth=paste(\"Mouth:\",res[,2])\n\nlength(bottle_name_mouth)\n\n\n\n\n9 Colour\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Colour\\\\s*(.*?)\\\\s*\\\\.\")\n\nbottle_name_colour=paste(\"Colour \",res[,2])\n\nlength(bottle_name_colour)\n\n\n\n\n10 bottle_name_finish\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Finish:\\\\s*(.*?)\\\\s*Comments:\")\nbottle_name_finish=paste(\"Finish:\",res[,2])\n\nlength(bottle_name_finish)\n\n\n\n\n11 bottle_name_comments\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Comments:\\\\s*(.*?)\\\\s*SGP:\")\nbottle_name_comments=paste(\"Comments:\",res[,2])\n\nlength(bottle_name_comments)\n\n\n\n\n12 combine\n\n\nCode\ndata=tibble(bottle_name,bottle_name_nose,bottle_name_mouth,bottle_name_finish,bottle_name_colour,bottle_name_comments,bottle_score,bottle_final_score,review_url)\n\nhead(data)\n\n\n\n\n13 output\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(data, file = \"./output/whiskyfun one page.xlsx\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "on page"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/1 whiskyfun data.html",
    "href": "other/3 Web scraping on whiskyfun.com/1 whiskyfun data.html",
    "title": "whiskyfun data",
    "section": "",
    "text": "1 whiskyfun data\nhttps://www.whiskyfun.com/\n\nI’m just an amateur whisky lover and I live in a part of France called Alsace, near the German border. I co-own two advertising agencies (200 people). I insist, I’m not a whisky pro, not even a proam. I like to talk about whisky with my friends the Malt Maniacs (and many other friends) but what I like best is tasting whisky. I do all that for fun, just for fun. I think whisky is serious matter only to people who make or sell it – or to people who drink way too much of it. What’s more, I like many other things, like all kinds of music, advertising (my work), motorcycling, wine, old watches, food, travelling and God knows what else. You know, toys for boys. And yes, friends… And last time I checked I was 49, happily married, three lovely children (who drink no whisky).—-Serge Valentin\n\n\n2 package\nrvest chromote selenium selenider\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "whiskyfun data"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/1 whiskybase data.html",
    "href": "other/2 Web scraping on whiskybase.com/1 whiskybase data.html",
    "title": "Whiskybase data",
    "section": "",
    "text": "1 whiskybase data\nhttps://www.whiskybase.com/\n\nFounded in the Netherlands in 2007, we’re the world’s premier provider of whisky data, shopping, and whisky-related services. We reach whisky enthusiasts and whisky professionals in nearly every country at all stages of their whisky journey.\nMillions of people use Whiskybase.com to look up their whisky bottles, organize a collection, plan a whisky event, or document their whisky experiences by adding ratings, reviews, and more to our whisky database, the world’s largest.\n\n\n2 package\nrvest chromote selenium selenider\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "Whiskybase data"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/3 whiskyfun all page link.html",
    "href": "other/3 Web scraping on whiskyfun.com/3 whiskyfun all page link.html",
    "title": "All page link frist time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 all review page\n\n\n2 first page\n\n\nCode\nfirst_url='https://www.whiskyfun.com'\nfirst_page=read_html(first_url)\n\n\n\n\nCode\nlast_page &lt;- first_page %&gt;%\n  html_elements(css = \"a.textegrandfoncegras\")%&gt;% html_attr(\"href\")\n\n\n\n\n3 start from secound page\n\n\nCode\npage_list=c()\n\n\n\n\nCode\nurl='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\n\npage=read_html(first_url)\n\nlast_page &lt;- (first_page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n\nprint(last_page)\npage_list=c(page_list,last_page)\n\n\n\n\n4 start to download 500 pages\n\n\nCode\nlast_page='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\npage_list=c()\n\nfor (i in seq(1:500)){\n  print(i)\n  page=read_html(last_page)\n  last_page &lt;- (page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n  last_page=paste0('https://www.whiskyfun.com/',last_page)\n  print(last_page)\n  page_list=c(page_list,last_page)\n  Sys.sleep(runif(n=1, min=0.1, max=0.8))\n  \n  \n  }\n\n\n\n\nCode\npage_list_data=page_list %&gt;% tibble()\n\n\n\n\n5 ouput\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(page_list_data, file = \"./output/wf_all_page_review.xlsx.xlsx\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page link frist time"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/4 whiskyfun all page.html",
    "href": "other/3 Web scraping on whiskyfun.com/4 whiskyfun all page.html",
    "title": "All page second time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 all review page\n\n\n2 first page\n\n\nCode\nfirst_url='https://www.whiskyfun.com'\nfirst_page=read_html(first_url)\n\n\n\n\nCode\nlast_page &lt;- first_page %&gt;%\n  html_elements(css = \"a.textegrandfoncegras\")%&gt;% html_attr(\"href\")\n\n\n\n\n3 start from secound page\n\n\nCode\npage_list=c()\n\n\n\n\nCode\nurl='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\n\npage=read_html(first_url)\n\nlast_page &lt;- (first_page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n\nprint(last_page)\npage_list=c(page_list,last_page)\n\n\n\n\n4 start to download 500 pages\n\n\nCode\nlast_page='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\n\npage_list=c()\ndata_list=tibble()\n\ni=0\na=0\n\nwhile (i &lt; 500) {\n  loop_num=i\n  print(paste0(\"current page: \",loop_num))\n  old_page=last_page\n  tryCatch({\n    page=read_html(last_page)\n    i=i+1\n    \n  Sys.sleep(runif(n=1, min=0.1, max=0.3))\n },error = function(msg){print('eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee')\n    i=i-1\n    print(paste0(\"new i : \",i))\n    a=a+1\n    })\n   if(a&gt;10){break}\n  \n\n last_page &lt;- (page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n  last_page=paste0('https://www.whiskyfun.com/',last_page)\n    \n  page_link_count=str_count(last_page,'www.whiskyfun.com')\n  last_page=ifelse(page_link_count==2,str_replace(last_page,\"https://www.whiskyfun.com/\",\"\"),last_page)\n  \n  last_page=last_page\n  print(last_page)\n  page_list=c(page_list,last_page)\n  \n  #######################\n  review_html_elements=\".textegrandfoncegras , .TextenormalNEW, .Textenormal,td &gt; font,div td font\"\n  bottle_review=page  %&gt;% html_elements(review_html_elements) %&gt;% html_text2()\n# remove space element\n\n  bottle_review1=bottle_review[bottle_review %&gt;% str_detect(' points')]\n\n  bottle_review2=bottle_review1[bottle_review1 %&gt;% str_detect('Nose:')]\n\n  bottle_review2=bottle_review2%&gt;% str_replace(\"Palate:\", \"Mouth\")%&gt;% str_replace(\"–\", \"-\")\n\n  bottle_name=str_extract(bottle_review2, regex( \"[^)]+\"))\n  bottle_name=paste0(bottle_name,\")\")\n  print(head(bottle_name,2))\n  print(paste0(\"this page have bottle: \",length(bottle_name)))\n  \n\n  ##### break the loop if can not download continue &gt;=3 pages\n  if (length(bottle_name)==1){fail_num=fail_num+1}else{fail_num=0}\n    \n  if (fail_num&gt;=3){\n    print(paste0(\"breaking page url: \",old_page))\n    break\n    }\n  ################################################################\n  \n  # res &lt;- str_match(bottle_review2, \" \\\\s*(.*?)\\\\s*points\")\n  # bottle_score=paste(\"SGP:\",res[,2],\" points\")%&gt;% str_replace(\"–\", \"-\")\n  # \n  # res &lt;- str_match(bottle_score, \" - \\\\s*(.*?)\\\\s*points\")\n  # bottle_final_score=res[,2]\n  # \n  # res &lt;- str_match(bottle_review2, \"Nose:\\\\s*(.*?)\\\\s*Mouth\")\n  # bottle_name_nose=paste(\"Nose:\",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Mouth\\\\s*(.*?)\\\\s*Finish:\")\n  # bottle_name_mouth=paste(\"Mouth:\",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Colour\\\\s*(.*?)\\\\s*\\\\.\")\n  # bottle_name_colour=paste(\"Colour \",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Finish:\\\\s*(.*?)\\\\s*Comments:\")\n  # bottle_name_finish=paste(\"Finish:\",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Comments:\\\\s*(.*?)\\\\s*SGP:\")\n  # bottle_name_comments=paste(\"Comments:\",res[,2])\n  # \n  # data=tibble(bottle_review2,bottle_name,bottle_name_nose,bottle_name_mouth,bottle_name_finish,bottle_name_colour,bottle_name_comments,bottle_score,bottle_final_score,old_page,loop_num) %&gt;% unique()\n  # \n  # data_list=rbind(data_list,data)\n  # print(paste0(\"total bootle downlaoded: \",nrow(data_list)))\n  data=tibble(bottle_review2,bottle_name,old_page,loop_num) %&gt;% unique()\n  data_list=rbind(data_list,data)\n  print(paste0(\"total bootle downlaoded: \",nrow(data_list)))\n  \n\n  ####### ouput every 10 page\n  if (i%%10==0){\n\n      print(paste0(\"output to excel: \", i))\n      write.xlsx(data_list,'all_page_review_all.xlsx')\n     }\n  \n  Sys.sleep(runif(n=1, min=0.1, max=0.5))\n}\n\nwrite.xlsx(data_list,'all_page_review_all.xlsx')\n\n\n\n\n5 after(https://www.whiskyfun.com/ArchiveSeptember04.html) start to download 10 pages\n\n\nCode\nlast_page='https://www.whiskyfun.com/ArchiveSeptember04.html'\nfail_num=0\npage_list=c()\ndata_list=tibble()\n\nfor (i in seq(1:100)){\n\n  print(paste0(\"current page\",i))\n  old_page=last_page\n  tryCatch({\n    page=read_html(last_page)\n    Sys.sleep(runif(n=1, min=0.1, max=0.5))\n  }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n  \n  Sys.sleep(runif(n=1, min=0.1, max=0.3))\n  \n  last_page &lt;- (page %&gt;%html_elements(\"font:nth-child(1) b a\")%&gt;%html_attr(\"href\"))[1]\n  last_page=paste0('https://www.whiskyfun.com/',last_page)\n    \n  page_link_count=str_count(last_page,'www.whiskyfun.com')\n  last_page=ifelse(page_link_count==2,str_replace(last_page,\"https://www.whiskyfun.com/\",\"\"),last_page)\n  \n  last_page=last_page\n  print(last_page)\n  page_list=c(page_list,last_page)\n  \n  #######################\n  review_html_elements=\".textegrandfoncegras , .TextenormalNEW, .Textenormal,td &gt; font,div td font\"\n  bottle_review=page  %&gt;% html_elements(review_html_elements) %&gt;% html_text2()\n# remove space element\n\n  bottle_review1=bottle_review[bottle_review %&gt;% str_detect(' points')]\n\n  bottle_review2=bottle_review1[bottle_review1 %&gt;% str_detect('Nose:')]\n\n  bottle_review2=bottle_review2%&gt;% str_replace(\"Palate:\", \"Mouth\")%&gt;% str_replace(\"–\", \"-\")\n\n  bottle_name=str_extract(bottle_review2, regex( \"[^)]+\"))\n  bottle_name=paste0(bottle_name,\")\")\n  print(head(bottle_name,1))\n  print(paste0(\"this page have bottle: \",length(bottle_name)))\n  \n\n  ##### break the loop if can not download continue &gt;=3 pages\n  if (length(bottle_name)==1){fail_num=fail_num+1}else{fail_num=0}\n    \n  if (fail_num&gt;=3){\n    print(paste0(\"breaking page url: \",old_page))\n    break\n    }\n  ################################################################\n  \n  res &lt;- str_match(bottle_review2, \" \\\\s*(.*?)\\\\s*points\")\n  bottle_score=paste(\"SGP:\",res[,2],\" points\")%&gt;% str_replace(\"–\", \"-\")\n\n  res &lt;- str_match(bottle_score, \" - \\\\s*(.*?)\\\\s*points\")\n  bottle_final_score=res[,2]\n\n  res &lt;- str_match(bottle_review2, \"Nose:\\\\s*(.*?)\\\\s*Mouth\")\n  bottle_name_nose=paste(\"Nose:\",res[,2])\n\n  res &lt;- str_match(bottle_review2, \"Mouth\\\\s*(.*?)\\\\s*Finish:\")\n  bottle_name_mouth=paste(\"Mouth:\",res[,2])\n\n  res &lt;- str_match(bottle_review2, \"Colour\\\\s*(.*?)\\\\s*\\\\.\")\n  bottle_name_colour=paste(\"Colour \",res[,2])\n\n  res &lt;- str_match(bottle_review2, \"Finish:\\\\s*(.*?)\\\\s*Comments:\")\n  bottle_name_finish=paste(\"Finish:\",res[,2])\n\n  res &lt;- str_match(bottle_review2, \"Comments:\\\\s*(.*?)\\\\s*SGP:\")\n  bottle_name_comments=paste(\"Comments:\",res[,2])\n\n  data=tibble(bottle_review2,bottle_name,bottle_name_nose,bottle_name_mouth,bottle_name_finish,bottle_name_colour,bottle_name_comments,bottle_score,bottle_final_score,old_page) %&gt;% unique()\n\n  data_list=rbind(data_list,data)\n  # ouput every 10 page\n  if (i%%10==0){\n      print(paste0(\"output to excel: \", i/10))\n      write.xlsx(data_list,'all_page_review_v2.xlsx')\n     }\n  \n  Sys.sleep(runif(n=1, min=0.1, max=0.5))\n}\n\nwrite.xlsx(data_list,'all_page_review_missing.xlsx')\n\n\n\n\n6 download missing pages with speical method\n\n\nCode\nmissing_page=c('https://www.whiskyfun.com/archiveaugust22-2-Speyburn-Caroni.html'\n               ,'https://www.whiskyfun.com/archivejuly22-2-Strathisla-Dufftown.html')\n\n\n\n\n7 ouput\n\n\nCode\nwrite.xlsx(data_list,'wf_all_page_review.xlsx')\n#write.xlsx(page_list_data,'all_page_link.xlsx')\n\n\n\n\n8 whiskyfun first page\nhttps://www.whiskyfun.com/ArchiveJan04.html\n\n\n9 whiskyfun last muic page\nhttps://www.whiskyfun.com/archivejanuary18-1-Linkwood-Ardmore-Clynelish.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page second time"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-txt",
    "href": "data manipulation/1 input ouput.html#write-txt",
    "title": "input & ouput in R",
    "section": "2.5 write txt",
    "text": "2.5 write txt\n\n\nCode\ntext=tibble('hello world\nits time!')\n\nwrite_delim(text, \"text.txt\")",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#error-handling-on-whie-loop-try-when-the-error-gone",
    "href": "intro/1 basic R.html#error-handling-on-whie-loop-try-when-the-error-gone",
    "title": "Basic R",
    "section": "3.4 Error handling on whie Loop: try when the error gone",
    "text": "3.4 Error handling on whie Loop: try when the error gone\n\n\nCode\ni=0\na=0\nwhile (i &lt; 4) {\n  a=a+1\n  print(i)\n  tryCatch({\n  asdfgaergae5gh5hae5h\n    i=i+1\n  },error = function(msg){print('eeeeeeee')\n    i=i-1\n    print(paste0(\"new i : \",i))\n   \n    })\n   if(a&gt;10){break}\n  }\n\n\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/5 whiskyfun all page data cleaning.html",
    "href": "other/3 Web scraping on whiskyfun.com/5 whiskyfun all page data cleaning.html",
    "title": "All page clean up",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 input\n\n\nCode\ndata001=read_excel('all_page_review_1001-2000.xlsx')\n\n\n\n\nCode\nglimpse(data001)\n\n\n\n\nCode\n'asdgarsg d552 points'%&gt;% str_extract(\"[:digit:][:digit:][:space:]points\")\n\n\n\n\nCode\ndata002=data001%&gt;% mutate(\n  \n  bottle_review2=bottle_review2%&gt;% str_replace(\"–\", \"-\")%&gt;% str_replace(\"Palate:\", \"Mouth\")\n  ,name=paste0(str_extract(bottle_review2, regex( \"[^)]+\")),\")\")\n  \n  ,colour=(bottle_review2 %&gt;% str_match(\"Colour\\\\s*(.*?)\\\\s*\\\\.\"))[,2]\n  ,nose=(bottle_review2 %&gt;% str_match(\"Nose:\\\\s*(.*?)\\\\s*Mouth\"))[,2]\n  ,mouth=(bottle_review2 %&gt;% str_match(\"Mouth\\\\s*(.*?)\\\\s*Finish:\"))[,2]\n  ,finish=(bottle_review2 %&gt;% str_match(\"Finish:\\\\s*(.*?)\\\\s*Comments:\"))[,2]\n  ,comments=(bottle_review2 %&gt;% str_match(\"Comments:\\\\s*(.*?)\\\\s*SGP:\"))[,2]\n  \n  #,full_score=(bottle_review2 %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n  ,full_score=(bottle_review2 %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n  ,score=full_score %&gt;% str_replace(\"points.\",\"\") %&gt;% as.numeric()\n  \n  ,review_date=((str_match(old_page %&gt;%str_to_lower(),\"https://www.whiskyfun.com/archive\\\\s*(.*?)\\\\s*-\"))[,2] )%&gt;% str_to_title()\n  ,review_date2= myd(review_date, truncated = 1)\n  ,review_year=year(review_date2)\n)\n\nglimpse(data002)\n\n\n\n\nCode\nwrite.xlsx(data002,'test.xlsx')\n\n\nPort Ellen 12 yo (OB, The Queen’s Visit to Port Ellen’s Maltings, 1980)\nFebruary 4, 2015 https://www.whiskyfun.com/archivefebruary15-1-Ardbeg-Laphroaig-Caol-Ila-Lagavulin-Bowmore-Bunnahabhain.html\nSGP:657 - 99 points.\n\n\nCode\n(\"he short run): 99 points. SGP:920 - 49 points.\" %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n\n\n\n\nCode\ndata002=data001 %&gt;% mutate(\n  page_link_count=str_count(old_page,'www.whiskyfun.com'))%&gt;%mutate(\n    page_link=ifelse(page_link_count==2,str_replace(old_page,\"https://www.whiskyfun.com/\",\"\"),old_page))%&gt;%mutate(\n    after_page_link_count=str_count(page_link,'www.whiskyfun.com')) %&gt;% mutate(\n      review_date=((str_match(page_link,\"https://www.whiskyfun.com/archive\\\\s*(.*?)\\\\s*-\"))[,2] )%&gt;% str_to_title()\n      ,review_date2= myd(review_date, truncated = 1)\n      ,review_year=year(review_date2)\n      ,bottle_score=str_replace(bottle_score,'–','-')\n      ,bottle_final_score= (bottle_score%&gt;% str_match(\"-\\\\s*(.*?)\\\\s*points\"))[,2]\n        ,score=bottle_final_score %&gt;% str_extract(\"(\\\\d)+\")%&gt;% as.numeric()           \n              ,review_year_flag=ifelse(review_year&gt;=2020,'&gt;=2020','&lt;2020')    \n    ) %&gt;% arrange(desc(score))\n\n\n\n\nCode\ndata003=data002 %&gt;%  filter(review_date2&gt;='2010-01-01'\n                            ,score&lt;=98)\n                            #,score&gt;=70)\n\n\n\n\nCode\nglimpse(data003)\n\n\n\n\nCode\nlibrary(scales)\ntest001a=data003 %&gt;% filter(review_year&gt;=2018) %&gt;% group_by(score) %&gt;% summarise(n=n()) %&gt;% mutate(percent = (n/sum(n))) %&gt;% arrange(desc(score)) %&gt;% mutate(review_year_flag='&gt;=2020')\n\n\n\n\nCode\nlibrary(scales)\ntest001b=data003 %&gt;% filter(review_year&lt;2018) %&gt;% group_by(score) %&gt;% summarise(n=n()) %&gt;% mutate(percent = (n/sum(n))) %&gt;% arrange(desc(score)) %&gt;% mutate(review_year_flag='&lt;2020')\n\n\n\n\nCode\ntest001c=rbind(test001a,test001b) %&gt;% filter(score&gt;=75)\n\n\n\n\nCode\np=ggplot(test001c, aes(score,percent,color=review_year_flag)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\nggplot(data003, aes(score,fill=review_year_flag))+geom_histogram(position = 'dodge')\n\n\n\n\nCode\nggplot(test001b, aes(x=score,y=percent))+ geom_bar(stat=\"identity\")\n\n\n\n\nCode\nggplot(data003, aes(score)) + \n  geom_histogram()\n\n\n\n\nCode\np=ggplot(data003, aes(review_date2, score)) + geom_point()\np\n\n\n\n\nCode\ndata004=data003 %&gt;% mutate(above_90=ifelse(score&gt;=90,1,0)) %&gt;% group_by(review_year) %&gt;% summarise(n=n()\n                                            ,avg_score=mean(score)\n                                            ,above_90=sum(above_90)\n                                            )\n\n\n\n\nCode\np=ggplot(data004, aes(review_year,above_90/n)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(data004, aes(review_year,avg_score)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(data004, aes(review_year,n)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(data003, aes(review_year,score,color=as.character(review_year)))  + geom_boxplot()\np\n\n\n\n\n2 ouput\n\n\nCode\nwrite.xlsx(data003,'all_page_review_after_clean.xlsx')\n\n\n\n\n3 reference\n%d = Day number of month (5, 17, 28, etc.)\n%j = Day number of the year (Julian day 001-366)\n%a = Abbreviated weekday (Mon, Tue, Wed, etc.)\n%A = Full weekday (Monday, Tuesday, etc.) %w = Weekday number (0-6, Sunday is 0)\n%u = Weekday number (1-7, Monday is 1)\n%W = Week number (00-53, Monday is week start)\n%U = Week number (01-53, Sunday is week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds %z = offset from GMT\n%Z = Time zone (character)\nhttps://epirhandbook.com/en/working-with-dates.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page clean up"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 all distillery.html",
    "href": "other/2 Web scraping on whiskybase.com/3 all distillery.html",
    "title": "all distrillery and bottler name",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\nlibrary(gt)\n\n\n\n1 all distrillery\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/distilleries'\n\n\n\n\nCode\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ntext=page%&gt;% html_nodes(\"*\")%&gt;% html_text2()\n\n\n\n\nCode\nhead(text)\n\n\n[1] \"document.documentElement.className += 'js' Distilleries - Whiskybase - Ratings and reviews for whisky window.__exc = { e: [], a: function(e) { return window.application ? window.application.exec(e) : __exc.e.push(e) } } (function(c, l, a, r, i, t, y) { c[a] = c[a] || function() { (c[a].q = c[a].q || []).push(arguments) }; t = l.createElement(r); t.async = 1; t.src = \\\"https://www.clarity.ms/tag/\\\" + i; y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y); })(window, document, \\\"clarity\\\", \\\"script\\\", \\\"cdpmv56i88\\\");\"\n[2] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[3] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[4] \"document.documentElement.className += 'js'\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[6] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n\n\n\n\nCode\nwrite_delim(tibble(text), \"./data/all distillery name.txt\")\n\n\n\n\nCode\nlink= page%&gt;%html_nodes(\".clickable a\")%&gt;% html_attr('href')\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% mutate(link=link) %&gt;% select(-Var.6)\n\n\noutput\n\n\nCode\nwrite.xlsx(data,'./output/all distillery.xlsx')\n\n\n\n\n2 summary of the data\n\n\nCode\ndata002=data %&gt;% filter(Whiskies&gt;10,Votes&gt;100) %&gt;% arrange(desc(Rating)) %&gt;% select(-link)\n\ndata003=data002 %&gt;% rowid_to_column(\"No\")\nhead(data003) %&gt;% gt() %&gt;% as_raw_html()\n\n\n\n\n  \n  \n\n\n\nNo\nName\nCountry\nWhiskies\nVotes\nRating\n\n\n\n\n1\nKawasaki\nJapan\n31\n366\n90.04\n\n\n2\nBrora\nScotland\n282\n10586\n89.94\n\n\n3\nGlenlochy\nScotland\n120\n1789\n89.76\n\n\n4\nPort Ellen\nScotland\n1492\n26495\n89.27\n\n\n5\nGlenugie\nScotland\n134\n1669\n89.21\n\n\n6\nBen Wyvis\nScotland\n18\n243\n89.17\n\n\n\n\n\n\n\n\n\n\n3 all bottler\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/bottlers'\n\n\n\n\nCode\nlink= page%&gt;%html_nodes(\".clickable a\")%&gt;% html_attr('href')\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% mutate(link=link) %&gt;% select(-'Var.6')\n\n\n\n\nCode\nnames(data)\n\n\n[1] \"Name\"     \"Country\"  \"Whiskies\" \"Votes\"    \"Rating\"   \"link\"    \n\n\n\n\nCode\n#glimpse(data)\n\n\noutput\n\n\nCode\nwrite.xlsx(data,'./output/all bottler.xlsx')\n\n\n\n\n4 summary of the data\n\n\nCode\ndata002=data %&gt;% filter(Whiskies&gt;10,Votes&gt;100) %&gt;% arrange(desc(Rating))  %&gt;% select(-link)\n\ndata003=data002 %&gt;% rowid_to_column(\"No\")\nhead(data003) %&gt;% gt() %&gt;% as_raw_html()\n\n\n\n\n  \n  \n\n\n\nNo\nName\nCountry\nWhiskies\nVotes\nRating\n\n\n\n\n1\nKawasaki\nJapan\n31\n366\n90.04\n\n\n2\nBrora\nScotland\n282\n10586\n89.94\n\n\n3\nGlenlochy\nScotland\n120\n1789\n89.76\n\n\n4\nPort Ellen\nScotland\n1492\n26495\n89.27\n\n\n5\nGlenugie\nScotland\n134\n1669\n89.21\n\n\n6\nBen Wyvis\nScotland\n18\n243\n89.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "all distrillery and bottler name"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/2 one bottle review.html",
    "href": "other/2 Web scraping on whiskybase.com/2 one bottle review.html",
    "title": "on bottle review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/whisky/147142/macallan-12-year-old'\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ntext=page%&gt;% html_nodes(\"*\")%&gt;% html_text2()\n\n\n\n\nCode\nhead(text)\n\n\n[1] \"document.documentElement.className += 'js' Macallan 12-year-old - Ratings and reviews - Whiskybase {\\\"@context\\\":\\\"https:\\\\/\\\\/schema.org\\\\/\\\",\\\"@type\\\":\\\"Product\\\",\\\"name\\\":\\\"Macallan 12-year-old\\\",\\\"sku\\\":147142,\\\"brand\\\":{\\\"@type\\\":\\\"Brand\\\",\\\"name\\\":\\\"Macallan\\\"},\\\"gtin\\\":\\\"5010314017408\\\",\\\"gtin13\\\":\\\"5010314017408\\\",\\\"image\\\":\\\"https:\\\\/\\\\/static.whiskybase.com\\\\/storage\\\\/whiskies\\\\/1\\\\/4\\\\/7142\\\\/304090-normal.png\\\",\\\"offers\\\":{\\\"@type\\\":\\\"AggregateOffer\\\",\\\"lowPrice\\\":68.5799999999999982946974341757595539093017578125,\\\"highPrice\\\":288.41000000000002501110429875552654266357421875,\\\"priceCurrency\\\":\\\"EUR\\\",\\\"offerCount\\\":26},\\\"aggregateRating\\\":{\\\"@type\\\":\\\"AggregateRating\\\",\\\"bestRating\\\":100,\\\"worstRating\\\":0,\\\"ratingValue\\\":84.5499999999999971578290569595992565155029296875,\\\"reviewCount\\\":238},\\\"description\\\":\\\"Macallan 12-year-old 12 yr. The strength of this whisky is 40.0 % Vol. A bottle from Macallan\\\"}window.__exc = { e: [], a: function(e) { return window.application ? window.application.exec(e) : __exc.e.push(e) } } (function(c, l, a, r, i, t, y) { c[a] = c[a] || function() { (c[a].q = c[a].q || []).push(arguments) }; t = l.createElement(r); t.async = 1; t.src = \\\"https://www.clarity.ms/tag/\\\" + i; y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y); })(window, document, \\\"clarity\\\", \\\"script\\\", \\\"cdpmv56i88\\\");\"\n[2] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[3] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[4] \"document.documentElement.className += 'js'\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[6] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n\nCode\nwrite_delim(tibble(text), \"./data/text.txt\")\n\n\n\n\nCode\nrating_people_num_list=c()\navg_price_list=c()\nlowest_price_list=c()\ncask_type_list=c() \npic_link_list=c()\nwb_id=c()\nstart_time=now()\ncask_number_list=c()\nnumber_of_bottle_list=c()\nscore_list=c()\nbottler_list=c()\nbottle_list=c()\nstrength_list=c()\n\norder_num=1\n\n\n\n\nCode\n###################### score\nbottle=(page%&gt;% html_nodes('h1')%&gt;% html_text())[1]\nbottle=bottle %&gt;% str_remove_all('\\n') %&gt;% str_remove_all('\\t')\nprint(paste0(\"bottle: \",(bottle)[1]))\n\n\n[1] \"bottle: Macallan12-year-old\"\n\n\nCode\nbottle_list=c(bottle_list,bottle)\n\n\n###################### score\nscore=(page%&gt;% html_nodes('.votes-rating-current')%&gt;% html_text())[1]\nprint(paste0(\"score: \",score))\n\n\n[1] \"score: 84.55\"\n\n\nCode\nscore_list=c(score_list,score)\n\n####################### rating_people_num\nrating_people_num=page%&gt;% html_nodes('.votes-count')%&gt;% html_text()\nprint(rating_people_num)[1]\n\n\n[1] \"238\" \"238\"\n\n\n[1] \"238\"\n\n\nCode\nrating_people_num_list=c(rating_people_num_list,rating_people_num[1])\n\n\n##################### lowest price\nlowest_price=page%&gt;% html_nodes('.wb--shop-links-panel--price')%&gt;% html_text()\nlowest_price2=if(identical(lowest_price, character(0))==TRUE){0}else{lowest_price}\nprint(lowest_price2)\n\n\n[1] \"€ 78.00\"\n\n\nCode\nlowest_price_list=c(lowest_price_list,lowest_price2)\n\n############################# average price\navg_price=page%&gt;% html_nodes('p+ p')%&gt;% html_text()\navg_price6=case_when(str_detect(avg_price, \"[0-9]\")==TRUE~avg_price,.default='')\nprint(paste('price is :',avg_price6[1]))\n\n\n[1] \"price is : € 128.49\"\n\n\nCode\navg_price_list=c(avg_price_list,avg_price6[1])\n\n################################## cask type\nbottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\nbottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\nbottle_name_value=data.frame(bottle_name,bottle_value)\ncask=bottle_name_value%&gt;% filter(bottle_name=='Cask Type') %&gt;% select(bottle_value)\ncask2=if(nrow(cask)==0){'unknow cask'}else{ unname(unlist(cask[1,]))}\nprint(cask2)\n\n\n[1] \"Sherry Seasoned Oak casks from Jerez\"\n\n\nCode\ncask_type_list=c(cask_type_list,cask2)\n\n################################## Bottler\n#bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n#bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n#bottle_name_value=data.frame(bottle_name,bottle_value)\nbottler=bottle_name_value%&gt;% filter(bottle_name=='Bottler') %&gt;% select(bottle_value)\nbottler=if(nrow(bottler)==0){'unknow Bottler'}else{ unname(unlist(bottler[1,]))}\nprint(bottler)\n\n\n[1] \"Distillery Bottling\"\n\n\nCode\nbottler_list=c(bottler_list,bottler)\n\n################################## strength\n#bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n#bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n#bottle_name_value=data.frame(bottle_name,bottle_value)\nstrength=bottle_name_value%&gt;% filter(bottle_name=='Strength') %&gt;% select(bottle_value)\nstrength=if(nrow(strength)==0){'unknow strength'}else{ unname(unlist(strength[1,]))}\nprint(strength)\n\n\n[1] \"40.0 % Vol.\"\n\n\nCode\nstrength_list=c(strength_list,strength)\n\n\n  \n##################### number_of_bottle \nnumber_of_bottle1=bottle_name_value%&gt;% filter(bottle_name=='Number of bottles') %&gt;% select(bottle_value)\nnumber_of_bottle2=if(nrow(number_of_bottle1)==0){'unknow Number of bottles'}else{ unname(unlist(number_of_bottle1[1,]))}\n  \nprint(number_of_bottle2)\n\n\n[1] \"unknow Number of bottles\"\n\n\nCode\nnumber_of_bottle_list=c(number_of_bottle_list,number_of_bottle2)\n  \n##################### Casknumber \ncask_number1=bottle_name_value%&gt;% filter(bottle_name=='Casknumber') %&gt;% select(bottle_value)\ncask_number2=if(nrow(cask_number1)==0){'unknow Casknumber'}else{ unname(unlist(cask_number1[1,]))}\n  \nprint(paste('casknumber:',cask_number2))\n\n\n[1] \"casknumber: unknow Casknumber\"\n\n\nCode\ncask_number_list=c(cask_number_list,cask_number2)\n  \n  \n########################################### wb id \nid_name=page%&gt;% html_nodes(' #whisky-details dd:nth-child(2)')%&gt;% html_text()\nprint(id_name)\n\n\n[1] \"WB147142\"\n\n\nCode\nwb_id=c(wb_id,id_name)\n  \n####### check \n  \nid_num=as.numeric(str_replace(id_name,'WB',''))\nprint(id_num)\n\n\n[1] 147142\n\n\nCode\na=(str_split(url,'/')[[1]])\nb=as.numeric(a[length(a)-1])\nprint(paste(\"wb id from link\",b))\n\n\n[1] \"wb id from link 147142\"\n\n\nCode\nprint(paste(\"wb id from page\",id_num))\n\n\n[1] \"wb id from page 147142\"\n\n\nCode\nif(id_num!=b){\n    print(i)\n    print('############## error !!!!!!!!##################')\n    break\n}\n##################     pic link   #######################\npic_link=(page%&gt;% html_nodes('.photo')%&gt;% html_attr('href'))[1]\npic_link2=if(identical(pic_link, character(0))==TRUE){0}else{pic_link}\n  \nprint(pic_link2)\n\n\n[1] \"https://static.whiskybase.com/storage/whiskies/1/4/7142/304090-big.jpg\"\n\n\nCode\npic_link_list=c(pic_link_list,pic_link2)\n#########################################################  \n\n\n\n\nCode\ndata=cbind(bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,url) %&gt;% as_tibble()\n\n\n\n\nCode\nglimpse(data)\n\n\nRows: 1\nColumns: 13\n$ bottle_list            &lt;chr&gt; \"Macallan12-year-old\"\n$ score_list             &lt;chr&gt; \"84.55\"\n$ rating_people_num_list &lt;chr&gt; \"238\"\n$ lowest_price_list      &lt;chr&gt; \"€ 78.00\"\n$ avg_price_list         &lt;chr&gt; \"€ 128.49\"\n$ cask_type_list         &lt;chr&gt; \"Sherry Seasoned Oak casks from Jerez\"\n$ number_of_bottle_list  &lt;chr&gt; \"unknow Number of bottles\"\n$ bottler_list           &lt;chr&gt; \"Distillery Bottling\"\n$ strength_list          &lt;chr&gt; \"40.0 % Vol.\"\n$ cask_number_list       &lt;chr&gt; \"unknow Casknumber\"\n$ wb_id                  &lt;chr&gt; \"WB147142\"\n$ pic_link_list          &lt;chr&gt; \"https://static.whiskybase.com/storage/whiskies…\n$ url                    &lt;chr&gt; \"https://www.whiskybase.com/whiskies/whisky/147…\n\n\n\n1 output\n\n\nCode\nwrite.xlsx(data,'./output/one_page_review.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/4 all bottle from a distillery.html",
    "href": "other/2 Web scraping on whiskybase.com/4 all bottle from a distillery.html",
    "title": "All bottle from a distillery review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\n\n\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/distillery/257/kawasaki'\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% clean_names()\n\n\n\n\nCode\nbottle_link= page%&gt;%html_nodes(\".clickable\")%&gt;% html_attr('href')\n\n\n\n\nCode\nnames(data)\n\n\n\n\nCode\ndata2=data %&gt;% mutate(var_2=str_trim(var_2),l=ifelse(var_2=='',1,0)) %&gt;% filter(l==1) %&gt;% mutate(bottle_link=bottle_link) %&gt;% select(name,stated_age,strength,bottled,casknumber,rating,bottle_link)\n\n\noutput\n\n\nCode\nwrite.xlsx(data2,'./output/all bottler under one distillery.xlsx')\n\n\n\n1 add detail\n\n\nCode\ndata002=read_excel('./output/all bottler under one distillery.xlsx')\n\n\n\n\nCode\nrating_people_num_list=c()\navg_price_list=c()\nlowest_price_list=c()\ncask_type_list=c() \npic_link_list=c()\nwb_id=c()\nstart_time=now()\ncask_number_list=c()\nnumber_of_bottle_list=c()\nscore_list=c()\nbottler_list=c()\nbottle_list=c()\nstrength_list=c()\nbottle_link_list=c()\norder_num=0\n\n\n\n\nCode\nfor (i in data002$bottle_link){\n    Sys.sleep(runif(n=1, min=0.1, max=0.5))\n    order_num=order_num+1\n    tryCatch({\n    \n    print(paste('#############',order_num,'bottle ######################################## '))\n    print(i)\n    url=i\n    page = read_html(url)\n  }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n    #################### bottle_link_list\n    \n    bottle_link_list=c(bottle_link_list,i)\n      \n    ###################### score\n    bottle=(page%&gt;% html_nodes('h1')%&gt;% html_text())[1]\n    bottle=bottle %&gt;% str_remove_all('\\n') %&gt;% str_remove_all('\\t')\n    print(paste0(\"bottle: \",(bottle)[1]))\n    bottle_list=c(bottle_list,bottle)\n    \n    \n    ###################### score\n    score=(page%&gt;% html_nodes('.votes-rating-current')%&gt;% html_text())[1]\n    print(paste0(\"score: \",score))\n    score_list=c(score_list,score)\n    \n    ####################### rating_people_num\n    rating_people_num=page%&gt;% html_nodes('.votes-count')%&gt;% html_text()\n    print(rating_people_num)[1]\n    rating_people_num_list=c(rating_people_num_list,rating_people_num[1])\n    \n    \n    ##################### lowest price\n    lowest_price=page%&gt;% html_nodes('.wb--shop-links-panel--price')%&gt;% html_text()\n    lowest_price2=if(identical(lowest_price, character(0))==TRUE){0}else{lowest_price}\n    print(lowest_price2)\n    lowest_price_list=c(lowest_price_list,lowest_price2)\n    \n    ############################# average price\n    avg_price=page%&gt;% html_nodes('p+ p')%&gt;% html_text()\n    avg_price6=case_when(str_detect(avg_price, \"[0-9]\")==TRUE~avg_price,.default='')\n    print(paste('price is :',avg_price6[1]))\n    avg_price_list=c(avg_price_list,avg_price6[1])\n    \n    ################################## cask type\n    bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    bottle_name_value=data.frame(bottle_name,bottle_value)\n    cask=bottle_name_value%&gt;% filter(bottle_name=='Cask Type') %&gt;% select(bottle_value)\n    cask2=if(nrow(cask)==0){'unknow cask'}else{ unname(unlist(cask[1,]))}\n    print(cask2)\n    cask_type_list=c(cask_type_list,cask2)\n    \n    ################################## Bottler\n    #bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    #bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    #bottle_name_value=data.frame(bottle_name,bottle_value)\n    bottler=bottle_name_value%&gt;% filter(bottle_name=='Bottler') %&gt;% select(bottle_value)\n    bottler=if(nrow(bottler)==0){'unknow Bottler'}else{ unname(unlist(bottler[1,]))}\n    print(bottler)\n    bottler_list=c(bottler_list,bottler)\n    \n    ################################## strength\n    #bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    #bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    #bottle_name_value=data.frame(bottle_name,bottle_value)\n    strength=bottle_name_value%&gt;% filter(bottle_name=='Strength') %&gt;% select(bottle_value)\n    strength=if(nrow(strength)==0){'unknow strength'}else{ unname(unlist(strength[1,]))}\n    print(strength)\n    strength_list=c(strength_list,strength)\n    \n    \n      \n    ##################### number_of_bottle \n    number_of_bottle1=bottle_name_value%&gt;% filter(bottle_name=='Number of bottles') %&gt;% select(bottle_value)\n    number_of_bottle2=if(nrow(number_of_bottle1)==0){'unknow Number of bottles'}else{ unname(unlist(number_of_bottle1[1,]))}\n      \n    print(number_of_bottle2)\n    number_of_bottle_list=c(number_of_bottle_list,number_of_bottle2)\n      \n    ##################### Casknumber \n    cask_number1=bottle_name_value%&gt;% filter(bottle_name=='Casknumber') %&gt;% select(bottle_value)\n    cask_number2=if(nrow(cask_number1)==0){'unknow Casknumber'}else{ unname(unlist(cask_number1[1,]))}\n      \n    print(paste('casknumber:',cask_number2))\n    cask_number_list=c(cask_number_list,cask_number2)\n      \n      \n    ########################################### wb id \n    id_name=page%&gt;% html_nodes(' #whisky-details dd:nth-child(2)')%&gt;% html_text()\n    print(id_name)\n    wb_id=c(wb_id,id_name)\n      \n    ####### check \n      \n    id_num=as.numeric(str_replace(id_name,'WB',''))\n    print(id_num)\n      \n    a=(str_split(url,'/')[[1]])\n    b=as.numeric(a[length(a)-1])\n    #print(paste(\"wb id from link\",b))\n    #print(paste(\"wb id from page\",id_num))\n    if(id_num!=b){\n        print(i)\n        print('############## error !!!!!!!!##################')\n        break\n    }\n    ##################     pic link   #######################\n    pic_link=(page%&gt;% html_nodes('.photo')%&gt;% html_attr('href'))[1]\n    pic_link2=if(identical(pic_link, character(0))==TRUE){0}else{pic_link}\n      \n    print(pic_link2)\n    pic_link_list=c(pic_link_list,pic_link2)\n    \n ######### output to excel on every 10 bottle\n  if(order_num%%10==0){\n    data003=cbind((data002[1:order_num,]),bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,bottle_link_list)%&gt;% as_tibble()\n    \n    \n    write_xlsx(data003,'./output/all bottel under one distillery with detail.xlsx')\n  }\n}\n#########################################################  \n\n\n\n\nCode\ndata003=cbind(data002,bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,bottle_link_list) %&gt;% as_tibble()\n\nwrite_xlsx(data003,'./output/all bottel under one distillery with detail.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "All bottle from a distillery review"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/5 all bottle from a distillery.html",
    "href": "other/2 Web scraping on whiskybase.com/5 all bottle from a distillery.html",
    "title": "All bottle from a distillery review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\n\n\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/distillery/257/kawasaki'\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% clean_names()\n\n\n\n\nCode\nbottle_link= page%&gt;%html_nodes(\".clickable\")%&gt;% html_attr('href')\n\n\n\n\nCode\nnames(data)\n\n\n\n\nCode\ndata2=data %&gt;% mutate(var_2=str_trim(var_2),l=ifelse(var_2=='',1,0)) %&gt;% filter(l==1) %&gt;% mutate(bottle_link=bottle_link) %&gt;% select(name,stated_age,strength,bottled,casknumber,rating,bottle_link)\n\n\noutput\n\n\nCode\nwrite.xlsx(data2,'./output/all bottler under one distillery.xlsx')\n\n\n\n1 add detail\n\n\nCode\ndata002=read_excel('./output/all bottler under one distillery.xlsx')\n\n\n\n\nCode\nrating_people_num_list=c()\navg_price_list=c()\nlowest_price_list=c()\ncask_type_list=c() \npic_link_list=c()\nwb_id=c()\nstart_time=now()\ncask_number_list=c()\nnumber_of_bottle_list=c()\nscore_list=c()\nbottler_list=c()\nbottle_list=c()\nstrength_list=c()\nbottle_link_list=c()\norder_num=0\n\n\n\n\nCode\nfor (i in data002$bottle_link){\n    Sys.sleep(runif(n=1, min=0.1, max=0.5))\n    order_num=order_num+1\n    tryCatch({\n    \n    print(paste('#############',order_num,'bottle ######################################## '))\n    print(i)\n    url=i\n    page = read_html(url)\n  }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n    #################### bottle_link_list\n    \n    bottle_link_list=c(bottle_link_list,i)\n      \n    ###################### score\n    bottle=(page%&gt;% html_nodes('h1')%&gt;% html_text())[1]\n    bottle=bottle %&gt;% str_remove_all('\\n') %&gt;% str_remove_all('\\t')\n    print(paste0(\"bottle: \",(bottle)[1]))\n    bottle_list=c(bottle_list,bottle)\n    \n    \n    ###################### score\n    score=(page%&gt;% html_nodes('.votes-rating-current')%&gt;% html_text())[1]\n    print(paste0(\"score: \",score))\n    score_list=c(score_list,score)\n    \n    ####################### rating_people_num\n    rating_people_num=page%&gt;% html_nodes('.votes-count')%&gt;% html_text()\n    print(rating_people_num)[1]\n    rating_people_num_list=c(rating_people_num_list,rating_people_num[1])\n    \n    \n    ##################### lowest price\n    lowest_price=page%&gt;% html_nodes('.wb--shop-links-panel--price')%&gt;% html_text()\n    lowest_price2=if(identical(lowest_price, character(0))==TRUE){0}else{lowest_price}\n    print(lowest_price2)\n    lowest_price_list=c(lowest_price_list,lowest_price2)\n    \n    ############################# average price\n    avg_price=page%&gt;% html_nodes('p+ p')%&gt;% html_text()\n    avg_price6=case_when(str_detect(avg_price, \"[0-9]\")==TRUE~avg_price,.default='')\n    print(paste('price is :',avg_price6[1]))\n    avg_price_list=c(avg_price_list,avg_price6[1])\n    \n    ################################## cask type\n    bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    bottle_name_value=data.frame(bottle_name,bottle_value)\n    cask=bottle_name_value%&gt;% filter(bottle_name=='Cask Type') %&gt;% select(bottle_value)\n    cask2=if(nrow(cask)==0){'unknow cask'}else{ unname(unlist(cask[1,]))}\n    print(cask2)\n    cask_type_list=c(cask_type_list,cask2)\n    \n    ################################## Bottler\n    #bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    #bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    #bottle_name_value=data.frame(bottle_name,bottle_value)\n    bottler=bottle_name_value%&gt;% filter(bottle_name=='Bottler') %&gt;% select(bottle_value)\n    bottler=if(nrow(bottler)==0){'unknow Bottler'}else{ unname(unlist(bottler[1,]))}\n    print(bottler)\n    bottler_list=c(bottler_list,bottler)\n    \n    ################################## strength\n    #bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    #bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    #bottle_name_value=data.frame(bottle_name,bottle_value)\n    strength=bottle_name_value%&gt;% filter(bottle_name=='Strength') %&gt;% select(bottle_value)\n    strength=if(nrow(strength)==0){'unknow strength'}else{ unname(unlist(strength[1,]))}\n    print(strength)\n    strength_list=c(strength_list,strength)\n    \n    \n      \n    ##################### number_of_bottle \n    number_of_bottle1=bottle_name_value%&gt;% filter(bottle_name=='Number of bottles') %&gt;% select(bottle_value)\n    number_of_bottle2=if(nrow(number_of_bottle1)==0){'unknow Number of bottles'}else{ unname(unlist(number_of_bottle1[1,]))}\n      \n    print(number_of_bottle2)\n    number_of_bottle_list=c(number_of_bottle_list,number_of_bottle2)\n      \n    ##################### Casknumber \n    cask_number1=bottle_name_value%&gt;% filter(bottle_name=='Casknumber') %&gt;% select(bottle_value)\n    cask_number2=if(nrow(cask_number1)==0){'unknow Casknumber'}else{ unname(unlist(cask_number1[1,]))}\n      \n    print(paste('casknumber:',cask_number2))\n    cask_number_list=c(cask_number_list,cask_number2)\n      \n      \n    ########################################### wb id \n    id_name=page%&gt;% html_nodes(' #whisky-details dd:nth-child(2)')%&gt;% html_text()\n    print(id_name)\n    wb_id=c(wb_id,id_name)\n      \n    ####### check \n      \n    id_num=as.numeric(str_replace(id_name,'WB',''))\n    print(id_num)\n      \n    a=(str_split(url,'/')[[1]])\n    b=as.numeric(a[length(a)-1])\n    #print(paste(\"wb id from link\",b))\n    #print(paste(\"wb id from page\",id_num))\n    if(id_num!=b){\n        print(i)\n        print('############## error !!!!!!!!##################')\n        break\n    }\n    ##################     pic link   #######################\n    pic_link=(page%&gt;% html_nodes('.photo')%&gt;% html_attr('href'))[1]\n    pic_link2=if(identical(pic_link, character(0))==TRUE){0}else{pic_link}\n      \n    print(pic_link2)\n    pic_link_list=c(pic_link_list,pic_link2)\n    \n ######### output to excel on every 10 bottle\n  if(order_num%%10==0){\n    data003=cbind((data002[1:order_num,]),bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,bottle_link_list)%&gt;% as_tibble()\n    \n    \n    write_xlsx(data003,'./output/all bottel under one distillery with detail.xlsx')\n  }\n}\n#########################################################  \n\n\n\n\nCode\ndata003=cbind(data002,bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,bottle_link_list) %&gt;% as_tibble()\n\nwrite_xlsx(data003,'./output/all bottel under one distillery with detail.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "All bottle from a distillery review"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html",
    "href": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html",
    "title": "on bottle review with log in",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(httr)",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review with log in"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#find-require-info",
    "href": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#find-require-info",
    "title": "on bottle review with log in",
    "section": "5.1 find require info",
    "text": "5.1 find require info\nform 4 is login form\n\n\nCode\nread_html('https://www.whiskybase.com/') %&gt;%  html_form(\"form\")",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review with log in"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#in-whisky-list",
    "href": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#in-whisky-list",
    "title": "on bottle review with log in",
    "section": "9.1 in whisky list",
    "text": "9.1 in whisky list\n\n\nCode\nreview_people=page%&gt;% html_nodes('#whisky-community a')%&gt;% html_text2()\nreview_people",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review with log in"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/4 all distillery.html",
    "href": "other/2 Web scraping on whiskybase.com/4 all distillery.html",
    "title": "all distrillery and bottler name",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\nlibrary(gt)\n\n\n\n1 all distrillery\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/distilleries'\n\n\n\n\nCode\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ntext=page%&gt;% html_nodes(\"*\")%&gt;% html_text2()\n\n\n\n\nCode\nhead(text)\n\n\n[1] \"document.documentElement.className += 'js' Distilleries - Whiskybase - Ratings and reviews for whisky window.__exc = { e: [], a: function(e) { return window.application ? window.application.exec(e) : __exc.e.push(e) } } (function(c, l, a, r, i, t, y) { c[a] = c[a] || function() { (c[a].q = c[a].q || []).push(arguments) }; t = l.createElement(r); t.async = 1; t.src = \\\"https://www.clarity.ms/tag/\\\" + i; y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y); })(window, document, \\\"clarity\\\", \\\"script\\\", \\\"cdpmv56i88\\\");\"\n[2] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[3] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[4] \"document.documentElement.className += 'js'\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[6] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n\n\n\n\nCode\nwrite_delim(tibble(text), \"./data/all distillery name.txt\")\n\n\n\n\nCode\nlink= page%&gt;%html_nodes(\".clickable a\")%&gt;% html_attr('href')\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% mutate(link=link) %&gt;% select(-Var.6)\n\n\noutput\n\n\nCode\nwrite.xlsx(data,'./output/all distillery.xlsx')\n\n\n\n\n2 summary of the data\n\n\nCode\ndata002=data %&gt;% filter(Whiskies&gt;10,Votes&gt;100) %&gt;% arrange(desc(Rating)) %&gt;% select(-link)\n\ndata003=data002 %&gt;% rowid_to_column(\"No\")\nhead(data003) %&gt;% gt() %&gt;% as_raw_html()\n\n\n\n\n  \n  \n\n\n\nNo\nName\nCountry\nWhiskies\nVotes\nRating\n\n\n\n\n1\nKawasaki\nJapan\n31\n366\n90.04\n\n\n2\nBrora\nScotland\n282\n10586\n89.94\n\n\n3\nGlenlochy\nScotland\n120\n1789\n89.76\n\n\n4\nPort Ellen\nScotland\n1492\n26495\n89.27\n\n\n5\nGlenugie\nScotland\n134\n1669\n89.21\n\n\n6\nBen Wyvis\nScotland\n18\n243\n89.17\n\n\n\n\n\n\n\n\n\n\n3 all bottler\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/bottlers'\n\n\n\n\nCode\nlink= page%&gt;%html_nodes(\".clickable a\")%&gt;% html_attr('href')\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% mutate(link=link) %&gt;% select(-'Var.6')\n\n\n\n\nCode\nnames(data)\n\n\n[1] \"Name\"     \"Country\"  \"Whiskies\" \"Votes\"    \"Rating\"   \"link\"    \n\n\n\n\nCode\n#glimpse(data)\n\n\noutput\n\n\nCode\nwrite.xlsx(data,'./output/all bottler.xlsx')\n\n\n\n\n4 summary of the data\n\n\nCode\ndata002=data %&gt;% filter(Whiskies&gt;10,Votes&gt;100) %&gt;% arrange(desc(Rating))  %&gt;% select(-link)\n\ndata003=data002 %&gt;% rowid_to_column(\"No\")\nhead(data003) %&gt;% gt() %&gt;% as_raw_html()\n\n\n\n\n  \n  \n\n\n\nNo\nName\nCountry\nWhiskies\nVotes\nRating\n\n\n\n\n1\nKawasaki\nJapan\n31\n366\n90.04\n\n\n2\nBrora\nScotland\n282\n10586\n89.94\n\n\n3\nGlenlochy\nScotland\n120\n1789\n89.76\n\n\n4\nPort Ellen\nScotland\n1492\n26495\n89.27\n\n\n5\nGlenugie\nScotland\n134\n1669\n89.21\n\n\n6\nBen Wyvis\nScotland\n18\n243\n89.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "all distrillery and bottler name"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/7 clean up.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/7 clean up.html",
    "title": "clean up",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\nlibrary(lubridate)\n\n\n\n1 input data\n\n\nCode\ndata001=read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\n2 clean data\n\n\nCode\ndata002=data001 %&gt;% clean_names()\n\n\n\n\nCode\nglimpse(data002)\n\n\n\n\nCode\ndata003=data002 %&gt;%  mutate(published_date=dmy(page_published_date)\n                            ,year=year(published_date)\n                            ,score=as.numeric(all_page_score)\n                            ,high_score=if_else(score&gt;=90,1,0)\n                             ,score_group=case_when(\n                                        score &gt;= 90 ~ \"1.&gt;=90\",\n                                        score &gt; 85 ~ \"2. &gt;=85\",\n                                          TRUE ~ \"3. &lt;85\")\n                            ,bottle_name=bottle_name%&gt;% str_replace('allt-à-bhainne','Allt-a-Bhainne')%&gt;% str_replace('Allt-a-Bhaine','Allt-a-Bhainne') %&gt;% str_to_lower()\n                            )%&gt;% filter(score&gt;0\n                                        ,score&lt;=100\n                                        ,!page_class %in% c(\"* Armagnac\",\"* Cognac\",\"* Rum\",\"* Armagnac-* Cognac\",\"* Other spirits\",\"* Distillery visits\",\"\")\n                                        ,bottle_review_nose!='no comment'\n                                        ,bottle_review_mouth!='no comment'\n                                        ,bottle_review_finish!='no comment')%&gt;% arrange(score)\n\n\n\nglimpse(data003)\n\n\n\n\nCode\np=ggplot(data003, aes(year,score,group=year)) + geom_boxplot()\np\n\n\n\n\nCode\nsummary001=data003 %&gt;% group_by(year) %&gt;% summarise(bottles=n(),avg_score=mean(score),high=sum(high_score)\n                                                 \n                                                 ,high_pct=sum(high_score)/n()\n                                                 )\nsummary001\n\n\n\n\nCode\nall_distrillery_from_wb=read_xlsx('data/all distrillery from wb.xlsx') %&gt;% mutate(name=Name %&gt;% str_replace('Isle of Jura','jura')  %&gt;% str_replace('Teeling Whiskey Distillery','Teeling') %&gt;% str_replace('Distillery','')%&gt;% str_replace('(Closed)','') %&gt;% str_replace('St. Magdalene','St Magdalene') %&gt;% str_trim()%&gt;% str_to_lower()\n                                                                              ) \n\n\n\n\nCode\nkeywords &lt;- as.character(all_distrillery_from_wb$name)\n\n\n\n\nCode\ndata004=data003[grepl(paste(keywords, collapse=\"|\"), data003$bottle_name),]\n\n\n\n\nCode\ndata005=str_extract_all(tolower(data003$bottle_name),paste(keywords,collapse  = \"|\"))\n\n\nkeep first match\n\n\nCode\ndata006=lapply(data005, `[`, 1)\n\n\n\n\nCode\ndata006[lengths(data006)==0] &lt;- NA\ndata007=unlist(data006)\n\n\n\n\nCode\ndata008=data003 %&gt;% mutate(distillery_name=data007)\n\n\n\n\nCode\nlibrary(\"ggthemes\")\nlibrary(\"scales\")\nlibrary(showtext)\nshowtext_auto()\n\ncoeff &lt;- 5\n\np=ggplot(summary001, aes(year,avg_score)) + geom_line(size=2) +\n  geom_col(aes(year,bottles/ coeff), fill = \"blue\")+scale_y_continuous(\"平均分\",limits=c(0,100), sec.axis = sec_axis(~.*coeff, name = \"评分酒款数量\",breaks = seq(0, 500, by = 100)))+labs(caption = \"2010-01 to 2024-04\")+ ggtitle(\"whiskynote.be\")+ xlim(min=2009, 2025)\np+theme_economist()+scale_x_continuous(breaks=pretty_breaks(n = 20))+scale_y_continuous(breaks=pretty_breaks(n = 20))\n\n\n\n\nCode\nsummary002=data003 %&gt;% group_by(year,score_group) %&gt;% \n  summarise(bottles=n())%&gt;% \n  mutate(score_group=score_group %&gt;% as.factor()) %&gt;% group_by(year) %&gt;% mutate(share=round(bottles/sum(bottles),2))\n\nsummary002\n\n\n\n\nCode\nlibrary(\"ggthemes\")\nlibrary(\"scales\")\nlibrary(showtext)\nshowtext_auto()\n\n\np=ggplot(summary002, aes(y=share, x=year,colour=score_group)) + \n    geom_line()\n\np+theme_economist()+scale_x_continuous(breaks=pretty_breaks(n = 20))+scale_y_continuous(breaks=pretty_breaks(n = 10))\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "clean up"
    ]
  },
  {
    "objectID": "other/4 other web scraping package/chromote.html",
    "href": "other/4 other web scraping package/chromote.html",
    "title": "chromote",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(chromote)\n\n\n\n\nCode\npackageVersion(\"chromote\")\n\n\n[1] '0.2.0'\n\n\n\n1 create view\n\n\nCode\nlibrary(chromote)\n\nb &lt;- ChromoteSession$new()\n\n# In a web browser, open a viewer for the headless browser. Works best with\n# Chromium-based browsers.\nb$view()\n\n\n\n\nCode\nb$Browser$getVersion()\n\n\n$protocolVersion\n[1] \"1.3\"\n\n$product\n[1] \"HeadlessChrome/124.0.6367.62\"\n\n$revision\n[1] \"@8771130bd84f76d855ae42fbe02752b03e352f17\"\n\n$userAgent\n[1] \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/124.0.6367.62 Safari/537.36\"\n\n$jsVersion\n[1] \"12.4.254.12\"\n\n\n\n\n2 go to page\n\n\nCode\nb$Page$navigate(\"https://www.r-project.org/\")\n\n\n$frameId\n[1] \"9DD89BA300D9902BE5C377F1E7132F87\"\n\n$loaderId\n[1] \"1253C287CB978628A7F5737A9A2C3987\"\n\n\n\n\n3 take picture\n\n\nCode\n# Saves to screenshot.png\nb$screenshot()\n\n\n[1] \"screenshot.png\"\n\n\n\n\nCode\n# Takes a screenshot of elements picked out by CSS selector\nis_interactive &lt;- interactive() # Display screenshot if interactive\nb$screenshot(\"sidebar.png\", selector = \"h1\" ,show = is_interactive)\n\n\n[1] \"sidebar.png\"\n\n\n\n\n4 take picture as pdf\n\n\nCode\nb$screenshot_pdf(filename='page.pdf')\n\n\n\n\n5 Reference:\nhttps://rstudio.github.io/chromote/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 other web scraping package",
      "chromote"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-all-file-name-under-currrents-parent-directory",
    "href": "intro/1 basic R.html#get-all-file-name-under-currrents-parent-directory",
    "title": "Basic R",
    "section": "1.3 get all file name under currrents parent directory",
    "text": "1.3 get all file name under currrents parent directory\n\n\nCode\nlist.files(\"../\")\n\n\n [1] \"_freeze\"                      \"_publish.yml\"                \n [3] \"_quarto.yml\"                  \"_site\"                       \n [5] \"clustering\"                   \"data manipulation\"           \n [7] \"docs\"                         \"hotel classification model\"  \n [9] \"house price regression model\" \"images\"                      \n[11] \"index_files\"                  \"index.qmd\"                   \n[13] \"intro\"                        \"logo.jpg\"                    \n[15] \"model type\"                   \"Multiclass classification\"   \n[17] \"other\"                        \"Plot\"                        \n[19] \"site_libs\"                    \"styles.css\"                  \n[21] \"tensorflow\"                   \"tidymodeling.Rproj\"          \n[23] \"titanic classification model\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/5 clean up.html",
    "href": "other/3 Web scraping on whiskyfun.com/5 clean up.html",
    "title": "All page clean up",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 input\n\n\nCode\ndata001=read_excel('/oputput/all_page_review.xlsx')\n\n\n\n\nCode\nglimpse(data001)\n\n\n\n\nCode\ndata002=data001%&gt;% mutate(\n  \n  bottle_review2=bottle_review2%&gt;% str_replace(\"–\", \"-\")%&gt;% str_replace(\"Palate:\", \"Mouth\")\n  ,name=paste0(str_extract(bottle_review2, regex( \"[^)]+\")),\")\")\n  \n  ,colour=(bottle_review2 %&gt;% str_match(\"Colour\\\\s*(.*?)\\\\s*\\\\.\"))[,2]\n  ,nose=(bottle_review2 %&gt;% str_match(\"Nose:\\\\s*(.*?)\\\\s*Mouth\"))[,2]\n  ,mouth=(bottle_review2 %&gt;% str_match(\"Mouth\\\\s*(.*?)\\\\s*Finish:\"))[,2]\n  ,finish=(bottle_review2 %&gt;% str_match(\"Finish:\\\\s*(.*?)\\\\s*Comments:\"))[,2]\n  ,comments=(bottle_review2 %&gt;% str_match(\"Comments:\\\\s*(.*?)\\\\s*SGP:\"))[,2]\n  \n  #,full_score=(bottle_review2 %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n  ,full_score=(bottle_review2 %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n  ,score=full_score %&gt;% str_replace(\"points.\",\"\") %&gt;% as.numeric()\n  \n  ,review_date=((str_match(old_page %&gt;%str_to_lower(),\"https://www.whiskyfun.com/archive\\\\s*(.*?)\\\\s*-\"))[,2] )%&gt;% str_to_title()\n  ,review_date2= myd(review_date, truncated = 1)\n  ,review_year=year(review_date2)\n)\n\nglimpse(data002)\n\n\n\n\nCode\ndata002=data001 %&gt;% mutate(\n  page_link_count=str_count(old_page,'www.whiskyfun.com'))%&gt;%mutate(\n    page_link=ifelse(page_link_count==2,str_replace(old_page,\"https://www.whiskyfun.com/\",\"\"),old_page))%&gt;%mutate(\n    after_page_link_count=str_count(page_link,'www.whiskyfun.com')) %&gt;% mutate(\n      review_date=((str_match(page_link,\"https://www.whiskyfun.com/archive\\\\s*(.*?)\\\\s*-\"))[,2] )%&gt;% str_to_title()\n      ,review_date2= myd(review_date, truncated = 1)\n      ,review_year=year(review_date2)\n      ,bottle_score=str_replace(bottle_score,'–','-')\n      ,bottle_final_score= (bottle_score%&gt;% str_match(\"-\\\\s*(.*?)\\\\s*points\"))[,2]\n        ,score=bottle_final_score %&gt;% str_extract(\"(\\\\d)+\")%&gt;% as.numeric()           \n              ,review_year_flag=ifelse(review_year&gt;=2020,'&gt;=2020','&lt;2020')    \n    ) %&gt;% arrange(desc(score))\n\n\n\n\nCode\ndata003=data002 %&gt;%  filter(review_date2&gt;='2010-01-01'\n                            ,score&lt;=98)\n                            #,score&gt;=70)\n\n\n\n\nCode\nglimpse(data003)\n\n\n\n\nCode\nlibrary(scales)\ntest001a=data003 %&gt;% filter(review_year&gt;=2018) %&gt;% group_by(score) %&gt;% summarise(n=n()) %&gt;% mutate(percent = (n/sum(n))) %&gt;% arrange(desc(score)) %&gt;% mutate(review_year_flag='&gt;=2020')\n\n\n\n\nCode\nlibrary(scales)\ntest001b=data003 %&gt;% filter(review_year&lt;2018) %&gt;% group_by(score) %&gt;% summarise(n=n()) %&gt;% mutate(percent = (n/sum(n))) %&gt;% arrange(desc(score)) %&gt;% mutate(review_year_flag='&lt;2020')\n\n\n\n\nCode\ntest001c=rbind(test001a,test001b) %&gt;% filter(score&gt;=75)\n\n\n\n\nCode\np=ggplot(test001c, aes(score,percent,color=review_year_flag)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\nggplot(data003, aes(score,fill=review_year_flag))+geom_histogram(position = 'dodge')\n\n\n\n\nCode\nggplot(test001b, aes(x=score,y=percent))+ geom_bar(stat=\"identity\")\n\n\n\n\nCode\nggplot(data003, aes(score)) + \n  geom_histogram()\n\n\n\n\nCode\np=ggplot(data003, aes(review_date2, score)) + geom_point()\np\n\n\n\n\nCode\ndata004=data003 %&gt;% mutate(above_90=ifelse(score&gt;=90,1,0)) %&gt;% group_by(review_year) %&gt;% summarise(n=n()\n                                            ,avg_score=mean(score)\n                                            ,above_90=sum(above_90)\n                                            )\n\n\n\n\nCode\np=ggplot(data004, aes(review_year,above_90/n)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(data004, aes(review_year,avg_score)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(data004, aes(review_year,n)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(data003, aes(review_year,score,color=as.character(review_year)))  + geom_boxplot()\np\n\n\n\n\n2 ouput\n\n\nCode\nwrite.xlsx(data003,'all_page_review_after_clean.xlsx')\n\n\n\n\n3 reference\n%d = Day number of month (5, 17, 28, etc.)\n%j = Day number of the year (Julian day 001-366)\n%a = Abbreviated weekday (Mon, Tue, Wed, etc.)\n%A = Full weekday (Monday, Tuesday, etc.) %w = Weekday number (0-6, Sunday is 0)\n%u = Weekday number (1-7, Monday is 1)\n%W = Week number (00-53, Monday is week start)\n%U = Week number (01-53, Sunday is week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds %z = offset from GMT\n%Z = Time zone (character)\nhttps://epirhandbook.com/en/working-with-dates.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page clean up"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-number",
    "href": "Plot/1 ggplot2.html#add-number",
    "title": "ggplot2 in R",
    "section": "3.1 add number",
    "text": "3.1 add number\n\n\nCode\nggplot(data002, aes(x=continent, y=pop)) +\n  geom_bar(stat=\"identity\")+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-footnote",
    "href": "Plot/1 ggplot2.html#add-footnote",
    "title": "ggplot2 in R",
    "section": "7.3 add footnote",
    "text": "7.3 add footnote\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+labs(caption = \"this is footnote\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-chinses",
    "href": "Plot/1 ggplot2.html#add-chinses",
    "title": "ggplot2 in R",
    "section": "6.7 add chinses",
    "text": "6.7 add chinses\n\n\nCode\nlibrary(showtext)\nshowtext_auto()\n\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"新的 x name\")+ scale_y_continuous(name=\"新的 y name\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#x-y-break-and-scales-limit",
    "href": "Plot/1 ggplot2.html#x-y-break-and-scales-limit",
    "title": "ggplot2 in R",
    "section": "7.8 x y break and scales limit",
    "text": "7.8 x y break and scales limit\n\n7.8.1 x scales limit\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\np+ xlim(min=0, 20)\n\n\n\n\n\n\n\n\n\n\n\n7.8.2 y scales limit\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\np+ ylim(0, 100)\n\n\n\n\n\n\n\n\n\n\n\n7.8.3 adding second aix\n\n\nCode\ndata002= data001%&gt;% group_by(year,continent) %&gt;% summarise(pop=sum(pop),lifeExp=mean(lifeExp))%&gt;%filter(continent=='Asia')\n\n\nremove scientific notation\n\n\nCode\ncoeff=1/40000000\n\n\np=ggplot(data002, aes(year, pop)) + geom_col() +\n  geom_line(aes(year,lifeExp/ coeff),size=2, color = \"red\") +scale_y_continuous(\"pop\", sec.axis = sec_axis(~.*coeff, name = \"lifeExp\"),labels = scales::comma)\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/4 shiny photo editor.html",
    "href": "Plot/4 shiny photo editor.html",
    "title": "Shiny in R:photo editor",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/photo_editor/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R:photo editor"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#with-arguments",
    "href": "intro/1 basic R.html#with-arguments",
    "title": "Basic R",
    "section": "4.2 with Arguments",
    "text": "4.2 with Arguments\n\n\nCode\nadding_ten &lt;- function(x) { \n  a=x+10\n  return(a)\n}\n\nadding_ten(5)\n\n\n[1] 15",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#with-default-arguments",
    "href": "intro/1 basic R.html#with-default-arguments",
    "title": "Basic R",
    "section": "4.3 with default Arguments",
    "text": "4.3 with default Arguments\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  return(a)\n}\n\n#if not define x, then x=10\n\nadding_ten()\n\n\n[1] 20",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "Plot/3 shiny weight tracking.html",
    "href": "Plot/3 shiny weight tracking.html",
    "title": "Shiny in R:weight tracking",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/weightshiny/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R:weight tracking"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 model.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 model.html",
    "title": "Model",
    "section": "",
    "text": "Code\nimport os\nos.system('pip3 install openpyxl')\nCode\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\nCode\nimport os\nos.system('pip3 show tensorflow')\n\n\nName: tensorflow\nVersion: 2.16.1\nSummary: TensorFlow is an open source machine learning framework for everyone.\nHome-page: https://www.tensorflow.org/\nAuthor: Google Inc.\nAuthor-email: packages@tensorflow.org\nLicense: Apache 2.0\nLocation: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\nRequires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, requests, setuptools, six, tensorboard, termcolor, typing-extensions, wrapt\nRequired-by: \n\n\n0",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/4 github json/1 github json.html",
    "href": "other/4 github json/1 github json.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\n\nmapview(all_data, map.types='OpenStreetMap',zoom=5,label='incident_type',xcol = \"Longitude\", ycol = \"Latitude\", crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n4 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 github json",
      "China accident map"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-json-file-and-convert-into-data-frame",
    "href": "data manipulation/1 input ouput.html#read-json-file-and-convert-into-data-frame",
    "title": "input & ouput in R",
    "section": "1.5 read JSON file and convert into data frame",
    "text": "1.5 read JSON file and convert into data frame\n\n\nCode\nlibrary(jsonlite)\ndata=read_json(\"./data/dataj.json\")\n\n\n\n\nCode\ndata002=(data) %&gt;% as.data.frame()\n\n\n\n\nCode\nglimpse(data002)\n\n\nRows: 1\nColumns: 11\n$ glossary.title                                                     &lt;chr&gt; \"ex…\n$ glossary.GlossDiv.title                                            &lt;chr&gt; \"S\"\n$ glossary.GlossDiv.GlossList.GlossEntry.ID                          &lt;chr&gt; \"SG…\n$ glossary.GlossDiv.GlossList.GlossEntry.SortAs                      &lt;chr&gt; \"SG…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossTerm                   &lt;chr&gt; \"St…\n$ glossary.GlossDiv.GlossList.GlossEntry.Acronym                     &lt;chr&gt; \"SG…\n$ glossary.GlossDiv.GlossList.GlossEntry.Abbrev                      &lt;chr&gt; \"IS…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossDef.para               &lt;chr&gt; \"A …\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossDef.GlossSeeAlso..GML. &lt;chr&gt; \"GM…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossDef.GlossSeeAlso..XML. &lt;chr&gt; \"XM…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossSee                    &lt;chr&gt; \"ma…",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "other/5 other web scraping package/chromote.html",
    "href": "other/5 other web scraping package/chromote.html",
    "title": "chromote",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(chromote)\n\n\n\n\nCode\npackageVersion(\"chromote\")\n\n\n\n1 create view\n\n\nCode\nlibrary(chromote)\n\nb &lt;- ChromoteSession$new()\n\n# In a web browser, open a viewer for the headless browser. Works best with\n# Chromium-based browsers.\nb$view()\n\n\n\n\nCode\nb$Browser$getVersion()\n\n\n\n\n2 go to page\n\n\nCode\nb$Page$navigate(\"https://www.r-project.org/\")\n\n\n\n\n3 take picture\n\n\nCode\n# Saves to screenshot.png\nb$screenshot()\n\n\n\n\nCode\n# Takes a screenshot of elements picked out by CSS selector\nis_interactive &lt;- interactive() # Display screenshot if interactive\nb$screenshot(\"sidebar.png\", selector = \"h1\" ,show = is_interactive)\n\n\n\n\n4 take picture as pdf\n\n\nCode\nb$screenshot_pdf(filename='page.pdf')\n\n\n\n\n5 Reference:\nhttps://rstudio.github.io/chromote/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other web scraping package",
      "chromote"
    ]
  },
  {
    "objectID": "other/4 github json/1 mapview.html",
    "href": "other/4 github json/1 mapview.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n\n\n\n\nCode\n#write.xlsx(all_data,'all_data.xlsx')\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\n\nmapview(all_data, map.types='OpenStreetMap',label='incident_type',xcol = \"Longitude\", ycol = \"Latitude\", crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n4 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 github json",
      "China accident map"
    ]
  },
  {
    "objectID": "other/4 Map/1 mapview.html",
    "href": "other/4 Map/1 mapview.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nall_data=all_data %&gt;% mutate(text=paste0(incident_type,\" \",\"死亡人数:\",person_death_num,\" 受伤人数:\",person_injury_num)\n                             ,month_year= format_ISO8601(ymd(start_date), precision = \"ym\")\n                             )\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 24\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ text               &lt;chr&gt; \"火灾 死亡人数:3 受伤人数:10\", \"溃水 死亡人数:3 受…\n$ month_year         &lt;chr&gt; \"2024-04\", \"2024-04\", \"2024-01\", \"2024-02\", \"2024-0…\n\n\n\n\nCode\n#write.xlsx(all_data,'all_data.xlsx')\n\n\n\n\n4 chart\ngroup to month\n\n\nCode\nchartdata001=all_data %&gt;% group_by(month_year)  %&gt;%  summarise(person_death_num=sum(person_death_num)\n                                                           ,person_injury_num=sum(person_injury_num)\n                                                           )\n\n\nwide to long\n\n\nCode\nchartdata002=chartdata001 %&gt;%select(month_year,person_death_num,person_injury_num) %&gt;% \n  pivot_longer(!c(month_year), names_to = 'type', values_to = 'DATA')\n\n\n\n\nCode\ngg=ggplot(chartdata001, aes(x=month_year, y=person_death_num,label = person_death_num))+\n  geom_bar(stat=\"identity\",fill='red')+ geom_text(vjust = -1,\n              position = position_dodge(width = 0.9))+ theme_bw()\n\n\nggplotly(gg)\n\n\n\n\n\n\n\n\nCode\ngg=ggplot(chartdata002, aes(fill=type, y=DATA, x=month_year)) +\n    geom_col(position = \"dodge\") +\n    geom_text(aes(label = DATA), vjust = 1.5,\n              position = position_dodge(width = 0.9))+scale_y_log10()+ theme_light()\n\npp=ggplotly(gg)\n\npp\n\n\n\n\n\n\n\n\n5 map\n\n\nCode\nall_data2 =all_data %&gt;%  mutate(report=report %&gt;% str_trunc(100))\n\n\n\n\nCode\n#write.xlsx(all_data2,'all_data2.xlsx')\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(stringr)\n\nmapview(all_data2, map.types='OpenStreetMap',label='text',xcol = \"Longitude\", ycol = \"Latitude\", zcol='incident_type',cex=\"person_death_num\",crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n6 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\nhttps://maps.clb.org.hk/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "China accident map"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 model.html#total",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 model.html#total",
    "title": "Model",
    "section": "4.1 total",
    "text": "4.1 total\n\n\nCode\nlen(padded)\nlen(review_flag_final)\n\n\n4655",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 model.html#train",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 model.html#train",
    "title": "Model",
    "section": "4.2 train",
    "text": "4.2 train\n\n\nCode\nlen(padded_train)\nlen(review_flag_final_train)\n\n\n4000",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 model.html#test",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 model.html#test",
    "title": "Model",
    "section": "4.3 test",
    "text": "4.3 test\n\n\nCode\nlen(padded_test)\nlen(review_flag_final_test)\n\n\n655\n\n\n\n\nCode\nsum(review_flag_final_test)\n\n\n169",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 model.html#if-all-guess-lower-than-90-points-then-0.72-accuracy",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 model.html#if-all-guess-lower-than-90-points-then-0.72-accuracy",
    "title": "Model",
    "section": "4.4 if all guess lower than 90 points then 0.72 accuracy",
    "text": "4.4 if all guess lower than 90 points then 0.72 accuracy\n\n\nCode\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)\n\n\n0.7419847328244275",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "Plot/5 China accident map.html",
    "href": "Plot/5 China accident map.html",
    "title": "Shiny in R:China accident map",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/China_accident_map/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R:China accident map"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#adjust-plot-size",
    "href": "Plot/1 ggplot2.html#adjust-plot-size",
    "title": "ggplot2 in R",
    "section": "7.4 adjust plot size",
    "text": "7.4 adjust plot size\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+theme(\n  plot.margin = margin(2, 2, 5, 5, \"cm\"))\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#adjust-text-size-and-center-title",
    "href": "Plot/1 ggplot2.html#adjust-text-size-and-center-title",
    "title": "ggplot2 in R",
    "section": "7.5 adjust text size and center title",
    "text": "7.5 adjust text size and center title\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+labs(caption = \"this is footnote\")\n\np+theme(plot.title = element_text(hjust = 0.5),text = element_text(size = 30))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#show-number",
    "href": "Plot/1 ggplot2.html#show-number",
    "title": "ggplot2 in R",
    "section": "3.1 show number",
    "text": "3.1 show number\n\n\nCode\nggplot(data002, aes(x=continent, y=pop)) +\n  geom_bar(stat=\"identity\")+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#change-bar-color",
    "href": "Plot/1 ggplot2.html#change-bar-color",
    "title": "ggplot2 in R",
    "section": "3.2 change bar color",
    "text": "3.2 change bar color\n\n\nCode\nggplot(data002, aes(x=continent, y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)\n\n\n\n\n\n\n\n\n\nCode\n# box plot",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#add-footnote",
    "href": "Plot/2 plotly.html#add-footnote",
    "title": "Plotly in R",
    "section": "7.4 add footnote",
    "text": "7.4 add footnote\n\n\nCode\nfig%&gt;% layout(annotations = \n                         list(x = 0, y = -0.1, \n                              text = \"this is footnote\", \n                              showarrow = F, \n                              xref='paper', \n                              yref='paper')\n    )",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "other/5 translation/1 translation.html",
    "href": "other/5 translation/1 translation.html",
    "title": "Translation",
    "section": "",
    "text": "Code\nlibrary(polyglotr)\n\n\n\n1 Translation word\n\n\nCode\nword_translation &lt;- linguee_word_translation(\"fruit\", source_language = \"en\", target_language = \"zh\")\n\nword_translation\n\n\n[1] \"水果\" \"果香\" \"果子\" \"果品\" \"实\"   \"檎\"  \n\n\n\n\n2 translate sentences\n\n\nCode\ngoogle_get_supported_languages()\n\n\n# A tibble: 134 × 2\n   Language    `ISO-639 code`\n   &lt;chr&gt;       &lt;chr&gt;         \n 1 Afrikaans   af            \n 2 Albanian    sq            \n 3 Amharic     am            \n 4 Arabic      ar            \n 5 Armenian    hy            \n 6 Assamese    as            \n 7 Aymara      ay            \n 8 Azerbaijani az            \n 9 Bambara     bm            \n10 Basque      eu            \n# ℹ 124 more rows\n\n\n\n\nCode\ntexts &lt;- c(\"Hello, how are you?\", \n           \"I love programming!\", \n           \"This is a test.\")\n\nlanguages &lt;- c(\"es\", \"fr\", \"zh-CN\")\n\n\ncreate_translation_table(texts, languages)\n\n\n        original_word                     es                          fr\n1 Hello, how are you?     ¿Hola, cómo estás? Bonjour comment allez-vous?\n2 I love programming! ¡Me encanta programar!  J'adore la programmation !\n3     This is a test.    Esto es una prueba.              C'est un test.\n           zh-CN\n1       你好吗？\n2   我喜欢编程！\n3 这是一个测试。\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 translation",
      "Translation"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 summary.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 summary.html",
    "title": "Summary",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n\n\n\n1 read in data\n\n\nCode\nimport pandas as pd\ndata=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\nCode\nlist(data)\n\n\n\n\nCode\ndata.info()\n\n\n\n\nCode\nimport re\ndata001=data&gt;&gt; filter(_.all_page_score &gt;0\n                      ,_.all_page_score &lt;100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) &gt;&gt;mutate(\n                      review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )&gt;&gt;mutate(review=_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',','').str.replace('(','').str.replace(')','').str.replace('-','').str.replace('apples','apple').str.replace('oranges','orange').str.replace('sweetness','sweet').str.replace('fruits','fruit'))&gt;&gt;mutate(review_len=_.review.str.count(' ') + 1)\n\n\n\n\nCode\ndata001['review_flag']= np.where(data001['all_page_score']&gt;=90, 1, 0)\n\n\n\n\n2 shuffle data\n\n\nCode\ndata002=data001.sample(frac=1)\n\n\n\n\nCode\ndata002.to_excel('data002.xlsx')\n\n\n\n\nCode\ndata002.info()\n\n\n\n\n3 Removing stop words with SkLearn\n\n\nCode\nimport nltk\nimport ssl\n\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('stopwords')\n\n\n\n\nCode\nfrom stop_words import get_stop_words\nfrom nltk.corpus import stopwords\n\nstop_words = list(get_stop_words('en'))         #About 900 stopwords\nnltk_words = list(stopwords.words('english')) #About 150 stopwords\nstop_words.extend(nltk_words)\n\n\n\n\nCode\nfrom nltk.corpus import stopwords\nimport string\n\nreview=data002[\"review\"]\n#stop_words = set(stopwords.words(\"english\"))\nexclude = set(string.punctuation)\n\ndef remove_stopwords(data):\n    output_array=[]\n    for sentence in data:\n        temp_list=[]\n        for word in sentence.split():\n            if word.lower() not in stop_words and word.lower() not in exclude :\n                temp_list.append(word)\n        output_array.append(' '.join(temp_list))\n    return output_array\n\nreview_remove_stop_word=remove_stopwords(review)\n\n\n\n\nCode\ntemp_list=[]\nfor sentence in review_remove_stop_word:\n        for word in sentence.split():\n          temp_list.append(word)\n\n\n\n\nCode\nfrom collections import Counter\ncounts = Counter(temp_list)\ndf = pd.DataFrame(list(counts.items()), columns=['Key', 'Values'])\n\n\n\n\nCode\ndf.to_excel('res.xlsx')\n\n\n\n\nCode\ndf002=df&gt;&gt;arrange(-_.Values) &gt;&gt;filter(_.Key!='notes'\n,_.Key!='well'\n,_.Key!='long'\n,_.Key!='quite'\n,_.Key!='hints'\n,_.Key!='hint'\n,_.Key!='light'\n,_.Key!='little'\n,_.Key!='slightly'\n,_.Key!='nice'\n,_.Key!='still'\n,_.Key!='medium'\n,_.Key!='subtle'\n,_.Key!='rather'\n,_.Key!='note'\n,_.Key!='also'\n,_.Key!='there’s'\n,_.Key!='background'\n,_.Key!='end'\n,_.Key!='side'\n,_.Key!='plenty'\n,_.Key!='towards'\n,_.Key!='bit'\n,_.Key!='dark'\n,_.Key!='really'\n,_.Key!='even'\n,_.Key!='like'\n,_.Key!='it’s'\n)\n\ndf003=df002[0:30]\n\n\n\n\n4 Word cloud 1 from data frame english\n\n\nCode\nd = {}\nfor a, x in df003.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = \"#FFFFFF\", contour_width = 2,\n     contour_color = '#FFFFFF')\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_en.png')\n\n\n\n\n5 word cloud 2 chinese\n\n\nCode\n#from translate import Translator\nfrom deep_translator import GoogleTranslator\n\nen=df003['Key'].tolist()\n\n\ncn_list=[]\nfor word in en:\n  result = GoogleTranslator(source='auto', target='zh-CN').translate(word) \n  cn_list.append(result)\n  \ncn_list\n\n\n\n\nCode\ndf003.to_excel('df003.xlsx',index=False)\ndf004_cn=df003.copy()\ndf004_cn['Key']=cn_list\ndf004_cn.to_excel('df004_cn.xlsx',index=False)\n\n\n\n\nCode\nd = {}\nfor a, x in df004_cn.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"#FFFFFF\", contour_width = 2,\n     contour_color = '#FFFFFF')\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\nwordcloud.to_file('wordcloud_cn.png')\n\n\n\n\n6 word cloud 3 chinese glass\n\n\nCode\nimport cv2\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom skimage.io import imread, imsave\nfrom skimage import util, data, transform\nfrom skimage.transform import rescale, resize, downscale_local_mean\n\n\nsample_img = imread('Glencairn.png')\nsample_img_resize=util.img_as_ubyte(transform.rescale(sample_img, 3))\nsample_img.shape\n\nsample_img_resize.shape\n\n\n\n\nCode\n#image = Image.open('glass.png')\n#new_image = image.resize((3000, 3000))\n#meta_mask = np.array(new_image)\n\nsample_img_resize[sample_img_resize&gt;240] = 255\n\n#meta_mask\n#im = Image.fromarray(meta_mask)\n#im.save('myimage_1.jpg')\n#np.unique(meta_mask)\n\n\n\n\nCode\nd = {}\nfor a, x in df004_cn.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"white\", contour_width = 2,mask = sample_img_resize)\n\n\n\nwordcloud.generate_from_frequencies(frequencies=d)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_cn_bottle.png')\n\n\n\n\n7 word cloud 4 English glass\n\n\nCode\nd = {}\nfor a, x in df003.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"white\", contour_width = 2,mask = sample_img_resize)\n\n\n\nwordcloud.generate_from_frequencies(frequencies=d)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_en_bottle.png')\n\n\n\n\n8 Chart 1\n\n\nCode\nplt.figure(figsize=(10, 6))\n\nplt.rcParams['font.family'] = ['Arial Unicode MS'] #用来正常显示中文标签\nplt.rcParams['axes.unicode_minus'] = False #用来正常显示负号\n \nsns.set_style('whitegrid',{'font.sans-serif':['Arial Unicode MS','Arial']})\n\nax=sns.barplot(df004_cn, x=\"Values\", y=\"Key\", legend=False)\n\nax.set_title(\"各风味出现频率\")\nax.set(xlabel='出现次数', ylabel='风味')\nfor i in ax.containers:\n    ax.bar_label(i,)\nplt.show()\n\n\n\n\n9 Chart 2 combine image and seaborn\n\n\nCode\nimport plotly.express as px\nfrom PIL import Image\npyLogo = Image.open(\"en_glass.png\")\n\n\nfig=px.bar(df004_cn,x=\"Values\", y=\"Key\",orientation='h',text=\"Values\",title=\"各风味出现频率\"\n,labels={\"Values\": \"出现次数\",\n         \"Key\": \"风味\"\n         }\n)\n\n# Add trace\n# fig.add_trace(\n#     go.Bar(x=df003[\"Values\"], y=df003[\"Key\"],orientation='h',text=df003[\"Values\"])\n#     #go.Bar(x=[0, 50, 100, 200, 220], y=[100, 200, 420, 300, 100])\n# )\n# \n# # Add images\nfig.add_layout_image(\n        dict(\n            source=pyLogo \n            ,x=0.6\n            ,y=0.8\n            ,sizex=1\n            ,sizey=0.8\n            #,sizing=\"stretch\"\n            ,opacity=0.8\n            ,layer=\"above\")\n)\n\n# # Set templates\nfig.update_layout(template=\"plotly_white\")\nfig.update_layout(yaxis=dict(autorange=\"reversed\"),height=600)\n\n\nfig.show()\n\n\n\n\n10 resource:\nhttps://medium.com/@m3redithw/wordclouds-with-python-c287887acc8b\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Summary"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/4b whiskynote all year page second time.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/4b whiskynote all year page second time.html",
    "title": "All year page second time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 read from 2024\n\n\nCode\nurl_list=\"https://www.whiskynotes.be/2024\"\n\n\n\n\nCode\nbottle_list=c()\ntopic_list=c()\ntopic_link_list=c()\nall_year_list_topic=c()\nall_year_list_bottle=c()\n\nfor (i in url_list){\n  year=tail(unlist(strsplit(i, split = \"/\")),1)\n  print(year)\n  print(i)\n  year_ur=i\n  year_page &lt;- read_html(year_ur)\n  bottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\n  bottle003=unlist(strsplit(bottle001,\"\\n\"))\n  \n  \n  topic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\n  topic_link_001 &lt;- year_page %&gt;%\n    html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\n  year_list_topic=rep(year,length(topic001))\n  year_list_bottle=rep(year,length(bottle003))\n  \n  all_year_list_topic=c(all_year_list_topic,year_list_topic)\n  all_year_list_bottle=c(all_year_list_bottle,year_list_bottle)\n  \n  bottle_list=c(bottle_list,bottle003)\n  topic_list=c(topic_list,topic001)\n  topic_link_list=c(topic_link_list,topic_link_001)\n  \n  Sys.sleep(1)\n  }\n\n\n\n\n2 combine\n\n\nCode\ndata=tibble(topic_list,topic_link_list,all_year_list_topic)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\ndata_all=read_excel('./output/all year page.xlsx')\n\n\n\n\nCode\ndata_all_new001=rbind(data_all,data)\n\n\n\n\nCode\nglimpse(data_all_new001)\n\n\n\n\nCode\ndata_all_new002=data_all_new001 %&gt;% unique()\n\n\n\n\nCode\nglimpse(data_all_new002)\n\n\n\n\n3 output\n\n\nCode\nlibrary(openxlsx)\nlist_of_datasets &lt;- list(\"topic\" = data_all_new002)\n\nwrite.xlsx(list_of_datasets, file = \"./output/all year page.xlsx\")\n\n\n\n\n4 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year page second time"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-subtitle",
    "href": "Plot/1 ggplot2.html#add-subtitle",
    "title": "ggplot2 in R",
    "section": "7.2 add subtitle",
    "text": "7.2 add subtitle\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\",subtitle = \"Subtitle of the plot\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html",
    "title": "Model",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#total",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#total",
    "title": "Model",
    "section": "4.1 total",
    "text": "4.1 total\n\n\nCode\nlen(padded)\nlen(review_flag_final)\n\n\n4633",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#train",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#train",
    "title": "Model",
    "section": "4.2 train",
    "text": "4.2 train\n\n\nCode\nlen(padded_train)\nlen(review_flag_final_train)\n\n\n4000",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#test",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#test",
    "title": "Model",
    "section": "4.3 test",
    "text": "4.3 test\n\n\nCode\nlen(padded_test)\nlen(review_flag_final_test)\n\n\n633\n\n\n\n\nCode\nsum(review_flag_final_test)\n\n\n176",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#if-all-guess-lower-than-90-points-then-0.72-accuracy",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#if-all-guess-lower-than-90-points-then-0.72-accuracy",
    "title": "Model",
    "section": "4.4 if all guess lower than 90 points then 0.72 accuracy",
    "text": "4.4 if all guess lower than 90 points then 0.72 accuracy\n\n\nCode\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)\n\n\n0.721958925750395",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#define-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#define-model",
    "title": "Model",
    "section": "5.1 define model",
    "text": "5.1 define model\n\n\nCode\n# Build the model\nmodel_dnn = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=  32),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#compile-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#compile-model",
    "title": "Model",
    "section": "5.2 compile model",
    "text": "5.2 compile model\n\n\nCode\n# Setup the training parameters\nmodel_dnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n\n\n\nCode\nmodel_dnn.summary()\n\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (Embedding)           │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ ?                      │   0 (unbuilt) │\n│ (GlobalAveragePooling1D)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (Dense)                   │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (Dense)                 │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (Dense)                 │ ?                      │   0 (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 0 (0.00 B)\n\n\n\n Trainable params: 0 (0.00 B)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#callbacks",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#callbacks",
    "title": "Model",
    "section": "5.3 Callbacks",
    "text": "5.3 Callbacks\n\n\nCode\nclass myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('val_accuracy')&gt;0.90):\n      print(\"\\nReached 88% val_accuracy so cancelling training!\")\n      self.model.stop_training = True\n\n# Instantiate class\ncallbacks = myCallback()",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#train-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#train-model",
    "title": "Model",
    "section": "5.4 train model",
    "text": "5.4 train model\n\n\nCode\nnum_epochs = 20\n\n# Train the model\nhistory=model_dnn.fit(x=padded_train, y=review_flag_final_train, validation_data=(padded_test, review_flag_final_test),epochs=num_epochs,shuffle=True,callbacks=[callbacks],verbose=0)\n\n#history=model.fit(x=padded, y=review_flag_final, validation_split=0.2, shuffle=True,epochs=num_epochs,callbacks=[callbacks])\n\n\n\n\nCode\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n\n\n\n\nCode\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.show()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#define-model-1",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#define-model-1",
    "title": "Model",
    "section": "6.1 define model",
    "text": "6.1 define model\n\n\nCode\nmodel_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(input_dim=vocab_size,output_dim= 32),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)),\n      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#compile-model-1",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#compile-model-1",
    "title": "Model",
    "section": "6.2 compile model",
    "text": "6.2 compile model\n\n\nCode\n# Setup the training parameters\nmodel_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n\n\n\nCode\nmodel_lstm.summary()\n\n\nModel: \"sequential_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (Embedding)         │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (Bidirectional)   │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (Bidirectional) │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (Dense)                 │ ?                      │   0 (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (Dense)                 │ ?                      │   0 (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 0 (0.00 B)\n\n\n\n Trainable params: 0 (0.00 B)\n\n\n\n Non-trainable params: 0 (0.00 B)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#train-model-2",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#train-model-2",
    "title": "Model",
    "section": "9.1 train model",
    "text": "9.1 train model\n\n\nCode\n# Train the model\nhistory = model_dnn.fit(x=padded_train, y=review_socre_final_train,validation_data=(padded_test, review_socre_final_test),epochs=200,verbose=0 )\n\n#history = model_dnn.fit(x=padded_train, y=review_socre_final_train,validation_split=0.2,epochs=20)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#predication",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#predication",
    "title": "Model",
    "section": "9.4 predication",
    "text": "9.4 predication\n\n\nCode\nx = padded_test\ny = model_dnn.predict(x)\n\n\n 1/20 ━━━━━━━━━━━━━━━━━━━━ 0s 29ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step \n\n\n\n\nCode\nlen(padded_test)\nlen(y)\nlen(review_socre_final_test)\n\n\n633\n\n\n\n\nCode\nreview_socre_final_test.shape\n\n\n(633,)\n\n\n\n\nCode\ny.shape\n\n\n(633, 1)\n\n\n\n\nCode\ny2 = y.flatten()\n\n\n\n\nCode\ny2.shape\n\n\n(633,)\n\n\n\n\nCode\ndataset = pd.DataFrame({'real': review_socre_final_test, 'predic': list(y2)}, columns=['real', 'predic'])\n\n\n\n\nCode\ndataset['predic']=round(dataset['predic'])\ndataset['predic']=round(dataset['predic'])\n\n\n\n\nCode\ndataset=dataset&gt;&gt; mutate(predic=if_else(_.predic &lt;70, 70, _.predic)\n                          ,dummy_pred=86\n                         ,diff=_.predic-_.real \n                         ,dummy_diff=_.dummy_pred-_.real\n                          )&gt;&gt; mutate(predic=if_else(_.predic &gt;100,100, _.predic))\n                          \ndataset002 = pd.concat([data002[4000:].reset_index(drop=True),dataset.reset_index(drop=True)], axis=1)                    \n\n\n\n\nCode\ndataset002.to_excel('pred.xlsx')\n\n\n\n\nCode\nimport seaborn as sns\nfig, ax = plt.subplots()\n\nsns.scatterplot(data=dataset,x='real',y='predic',ax=ax)\nsns.regplot(data=dataset, x=\"real\", y=\"predic\", x_jitter=.15,ax=ax)\nax.set(xlim=(65, 100),ylim=(65, 100))",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#save-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#save-model",
    "title": "Model",
    "section": "9.2 save model",
    "text": "9.2 save model\n\n\nCode\nmodel_dnn.save('whiskynote_score_dnn.keras')",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 model.html#load-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 model.html#load-model",
    "title": "Model",
    "section": "9.3 load model",
    "text": "9.3 load model\n\n\nCode\nnew_model = tf.keras.models.load_model('whiskynote_score_dnn.keras')\n\n\n\n\nCode\nnew_model.summary()\n\n\nModel: \"sequential_2\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (Embedding)         │ (32, 300, 32)          │       224,000 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_1      │ (32, 32)               │             0 │\n│ (GlobalAveragePooling1D)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (Dense)                 │ (32, 32)               │         1,056 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (Dense)                 │ (32, 24)               │           792 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (Dense)                 │ (32, 24)               │           600 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (Dense)                 │ (32, 1)                │            25 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 679,421 (2.59 MB)\n\n\n\n Trainable params: 226,473 (884.66 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n Optimizer params: 452,948 (1.73 MB)\n\n\n\n\n\nCode\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nmae = history.history['mae']\nval_mae = history.history['val_mae']\n\nepochs = range(len(val_loss))\n\n\n\n\nCode\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Only plot the last 80% of the epochs\nzoom_split = int(epochs[-1] * 0.2)\nepochs_zoom = epochs[zoom_split:]\nval_loss_zoom = val_loss[zoom_split:]\nloss_zoom = loss[zoom_split:]\n\n# Plot zoomed mae and loss\nplt.plot(epochs_zoom, loss_zoom, 'r', label='Training Loss')\nplt.plot(epochs_zoom, val_loss_zoom, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Only plot the last 80% of the epochs\nzoom_split = int(epochs[-1] * 0.2)\nepochs_zoom = epochs[zoom_split:]\n\nmae_zoom = mae[zoom_split:]\nval_mae_zoom = val_mae[zoom_split:]\n\n\n# Plot zoomed mae and loss\nplt.plot(epochs_zoom, mae_zoom, 'r', label='mae_zoom')\nplt.plot(epochs_zoom, val_mae_zoom, 'b', label='val_mae_zooms')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Model"
    ]
  },
  {
    "objectID": "other/4 Map/2 leaflet .html",
    "href": "other/4 Map/2 leaflet .html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(leaflet)\n\n\n\n\nCode\nm &lt;- leaflet() %&gt;%\n  addTiles() %&gt;%  # Add default OpenStreetMap map tiles\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\nm  # Print the map\n\n\n\n\n\n\n\n\n2 resouce:\nhttps://rstudio.github.io/leaflet/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "map"
    ]
  },
  {
    "objectID": "other/4 Map/1 China accident map with mapview.html",
    "href": "other/4 Map/1 China accident map with mapview.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nall_data=all_data %&gt;% mutate(text=paste0(incident_type,\" \",\"死亡人数:\",person_death_num,\" 受伤人数:\",person_injury_num)\n                             ,month_year= format_ISO8601(ymd(start_date), precision = \"ym\")\n                             )\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 24\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ text               &lt;chr&gt; \"火灾 死亡人数:3 受伤人数:10\", \"溃水 死亡人数:3 受…\n$ month_year         &lt;chr&gt; \"2024-04\", \"2024-04\", \"2024-01\", \"2024-02\", \"2024-0…\n\n\n\n\nCode\n#write.xlsx(all_data,'all_data.xlsx')\n\n\n\n\n4 chart\ngroup to month\n\n\nCode\nchartdata001=all_data %&gt;% group_by(month_year)  %&gt;%  summarise(person_death_num=sum(person_death_num)\n                                                           ,person_injury_num=sum(person_injury_num)\n                                                           )\n\n\nwide to long\n\n\nCode\nchartdata002=chartdata001 %&gt;%select(month_year,person_death_num,person_injury_num) %&gt;% \n  pivot_longer(!c(month_year), names_to = 'type', values_to = 'DATA')\n\n\n\n\nCode\ngg=ggplot(chartdata001, aes(x=month_year, y=person_death_num,label = person_death_num))+\n  geom_bar(stat=\"identity\",fill='red')+ geom_text(vjust = -1,\n              position = position_dodge(width = 0.9))+ theme_bw()\n\n\nggplotly(gg)\n\n\n\n\n\n\n\n\nCode\ngg=ggplot(chartdata002, aes(fill=type, y=DATA, x=month_year)) +\n    geom_col(position = \"dodge\") +\n    geom_text(aes(label = DATA), vjust = 1.5,\n              position = position_dodge(width = 0.9))+scale_y_log10()+ theme_light()\n\npp=ggplotly(gg)\n\npp\n\n\n\n\n\n\n\n\n5 map\n\n\nCode\nall_data2 =all_data %&gt;%  mutate(report=report %&gt;% str_trunc(100))\n\n\n\n\nCode\n#write.xlsx(all_data2,'all_data2.xlsx')\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(stringr)\n\nmapview(all_data2, map.types='OpenStreetMap',label='text',xcol = \"Longitude\", ycol = \"Latitude\", zcol='incident_type',cex=\"person_death_num\",crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n6 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\nhttps://maps.clb.org.hk/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "China accident map"
    ]
  },
  {
    "objectID": "other/4 Map/2 leaflet.html",
    "href": "other/4 Map/2 leaflet.html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(leaflet)\n\n\n\n\nCode\nm &lt;- leaflet() %&gt;%\n  addTiles() %&gt;%  # Add default OpenStreetMap map tiles\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\nm  # Print the map\n\n\n\n\n\n\n\n\n2 resouce:\nhttps://rstudio.github.io/leaflet/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "map"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8b summary in R.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/8b summary in R.html",
    "title": "Summary in R",
    "section": "",
    "text": "Code\n#must install the package from github\n#install.packages('devtools')  \n#devtools::install_github(\"lchiffon/wordcloud2\")  \n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n1 read in data\n\n\nCode\ndata001=read_excel('./output/all_page_bottle_list_all.xlsx')\nglimpse(data001)\n\n\nRows: 4,934\nColumns: 9\n$ bottle_name          &lt;chr&gt; \"Cognac Chollet Lot 1960 ‘Le Bon Vivant’ – Fins B…\n$ bottle_review_Nose   &lt;chr&gt; \"Nose: a rich, fragrant and fruity style. Honeyed…\n$ bottle_review_Mouth  &lt;chr&gt; \"Mouth: more spices now. Mint and pepper, leading…\n$ bottle_review_Finish &lt;chr&gt; \"Finish: medium to long, more on fruit tea now, a…\n$ all_page_score       &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"85\", \"82\", \"8…\n$ page_class           &lt;chr&gt; \"* Cognac\", \"* Cognac\", \"* Cognac\", \"Ledaig\", \"Le…\n$ page_published_date  &lt;chr&gt; \"30 November 2020\", \"30 November 2020\", \"30 Novem…\n$ page_title           &lt;chr&gt; \"Cognac Lot 1960 / XO / Lot 1906 (Malternative Be…\n$ review_url           &lt;chr&gt; \"https://www.whiskynotes.be/2020/cognac/cognac-lo…\n\n\n\n\nCode\ndata002=data001 %&gt;% filter(as.numeric(all_page_score)&gt;0,as.numeric(all_page_score)&lt;100\n                       ,bottle_review_Nose !='no comment'\n                      ,bottle_review_Mouth !='no comment'\n                      ,bottle_review_Finish !='no comment'\n                           \n                           \n                           ) %&gt;% \n  mutate(review=paste(bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish) %&gt;% \n                             str_to_lower() %&gt;% str_replace_all(\"[[:punct:]]\", \"\") %&gt;% \n                            str_replace_all('sweetness','sweet') %&gt;% str_replace_all('apples','apple')%&gt;% str_replace_all('oranges','orange') %&gt;% str_replace_all('fruits','fruit')\n\n                           )\n\nreivew002=data002$review\n\n\n\n\nCode\ntest='able stees a asdf df able' %&gt;%str_split(\" \") %&gt;% unlist %&gt;% unique %&gt;% paste(collapse = ' ')\ntest\n\n\n[1] \"able stees a asdf df\"\n\n\n\n\nCode\nreivew003=c()\n\nfor (i in reivew002){\n a=i%&gt;%str_split(\" \") %&gt;% unlist %&gt;% unique%&gt;% paste(collapse = ' ')\n  reivew003=c(reivew003,a)\n}\n\n\n\n\nCode\ntest001=reivew003 %&gt;% tibble() %&gt;% rename('review'='.')\n\n\n\n\nCode\ntest002_without_sweet=test001[!grepl(\"sweet\",test001$review),]\ntest002_sweet=test001[grepl(\"sweet\",test001$review),]\n\n\n\n\nCode\nstring &lt;- reivew003\n\ndata002=data.frame(string) %&gt;%\n  separate_rows(string) %&gt;%\n  count(string, sort = TRUE) %&gt;%\n  filter(n &gt;= 2)\n\n\n\n\n2 remove stop word\n\n\nCode\nlibrary(tidytext)\n\ndata003 &lt;- data002 %&gt;%\n  anti_join(stop_words, by= c(\"string\" = \"word\"))\n\n\n\n\n3 remove non favour word\n\n\nCode\ndata004 &lt;- data003 %&gt;% filter(!string %in% c('notes','hints'\n                                            ,'nose'\n                                           ,'finish'\n                                            ,'light', 'slightly', 'hint', 'nice'\n                                           ,'medium' , 'subtle', 'background','note' ,'plenty' ,'lots'\n                                           ,'mouth','bit','soft','dark')\n                                          )\n\n\n\n\n4 translate to chinese\n\n\nCode\ndata005=head(data004,30)\n\n\n\n\nCode\nlibrary(gtranslate)\n#lang_codes\n\ndata005_cn=translate(data005$string, from = \"en\", to = \"zh-CN\")\n\n\n\n\nCode\ndata005_cn=cbind(data005_cn,data005)\ndata005_cn=data005_cn %&gt;% select(-string)\n\n\n\n\n5 word cloud 1 english\n\n\nCode\nlibrary(wordcloud2) \n\n\n\n\nCode\nmy_graph_en=wordcloud2(data=data005, size=1)\n#my_graph_en\n\n\n\n\nCode\nlibrary(webshot2)\nlibrary(htmlwidgets)\n\nsaveWidget(my_graph_en,\"tmp_en.html\")#先保存为网页格式\n\nwebshot(\"tmp_en.html\", \"wordcloud_en.jpg\", delay = 2) ##IRIENI\n\n\n\n\n\n\n\n\n\n\n\n6 word cloud 2 chinese\n\n\nCode\nlibrary(showtext)\nshowtext_auto()\npar(family=\"PingFangSC-Regular\")\nmy_graph=wordcloud2(data=data005_cn,size=1)\n#my_graph\n\n\n\n\nCode\nlibrary(webshot2)\nlibrary(htmlwidgets)\n\nsaveWidget(my_graph,\"tmp.html\")#先保存为网页格式\n\nwebshot(\"tmp.html\", \"wordcloud.jpg\", delay = 2) ##IRIENI\n\n\n\n\n\n\n\n\n\n\n\n7 chart 1 with gglolt\n\n\nCode\nlibrary(ggplot2) \nggplot(data005, aes(x=reorder(string,n), y=n)) +geom_text(aes(label = n), hjust = -0.1)+ ylim(min=0, 3200)+\n  geom_bar(stat=\"identity\")+coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n8 chart 2 add image gglolt\n\n\nCode\nlibrary(ggplot2) \nlibrary(png)\nlibrary(grid)\nlibrary(patchwork) \n\n\nimg2 &lt;- readPNG(\"en_glass.png\")\nimg3=rasterGrob(img2, width = unit(1,\"npc\"), height = unit(1,\"npc\"))\n\ngg=ggplot(data005, aes(x=reorder(string,n), y=n))+theme_classic()+geom_text(aes(label = n), hjust = -0.1)+xlab(\"Flavor\") + ylab(\"Frequency\")+scale_y_continuous(expand=c(0,0),limits=c(0,3200))+\n  geom_bar(stat=\"identity\",fill=\"#CD5C5C\")+coord_flip()+ggtitle(\"Whisky notes Top30 most used words\",subtitle = \"5K review\")+labs(caption = \"data source from www.whiskynote.be between 2010 to 2024\")+\n  inset_element(img3, 0.66, 0.15, 1, 0.75,align_to = 'full')\n\n\n\n\nCode\ngg\n\n\n\n\n\n\n\n\n\n\n\n9 chart 2 add image gglolt in chinese\n\n\nCode\nlibrary(ggplot2) \nlibrary(png)\nlibrary(grid)\nlibrary(patchwork) \n\nlibrary(showtext)\nshowtext_auto()\n\n\nimg2 &lt;- readPNG(\"cn_glass.png\")\nimg3=rasterGrob(img2, width = unit(1,\"npc\"), height = unit(1,\"npc\"))\n\ngg=ggplot(data005_cn, aes(x=reorder(data005_cn,n), y=n))+theme_classic()+geom_text(aes(label = n), hjust = -0.1)+xlab(\"风味\") + ylab(\"次数\")+scale_y_continuous(expand=c(0,0),limits=c(0,3200))+\n  geom_bar(stat=\"identity\",fill=\"#CD5C5C\")+coord_flip()+ggtitle(\"Whisky notes Top30 风味词\",subtitle = \"5K+ 酒评\")+labs(caption = \"数据源:www.whiskynote.be 从2010年到2024年\")+\n  inset_element(img3, 0.65, 0.15, 1, 0.75,align_to = 'full')\n\n\n\n\nCode\ngg\n\n\n\n\n\n\n\n\n\n\n\n10 resource:\nhttps://github.com/Lchiffon/wordcloud2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Summary in R"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 summary in python.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 summary in python.html",
    "title": "Summary in Python",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n\n\n\n1 read in data\n\n\nCode\nimport pandas as pd\ndata=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\nCode\nlist(data)\n\n\n['bottle_name',\n 'bottle_review_Nose',\n 'bottle_review_Mouth',\n 'bottle_review_Finish',\n 'all_page_score',\n 'page_class',\n 'page_published_date',\n 'page_title',\n 'review_url']\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4934 entries, 0 to 4933\nData columns (total 9 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4934 non-null   object\n 1   bottle_review_Nose    4934 non-null   object\n 2   bottle_review_Mouth   4934 non-null   object\n 3   bottle_review_Finish  4934 non-null   object\n 4   all_page_score        4934 non-null   int64 \n 5   page_class            4934 non-null   object\n 6   page_published_date   4934 non-null   object\n 7   page_title            4934 non-null   object\n 8   review_url            4934 non-null   object\ndtypes: int64(1), object(8)\nmemory usage: 347.1+ KB\n\n\n\n\nCode\nimport re\ndata001=data&gt;&gt; filter(_.all_page_score &gt;0\n                      ,_.all_page_score &lt;100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) &gt;&gt;mutate(\n                      review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )&gt;&gt;mutate(review=_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',','').str.replace('(','').str.replace(')','').str.replace('-','').str.replace('apples','apple').str.replace('oranges','orange').str.replace('sweetness','sweet').str.replace('fruits','fruit'))&gt;&gt;mutate(review_len=_.review.str.count(' ') + 1)\n\n\n\n\nCode\ndata001['review_flag']= np.where(data001['all_page_score']&gt;=90, 1, 0)\n\n\n\n\n2 shuffle data\n\n\nCode\ndata002=data001.sample(frac=1)\n\n\n\n\nCode\ndata002.to_excel('data002.xlsx')\n\n\n\n\nCode\ndata002.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 4668 entries, 1260 to 2222\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4668 non-null   object\n 1   bottle_review_Nose    4668 non-null   object\n 2   bottle_review_Mouth   4668 non-null   object\n 3   bottle_review_Finish  4668 non-null   object\n 4   all_page_score        4668 non-null   int64 \n 5   page_class            4668 non-null   object\n 6   page_published_date   4668 non-null   object\n 7   page_title            4668 non-null   object\n 8   review_url            4668 non-null   object\n 9   review                4668 non-null   object\n 10  review_len            4668 non-null   int64 \n 11  review_flag           4668 non-null   int64 \ndtypes: int64(3), object(9)\nmemory usage: 474.1+ KB\n\n\n\n\n3 Removing stop words with SkLearn\n\n\nCode\nimport nltk\nimport ssl\n\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('stopwords')\n\n\nTrue\n\n\n\n\nCode\nfrom stop_words import get_stop_words\nfrom nltk.corpus import stopwords\n\nstop_words = list(get_stop_words('en'))         #About 900 stopwords\nnltk_words = list(stopwords.words('english')) #About 150 stopwords\nstop_words.extend(nltk_words)\n\n\n\n\nCode\nfrom nltk.corpus import stopwords\nimport string\n\nreview=data002[\"review\"]\n#stop_words = set(stopwords.words(\"english\"))\nexclude = set(string.punctuation)\n\ndef remove_stopwords(data):\n    output_array=[]\n    for sentence in data:\n        temp_list=[]\n        for word in sentence.split():\n            if word.lower() not in stop_words and word.lower() not in exclude :\n                temp_list.append(word)\n        output_array.append(' '.join(temp_list))\n    return output_array\n\nreview_remove_stop_word=remove_stopwords(review)\n\n\n\n\nCode\ntemp_list=[]\nfor sentence in review_remove_stop_word:\n        for word in sentence.split():\n          temp_list.append(word)\n\n\n\n\nCode\nfrom collections import Counter\ncounts = Counter(temp_list)\ndf = pd.DataFrame(list(counts.items()), columns=['Key', 'Values'])\n\n\n\n\nCode\ndf.to_excel('res.xlsx')\n\n\n\n\nCode\ndf002=df&gt;&gt;arrange(-_.Values) &gt;&gt;filter(_.Key!='notes'\n,_.Key!='well'\n,_.Key!='long'\n,_.Key!='quite'\n,_.Key!='hints'\n,_.Key!='hint'\n,_.Key!='light'\n,_.Key!='little'\n,_.Key!='slightly'\n,_.Key!='nice'\n,_.Key!='still'\n,_.Key!='medium'\n,_.Key!='subtle'\n,_.Key!='rather'\n,_.Key!='note'\n,_.Key!='also'\n,_.Key!='there’s'\n,_.Key!='background'\n,_.Key!='end'\n,_.Key!='side'\n,_.Key!='plenty'\n,_.Key!='towards'\n,_.Key!='bit'\n,_.Key!='dark'\n,_.Key!='really'\n,_.Key!='even'\n,_.Key!='like'\n,_.Key!='it’s'\n)\n\ndf003=df002[0:30]\n\n\n\n\n4 Word cloud 1 from data frame english\n\n\nCode\nd = {}\nfor a, x in df003.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = \"#FFFFFF\", contour_width = 2,\n     contour_color = '#FFFFFF')\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_en.png')\n\n\n\n\n\n\n\n\n\n\n\n5 translate to chinese\n\n\nCode\n#from translate import Translator\nfrom deep_translator import GoogleTranslator\n\nen=df003['Key'].tolist()\n\n\ncn_list=[]\nfor word in en:\n  result = GoogleTranslator(source='auto', target='zh-CN').translate(word) \n  cn_list.append(result)\n  \ncn_list\n\n\n['甜的',\n '水果',\n '橡木',\n '香草',\n '苹果',\n '橙子',\n '胡椒',\n '果味的',\n '蜂蜜',\n '草药的',\n '巧克力',\n '姜',\n '柠檬',\n '木头',\n '抽烟',\n '甘草',\n '薄荷',\n '烟草',\n '绿色的',\n '茶',\n '柚子',\n '肉桂',\n '新鲜的',\n '柑橘',\n '干的',\n '香料',\n '雪莉酒',\n '菠萝',\n '葡萄干',\n '长满青草的']\n\n\n\n\nCode\ndf003.to_excel('df003.xlsx',index=False)\ndf004_cn=df003.copy()\ndf004_cn['Key']=cn_list\ndf004_cn.to_excel('df004_cn.xlsx',index=False)\n\n\n\n\n6 word cloud 2 chinese\n\n\nCode\nd = {}\nfor a, x in df004_cn.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"#FFFFFF\", contour_width = 2,\n     contour_color = '#FFFFFF')\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\nwordcloud.to_file('wordcloud_cn.png')\n\n\n\n\n\n\n\n\n\n\n\n7 word cloud 3 chinese glass\n\n\nCode\nimport cv2\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom skimage.io import imread, imsave\nfrom skimage import util, data, transform\nfrom skimage.transform import rescale, resize, downscale_local_mean\n\n\nsample_img = imread('Glencairn.png')\nsample_img_resize=util.img_as_ubyte(transform.rescale(sample_img, 3))\nsample_img.shape\n\nsample_img_resize.shape\n\n\n(2328, 2892, 12)\n\n\n\n\nCode\n#image = Image.open('glass.png')\n#new_image = image.resize((3000, 3000))\n#meta_mask = np.array(new_image)\n\nsample_img_resize[sample_img_resize&gt;240] = 255\n\n\n#imsave(\"glass_new.png\", sample_img_resize)\n\n\n\n\nCode\nd = {}\nfor a, x in df004_cn.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"white\", contour_width = 2,mask = sample_img_resize)\n\n\n\nwordcloud.generate_from_frequencies(frequencies=d)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_cn_bottle.png')\n\n\n\n\n\n\n\n\n\n\n\n8 word cloud 4 English glass\n\n\nCode\nd = {}\nfor a, x in df003.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"white\", contour_width = 2,mask = sample_img_resize)\n\n\n\nwordcloud.generate_from_frequencies(frequencies=d)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_en_bottle.png')\n\n\n\n\n\n\n\n\n\n\n\n9 Chart 1\nusing seaborn\n\n\nCode\nplt.figure(figsize=(10, 6))\n\nplt.rcParams['font.family'] = ['Arial Unicode MS'] #用来正常显示中文标签\nplt.rcParams['axes.unicode_minus'] = False #用来正常显示负号\n \nsns.set_style('whitegrid',{'font.sans-serif':['Arial Unicode MS','Arial']})\n\nax=sns.barplot(df004_cn, x=\"Values\", y=\"Key\", legend=False,orient = 'h')\n\nax.set_title(\"各风味出现频率\")\nax.set(xlabel='出现次数', ylabel='风味')\nfor i in ax.containers:\n    ax.bar_label(i,)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n10 Chart 2 combine image and seaborn\nusing plotly\n\n\nCode\nimport plotly.express as px\nfrom PIL import Image\npyLogo = Image.open(\"en_glass.png\")\n\n\nfig=px.bar(df004_cn,x=\"Values\", y=\"Key\",orientation='h',text=\"Values\",title=\"各风味出现频率\"\n,labels={\"Values\": \"出现次数\",\n         \"Key\": \"风味\"\n         }\n)\n\n\n# Add images\nfig.add_layout_image(\n        dict(\n            source=pyLogo \n            ,x=0.6\n            ,y=0.8\n            ,sizex=1\n            ,sizey=0.8\n            #,sizing=\"stretch\"\n            ,opacity=0.8\n            ,layer=\"above\")\n)\n\n# # Set templates\nfig.update_layout(template=\"plotly_white\")\nfig.update_layout(yaxis=dict(autorange=\"reversed\"),height=600)\n\n\nfig.show()\n\n\n                                                \n\n\n\n\n11 resource:\nhttps://medium.com/@m3redithw/wordclouds-with-python-c287887acc8b\nhttps://github.com/nidhaloff/deep-translator\nhttps://cran.r-project.org/web/packages/polyglotr/vignettes/polyglotr.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Summary in Python"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-chinese",
    "href": "Plot/1 ggplot2.html#add-chinese",
    "title": "ggplot2 in R",
    "section": "7.7 add chinese",
    "text": "7.7 add chinese\n\n\nCode\nlibrary(showtext)\nshowtext_auto()\n\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"新的 x name\")+ scale_y_continuous(name=\"新的 y name\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#bar-plot-order",
    "href": "Plot/1 ggplot2.html#bar-plot-order",
    "title": "ggplot2 in R",
    "section": "3.3 bar plot order",
    "text": "3.3 bar plot order\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)\n\n\n\n\n\n\n\n\n\nCode\n# box plot\n\n\n\n\nCode\nggplot(data002, aes(x=reorder(continent,-pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)\n\n\n\n\n\n\n\n\n\nCode\n# box plot",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#horizontal-barplot",
    "href": "Plot/1 ggplot2.html#horizontal-barplot",
    "title": "ggplot2 in R",
    "section": "3.4 Horizontal Barplot",
    "text": "3.4 Horizontal Barplot\n`\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)+coord_flip()\n\n\n\n\n\n\n\n\n\nCode\n# box plot",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "other/5 other/3 image processing.html",
    "href": "other/5 other/3 image processing.html",
    "title": "image processing",
    "section": "",
    "text": "Code\nlibrary(magick)\n\n\n\n1 input\n\n\nCode\nraw_logo &lt;- image_read('./images/comb.webp')\n\n\n\n\n2 output\n\n\nCode\nimage_info(raw_logo)\n\n\n  format width height colorspace matte filesize density\n1   WEBP   450    303       sRGB  TRUE    49650   72x72\n\n\n\n\n3 change format\n\n\nCode\nnew_png &lt;- image_convert(raw_logo, \"png\")\n\n\n\n\nCode\nimage_info(new_png)\n\n\n  format width height colorspace matte filesize density\n1    PNG   450    303       sRGB  TRUE        0   72x72\n\n\n\n\n4 output\n\n\nCode\nimage_write(new_png, path = \"./images/new_png.png\", format = \"png\")\n\n\n\n\nCode\nraw_logo &lt;- image_read('./images/logo1.png')\n\n\n\n\nCode\nraw_logo %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE    53960   72x72\n\n\n\n\n\n\n\n\n\n\n\n5 fill corner white to greem\neach corner (top left, top right, bottom left, bottom right). For our real usage, we’re going to convert this “green” space to transparent instead.\n\n\nCode\nimg_filled &lt;- raw_logo %&gt;% \n    image_fill(\"green\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\nimg_filled %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n6 rotate\n\n\nCode\nimg_filled %&gt;% image_rotate(45) %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1632   1632       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n7 make backgroup transparent (given 0-100 green color backgroup)\n\n\nCode\nb=img_filled %&gt;% image_transparent(color='green',10)\n\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\nCode\nimage_write(b, path = \"b.png\", format = \"png\")\n\n\n\n\n8 change opacity level\n\n\nCode\nb=img_filled %&gt;% image_colorize(opacity =80, color = 'white')\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n9 change brightness level\n\n\nCode\nb=img_filled %&gt;%image_modulate(brightness = 30)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n10 change blur level\n\n\nCode\nb=img_filled %&gt;%  image_blur(10, 5)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n11 add text into picture\n\n\nCode\nb=img_filled %&gt;% image_annotate( \"The quick brown fox\", font = 'Times', size = 80,gravity = \"southwest\", color = \"red\")\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n12 resize\n\n\nCode\nb= img_filled%&gt;% image_resize(\"500\")\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nCode\nimage_info(img_filled)\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\nCode\nimage_info(b)\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n13 make logo black\n\n\nCode\nimg_filled2 &lt;- raw_logo %&gt;% \n    image_fill(\"transparent\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\n\n\n\nCode\nimg_filled2 %&gt;% \n    image_channel(\"Opacity\") %&gt;% \n    image_convert(matte=FALSE) %&gt;% \n  print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       Gray FALSE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.8.3\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     fastmap_1.1.1     xfun_0.43         magrittr_2.0.3   \n [5] knitr_1.45        htmltools_0.5.8.1 png_0.1-8         rmarkdown_2.26   \n [9] cli_3.6.2         compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1      \n[13] evaluate_0.23     Rcpp_1.0.12       yaml_2.3.8        rlang_1.1.3      \n[17] jsonlite_1.8.8    htmlwidgets_1.6.4\n\n\n\n\n\n14 add backgroup image\n\n\nCode\nlibrary(ggplot2)\nlibrary(png)\nlibrary(grid)\nlibrary(ggimage)\n\n\n\n\nCode\nimg &lt;- readPNG(\"./images/new_png.png\")\n\n\n\n\nCode\nbees &lt;- data.frame(distance = c(0.5, 1, 1.5, 2, 2.5, 3),\n                  number = c(40, 34, 32, 22,18, 10))\n\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_point() +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n15 replace scatter with image\n\n\nCode\nbees$image &lt;- \"./images/bee.png\"\n\n\n\n\nCode\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n16 add logo\n\n\nCode\nimg2 =image_read(\"./images/logo1.png\")\n\n\n\n\nCode\nlibrary(cowplot)\np=ggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\nggdraw() +draw_plot(p,x = 0, y = 0.15, width = 1, height = 0.85) +draw_image(img2,x = 0.1, y = 0.1, width = 0.1, height = 0.1) \n\n\n\n\n\n\n\n\n\n\n\n17 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\nhttps://buzzrbeeline.blog/2018/06/13/fun-and-easy-r-graphs-with-images/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "image processing"
    ]
  },
  {
    "objectID": "other/5 other/2 translation.html",
    "href": "other/5 other/2 translation.html",
    "title": "Translation",
    "section": "",
    "text": "Code\nlibrary(polyglotr)\n\n\n\n1 Translation word\n\n\nCode\nword_translation &lt;- linguee_word_translation(\"fruit\", source_language = \"en\", target_language = \"zh\")\n\nword_translation\n\n\n[1] \"水果\" \"果香\" \"果子\" \"果品\" \"实\"   \"檎\"  \n\n\n\n\n2 translate sentences\n\n\nCode\ngoogle_get_supported_languages()\n\n\n# A tibble: 134 × 2\n   Language    `ISO-639 code`\n   &lt;chr&gt;       &lt;chr&gt;         \n 1 Afrikaans   af            \n 2 Albanian    sq            \n 3 Amharic     am            \n 4 Arabic      ar            \n 5 Armenian    hy            \n 6 Assamese    as            \n 7 Aymara      ay            \n 8 Azerbaijani az            \n 9 Bambara     bm            \n10 Basque      eu            \n# ℹ 124 more rows\n\n\n\n\nCode\ntexts &lt;- c(\"Hello, how are you?\", \n           \"I love programming!\", \n           \"This is a test.\")\n\nlanguages &lt;- c(\"es\", \"fr\", \"zh-CN\")\n\n\ncreate_translation_table(texts, languages)\n\n\n        original_word                     es                          fr\n1 Hello, how are you?     ¿Hola, cómo estás? Bonjour comment allez-vous?\n2 I love programming! ¡Me encanta programar!  J'adore la programmation !\n3     This is a test.    Esto es una prueba.              C'est un test.\n           zh-CN\n1       你好吗？\n2   我喜欢编程！\n3 这是一个测试。\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "Translation"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-background-image",
    "href": "Plot/1 ggplot2.html#add-background-image",
    "title": "ggplot2 in R",
    "section": "11.1 add background image",
    "text": "11.1 add background image\n\n\nCode\nlibrary(ggplot2)\nlibrary(magick)\nimg4=image_read(\"bee.png\")\n\n\"bee.png\"\n\n\n[1] \"bee.png\"\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + background_image(img4) +geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\n\n\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "other/5 other/1 chromote.html",
    "href": "other/5 other/1 chromote.html",
    "title": "chromote",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(chromote)\n\n\n\n\nCode\npackageVersion(\"chromote\")\n\n\n\n1 create view\n\n\nCode\nlibrary(chromote)\n\nb &lt;- ChromoteSession$new()\n\n# In a web browser, open a viewer for the headless browser. Works best with\n# Chromium-based browsers.\nb$view()\n\n\n\n\nCode\nb$Browser$getVersion()\n\n\n\n\n2 go to page\n\n\nCode\nb$Page$navigate(\"https://www.r-project.org/\")\n\n\n\n\n3 take picture\n\n\nCode\n# Saves to screenshot.png\nb$screenshot()\n\n\n\n\nCode\n# Takes a screenshot of elements picked out by CSS selector\nis_interactive &lt;- interactive() # Display screenshot if interactive\nb$screenshot(\"sidebar.png\", selector = \"h1\" ,show = is_interactive)\n\n\n\n\n4 take picture as pdf\n\n\nCode\nb$screenshot_pdf(filename='page.pdf')\n\n\n\n\n5 Reference:\nhttps://rstudio.github.io/chromote/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "chromote"
    ]
  },
  {
    "objectID": "other/5 other/4 quarto blog.html",
    "href": "other/5 other/4 quarto blog.html",
    "title": "quarto block",
    "section": "",
    "text": "1 add a output folder bottom\n\nadd foldableCodeBlcok.lua into blog root folder\nadd in _quarto.yml\n\nfilters: - fold_results.lua\n\nput following on code chunk\n\n{r, attr.output=‘.details summary=“sessionInfo()”’} #| echo: false sessionInfo()\nreferece:\nhttps://github.com/quarto-dev/quarto-cli/issues/341\nhttps://gist.github.com/atusy/f2b5b992e45c68ab6823499f2339c6e6\n\n\n2 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "quarto block"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#make-bar-transparency",
    "href": "Plot/1 ggplot2.html#make-bar-transparency",
    "title": "ggplot2 in R",
    "section": "3.5 make bar transparency",
    "text": "3.5 make bar transparency\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red' ,alpha=0.2)+coord_flip()",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#make-bar-close-to-axis",
    "href": "Plot/1 ggplot2.html#make-bar-close-to-axis",
    "title": "ggplot2 in R",
    "section": "3.6 make bar close to axis",
    "text": "3.6 make bar close to axis\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",alpha=0.2,fill='red')+coord_flip()+scale_y_continuous(expand = expansion(mult = c(0, .1)))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#change-one-bar-color",
    "href": "Plot/1 ggplot2.html#change-one-bar-color",
    "title": "ggplot2 in R",
    "section": "3.7 change one bar color",
    "text": "3.7 change one bar color\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop,fill=factor(ifelse(continent==\"Asia\",\"Highlighted\",\"Normal\")))) +\n  geom_bar(stat=\"identity\",alpha=0.2,show.legend = FALSE)+scale_fill_manual(name = \"continent\", values=c(\"red\",\"grey50\"))+coord_flip()+scale_y_continuous(expand = expansion(mult = c(0, .1)))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  }
]