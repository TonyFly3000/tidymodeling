[
  {
    "objectID": "model type/2 random forest.html",
    "href": "model type/2 random forest.html",
    "title": "Random forest",
    "section": "",
    "text": "1 Pros\n\nEasier to interpret than Neural Network\nFast training and making inference\n\n\n\n2 Cons\n\nThe size & inference speed of the random forest can sometimes be an issue\nRandom forests cannot learn and reuse internal representations\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=w5gB8zyLx-8\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "model type",
      "Random forest"
    ]
  },
  {
    "objectID": "model type/3 gradient boosted trees.html",
    "href": "model type/3 gradient boosted trees.html",
    "title": "Gradient boosted trees",
    "section": "",
    "text": "1 Pros\n\nNative support for numerical and categorical features, and no necessary need for feature pre-processing.\nGBT are fast and light-weight and with great performance.\n\n\n\n2 Cons\n\nGBT can overfit.\nDecision tree trained sequentially -&gt; slower training.\nGBT cannot learn & reuse internal representations.Poor performance on image and long text.\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=w5gB8zyLx-8\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "model type",
      "Gradient boosted trees"
    ]
  },
  {
    "objectID": "Multiclass classification/0 multclass classification.html#measurement",
    "href": "Multiclass classification/0 multclass classification.html#measurement",
    "title": "Customer Segmentation Dataset",
    "section": "2.1 Measurement:",
    "text": "2.1 Measurement:\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nSpecificity=TN/(TN+FP)\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)\n\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nF1 score=2/(1/Precision+1/Recall)",
    "crumbs": [
      "Multiclass classification",
      "Customer Segmentation Dataset"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html",
    "href": "Multiclass classification/1 multclass classification.html",
    "title": "Classification Model",
    "section": "",
    "text": "Level 1 classification Tidy Modeling with 2 model and no recipe:\n*using basic Tidymodel package.\nNo recipe\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#read-data",
    "href": "Multiclass classification/1 multclass classification.html#read-data",
    "title": "Classification Model",
    "section": "3.1 read data",
    "text": "3.1 read data\n\n\nCode\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\n\n\n\n\nCode\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\ndf_test=df_test_raw\n\n\n\n\nCode\nglimpse(df_train)\n\n\nRows: 8,068\nColumns: 11\n$ ID              &lt;dbl&gt; 462809, 462643, 466315, 461735, 462669, 461319, 460156…\n$ Gender          &lt;chr&gt; \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", …\n$ Ever_Married    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"…\n$ Age             &lt;dbl&gt; 22, 38, 67, 67, 40, 56, 32, 33, 61, 55, 26, 19, 19, 70…\n$ Graduated       &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", …\n$ Profession      &lt;chr&gt; \"Healthcare\", \"Engineer\", \"Engineer\", \"Lawyer\", \"Enter…\n$ Work_Experience &lt;dbl&gt; 1, NA, 1, 0, NA, 0, 1, 1, 0, 1, 1, 4, 0, NA, 0, 1, 9, …\n$ Spending_Score  &lt;chr&gt; \"Low\", \"Average\", \"Low\", \"High\", \"High\", \"Average\", \"L…\n$ Family_Size     &lt;dbl&gt; 4, 3, 1, 2, 6, 2, 3, 3, 3, 4, 3, 4, NA, 1, 1, 2, 5, 6,…\n$ Var_1           &lt;chr&gt; \"Cat_4\", \"Cat_4\", \"Cat_6\", \"Cat_6\", \"Cat_6\", \"Cat_6\", …\n$ target_variable &lt;fct&gt; D, A, B, B, A, C, C, D, D, C, A, D, D, A, B, C, D, B, …",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#data-split",
    "href": "Multiclass classification/1 multclass classification.html#data-split",
    "title": "Classification Model",
    "section": "3.2 data split",
    "text": "3.2 data split\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 5647   11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 807  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 1614   11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#recipe",
    "href": "Multiclass classification/1 multclass classification.html#recipe",
    "title": "Classification Model",
    "section": "4.1 recipe",
    "text": "4.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#model",
    "href": "Multiclass classification/1 multclass classification.html#model",
    "title": "Classification Model",
    "section": "4.2 model",
    "text": "4.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#trainning",
    "href": "Multiclass classification/1 multclass classification.html#trainning",
    "title": "Classification Model",
    "section": "4.3 trainning",
    "text": "4.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.5423292\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5647 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 5647 4065 D (0.24508589 0.23339826 0.24136710 0.28014875)  \n   2) Age&gt;=34 3810 2653 C (0.26771654 0.29790026 0.30367454 0.13070866)  \n     4) Spending_Score=Low 1773 1108 A (0.37507050 0.26452341 0.15454033 0.20586576)  \n       8) Profession=Artist,Doctor 878  559 B (0.33485194 0.36332574 0.22209567 0.07972665) *\n       9) Profession=Engineer,Entertainment,Executive,Healthcare,Homemaker,Lawyer,Marketing 895  524 A (0.41452514 0.16759777 0.08826816 0.32960894)  \n        18) Profession=Engineer,Entertainment 433  198 A (0.54272517 0.18937644 0.06004619 0.20785219) *\n        19) Profession=Executive,Healthcare,Homemaker,Lawyer,Marketing 462  257 D (0.29437229 0.14718615 0.11471861 0.44372294) *\n     5) Spending_Score=Average,High 2037 1154 C (0.17427590 0.32695140 0.43348061 0.06529210)  \n      10) Profession=Doctor,Engineer,Entertainment,Executive,Healthcare,Homemaker,Lawyer,Marketing 1196  749 B (0.23076923 0.37374582 0.29598662 0.09949833) *\n      11) Profession=Artist 841  312 C (0.09393579 0.26040428 0.62901308 0.01664685) *\n   3) Age&lt; 34 1837  753 D (0.19814916 0.09961894 0.11213936 0.59009254) *",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#evaluate",
    "href": "Multiclass classification/1 multclass classification.html#evaluate",
    "title": "Classification Model",
    "section": "5.1 Evaluate",
    "text": "5.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   A   B   C   D\n         A  36  13   1  15\n         B  72  97  86  17\n         C  10  31  86   1\n         D  78  37  34 193\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.511\n2 kap      multiclass     0.345\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.511\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    macro          0.500\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    macro          0.837\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.511\n2 sens     macro          0.500\n3 spec     macro          0.837\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             multiclass     0.511\n 2 kap                  multiclass     0.345\n 3 sens                 macro          0.500\n 4 spec                 macro          0.837\n 5 ppv                  macro          0.537\n 6 npv                  macro          0.846\n 7 mcc                  multiclass     0.362\n 8 j_index              macro          0.336\n 9 bal_accuracy         macro          0.668\n10 detection_prevalence macro          0.25 \n11 precision            macro          0.537\n12 recall               macro          0.500\n13 f_meas               macro          0.475\n\n\nROC:receiver operating characteristic curve\n\n\nCode\n#roc_auc(\n#    truth = target_variable,\n#    .pred_A,\n #   .pred_B,\n #   .pred_C,\n #   .pred_D,\n #   estimator = \"macro_weighted\"\n # )",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#save-model",
    "href": "Multiclass classification/1 multclass classification.html#save-model",
    "title": "Classification Model",
    "section": "5.2 save model",
    "text": "5.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n591 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 multclass classification tree hotel model.RDS')",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "Multiclass classification/1 multclass classification.html#make-predication",
    "href": "Multiclass classification/1 multclass classification.html#make-predication",
    "title": "Classification Model",
    "section": "5.3 make predication",
    "text": "5.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 multclass classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 B          \n2 C          \n3 D          \n4 D          \n5 D          \n6 C          \n\n\n\n\nCode\nfinal_prediction %&gt;% count(.pred_class)\n\n\n# A tibble: 4 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 A             119\n2 B             538\n3 C             253\n4 D             704\n\n\n\n\nCode\ndata_valid %&gt;% count(target_variable)\n\n\n# A tibble: 4 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 A                 392\n2 B                 362\n3 C                 400\n4 D                 460",
    "crumbs": [
      "Multiclass classification",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html",
    "href": "hotel classification model/3 classification Tidy Modeling.html",
    "title": "Classification Model with recipe",
    "section": "",
    "text": "Level 3 classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/3 classification Tidy Modeling.html#read-data",
    "title": "Classification Model with recipe",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/3 classification Tidy Modeling.html#data-split",
    "title": "Classification Model with recipe",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(50000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    10",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#recipe",
    "title": "Classification Model with recipe",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#prep-the-recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Classification Model with recipe",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Classification Model with recipe",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 35000    23\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 5728   23\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 5728   23\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2864\n2 none            32136\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2864\n2 none             2864\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children         2864\n2 none             2864",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "hotel classification model/3 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Classification Model with recipe",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          393\n2 none             4607\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          820\n2 none             9180\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#model",
    "href": "hotel classification model/3 classification Tidy Modeling.html#model",
    "title": "Classification Model with recipe",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/3 classification Tidy Modeling.html#trainning",
    "title": "Classification Model with recipe",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2616969\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 5728 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 5728 2864 children (0.5000000 0.5000000)  \n   2) adr&gt;=0.3221018 1817  355 children (0.8046230 0.1953770) *\n   3) adr&lt; 0.3221018 3911 1402 none (0.3584761 0.6415239)  \n     6) total_of_special_requests&gt;=0.6520526 839  353 children (0.5792610 0.4207390)  \n      12) meal_SC&lt; 1.940923 781  307 children (0.6069142 0.3930858) *\n      13) meal_SC&gt;=1.940923 58   12 none (0.2068966 0.7931034) *\n     7) total_of_special_requests&lt; 0.6520526 3072  916 none (0.2981771 0.7018229) *",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/3 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model with recipe",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits             id        \n   &lt;list&gt;             &lt;chr&gt;     \n 1 &lt;split [5154/574]&gt; Resample01\n 2 &lt;split [5154/574]&gt; Resample02\n 3 &lt;split [5154/574]&gt; Resample03\n 4 &lt;split [5154/574]&gt; Resample04\n 5 &lt;split [5154/574]&gt; Resample05\n 6 &lt;split [5154/574]&gt; Resample06\n 7 &lt;split [5154/574]&gt; Resample07\n 8 &lt;split [5154/574]&gt; Resample08\n 9 &lt;split [5154/574]&gt; Resample09\n10 &lt;split [5154/574]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 3 × 6\n  .metric     .estimator  mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.739    25 0.00385 Preprocessor1_Model1\n2 brier_class binary     0.197    25 0.00244 Preprocessor1_Model1\n3 roc_auc     binary     0.801    25 0.00342 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 3 × 6\n  .metric     .estimator  mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.726    25 0.00365 Preprocessor1_Model1\n2 brier_class binary     0.194    25 0.00187 Preprocessor1_Model1\n3 roc_auc     binary     0.748    25 0.00492 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_children) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/3 classification Tidy Modeling.html#save-model",
    "title": "Classification Model with recipe",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n1.15 MB\n\n\nCode\nobj_size(knn_fit)\n\n\n1.10 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/3 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/3 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model with recipe",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 children   \n3 none       \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      578 2399\n  none          242 6781\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.736\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          820\n2 none             9180\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2977\n2 none         7023\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      578 2399\n  none          242 6781",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe"
    ]
  },
  {
    "objectID": "hotel classification model/0 classification Tidy Modeling.html",
    "href": "hotel classification model/0 classification Tidy Modeling.html",
    "title": "Hotel booking data",
    "section": "",
    "text": "Look at the hotel booking data.The target variable is whether have children.\n8590 booking with children.110800 bookings with no children.\nOnly 7% booking with children.Its imbalanced data.Why it causes problems?\nThe model cannot learn to predict the minority class well because of class imbalance.\nModel is only able to learn a simple heuristic (e.g. always predict the dominate class) and it gets stuck in a sub optimal solution.\nAn accuracy of over 90% can be misleading because the model may not have predictive power on the rare class.\nSo in the latter this chapter will introduce downsample method to overcome the this problem.",
    "crumbs": [
      "hotel classification model",
      "Hotel booking data"
    ]
  },
  {
    "objectID": "hotel classification model/0 classification Tidy Modeling.html#measurement",
    "href": "hotel classification model/0 classification Tidy Modeling.html#measurement",
    "title": "Hotel booking data",
    "section": "4.1 Measurement:",
    "text": "4.1 Measurement:\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nSpecificity=TN/(TN+FP)\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)\n\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nF1 score=2/(1/Precision+1/Recall)",
    "crumbs": [
      "hotel classification model",
      "Hotel booking data"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html",
    "href": "hotel classification model/1 classification Tidy Modeling.html",
    "title": "Classification Model",
    "section": "",
    "text": "Level 1 classification Tidy Modeling with 2 model and no recipe:\n*using basic Tidymodel package.\nNo recipe\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/1 classification Tidy Modeling.html#read-data",
    "title": "Classification Model",
    "section": "3.1 read data",
    "text": "3.1 read data\n\n\nCode\nlibrary(tidyverse)\n\n#hotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotels &lt;- readr::read_csv(\"./data/hotels.csv\")\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/1 classification Tidy Modeling.html#data-split",
    "title": "Classification Model",
    "section": "3.2 data split",
    "text": "3.2 data split\n\n\nPrepare & Split Data\nhotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% sample_n(10000)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 7000   10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 1000   10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 2000   10",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/1 classification Tidy Modeling.html#recipe",
    "title": "Classification Model",
    "section": "4.1 recipe",
    "text": "4.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#model",
    "href": "hotel classification model/1 classification Tidy Modeling.html#model",
    "title": "Classification Model",
    "section": "4.2 model",
    "text": "4.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#trainning",
    "href": "hotel classification model/1 classification Tidy Modeling.html#trainning",
    "title": "Classification Model",
    "section": "4.3 trainning",
    "text": "4.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.081\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 7000 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 7000 568 none (0.08114286 0.91885714)  \n   2) adr&gt;=171.07 571 193 none (0.33800350 0.66199650)  \n     4) adr&gt;=221.09 164  80 children (0.51219512 0.48780488)  \n       8) hotel=City Hotel 49  14 children (0.71428571 0.28571429) *\n       9) hotel=Resort Hotel 115  49 none (0.42608696 0.57391304)  \n        18) adr&gt;=273.25 31  10 children (0.67741935 0.32258065) *\n        19) adr&lt; 273.25 84  28 none (0.33333333 0.66666667) *\n     5) adr&lt; 221.09 407 109 none (0.26781327 0.73218673) *\n   3) adr&lt; 171.07 6429 375 none (0.05832944 0.94167056) *",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/1 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model",
    "section": "5.1 Evaluate",
    "text": "5.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children       10    5\n  none           84  901\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.911\n2 kap      binary         0.162\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.911\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.106\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.994\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.911\n2 sens     binary         0.106\n3 spec     binary         0.994\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.911\n 2 kap                  binary         0.162\n 3 sens                 binary         0.106\n 4 spec                 binary         0.994\n 5 ppv                  binary         0.667\n 6 npv                  binary         0.915\n 7 mcc                  binary         0.242\n 8 j_index              binary         0.101\n 9 bal_accuracy         binary         0.550\n10 detection_prevalence binary         0.015\n11 precision            binary         0.667\n12 recall               binary         0.106\n13 f_meas               binary         0.183\n\n\nROC:receiver operating characteristic curve\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\nAUC:Area under ROC Curve\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_children)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.654",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/1 classification Tidy Modeling.html#save-model",
    "title": "Classification Model",
    "section": "5.2 save model",
    "text": "5.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n544.50 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "hotel classification model/1 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/1 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model",
    "section": "5.3 make predication",
    "text": "5.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction %&gt;% count(.pred_class)\n\n\n# A tibble: 2 × 2\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children       24\n2 none         1976\n\n\n\n\nCode\ndata_valid %&gt;% count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          154\n2 none             1846",
    "crumbs": [
      "hotel classification model",
      "Classification Model"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html",
    "href": "titanic classification model/3 classification Tidy Modeling.html",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "",
    "text": "Level 4 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/3 classification Tidy Modeling.html#read-data",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/3 classification Tidy Modeling.html#eda",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/3 classification Tidy Modeling.html#plotting",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/3 classification Tidy Modeling.html#data-split",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/3 classification Tidy Modeling.html#recipe",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#model",
    "href": "titanic classification model/3 classification Tidy Modeling.html#model",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#workflow",
    "href": "titanic classification model/3 classification Tidy Modeling.html#workflow",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/3 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits           id     .metrics          .notes           .predictions\n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [560/63]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [560/63]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [560/63]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [561/62]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [561/62]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [561/62]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [561/62]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [561/62]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [561/62]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [561/62]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.774    10  0.0144 Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 3    0.0000000178          1 accuracy binary     0.774    10  0.0144 Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 5    0.00000316            1 accuracy binary     0.774    10  0.0144 Preproces…\n 6    0.00000316            1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 7    0.000562              1 accuracy binary     0.774    10  0.0144 Preproces…\n 8    0.000562              1 roc_auc  binary     0.751    10  0.0161 Preproces…\n 9    0.1                   1 accuracy binary     0.774    10  0.0144 Preproces…\n10    0.1                   1 roc_auc  binary     0.751    10  0.0161 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.0000000001          4 accuracy binary     0.788    10  0.0179 Preprocess…\n2    0.0000000178          4 accuracy binary     0.788    10  0.0179 Preprocess…\n3    0.00000316            4 accuracy binary     0.788    10  0.0179 Preprocess…\n4    0.000562              4 accuracy binary     0.788    10  0.0179 Preprocess…\n5    0.0000000001          1 accuracy binary     0.774    10  0.0144 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          4 Preprocessor1_Model06\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 4\n\nComputational engine: rpart",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/3 classification Tidy Modeling.html#last-fit",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/3 classification Tidy Modeling.html#evaluate",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.844 Preprocessor1_Model1\n2 roc_auc  binary         0.861 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 623 244 0 (0.60834671 0.39165329)  \n   2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n     4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237) *\n     5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n   3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n     6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n      12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n      13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n        26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143) *\n        27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970) *\n     7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/3 classification Tidy Modeling.html#save-model",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.14 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/3 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/3 classification Tidy Modeling.html#make-predication",
    "title": "Classification model with Recipe,workflow,tunning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.764\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              62\n2 1              27\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 49 13\n         1  8 19",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,tunning"
    ]
  },
  {
    "objectID": "titanic classification model/0 classification Tidy Modeling.html",
    "href": "titanic classification model/0 classification Tidy Modeling.html",
    "title": "Titanic data",
    "section": "",
    "text": "data download form kaggle\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\nData have 891 record and 12 variable\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;% group_by(Survived) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   Survived [2]\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342\n\n\n\n\n\nAccuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nSpecificity=TN/(TN+FP)\n\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)",
    "crumbs": [
      "titanic classification model",
      "Titanic data"
    ]
  },
  {
    "objectID": "titanic classification model/0 classification Tidy Modeling.html#measurement",
    "href": "titanic classification model/0 classification Tidy Modeling.html#measurement",
    "title": "Titanic data",
    "section": "",
    "text": "Accuracy=TP+TN+FP+FN\nPrecision — Out of all the examples that predicted as positive, how many are really positive?\n\nPrecision=TP/(TP+FP)\n\nRecall/Sensitivity(True Positive rate) — Out of all the positive examples, how many are predicted as positive?\n\nRecall=TP/(TP+FN)\n\nSpecificity(True Negative rate)— Out of all the people that do not have the disease, how many got negative results?\nFalse Negative Rate tells us what proportion of the positive class got incorrectly classified by the classifier\n\nSpecificity=TN/(TN+FP)\n\nFalse Positive rate=1-Specificity\nFalse Negative Rat=FN/(TP+FN)",
    "crumbs": [
      "titanic classification model",
      "Titanic data"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html",
    "href": "titanic classification model/1 classification Tidy Modeling.html",
    "title": "Classification model",
    "section": "",
    "text": "Level 1 classification Tidy Modeling: using basic Tidymodel package.",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/1 classification Tidy Modeling.html#read-data",
    "title": "Classification model",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/1 classification Tidy Modeling.html#eda",
    "title": "Classification model",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/1 classification Tidy Modeling.html#plotting",
    "title": "Classification model",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/1 classification Tidy Modeling.html#data-split",
    "title": "Classification model",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name,-Ticket) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  10\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  10\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 10",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/1 classification Tidy Modeling.html#recipe",
    "title": "Classification model",
    "section": "3.1 recipe",
    "text": "3.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#model",
    "href": "titanic classification model/1 classification Tidy Modeling.html#model",
    "title": "Classification model",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/1 classification Tidy Modeling.html#trainning",
    "title": "Classification model",
    "section": "3.3 trainning",
    "text": "3.3 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.3684211\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex=male 406  84 0 (0.79310345 0.20689655)  \n      4) Cabin=A14,A19,A32,A5,B102,B19,B22,B30,B37,B38,B51 B53 B55,B71,B94,C118,C123,C124,C128,C23 C25 C27,C30,C46,C65,C68,C82,C83,C86,C87,C95,D,D26,D30,D48,E38,E58,E63,E67,F G63,F G73,F38,T 288  36 0 (0.87500000 0.12500000) *\n      5) Cabin=A20,A23,A31,A34,B20,B41,B49,B50,B96 B98,C104,C106,C126,C148,C22 C26,C47,C52,C70,C92,C93,D10 D12,D33,D35,D49,D56,E10,E12,E121,E24,E25,E50,F2,F4 118  48 0 (0.59322034 0.40677966)  \n       10) Pclass&gt;=1.5 88  20 0 (0.77272727 0.22727273)  \n         20) Age&gt;=6.5 75  10 0 (0.86666667 0.13333333) *\n         21) Age&lt; 6.5 13   3 1 (0.23076923 0.76923077) *\n       11) Pclass&lt; 1.5 30   2 1 (0.06666667 0.93333333) *\n    3) Sex=female 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=2.5 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=24.80835 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; 24.80835 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked=S 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=17.35 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; 17.35 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; 11.375 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=11.375 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked=C,Q 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 2.5 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/1 classification Tidy Modeling.html#evaluate",
    "title": "Classification model",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\nMake predictions on the testing data\n\n\nCode\npredictions &lt;- predict(tree_fit,data_test) \n\npredictions_probability &lt;- predict(tree_fit,data_test,type=\"prob\")\n\n\n\n\nCode\ndata_test_result=cbind(data_test,predictions,predictions_probability) \n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   0   1\n         0 105  19\n         1   8  47\n\n\n\n\nCode\nmetrics(data_test_result, target_variable, .pred_class)\n\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 kap      binary         0.664\n\n\n\n\nCode\naccuracy(data_test_result, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n\n\n\n\nCode\nsens(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 sens    binary         0.929\n\n\n\n\nCode\nspec(data_test_result, truth = target_variable,\n    estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 spec    binary         0.712\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, sens, spec)\n\nall_metrics(data_test_result, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 3 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.849\n2 sens     binary         0.929\n3 spec     binary         0.712\n\n\n\n\nCode\nconf_mat(data_test_result, truth = target_variable,estimate = .pred_class) %&gt;% \n  summary()\n\n\n# A tibble: 13 × 3\n   .metric              .estimator .estimate\n   &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;\n 1 accuracy             binary         0.849\n 2 kap                  binary         0.664\n 3 sens                 binary         0.929\n 4 spec                 binary         0.712\n 5 ppv                  binary         0.847\n 6 npv                  binary         0.855\n 7 mcc                  binary         0.671\n 8 j_index              binary         0.641\n 9 bal_accuracy         binary         0.821\n10 detection_prevalence binary         0.693\n11 precision            binary         0.847\n12 recall               binary         0.929\n13 f_meas               binary         0.886\n\n\n\n\nCode\nroc_auc(data_test_result, truth = target_variable, .pred_0)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.881\n\n\n\n\nCode\nroc_curve(data_test_result, truth = target_variable, .pred_0) %&gt;% \n  autoplot()",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/1 classification Tidy Modeling.html#save-model",
    "title": "Classification model",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n130.17 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(tree_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 1 classification tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "titanic classification model/1 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/1 classification Tidy Modeling.html#make-predication",
    "title": "Classification model",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 1 classification tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0",
    "crumbs": [
      "titanic classification model",
      "Classification model"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "R is based heavily on the S language, first developed in the 1960s and 1970s by researchers at Bell Laboratories in New Jersey\nR’s developers—Ross Ihaka and Robert Gentleman at the Univer- sity of Auckland in New Zealand—released it in the early 1990s under the\nGNU public license. (The software was named for Ross and Robert’s shared first initial.)\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html",
    "href": "clustering/1.2 k mean Clustering.html",
    "title": "K mean Clustering with image",
    "section": "",
    "text": "Using K mean Clustering to replace colow on below picture",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#input-image",
    "href": "clustering/1.2 k mean Clustering.html#input-image",
    "title": "K mean Clustering with image",
    "section": "2.1 input image",
    "text": "2.1 input image\n\n\nCode\nimage &lt;- image_read('images/python logo.jpg')",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix",
    "href": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix",
    "title": "K mean Clustering with image",
    "section": "2.2 convert png to matrix",
    "text": "2.2 convert png to matrix\n\n\nCode\nimage_tiff &lt;- image_convert(image, \"tiff\")\nimage_array &lt;- as.integer(image_tiff[[1]])                \n\n\n\n\nCode\nmagick::image_read(image_array/ 255)\n\n\n\n\n\n\n\n\n\n235 * 214 pixcel and 3 channels\n\n\nCode\ndim(image_array)\n\n\n[1] 235 214   3\n\n\n\n\nCode\nclass(image_array)\n\n\n[1] \"array\"\n\n\nData Normalization\nSince the dataset contains a range of values from 0 to 255, the dataset has to be normalized. Data Normalization is an important preprocessing step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This fastens the process of covergence while training the model. Also Normalization makes sure no one particular parameter influences the output significantly.\n\n\nCode\nimage_array=image_array/255\n\n\n\n\nCode\nimage_array_old=image_array",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d",
    "href": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d",
    "title": "K mean Clustering with image",
    "section": "2.3 reshape from 3 D to 2 D",
    "text": "2.3 reshape from 3 D to 2 D\n\n\nCode\ndim(image_array) &lt;- c(dim(image_array)[1]*dim(image_array)[2],3)\n\n\n\n\nCode\ndim(image_array)\n\n\n[1] 50290     3",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters",
    "href": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters",
    "title": "K mean Clustering with image",
    "section": "2.4 Optimal number of k-clusters",
    "text": "2.4 Optimal number of k-clusters\n\n\nCode\nkclusts &lt;- \n  tibble(k = 1:9) %&gt;%\n  mutate(\n    kclust = map(k, ~kmeans(image_array, .x)),\n    tidied = map(kclust, tidy),\n    glanced = map(kclust, glance),\n    augmented = map(kclust, augment, image_array)\n  )\n\nkclusts\n\n\n# A tibble: 9 × 5\n      k kclust   tidied           glanced          augmented            \n  &lt;int&gt; &lt;list&gt;   &lt;list&gt;           &lt;list&gt;           &lt;list&gt;               \n1     1 &lt;kmeans&gt; &lt;tibble [1 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n2     2 &lt;kmeans&gt; &lt;tibble [2 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n3     3 &lt;kmeans&gt; &lt;tibble [3 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n4     4 &lt;kmeans&gt; &lt;tibble [4 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n5     5 &lt;kmeans&gt; &lt;tibble [5 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n6     6 &lt;kmeans&gt; &lt;tibble [6 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n7     7 &lt;kmeans&gt; &lt;tibble [7 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n8     8 &lt;kmeans&gt; &lt;tibble [8 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n9     9 &lt;kmeans&gt; &lt;tibble [9 × 6]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [50,290 × 4]&gt;\n\n\n\n\nCode\nclusters &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(tidied))\n\nassignments &lt;- \n  kclusts %&gt;% \n  unnest(cols = c(augmented))\n\nclusterings &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(glanced))\n\n\n\n\nCode\nlibrary(scales)\nggplot(clusterings, aes(k, tot.withinss)) +\n  geom_line() +\n  geom_point()+scale_x_continuous(breaks= pretty_breaks())+scale_y_continuous(labels = scales::comma)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#group-to-3",
    "href": "clustering/1.2 k mean Clustering.html#group-to-3",
    "title": "K mean Clustering with image",
    "section": "2.5 group to 3",
    "text": "2.5 group to 3\n\n\nCode\nkclust &lt;- kmeans(image_array, centers = 3)\n\n\n\n\nCode\nresult=augment(kclust, image_array) %&gt;% clean_names()\n\n\n\n\nCode\nresult %&gt;% count(cluster)\n\n\n# A tibble: 3 × 2\n  cluster     n\n  &lt;fct&gt;   &lt;int&gt;\n1 1       13560\n2 2       13631\n3 3       23099",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#change-2-color",
    "href": "clustering/1.2 k mean Clustering.html#change-2-color",
    "title": "K mean Clustering with image",
    "section": "2.6 change 2 color",
    "text": "2.6 change 2 color\n\n\nCode\n# black RGB code 0 0 0\n# red RGB code 255 0 0\n\nresult2=result %&gt;%mutate(x1=if_else(cluster==3,0,x1) \n                          ,x2=if_else(cluster==3,0,x2) \n                          ,x3=if_else(cluster==3,0,x3) \n                          )%&gt;%mutate(x1=if_else(cluster==1,255,x1) \n                          ,x2=if_else(cluster==1,0,x2) \n                          ,x3=if_else(cluster==1,0,x3)) %&gt;% select(-cluster)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-3-d",
    "href": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-3-d",
    "title": "K mean Clustering with image",
    "section": "2.7 convert 2 D back to 3 D",
    "text": "2.7 convert 2 D back to 3 D\n\n\nCode\nresult2arrary=array(unlist(result2),c(dim(image_array_old)[1],dim(image_array_old)[2],3))\n\n\n\n\nCode\ndim(result2arrary)\n\n\n[1] 235 214   3\n\n\nconvert from 0-1 back to 0-255\n\n\nCode\nresult2arrary=result2arrary*255\n\n\n\n\nCode\nmagick::image_read(result2arrary/ 255)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#input-image-1",
    "href": "clustering/1.2 k mean Clustering.html#input-image-1",
    "title": "K mean Clustering with image",
    "section": "3.1 input image",
    "text": "3.1 input image\n\n\nCode\nimage &lt;- image_read('images/R_logo.png')",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix-1",
    "href": "clustering/1.2 k mean Clustering.html#convert-png-to-matrix-1",
    "title": "K mean Clustering with image",
    "section": "3.2 convert png to matrix",
    "text": "3.2 convert png to matrix\n\n\nCode\nimage_tiff &lt;- image_convert(image, \"tiff\")\nimage_array &lt;- as.integer(image_tiff[[1]])                \n\n\n\n\nCode\nmagick::image_read(image_array/ 255)\n\n\n\n\n\n\n\n\n\n561 * 724 pixcel and 4 channels\n\n\nCode\ndim(image_array)\n\n\n[1] 561 724   4\n\n\n\n\nCode\nclass(image_array)\n\n\n[1] \"array\"\n\n\n\n\nCode\nimage_array_old=image_array",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d-1",
    "href": "clustering/1.2 k mean Clustering.html#reshape-from-3-d-to-2-d-1",
    "title": "K mean Clustering with image",
    "section": "3.3 reshape from 3 D to 2 D",
    "text": "3.3 reshape from 3 D to 2 D\n\n\nCode\ndim(image_array) &lt;- c(dim(image_array)[1]*dim(image_array)[2],4)\n\n\n\n\nCode\ndim(image_array)\n\n\n[1] 406164      4\n\n\nData Normalization\nSince the dataset contains a range of values from 0 to 255, the dataset has to be normalized. Data Normalization is an important preprocessing step which ensures that each input parameter (pixel, in this case) has a similar data distribution. This fastens the process of covergence while training the model. Also Normalization makes sure no one particular parameter influences the output significantly.\n\n\nCode\nimage_array=image_array/255",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters-1",
    "href": "clustering/1.2 k mean Clustering.html#optimal-number-of-k-clusters-1",
    "title": "K mean Clustering with image",
    "section": "3.4 Optimal number of k-clusters",
    "text": "3.4 Optimal number of k-clusters\n\n\nCode\nkclusts &lt;- \n  tibble(k = 1:9) %&gt;%\n  mutate(\n    kclust = map(k, ~kmeans(image_array, .x)),\n    tidied = map(kclust, tidy),\n    glanced = map(kclust, glance),\n    augmented = map(kclust, augment, image_array)\n  )\n\nkclusts\n\n\n# A tibble: 9 × 5\n      k kclust   tidied           glanced          augmented             \n  &lt;int&gt; &lt;list&gt;   &lt;list&gt;           &lt;list&gt;           &lt;list&gt;                \n1     1 &lt;kmeans&gt; &lt;tibble [1 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n2     2 &lt;kmeans&gt; &lt;tibble [2 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n3     3 &lt;kmeans&gt; &lt;tibble [3 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n4     4 &lt;kmeans&gt; &lt;tibble [4 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n5     5 &lt;kmeans&gt; &lt;tibble [5 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n6     6 &lt;kmeans&gt; &lt;tibble [6 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n7     7 &lt;kmeans&gt; &lt;tibble [7 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n8     8 &lt;kmeans&gt; &lt;tibble [8 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n9     9 &lt;kmeans&gt; &lt;tibble [9 × 7]&gt; &lt;tibble [1 × 4]&gt; &lt;tibble [406,164 × 5]&gt;\n\n\n\n\nCode\nclusters &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(tidied))\n\nassignments &lt;- \n  kclusts %&gt;% \n  unnest(cols = c(augmented))\n\nclusterings &lt;- \n  kclusts %&gt;%\n  unnest(cols = c(glanced))\n\n\n\n\nCode\nlibrary(scales)\nggplot(clusterings, aes(k, tot.withinss)) +\n  geom_line() +\n  geom_point()+scale_x_continuous(breaks= pretty_breaks())+scale_y_continuous(labels = scales::comma)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#group-to-3-1",
    "href": "clustering/1.2 k mean Clustering.html#group-to-3-1",
    "title": "K mean Clustering with image",
    "section": "3.5 group to 3",
    "text": "3.5 group to 3\n\n\nCode\nkclust &lt;- kmeans(image_array, centers = 3)\n\n\n\n\nCode\nresult=augment(kclust, image_array) %&gt;% clean_names()\n\n\n\n\nCode\nresult %&gt;% count(cluster)\n\n\n# A tibble: 3 × 2\n  cluster      n\n  &lt;fct&gt;    &lt;int&gt;\n1 1       120865\n2 2       169342\n3 3       115957",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#change-2-color-1",
    "href": "clustering/1.2 k mean Clustering.html#change-2-color-1",
    "title": "K mean Clustering with image",
    "section": "3.6 change 2 color",
    "text": "3.6 change 2 color\n\n\nCode\n# black RGB code 0 0 0\n# red RGB code 255 0 0\n\nresult2=result %&gt;%mutate(x1=if_else(cluster==3,0,x1) \n                          ,x2=if_else(cluster==3,0,x2) \n                          ,x3=if_else(cluster==3,0,x3) \n                          )%&gt;%mutate(x1=if_else(cluster==1,255,x1) \n                          ,x2=if_else(cluster==1,0,x2) \n                          ,x3=if_else(cluster==1,0,x3)) %&gt;% select(-cluster)",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-4-d",
    "href": "clustering/1.2 k mean Clustering.html#convert-2-d-back-to-4-d",
    "title": "K mean Clustering with image",
    "section": "3.7 convert 2 D back to 4 D",
    "text": "3.7 convert 2 D back to 4 D\n\n\nCode\nresult2arrary=array(unlist(result2),c(dim(image_array_old)[1],dim(image_array_old)[2],4))\n\n\n\n\nCode\ndim(result2arrary)\n\n\n[1] 561 724   4\n\n\nconvert from 0-1 back to 0-255\n\n\nCode\nresult2arrary=result2arrary*255\n\n\n\n\nCode\nmagick::image_read(result2arrary/ 255)\n\n\n\n\n\n\n\n\n\n\n\nCode\nimg &lt;- magick::image_read(result2arrary / 255)\n\nimage_write(img, path = \"final.png\", format = \"png\")",
    "crumbs": [
      "Clustering",
      "K mean Clustering with image"
    ]
  },
  {
    "objectID": "clustering/2 Hierarchical Clustering.html",
    "href": "clustering/2 Hierarchical Clustering.html",
    "title": "Hierarchical Clustering",
    "section": "",
    "text": "Coming soon\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Clustering",
      "Hierarchical Clustering"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html",
    "href": "clustering/4 Principal component analysis .html",
    "title": "Principal component analysis",
    "section": "",
    "text": "Principal component analysis (PCA) is a method of reducing the dimensionality of data and is used to improve data visualization and speed up machine learning model training.",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#download-data",
    "href": "clustering/4 Principal component analysis .html#download-data",
    "title": "Principal component analysis",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/datasets/shwetabh123/mall-customer",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#input-data",
    "href": "clustering/4 Principal component analysis .html#input-data",
    "title": "Principal component analysis",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\nurl = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n\n# load dataset into Pandas DataFrame\ndf = read_csv(url,col_names = c('sepal_length','sepal_width','petal_length','petal_width','target'))\n\n# Showing overview of the train dataset\nhead(df)\n\n\n# A tibble: 6 × 5\n  sepal_length sepal_width petal_length petal_width target     \n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;      \n1          5.1         3.5          1.4         0.2 Iris-setosa\n2          4.9         3            1.4         0.2 Iris-setosa\n3          4.7         3.2          1.3         0.2 Iris-setosa\n4          4.6         3.1          1.5         0.2 Iris-setosa\n5          5           3.6          1.4         0.2 Iris-setosa\n6          5.4         3.9          1.7         0.4 Iris-setosa",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#standardize-the-data",
    "href": "clustering/4 Principal component analysis .html#standardize-the-data",
    "title": "Principal component analysis",
    "section": "2.3 STANDARDIZE THE DATA",
    "text": "2.3 STANDARDIZE THE DATA\nPCA is affected by scale, so you need to scale the features in your data before applying PCA. Use StandardScaler to help you standardize the data set’s features onto unit scale (mean = 0 and variance = 1), which is a requirement for the optimal performance of many machine learning algorithms. If you don’t scale your data, it can have a negative effect on your algorithm.\n\n\nCode\nnumerical_data=data.matrix(df[c('sepal_length','sepal_width','petal_length','petal_width')])\n\n\n\n\nCode\ndata_normalized &lt;- scale(numerical_data)\nhead(data_normalized)\n\n\n     sepal_length sepal_width petal_length petal_width\n[1,]   -0.8976739   1.0286113    -1.336794   -1.308593\n[2,]   -1.1392005  -0.1245404    -1.336794   -1.308593\n[3,]   -1.3807271   0.3367203    -1.393470   -1.308593\n[4,]   -1.5014904   0.1060900    -1.280118   -1.308593\n[5,]   -1.0184372   1.2592416    -1.336794   -1.308593\n[6,]   -0.5353840   1.9511326    -1.166767   -1.046525",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#before-standardize",
    "href": "clustering/4 Principal component analysis .html#before-standardize",
    "title": "Principal component analysis",
    "section": "2.4 Before STANDARDIZE",
    "text": "2.4 Before STANDARDIZE",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#after-standardize",
    "href": "clustering/4 Principal component analysis .html#after-standardize",
    "title": "Principal component analysis",
    "section": "2.5 After STANDARDIZE",
    "text": "2.5 After STANDARDIZE",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "clustering/4 Principal component analysis .html#inverse-standardize.for-testing-purpose-only-have-no-impact-on-pca.",
    "href": "clustering/4 Principal component analysis .html#inverse-standardize.for-testing-purpose-only-have-no-impact-on-pca.",
    "title": "Principal component analysis",
    "section": "2.6 inverse STANDARDIZE.for testing purpose only, have no impact on PCA.",
    "text": "2.6 inverse STANDARDIZE.for testing purpose only, have no impact on PCA.\nfor testing purpose only.",
    "crumbs": [
      "Clustering",
      "Principal component analysis"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/4 whiskynote all year page.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/4 whiskynote all year page.html",
    "title": "All year page",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 loop all year page\n\n\nCode\nyear_list=seq(2010,2024)\nyear_list\n\n\n\n\nCode\nurl_list=paste0('https://www.whiskynotes.be/',year_list)\nurl_list\n\n\n\n\nCode\nbottle_list=c()\ntopic_list=c()\ntopic_link_list=c()\nall_year_list_topic=c()\nall_year_list_bottle=c()\n\n\n\n\nCode\nfor (i in url_list){\n  year=tail(unlist(strsplit(i, split = \"/\")),1)\n  print(year)\n  print(i)\n  year_ur=i\n  year_page &lt;- read_html(year_ur)\n  bottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\n  bottle003=unlist(strsplit(bottle001,\"\\n\"))\n  \n  \n  topic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\n  topic_link_001 &lt;- year_page %&gt;%\n    html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\n  year_list_topic=rep(year,length(topic001))\n  year_list_bottle=rep(year,length(bottle003))\n  \n  all_year_list_topic=c(all_year_list_topic,year_list_topic)\n  all_year_list_bottle=c(all_year_list_bottle,year_list_bottle)\n  \n  bottle_list=c(bottle_list,bottle003)\n  topic_list=c(topic_list,topic001)\n  topic_link_list=c(topic_link_list,topic_link_001)\n  \n  Sys.sleep(1)\n  }\n\n\n\n\n2 combine\n\n\nCode\ndata=tibble(topic_list,topic_link_list,all_year_list_topic)\n\n\n\n\nCode\nglimpse(data)\n\n\n\n\n3 output\n\n\nCode\nlibrary(openxlsx)\nlist_of_datasets &lt;- list(\"topic\" = data)\n\nwrite.xlsx(list_of_datasets, file = \"./output/all year page.xlsx\")\n\n\n\n\n4 secound time web scraping\n\n\nCode\nyear_list=2024\nyear_list\n\n\n\n\nCode\nurl_list=paste0('https://www.whiskynotes.be/',year_list)\nurl_list\n\n\n\n\nCode\nbottle_list=c()\ntopic_list=c()\ntopic_link_list=c()\nall_year_list_topic=c()\nall_year_list_bottle=c()\n\n\n\n\nCode\nfor (i in url_list){\n  year=tail(unlist(strsplit(i, split = \"/\")),1)\n  print(year)\n  print(i)\n  year_ur=i\n  year_page &lt;- read_html(year_ur)\n  bottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\n  bottle003=unlist(strsplit(bottle001,\"\\n\"))\n  \n  \n  topic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\n  topic_link_001 &lt;- year_page %&gt;%\n    html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\n  year_list_topic=rep(year,length(topic001))\n  year_list_bottle=rep(year,length(bottle003))\n  \n  all_year_list_topic=c(all_year_list_topic,year_list_topic)\n  all_year_list_bottle=c(all_year_list_bottle,year_list_bottle)\n  \n  bottle_list=c(bottle_list,bottle003)\n  topic_list=c(topic_list,topic001)\n  topic_link_list=c(topic_link_list,topic_link_001)\n  \n  Sys.sleep(1)\n  }\n\n\n\n\n5 combine\n\n\nCode\ndata=tibble(topic_list,topic_link_list,all_year_list_topic)\n\n\n\n\nCode\nglimpse(data)\n\n\nappend into downloaded data\ndownloaded url\n\n\nCode\ndownload_url=read_excel(\"./output/all year page.xlsx\")\n\n\n\n\nCode\nglimpse(download_url)\n\n\n\n\nCode\nall_data=rbind(data,download_url) %&gt;% unique()\n\n\n\n\nCode\nglimpse(all_data)\n\n\n\n\nCode\nlibrary(openxlsx)\n\nwrite.xlsx(all_data, file = \"./output/all year page.xlsx\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year page"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/2 whiskynote one page.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/2 whiskynote one page.html",
    "title": "One page reveiw",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\nWeb scraping on www.whiskynotes.be\n\n1 review page\n\n\nCode\nreview_url='https://www.whiskynotes.be/2024/ardbeg/spheric-spirits-springbank-blended-malt-islay-malt/'\n\n#review_url='https://www.whiskynotes.be/2011/port-ellen/port-ellen-10th-release-1978/'\n\n\n\n\n\n2 read in html\n\n\nCode\nreview_page &lt;- read_html(review_url)\n\n\n\n\n3 take picture of url\n\n\n4 bottle_name\n\n\nCode\nbottle_name=review_page  %&gt;% html_elements(\".entry-content h2\") %&gt;% html_text2()\n# remove empty element\nbottle_name=bottle_name[nzchar(bottle_name)]\n# remove space element\nbottle_name=bottle_name[nchar(bottle_name)&gt;2]\nbottle_name\n\n\n[1] \"Blended Malt 44 yo 1978 (59,8%, Spheric Spirits 2023, refill sherry butt #6, 331 btl.)\"   \n[2] \"Springbank 27 yo 1994 (47,1%, Spheric Spirits 2022, refill sherry hogshead #95, 241 btl.)\"\n[3] \"Islay Malt 25 yo (48,4%, Spheric Spirits 2022, 407 btl.)\"                                 \n\n\n\n\n5 bottle_review\n\n\nCode\nbottle_review=review_page  %&gt;% html_elements(\"p\") %&gt;% html_text2()\nbottle_review\n\n\n [1] \"Spheric Spirits is a young indie bottler from Germany, started by Benedict and Claudio. They have a slightly edgy / flashy branding (check the website) – I like the vibrant colours on the labels but apparently not everything agrees. Besides whisky, they’re also looking at armagnac and destilado de agave. They’re not just bottlers, by the way, they like to get involved at the beginning of production.\"\n [2] \"First up is a Blended Malt 1978, which is probably old Long John blending stock. It ended up forgotten due to a change of brand ownership in 1981. If this is true, then the peated component is probably 1970s Laphroaig.\"                                                                                                                                                                                        \n [3] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n [4] \"Nose: indeed you get this old school faded peat mixed with tropical fruits. Yellow plums, papaya, dried pineapple slices, peach and drizzles of honey. There’s a good dose of polished wood and light coconut (giving it an American touch) as well as paraffin, pine needles, buttery cake dough, walnuts and hints of old Amontillado. Quite stunning so far, you don’t get this profile often.\"                 \n [5] \"Mouth: peatier now, and more woody. Hints of plums and melons, as well as tangerines and overripe bananas. Something of the 1960s Ben Nevis waxiness, coconut, and some bitter herbs. Then a grassy sharpness, some cinnamon and ginger, as well as butter cookies, hazelnuts and pipe tobacco. Slightly astringent at times, but still it’s an uncommon, intruiging profile including nicely medicinal smoke.\"    \n [6] \"Finish: long, honeyed but also spicy, with peppery notes and a little fruit tea. Caramelized nuts and wood until the very end.\"                                                                                                                                                                                                                                                                                    \n [7] \"I remember hesitating to buy a bottle of this blended malt – honestly I thought it was too expensive at € 800+. However after trying it, I’m hesitating again because it’s such a unique profile. Almost sold out, I believe, but still seen at Whisky-Maniac for instance.\"                                                                                                                                       \n [8] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n [9] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[10] \"Nose: very mineral, you could almost think of mezcal here. Plenty of linseed or sunflower oil and waxed canvas, wax candles and some vegetal hints. Light orchard fruits in second row, maybe even a hint of green pineapple. Then a mossy note and a drop of seawater. Very clean, with virtually voiceless sherry (unless it was Fino).\"                                                                         \n[11] \"Mouth: a rather wonderful mix of minerals and waxes, with green fruits. Think kiwi and green apple. Then chalky notes and more vegetal oils, as well as grapefruit. Fresh herbs and a little eucalyptus. Light coastal touches. Just a hint of marshmallow sweetness in the background.\"                                                                                                                           \n[12] \"Finish: long, still lean and elegant, with lime and herbs, barley sweetness and aniseed.\"                                                                                                                                                                                                                                                                                                                          \n[13] \"Again, not a cheap whisky but very well chosen. Reminds me of the Whisky Sponge 60a, although this one is even more clean. Perhaps too clean for some. Still listed on the website of Hogshead Imports, but I believe we’ll be too late… Score: 91/100\"                                                                                                                                                            \n[14] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[15] \"We end this (already impressive) session with a secret Islay Malt, a mix of the 1993 and 1994 vintages. Spheric Spirits tell us that this is one of the unusual batches produced on site in the early 1990s by the team of a neighbouring brand, just to keep the distillery operational. Isn’t that the time when Allied Distillers made Laphroaig at Ardbeg?\"                                                    \n[16] \"Medicinal peat smoke is well integrated into its otherwise fruity and citrusy nose. Even hints of tropical nuances are detectable. On the pallet sweet peat shows up more present with a salty tang. Lovely old school earthy medicinal peatiness, no bonfire smoke. The mouthfeel is incredibly oily and lingering.\"                                                                                              \n[17] \" \"                                                                                                                                                                                                                                                                                                                                                                                                                 \n[18] \"Nose: nice engine oil along with medicinal peat. Perhaps a little smokier / Laphroaigier than some other ‘Begs? Mentholated notes and subtle antiseptics. Then delicated earthy notes, big hints of lemons and just a hint of vanilla. Soft orange notes, malty sweetness and peaches. All in all quite mild.\"                                                                                                     \n[19] \"Mouth: more intensely peaty now, more clearly Ardbeg. Big medicinal notes, with some tar in the distance, as well as smoked meat. Then some lighter, fruitier notes, a little salt, and a hint of tea leaves. Towards the end it becomes more narrow again, with sour citrus and mineral notes that remind me of Caol Ila.\"                                                                                        \n[20] \"Finish: long, citrusy, with hints of charcoal, light pear and tarry ropes. Just a subtle touch of bitter herbs.\"                                                                                                                                                                                                                                                                                                   \n[21] \"Some beautiful old school notes in here again, although they may not be entirely Ardbeg if you know what I mean. Sold out. I apologize for not discovering Spheric Spirits sooner. Score: 90/100\"                                                                                                                                                                                                                  \n[22] \"Your email address will not be published. Required fields are marked *\"                                                                                                                                                                                                                                                                                                                                            \n[23] \"Comment *\"                                                                                                                                                                                                                                                                                                                                                                                                         \n[24] \"Name *\"                                                                                                                                                                                                                                                                                                                                                                                                            \n[25] \"Email *\"                                                                                                                                                                                                                                                                                                                                                                                                           \n[26] \"Website\"                                                                                                                                                                                                                                                                                                                                                                                                           \n[27] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                  \n[28] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                  \n[29] \"Δdocument.getElementById( \\\"ak_js_1\\\" ).setAttribute( \\\"value\\\", ( new Date() ).getTime() );\"                                                                                                                                                                                                                                                                                                                      \n[30] \"This site uses Akismet to reduce spam. Learn how your comment data is processed.\"                                                                                                                                                                                                                                                                                                                                  \n[31] \"Begin typing your search above and press return to search. Press Esc to cancel.\"                                                                                                                                                                                                                                                                                                                                   \n\n\n\n\n6 bottle_review_Nose\n\n\nCode\nbottle_review_Nose=bottle_review[bottle_review %&gt;% str_detect('Nose:')]\nbottle_review_Nose\n\n\n[1] \"Nose: indeed you get this old school faded peat mixed with tropical fruits. Yellow plums, papaya, dried pineapple slices, peach and drizzles of honey. There’s a good dose of polished wood and light coconut (giving it an American touch) as well as paraffin, pine needles, buttery cake dough, walnuts and hints of old Amontillado. Quite stunning so far, you don’t get this profile often.\"\n[2] \"Nose: very mineral, you could almost think of mezcal here. Plenty of linseed or sunflower oil and waxed canvas, wax candles and some vegetal hints. Light orchard fruits in second row, maybe even a hint of green pineapple. Then a mossy note and a drop of seawater. Very clean, with virtually voiceless sherry (unless it was Fino).\"                                                        \n[3] \"Nose: nice engine oil along with medicinal peat. Perhaps a little smokier / Laphroaigier than some other ‘Begs? Mentholated notes and subtle antiseptics. Then delicated earthy notes, big hints of lemons and just a hint of vanilla. Soft orange notes, malty sweetness and peaches. All in all quite mild.\"                                                                                    \n\n\n\n\n7 bottle_review_Mouth\n\n\nCode\nbottle_review_Mouth=bottle_review[bottle_review %&gt;% str_detect('Mouth:')]\nbottle_review_Mouth\n\n\n[1] \"Mouth: peatier now, and more woody. Hints of plums and melons, as well as tangerines and overripe bananas. Something of the 1960s Ben Nevis waxiness, coconut, and some bitter herbs. Then a grassy sharpness, some cinnamon and ginger, as well as butter cookies, hazelnuts and pipe tobacco. Slightly astringent at times, but still it’s an uncommon, intruiging profile including nicely medicinal smoke.\"\n[2] \"Mouth: a rather wonderful mix of minerals and waxes, with green fruits. Think kiwi and green apple. Then chalky notes and more vegetal oils, as well as grapefruit. Fresh herbs and a little eucalyptus. Light coastal touches. Just a hint of marshmallow sweetness in the background.\"                                                                                                                       \n[3] \"Mouth: more intensely peaty now, more clearly Ardbeg. Big medicinal notes, with some tar in the distance, as well as smoked meat. Then some lighter, fruitier notes, a little salt, and a hint of tea leaves. Towards the end it becomes more narrow again, with sour citrus and mineral notes that remind me of Caol Ila.\"                                                                                    \n\n\n\n\n8 bottle_review_Finish\n\n\nCode\nbottle_review_Finish=bottle_review[bottle_review %&gt;% str_detect('Finish:')]\nbottle_review_Finish\n\n\n[1] \"Finish: long, honeyed but also spicy, with peppery notes and a little fruit tea. Caramelized nuts and wood until the very end.\"\n[2] \"Finish: long, still lean and elegant, with lime and herbs, barley sweetness and aniseed.\"                                      \n[3] \"Finish: long, citrusy, with hints of charcoal, light pear and tarry ropes. Just a subtle touch of bitter herbs.\"               \n\n\n\n\n9 first score\n\n\nCode\nfirst_bottle_score=review_page  %&gt;% html_elements(\".entry-score\") %&gt;% html_text2()\nfirst_bottle_score=first_bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n\n\n\n\n10 all other score\n\n\nCode\nbottle_score=review_page  %&gt;% html_elements(\"strong\") %&gt;% html_text2()\n  \nbottle_score2=bottle_score %&gt;% str_match('[0-9][0-9]/100') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n\nbottle_score2=bottle_score2 %&gt;% mutate(V1=str_replace(V1,'/100',''))\n\n\n\n\n11 combine all score\n\n\nCode\n# move the last one to the first one\nif(identical(bottle_score, character(0))==TRUE|nrow(bottle_score2)==0){\n    all_page_score=first_bottle_score %&gt;% tibble()%&gt;% rename(all_page_score='.') \n  }else{\n  #bottle_score=bottle_score %&gt;% str_match('[0-9][0-9]') %&gt;% as.data.frame() %&gt;% filter(is.na(V1)==FALSE)\n  all_page_score=rbind(first_bottle_score,bottle_score2) %&gt;% rename(all_page_score=V1) \n  }\nall_page_score\n\n\n  all_page_score\n1             92\n2             91\n3             90\n\n\n\n\n12 page_published_date\n\n\nCode\npage_published_date=review_page  %&gt;% html_elements(\".published\") %&gt;% html_text2()\npage_published_date\n\n\n[1] \"16 April 2024\"\n\n\n\n\n13 page_class\n\n\nCode\npage_class=review_page  %&gt;% html_elements(\".cat-links a\") %&gt;% html_text2()\npage_class=str_flatten(page_class,collapse = \"--\")\npage_class\n\n\n[1] \"* Blends--Ardbeg--Springbank\"\n\n\n\n\n14 page_title\n\n\nCode\npage_title=review_page  %&gt;% html_elements(\".entry-title\") %&gt;% html_text2()\npage_title\n\n\n[1] \"Spheric Spirits: Springbank / Blended Malt / Islay Malt\"\n\n\n\n\n15 combine all one_page_review\n\n\nCode\none_page_review=data_frame(bottle_name,bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish,all_page_score,page_class,page_published_date,page_title,review_url)\none_page_review\n\n\n# A tibble: 3 × 9\n  bottle_name        bottle_review_Nose bottle_review_Mouth bottle_review_Finish\n  &lt;chr&gt;              &lt;chr&gt;              &lt;chr&gt;               &lt;chr&gt;               \n1 Blended Malt 44 y… Nose: indeed you … Mouth: peatier now… Finish: long, honey…\n2 Springbank 27 yo … Nose: very minera… Mouth: a rather wo… Finish: long, still…\n3 Islay Malt 25 yo … Nose: nice engine… Mouth: more intens… Finish: long, citru…\n# ℹ 5 more variables: all_page_score &lt;chr&gt;, page_class &lt;chr&gt;,\n#   page_published_date &lt;chr&gt;, page_title &lt;chr&gt;, review_url &lt;chr&gt;\n\n\n\n\n16 output\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(one_page_review,'one_page_review.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "One page reveiw"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/6 web scraping with rvest all second time.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/6 web scraping with rvest all second time.html",
    "title": "All year all topic second time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n1 one page function\n\n\nCode\nsource('one_page.r')\n\n\n\n\n2 read in all link\n\n\nCode\nlibrary(readxl)\ntopic_link=read_excel('./output/all year page.xlsx',sheet='topic')\n\n\n\n\nCode\nglimpse(topic_link)\n\n\nexclude news\n\n\nCode\nnews=topic_link$topic_link_list %&gt;% str_detect('whisky-news|whisky-bar')\n\n\n\n\nCode\ntopic_link002=topic_link$topic_link_list[!news]\n\n\nexclude no score page:\n\n\nCode\nno_score_page=c(\n\"https://www.whiskynotes.be/2011/blends/bloggers-blend-masterofmalt/\"         \n,\"https://www.whiskynotes.be/2012/glenfarclas/glenfarclas-1968-mytribute-5241/\"\n,\"https://www.whiskynotes.be/2012/ancnoc/ancnoc-distillery-visit/\"             \n,\"https://www.whiskynotes.be/2012/distillery-visits/old-pulteney/\"             \n,\"https://www.whiskynotes.be/2013/blends/cutty-sark-storm-appletiser/\"         \n,\"https://www.whiskynotes.be/2013/glenfarclas/glenfarclas-verticale/\"  \n)\n\n\n\n\n3 read in donload page:\n\n\nCode\nfinish_download=read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\nCode\nfinish_download_topic_link=unique(finish_download$review_url)\n\n\n\n\nCode\nlength(finish_download_topic_link)\n\n\n\n\nCode\nnon_finish_link=topic_link002 [! topic_link002 %in% c(finish_download_topic_link,no_score_page)]\n\n\n\n\nCode\nlength(non_finish_link)\n\n\n\n\n4 download non download page:\n\n\nCode\nlibrary(openxlsx)\npage=non_finish_link\n\nall_page_review_list=data.frame()\n\nstart_time=Sys.time()\nprint(paste0(\"Start time: \", start_time))\n\nloop_num=0\n\nfor (i in page){\n   tryCatch({\n#############################     \n   loop_num=loop_num+1\n   print(paste0(\"Running loop No.\",which(page==i)))\n         \n   print(paste0(\"current time: \", Sys.time()))\n   \n   output=one_page_function(i)\n\n   all_page_review_list=rbind(all_page_review_list,output)\n   \n   \n   print(paste0(\"Used time: \", Sys.time()-start_time))\n   # ouput every 20 page\n   if (loop_num%%20==0){\n      print(paste0(\"#########################. output to excel: \", loop_num))\n      all_page_review_list_total=rbind(finish_download,all_page_review_list)\n      write.xlsx(all_page_review_list_total,'./output/all_page_bottle_list_all.xlsx')\n     }\n    \n   \n#############################        \n    }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n}\n\nend_time=Sys.time()\nprint(paste0(\"End time: \", end_time))\nprint(paste0(\"total used time: \", end_time-start_time))\n\n\noutput=one_page_function(i)\n\nall_page_review_list_total=rbind(finish_download,all_page_review_list)\n   \nwrite.xlsx(all_page_review_list_total,'./output/all_page_bottle_list_all.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year all topic second time"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/4b whiskynote all year page second time.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/4b whiskynote all year page second time.html",
    "title": "All year page second time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 read from 2024\n\n\nCode\nurl_list=\"https://www.whiskynotes.be/2024\"\n\n\n\n\nCode\nbottle_list=c()\ntopic_list=c()\ntopic_link_list=c()\nall_year_list_topic=c()\nall_year_list_bottle=c()\n\nfor (i in url_list){\n  year=tail(unlist(strsplit(i, split = \"/\")),1)\n  print(year)\n  print(i)\n  year_ur=i\n  year_page &lt;- read_html(year_ur)\n  bottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\n  bottle003=unlist(strsplit(bottle001,\"\\n\"))\n  \n  \n  topic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\n  topic_link_001 &lt;- year_page %&gt;%\n    html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\n  year_list_topic=rep(year,length(topic001))\n  year_list_bottle=rep(year,length(bottle003))\n  \n  all_year_list_topic=c(all_year_list_topic,year_list_topic)\n  all_year_list_bottle=c(all_year_list_bottle,year_list_bottle)\n  \n  bottle_list=c(bottle_list,bottle003)\n  topic_list=c(topic_list,topic001)\n  topic_link_list=c(topic_link_list,topic_link_001)\n  \n  Sys.sleep(1)\n  }\n\n\n\n\n2 combine\n\n\nCode\ndata=tibble(topic_list,topic_link_list,all_year_list_topic)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\ndata_all=read_excel('./output/all year page.xlsx')\n\n\n\n\nCode\ndata_all_new001=rbind(data_all,data)\n\n\n\n\nCode\nglimpse(data_all_new001)\n\n\n\n\nCode\ndata_all_new002=data_all_new001 %&gt;% unique()\n\n\n\n\nCode\nglimpse(data_all_new002)\n\n\n\n\n3 output\n\n\nCode\nlibrary(openxlsx)\nlist_of_datasets &lt;- list(\"topic\" = data_all_new002)\n\nwrite.xlsx(list_of_datasets, file = \"./output/all year page.xlsx\")\n\n\n\n\n4 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year page second time"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8b summary in R.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/8b summary in R.html",
    "title": "Summary in R",
    "section": "",
    "text": "Code\n#must install the package from github\n#install.packages('devtools')  \n#devtools::install_github(\"lchiffon/wordcloud2\")  \n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n1 read in data\n\n\nCode\ndata001=read_excel('./output/all_page_bottle_list_all.xlsx')\nglimpse(data001)\n\n\nRows: 4,934\nColumns: 9\n$ bottle_name          &lt;chr&gt; \"Cognac Chollet Lot 1960 ‘Le Bon Vivant’ – Fins B…\n$ bottle_review_Nose   &lt;chr&gt; \"Nose: a rich, fragrant and fruity style. Honeyed…\n$ bottle_review_Mouth  &lt;chr&gt; \"Mouth: more spices now. Mint and pepper, leading…\n$ bottle_review_Finish &lt;chr&gt; \"Finish: medium to long, more on fruit tea now, a…\n$ all_page_score       &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"85\", \"82\", \"8…\n$ page_class           &lt;chr&gt; \"* Cognac\", \"* Cognac\", \"* Cognac\", \"Ledaig\", \"Le…\n$ page_published_date  &lt;chr&gt; \"30 November 2020\", \"30 November 2020\", \"30 Novem…\n$ page_title           &lt;chr&gt; \"Cognac Lot 1960 / XO / Lot 1906 (Malternative Be…\n$ review_url           &lt;chr&gt; \"https://www.whiskynotes.be/2020/cognac/cognac-lo…\n\n\n\n\nCode\ndata002=data001 %&gt;% filter(as.numeric(all_page_score)&gt;0,as.numeric(all_page_score)&lt;100\n                       ,bottle_review_Nose !='no comment'\n                      ,bottle_review_Mouth !='no comment'\n                      ,bottle_review_Finish !='no comment'\n                           \n                           \n                           ) %&gt;% \n  mutate(review=paste(bottle_review_Nose,bottle_review_Mouth,bottle_review_Finish) %&gt;% \n                             str_to_lower() %&gt;% str_replace_all(\"[[:punct:]]\", \"\") %&gt;% \n                            str_replace_all('sweetness','sweet') %&gt;% str_replace_all('apples','apple')%&gt;% str_replace_all('oranges','orange') %&gt;% str_replace_all('fruits','fruit')\n\n                           )\n\nreivew002=data002$review\n\n\n\n\nCode\ntest='able stees a asdf df able' %&gt;%str_split(\" \") %&gt;% unlist %&gt;% unique %&gt;% paste(collapse = ' ')\ntest\n\n\n[1] \"able stees a asdf df\"\n\n\n\n\nCode\nreivew003=c()\n\nfor (i in reivew002){\n a=i%&gt;%str_split(\" \") %&gt;% unlist %&gt;% unique%&gt;% paste(collapse = ' ')\n  reivew003=c(reivew003,a)\n}\n\n\n\n\nCode\ntest001=reivew003 %&gt;% tibble() %&gt;% rename('review'='.')\n\n\n\n\nCode\ntest002_without_sweet=test001[!grepl(\"sweet\",test001$review),]\ntest002_sweet=test001[grepl(\"sweet\",test001$review),]\n\n\n\n\nCode\nstring &lt;- reivew003\n\ndata002=data.frame(string) %&gt;%\n  separate_rows(string) %&gt;%\n  count(string, sort = TRUE) %&gt;%\n  filter(n &gt;= 2)\n\n\n\n\n2 remove stop word\n\n\nCode\nlibrary(tidytext)\n\ndata003 &lt;- data002 %&gt;%\n  anti_join(stop_words, by= c(\"string\" = \"word\"))\n\n\n\n\n3 remove non favour word\n\n\nCode\ndata004 &lt;- data003 %&gt;% filter(!string %in% c('notes','hints'\n                                            ,'nose'\n                                           ,'finish'\n                                            ,'light', 'slightly', 'hint', 'nice'\n                                           ,'medium' , 'subtle', 'background','note' ,'plenty' ,'lots'\n                                           ,'mouth','bit','soft','dark')\n                                          )\n\n\n\n\n4 translate to chinese\n\n\nCode\ndata005=head(data004,30)\n\n\n\n\nCode\nlibrary(gtranslate)\n#lang_codes\n\ndata005_cn=translate(data005$string, from = \"en\", to = \"zh-CN\")\n\n\n\n\nCode\ndata005_cn=cbind(data005_cn,data005)\ndata005_cn=data005_cn %&gt;% select(-string)\n\n\n\n\n5 word cloud 1 english\n\n\nCode\nlibrary(wordcloud2) \n\n\n\n\nCode\nmy_graph_en=wordcloud2(data=data005, size=1)\n#my_graph_en\n\n\n\n\nCode\nlibrary(webshot2)\nlibrary(htmlwidgets)\n\nsaveWidget(my_graph_en,\"tmp_en.html\")#先保存为网页格式\n\nwebshot(\"tmp_en.html\", \"wordcloud_en.jpg\", delay = 2) ##IRIENI\n\n\n\n\n\n\n\n\n\n\n\n6 word cloud 2 chinese\n\n\nCode\nlibrary(showtext)\nshowtext_auto()\npar(family=\"PingFangSC-Regular\")\nmy_graph=wordcloud2(data=data005_cn,size=1)\n#my_graph\n\n\n\n\nCode\nlibrary(webshot2)\nlibrary(htmlwidgets)\n\nsaveWidget(my_graph,\"tmp.html\")#先保存为网页格式\n\nwebshot(\"tmp.html\", \"wordcloud.jpg\", delay = 2) ##IRIENI\n\n\n\n\n\n\n\n\n\n\n\n7 chart 1 with gglolt\n\n\nCode\nlibrary(ggplot2) \nggplot(data005, aes(x=reorder(string,n), y=n)) +geom_text(aes(label = n), hjust = -0.1)+ ylim(min=0, 3200)+\n  geom_bar(stat=\"identity\")+coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n8 chart 2 add image gglolt\n\n\nCode\nlibrary(ggplot2) \nlibrary(png)\nlibrary(grid)\nlibrary(patchwork) \n\n\nimg2 &lt;- readPNG(\"en_glass.png\")\nimg3=rasterGrob(img2, width = unit(1,\"npc\"), height = unit(1,\"npc\"))\n\ngg=ggplot(data005, aes(x=reorder(string,n), y=n))+theme_classic()+geom_text(aes(label = n), hjust = -0.1)+xlab(\"Flavor\") + ylab(\"Frequency\")+scale_y_continuous(expand=c(0,0),limits=c(0,3200))+\n  geom_bar(stat=\"identity\",fill=\"#CD5C5C\")+coord_flip()+ggtitle(\"Whisky notes Top30 most used words\",subtitle = \"5K review\")+labs(caption = \"data source from www.whiskynote.be between 2010 to 2024\")+\n  inset_element(img3, 0.66, 0.15, 1, 0.75,align_to = 'full')\n\n\n\n\nCode\ngg\n\n\n\n\n\n\n\n\n\n\n\n9 chart 2 add image gglolt in chinese\n\n\nCode\n# Add  logo to the graph you created\nlibrary(magick)\nlogo &lt;- image_read(\"logo.png\")\n\n\n\n\nCode\nlibrary(ggplot2) \nlibrary(png)\nlibrary(grid)\nlibrary(patchwork) \n\nlibrary(showtext)\nshowtext_auto()\n\n\nimg2 &lt;- readPNG(\"cn_glass.png\")\nimg3=rasterGrob(img2, width = unit(1,\"npc\"), height = unit(1,\"npc\"))\n\ngg=ggplot(data005_cn, aes(x=reorder(data005_cn,n), y=n))+theme_classic()+geom_text(aes(label = n), hjust = -0.1)+xlab(\"风味\") + ylab(\"次数\")+scale_y_continuous(expand=c(0,0),limits=c(0,3200))+\n  geom_bar(stat=\"identity\",fill=\"#CD5C5C\")+coord_flip()+ggtitle(\"Whisky notes Top30 风味词\",subtitle = \"5K+ 酒评\")+labs(caption = \"数据源:www.whiskynote.be 从2010年到2024年\")+\n  inset_element(img3, 0.65, 0.15, 1, 0.75,align_to = 'full')\n\n\n\n\nCode\ngg\ngrid::grid.raster(logo, x = 0.05, y = 0.01, just = c('left', 'bottom'), width = unit(2.5, 'inches'))\n\n\n\n\n\n\n\n\n\n\n\nCode\nggsave(\"myplot.png\")\n\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] grid      stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] magick_2.8.3      patchwork_1.2.0   png_0.1-8         showtext_0.9-7   \n [5] showtextdb_3.0    sysfonts_0.8.9    htmlwidgets_1.6.4 webshot2_0.1.1   \n [9] wordcloud2_0.2.2  gtranslate_0.0.1  tidytext_0.4.1    readxl_1.4.3     \n[13] openxlsx_4.2.5.2  lubridate_1.9.3   forcats_1.0.0     stringr_1.5.1    \n[17] dplyr_1.1.4       purrr_1.0.2       readr_2.1.5       tidyr_1.3.1      \n[21] tibble_3.2.1      ggplot2_3.5.1     tidyverse_2.0.0  \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5      xfun_0.43         websocket_1.4.1   processx_3.8.4   \n [5] lattice_0.22-6    tzdb_0.4.0        vctrs_0.6.5       tools_4.3.1      \n [9] ps_1.7.6          generics_0.1.3    curl_5.2.1        fansi_1.0.6      \n[13] janeaustenr_1.0.0 pkgconfig_2.0.3   tokenizers_0.3.0  Matrix_1.6-5     \n[17] lifecycle_1.0.4   farver_2.1.1      compiler_4.3.1    textshaping_0.3.7\n[21] munsell_0.5.1     chromote_0.2.0    htmltools_0.5.8.1 SnowballC_0.7.1  \n[25] yaml_2.3.8        pillar_1.9.0      later_1.3.2       tidyselect_1.2.1 \n[29] rvest_1.0.4       zip_2.3.1         digest_0.6.35     stringi_1.8.4    \n[33] labeling_0.4.3    fastmap_1.1.1     colorspace_2.1-0  cli_3.6.2        \n[37] magrittr_2.0.3    utf8_1.2.4        withr_3.0.0       scales_1.3.0     \n[41] promises_1.3.0    timechange_0.3.0  rmarkdown_2.26    httr_1.4.7       \n[45] cellranger_1.1.0  ragg_1.3.0        hms_1.1.3         evaluate_0.23    \n[49] knitr_1.45        rlang_1.1.3       Rcpp_1.0.12       glue_1.7.0       \n[53] xml2_1.3.6        rstudioapi_0.16.0 jsonlite_1.8.8    R6_2.5.1         \n[57] systemfonts_1.0.6\n\n\n\n\n\n10 resource:\nhttps://github.com/Lchiffon/wordcloud2\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Summary in R"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/3 whiskynote one year page.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/3 whiskynote one year page.html",
    "title": "One year page review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\nWeb scraping on www.whiskynotes.be\n\n1 year page\n\n\nCode\nyear_ur='https://www.whiskynotes.be/2023'\n\n\n\n\n\n2 read in html\n\n\nCode\nyear_page &lt;- read_html(year_ur)\n\n\n\n\n3 review bottle name on one year\n\n\nCode\nbottle001 &lt;- year_page %&gt;% html_elements(\"p\")%&gt;% html_text2()\nbottle001[length(bottle001)]\n\n\n\n\nCode\n# drop last one which is not bottle\nbottle002=bottle001[-length(bottle001)]\nhead(bottle002,3)\n\n\n\n\nCode\nlength(bottle002)\n\n\n\n\nCode\n# split to each bottle \nbottle003=unlist(strsplit(bottle002,\"\\n\"))\n\n\n\n\nCode\nhead(bottle003,5)\n\n\n\n\nCode\nlength(bottle003)\n\n\n\n\n4 review topic name on one year\n\n\nCode\ntopic001 &lt;- year_page %&gt;% html_elements(\".archive-link\") %&gt;% html_text2()\nhead(topic001)\n\n\n\n\nCode\nlength(topic001)\n\n\n\n\n5 review topic link on one year\n\n\nCode\ntopic_link_list &lt;- year_page %&gt;%\n  html_elements(css = \".entry-permalink\")%&gt;% html_attr(\"href\")\n\nhead(topic_link_list)\n\n\n\n\nCode\nlength(topic_link_list)\n\n\n\n\n6 combine\n\n\nCode\ndata=tibble(topic001,topic_link_list)\n\n\n\n\nCode\nbottle003=tibble(bottle003)\n\n\n\n\n7 output\n\n\nCode\nlibrary(openxlsx)\nlist_of_datasets &lt;- list(\"Name of DataSheet1\" = data, \"Name of Datasheet2\" = bottle003)\n\nwrite.xlsx(list_of_datasets, file = \"on year page.xlsx\")\n\n\n\n\n8 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "One year page review"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/5 clean up.html",
    "href": "other/3 Web scraping on whiskyfun.com/5 clean up.html",
    "title": "All page clean up",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 input\n\n\nCode\ndata001=read_excel('./output/all_page_review_all_v2.xlsx')\n\n\n\n\nCode\nglimpse(data001)\n\n\n\n\nCode\ndata002=data001%&gt;% mutate(\n  \n  bottle_review2=bottle_review2%&gt;% str_replace(\"–\", \"-\")%&gt;% str_replace(\"Palate\", \"Mouth\")\n  ,name=paste0(str_extract(bottle_review2, regex( \"[^)]+\")),\")\")\n  ,distillery=bottle_review2 %&gt;% str_extract(\".*?\\\\d\")%&gt;% str_sub(end=-3)\n  \n  ,colour=(bottle_review2 %&gt;% str_match(\"Colour:\\\\s*(.*?)\\\\s*\\\\.\"))[,2]\n  ,nose=(bottle_review2 %&gt;% str_match(\"Nose\\\\s*(.*?)\\\\s*Mouth\"))[,2]\n  ,mouth=(bottle_review2 %&gt;% str_match(\"Mouth\\\\s*(.*?)\\\\s*Finish\"))[,2]\n  ,finish=(bottle_review2 %&gt;% str_match(\"Finish:\\\\s*(.*?)\\\\s*Comments\"))[,2]\n  ,comments=(bottle_review2 %&gt;% str_match(\"Comments:\\\\s*(.*?)\\\\s*SGP\"))[,2]\n  \n  #,full_score=(bottle_review2 %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n  ,full_score=(bottle_review2 %&gt;%str_match_all(\"[:digit:][:digit:][:space:]points.\"))%&gt;% sapply(tail, 1)\n  ,score=full_score %&gt;% str_replace(\"points.\",\"\") %&gt;% as.numeric()\n  \n  ,review_date=((str_match(old_page %&gt;%str_to_lower(),\"https://www.whiskyfun.com/archive\\\\s*(.*?)\\\\s*-\"))[,2] )%&gt;% str_to_title()\n \n  ,review_date2= myd(review_date, truncated = 1)\n  ,review_date2=if_else(is.na(review_date)==TRUE,today(),review_date2)\n  \n  ,review_year=year(review_date2)\n) %&gt;% unique()\n\nglimpse(data002)\n\n\n\n\nCode\ncols=names(data002)\ntest001=data002 %&gt;%filter(if_any(.cols = cols, .fns = ~is.na(.x)))\nglimpse(test001)\n\n\n\n\nCode\nwrite.xlsx(data002,'./output/all_page_review_clean_v2.xlsx')\n\n\n\n\nCode\ntest001=data002 %&gt;% filter(bottle_review2 %&gt;% str_sub(1,4)=='Nose'|bottle_review2 %&gt;% str_sub(1,6)=='Colour'|bottle_review2 %&gt;% str_sub(1,5)=='Mouth'|bottle_review2 %&gt;% str_sub(1,6)=='Finish'|bottle_review2 %&gt;% str_sub(1,8)=='Comments')\n\n\n\n\nCode\nglimpse(test001)\n\n\n\n\nCode\ntest002=test001 %&gt;% head()\n\n\n\n\nCode\nreview_html_elements=\".textegrandfoncegras , .TextenormalNEW, .Textenormal,td &gt; font,div td font\"\n\nbottle_review_up1_list=c()\nbottle_review_up2_list=c()\n\nfor (i in test002$bottle_review2){\n  #print(i)\n  link=(test002 %&gt;% filter(bottle_review2==i))$old_page\n  print(link)\n  page=read_html(curl(link, handle = curl::new_handle(\"useragent\" = \"Mozilla/5.0\")))\n  bottle_review=page  %&gt;% html_elements(review_html_elements) %&gt;% html_text2()\n  \n  bottle_review=unique(bottle_review[bottle_review != \"\"])\n  \n  index_num=match(i,bottle_review)\n  \n  bottle_review_up1=bottle_review[index_num-1]\n  bottle_review_up2=bottle_review[index_num-2]\n  \n  bottle_review_up1_list=c(bottle_review_up1_list,bottle_review_up1)\n  bottle_review_up2_list=c(bottle_review_up2_list,bottle_review_up2)\n}\n\n\n\n\n2 reference\n%d = Day number of month (5, 17, 28, etc.)\n%j = Day number of the year (Julian day 001-366)\n%a = Abbreviated weekday (Mon, Tue, Wed, etc.)\n%A = Full weekday (Monday, Tuesday, etc.) %w = Weekday number (0-6, Sunday is 0)\n%u = Weekday number (1-7, Monday is 1)\n%W = Week number (00-53, Monday is week start)\n%U = Week number (01-53, Sunday is week start)\n%m = Month number (e.g. 01, 02, 03, 04)\n%b = Abbreviated month (Jan, Feb, etc.)\n%B = Full month (January, February, etc.)\n%y = 2-digit year (e.g. 89)\n%Y = 4-digit year (e.g. 1989)\n%h = hours (24-hr clock)\n%m = minutes\n%s = seconds %z = offset from GMT\n%Z = Time zone (character)\nhttps://epirhandbook.com/en/working-with-dates.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page clean up"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/4 whiskyfun all page.html",
    "href": "other/3 Web scraping on whiskyfun.com/4 whiskyfun all page.html",
    "title": "All page second time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(curl)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 all review page\n\n\n2 first page\n\n\nCode\nfirst_url='https://www.whiskyfun.com'\nfirst_page=read_html(first_url)\n\n\n\n\nCode\nlast_page &lt;- first_page %&gt;%\n  html_elements(css = \"a.textegrandfoncegras\")%&gt;% html_attr(\"href\")\n\n\n\n\n3 start from secound page\n\n\nCode\npage_list=c()\n\n\n\n\nCode\nurl='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\n\npage=read_html(first_url)\n\nlast_page &lt;- (first_page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n\nprint(last_page)\npage_list=c(page_list,last_page)\n\n\n\n\n4 start to download 500 pages\n\n\nCode\nlast_page='https://www.whiskyfun.com/'\n\npage_list=c()\ndata_list=tibble()\n\ni=0\na=0\n\nwhile (i &lt; 500) {\n  loop_num=i\n  print(paste0(\"current page: \",loop_num))\n\n  tryCatch({\n    #page=read_html(last_page)\n    old_page=last_page\n    page=read_html(curl(last_page, handle = curl::new_handle(\"useragent\" = \"Mozilla/5.0\")))\n    i=i+1\n    \n  Sys.sleep(runif(n=1, min=0.1, max=0.3))\n },error = function(msg){print('eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee')\n    i=i-1\n    print(paste0(\"new i : \",i))\n    a=a+1\n    })\n   if(a&gt;10){break}\n  \n\n##############################################\n  #if (last_page %&gt;% is.na()==TRUE){break}\n\n  ### first page\n   if(last_page=='https://www.whiskyfun.com/'){\n    last_page &lt;- (page %&gt;%html_elements(css = \"a.textegrandfoncegras\")%&gt;%html_attr(\"href\"))[1]\n    \n  #### all other     \n    }else {\n  last_page &lt;- (page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n   ###  before 2004 oct\n  if(last_page %&gt;% is.na()==TRUE){\n    last_page &lt;- (page %&gt;%html_elements(css = \"font:nth-child(1) b a\")%&gt;%html_attr(\"href\"))[1]\n  }\n    }\n  \n  if(last_page%&gt;% str_sub(1,26)=='https://www.whiskyfun.com/'){\n    last_page=last_page}else{\n  last_page=paste0('https://www.whiskyfun.com/',last_page)\n    }\n  \n  print(last_page)\n  #if (last_page %in% page_list|last_page==\"https://www.whiskyfun.com/http://www.lambchop.net/\"){break}\n  page_list=c(page_list,last_page)\n  Sys.sleep(runif(n=1, min=0.1, max=0.8))\n  \n  \n  #######################\n  review_html_elements=\".textegrandfoncegras , .TextenormalNEW, .Textenormal,td &gt; font,div td font\"\n  bottle_review=page  %&gt;% html_elements(review_html_elements) %&gt;% html_text2()\n# remove space element\n\n  bottle_review1=bottle_review[bottle_review %&gt;% str_detect(' points')]\n\n  bottle_review2=bottle_review1[bottle_review1 %&gt;% str_detect('Nose:')]\n\n  bottle_review2=bottle_review2%&gt;% str_replace(\"Palate:\", \"Mouth\")%&gt;% str_replace(\"–\", \"-\")\n\n  bottle_name=str_extract(bottle_review2, regex( \"[^)]+\"))\n  bottle_name=paste0(bottle_name,\")\")\n  print(head(bottle_name,2))\n  print(paste0(\"this page have bottle: \",length(bottle_name)))\n  \n\n  ##### break the loop if can not download continue &gt;=3 pages\n  if (length(bottle_name)==1){fail_num=fail_num+1}else{fail_num=0}\n    \n  if (fail_num&gt;=3){\n    print(paste0(\"breaking page url: \",old_page))\n    break\n    }\n  ################################################################\n  \n  # res &lt;- str_match(bottle_review2, \" \\\\s*(.*?)\\\\s*points\")\n  # bottle_score=paste(\"SGP:\",res[,2],\" points\")%&gt;% str_replace(\"–\", \"-\")\n  # \n  # res &lt;- str_match(bottle_score, \" - \\\\s*(.*?)\\\\s*points\")\n  # bottle_final_score=res[,2]\n  # \n  # res &lt;- str_match(bottle_review2, \"Nose:\\\\s*(.*?)\\\\s*Mouth\")\n  # bottle_name_nose=paste(\"Nose:\",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Mouth\\\\s*(.*?)\\\\s*Finish:\")\n  # bottle_name_mouth=paste(\"Mouth:\",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Colour\\\\s*(.*?)\\\\s*\\\\.\")\n  # bottle_name_colour=paste(\"Colour \",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Finish:\\\\s*(.*?)\\\\s*Comments:\")\n  # bottle_name_finish=paste(\"Finish:\",res[,2])\n  # \n  # res &lt;- str_match(bottle_review2, \"Comments:\\\\s*(.*?)\\\\s*SGP:\")\n  # bottle_name_comments=paste(\"Comments:\",res[,2])\n  # \n  # data=tibble(bottle_review2,bottle_name,bottle_name_nose,bottle_name_mouth,bottle_name_finish,bottle_name_colour,bottle_name_comments,bottle_score,bottle_final_score,old_page,loop_num) %&gt;% unique()\n  # \n  # data_list=rbind(data_list,data)\n  # print(paste0(\"total bootle downlaoded: \",nrow(data_list)))\n  data=tibble(bottle_review2,bottle_name,old_page,loop_num) %&gt;% unique()\n  data_list=rbind(data_list,data)\n  print(paste0(\"total bootle downlaoded: \",nrow(data_list)))\n  \n\n  ####### ouput every 10 page\n  if (i%%10==0){\n\n      print(paste0(\"output to excel: \", i))\n      write.xlsx(data_list,'all_page_review_all_v2.xlsx')\n     }\n  \n  Sys.sleep(runif(n=1, min=0.1, max=0.3))\n}\n\ndata_list=data_list %&gt;% select(-loop_num)%&gt;% unique()\nwrite.xlsx(data_list,'./output/all_page_review_all_v2.xlsx')\n\n\n\n\n5 whiskyfun first page\nhttps://www.whiskyfun.com/ArchiveJan04.html\n\n\n6 whiskyfun last muic page\nhttps://www.whiskyfun.com/archivejanuary18-1-Linkwood-Ardmore-Clynelish.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page second time"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/1 whiskyfun data.html",
    "href": "other/3 Web scraping on whiskyfun.com/1 whiskyfun data.html",
    "title": "whiskyfun data",
    "section": "",
    "text": "1 whiskyfun data\nhttps://www.whiskyfun.com/\n\nI’m just an amateur whisky lover and I live in a part of France called Alsace, near the German border. I co-own two advertising agencies (200 people). I insist, I’m not a whisky pro, not even a proam. I like to talk about whisky with my friends the Malt Maniacs (and many other friends) but what I like best is tasting whisky. I do all that for fun, just for fun. I think whisky is serious matter only to people who make or sell it – or to people who drink way too much of it. What’s more, I like many other things, like all kinds of music, advertising (my work), motorcycling, wine, old watches, food, travelling and God knows what else. You know, toys for boys. And yes, friends… And last time I checked I was 49, happily married, three lovely children (who drink no whisky).—-Serge Valentin\n\n\n2 package\nrvest chromote selenium selenider\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "whiskyfun data"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/4 all distillery.html",
    "href": "other/2 Web scraping on whiskybase.com/4 all distillery.html",
    "title": "all distrillery and bottler name",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\nlibrary(gt)\n\n\n\n1 all distrillery\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/distilleries'\n\n\n\n\nCode\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ntext=page%&gt;% html_nodes(\"*\")%&gt;% html_text2()\n\n\n\n\nCode\nhead(text)\n\n\n[1] \"document.documentElement.className += 'js' Distilleries - Whiskybase - Ratings and reviews for whisky window.__exc = { e: [], a: function(e) { return window.application ? window.application.exec(e) : __exc.e.push(e) } } (function(c, l, a, r, i, t, y) { c[a] = c[a] || function() { (c[a].q = c[a].q || []).push(arguments) }; t = l.createElement(r); t.async = 1; t.src = \\\"https://www.clarity.ms/tag/\\\" + i; y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y); })(window, document, \\\"clarity\\\", \\\"script\\\", \\\"cdpmv56i88\\\");\"\n[2] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[3] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[4] \"document.documentElement.className += 'js'\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n[6] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n\n\n\n\nCode\nwrite_delim(tibble(text), \"./data/all distillery name.txt\")\n\n\n\n\nCode\nlink= page%&gt;%html_nodes(\".clickable a\")%&gt;% html_attr('href')\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% mutate(link=link) %&gt;% select(-Var.6)\n\n\noutput\n\n\nCode\nwrite.xlsx(data,'./output/all distillery.xlsx')\n\n\n\n\n2 summary of the data\n\n\nCode\ndata002=data %&gt;% filter(Whiskies&gt;10,Votes&gt;100) %&gt;% arrange(desc(Rating)) %&gt;% select(-link)\n\ndata003=data002 %&gt;% rowid_to_column(\"No\")\nhead(data003) %&gt;% gt() %&gt;% as_raw_html()\n\n\n\n\n  \n  \n\n\n\nNo\nName\nCountry\nWhiskies\nVotes\nRating\n\n\n\n\n1\nKawasaki\nJapan\n31\n366\n90.04\n\n\n2\nBrora\nScotland\n282\n10586\n89.94\n\n\n3\nGlenlochy\nScotland\n120\n1789\n89.76\n\n\n4\nPort Ellen\nScotland\n1492\n26495\n89.27\n\n\n5\nGlenugie\nScotland\n134\n1669\n89.21\n\n\n6\nBen Wyvis\nScotland\n18\n243\n89.17\n\n\n\n\n\n\n\n\n\n\n3 all bottler\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/bottlers'\n\n\n\n\nCode\nlink= page%&gt;%html_nodes(\".clickable a\")%&gt;% html_attr('href')\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% mutate(link=link) %&gt;% select(-'Var.6')\n\n\n\n\nCode\nnames(data)\n\n\n[1] \"Name\"     \"Country\"  \"Whiskies\" \"Votes\"    \"Rating\"   \"link\"    \n\n\n\n\nCode\n#glimpse(data)\n\n\noutput\n\n\nCode\nwrite.xlsx(data,'./output/all bottler.xlsx')\n\n\n\n\n4 summary of the data\n\n\nCode\ndata002=data %&gt;% filter(Whiskies&gt;10,Votes&gt;100) %&gt;% arrange(desc(Rating))  %&gt;% select(-link)\n\ndata003=data002 %&gt;% rowid_to_column(\"No\")\nhead(data003) %&gt;% gt() %&gt;% as_raw_html()\n\n\n\n\n  \n  \n\n\n\nNo\nName\nCountry\nWhiskies\nVotes\nRating\n\n\n\n\n1\nKawasaki\nJapan\n31\n366\n90.04\n\n\n2\nBrora\nScotland\n282\n10586\n89.94\n\n\n3\nGlenlochy\nScotland\n120\n1789\n89.76\n\n\n4\nPort Ellen\nScotland\n1492\n26495\n89.27\n\n\n5\nGlenugie\nScotland\n134\n1669\n89.21\n\n\n6\nBen Wyvis\nScotland\n18\n243\n89.17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "all distrillery and bottler name"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html",
    "href": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html",
    "title": "on bottle review with log in",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(httr)",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review with log in"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#find-require-info",
    "href": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#find-require-info",
    "title": "on bottle review with log in",
    "section": "5.1 find require info",
    "text": "5.1 find require info\nform 4 is login form\n\n\nCode\nread_html('https://www.whiskybase.com/') %&gt;%  html_form(\"form\")",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review with log in"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#in-whisky-list",
    "href": "other/2 Web scraping on whiskybase.com/3 one bottle review with login.html#in-whisky-list",
    "title": "on bottle review with log in",
    "section": "9.1 in whisky list",
    "text": "9.1 in whisky list\n\n\nCode\nreview_people=page%&gt;% html_nodes('#whisky-community a')%&gt;% html_text2()\nreview_people",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review with log in"
    ]
  },
  {
    "objectID": "other/5 other/1 chromote.html",
    "href": "other/5 other/1 chromote.html",
    "title": "chromote",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(chromote)\n\n\n\n\nCode\npackageVersion(\"chromote\")\n\n\n\n1 create view\n\n\nCode\nlibrary(chromote)\n\nb &lt;- ChromoteSession$new()\n\n# In a web browser, open a viewer for the headless browser. Works best with\n# Chromium-based browsers.\nb$view()\n\n\n\n\nCode\nb$Browser$getVersion()\n\n\n\n\n2 go to page\n\n\nCode\nb$Page$navigate(\"https://www.r-project.org/\")\n\n\n\n\n3 take picture\n\n\nCode\n# Saves to screenshot.png\nb$screenshot()\n\n\n\n\nCode\n# Takes a screenshot of elements picked out by CSS selector\nis_interactive &lt;- interactive() # Display screenshot if interactive\nb$screenshot(\"sidebar.png\", selector = \"h1\" ,show = is_interactive)\n\n\n\n\n4 take picture as pdf\n\n\nCode\nb$screenshot_pdf(filename='page.pdf')\n\n\n\n\n5 Reference:\nhttps://rstudio.github.io/chromote/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "chromote"
    ]
  },
  {
    "objectID": "other/5 other/3 image processing.html",
    "href": "other/5 other/3 image processing.html",
    "title": "image processing",
    "section": "",
    "text": "Code\nlibrary(magick)\n\n\n\n1 input\n\n\nCode\nraw_logo &lt;- image_read('./images/comb.webp')\n\n\n\n\n2 output\n\n\nCode\nimage_info(raw_logo)\n\n\n  format width height colorspace matte filesize density\n1   WEBP   450    303       sRGB  TRUE    49650   72x72\n\n\n\n\n3 change format\n\n\nCode\nnew_png &lt;- image_convert(raw_logo, \"png\")\n\n\n\n\nCode\nimage_info(new_png)\n\n\n  format width height colorspace matte filesize density\n1    PNG   450    303       sRGB  TRUE        0   72x72\n\n\n\n\n4 output\n\n\nCode\nimage_write(new_png, path = \"./images/new_png.png\", format = \"png\")\n\n\n\n\nCode\nraw_logo &lt;- image_read('./images/logo1.png')\n\n\n\n\nCode\nraw_logo %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE    53960   72x72\n\n\n\n\n\n\n\n\n\n\n\n5 fill corner white to greem\neach corner (top left, top right, bottom left, bottom right). For our real usage, we’re going to convert this “green” space to transparent instead.\n\n\nCode\nimg_filled &lt;- raw_logo %&gt;% \n    image_fill(\"green\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\nimg_filled %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n6 rotate\n\n\nCode\nimg_filled %&gt;% image_rotate(45) %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1632   1632       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n7 make backgroup transparent (given 0-100 green color backgroup)\n\n\nCode\nb=img_filled %&gt;% image_transparent(color='green',10)\n\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\nCode\nimage_write(b, path = \"b.png\", format = \"png\")\n\n\n\n\n8 change opacity level\n\n\nCode\nb=img_filled %&gt;% image_colorize(opacity =80, color = 'white')\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n9 change brightness level\n\n\nCode\nb=img_filled %&gt;%image_modulate(brightness = 30)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n10 change blur level\n\n\nCode\nb=img_filled %&gt;%  image_blur(10, 5)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n11 add text into picture\n\n\nCode\nb=img_filled %&gt;% image_annotate( \"The quick brown fox\", font = 'Times', size = 80,gravity = \"southwest\", color = \"red\")\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n12 resize\n\n\nCode\nb= img_filled%&gt;% image_resize(\"500\")\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nCode\nimage_info(img_filled)\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\nCode\nimage_info(b)\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n13 make logo black\n\n\nCode\nimg_filled2 &lt;- raw_logo %&gt;% \n    image_fill(\"transparent\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\n\n\n\nCode\nimg_filled2 %&gt;% \n    image_channel(\"Opacity\") %&gt;% \n    image_convert(matte=FALSE) %&gt;% \n  print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       Gray FALSE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.8.3\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     fastmap_1.1.1     xfun_0.43         magrittr_2.0.3   \n [5] knitr_1.45        htmltools_0.5.8.1 png_0.1-8         rmarkdown_2.26   \n [9] cli_3.6.2         compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1      \n[13] evaluate_0.23     Rcpp_1.0.12       yaml_2.3.8        rlang_1.1.3      \n[17] jsonlite_1.8.8    htmlwidgets_1.6.4\n\n\n\n\n\n14 add backgroup image\n\n\nCode\nlibrary(ggplot2)\nlibrary(png)\nlibrary(grid)\nlibrary(ggimage)\n\n\n\n\nCode\nimg &lt;- readPNG(\"./images/new_png.png\")\n\n\n\n\nCode\nbees &lt;- data.frame(distance = c(0.5, 1, 1.5, 2, 2.5, 3),\n                  number = c(40, 34, 32, 22,18, 10))\n\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_point() +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n15 replace scatter with image\n\n\nCode\nbees$image &lt;- \"./images/bee.png\"\n\n\n\n\nCode\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n16 add logo\n\n\nCode\nimg2 =image_read(\"./images/logo1.png\")\n\n\n\n\nCode\nlibrary(cowplot)\np=ggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\nggdraw() +draw_plot(p,x = 0, y = 0.15, width = 1, height = 0.85) +draw_image(img2,x = 0.1, y = 0.1, width = 0.1, height = 0.1) \n\n\n\n\n\n\n\n\n\n\n\n17 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\nhttps://buzzrbeeline.blog/2018/06/13/fun-and-easy-r-graphs-with-images/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "image processing"
    ]
  },
  {
    "objectID": "other/4 Map/2 leaflet.html",
    "href": "other/4 Map/2 leaflet.html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\n\nlibrary(sf)\nlibrary(leaflet)\nlibrary(geojsonio)\nlibrary(leaflet.extras)\n\n\n\n\n2 display at openstreet map\n\n\nCode\nm &lt;- leaflet() %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\n\nm  \n\n\n\n\n\n\n\n\n3 display at google map\n\n\nCode\nleaflet() |&gt;\n  # add base mao\n  addTiles(urlTemplate = \"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\") |&gt;\n  # set view\n  setView(116.347817690225, 39.997202126977, zoom = 16) |&gt;\n  # add markers\n  addMarkers(116.347817690225, 39.997202126977)\n\n\n\n\n\n\n\n\n4 Third-Party map\n\n\nCode\n#m &lt;- leaflet() %&gt;% setView(lng = -71.0589, lat = 42.3601, zoom = 10)\n#m %&gt;% addProviderTiles(providers$Stadia.StamenToner)\n\n\n\n\n5 add pop up\nPopups are small boxes containing arbitrary HTML, that point to a specific point on the map.\n\n\nCode\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.samurainoodle.com/'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() %&gt;% addTiles() %&gt;%\n  setView(-122.327298, 47.597131,zoom = 12) %&gt;% \n  addPopups(-122.327298, 47.597131, content,\n    #options = popupOptions(closeButton = FALSE)\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\n\n\n6 add Markers\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"\n))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, popup = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n7 add Labels\nA label is a textual or HTML content that can attached to markers and shapes to be always displayed or displayed on mouse over. Unlike popups you don’t need to click a marker/polygon for the label to be shown.\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, label = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n8 World map\n\n\nCode\n#install.packages(\"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\")\n\n\n\n\nCode\njson_data=read_sf(\"world-administrative-boundaries.geojson\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\n#Get my variable\n#name&lt;-c(\"Ghana\", \"Grenada\", \"Guyana\", \"India\", \"Jamaica\", \"Kenya\", \"United States\",\"Canada\")\n#val&lt;-c(1,2,4,5,5,1000,20000, 100)\n\n#per_gdp_usd&lt;-data.frame(name,val)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('world data.xlsx') %&gt;% mutate(\n  name=case_when(\n    name ==\"United States\" ~ \"United States of America\"\n     ,name ==\"Russia\" ~ \"Russian Federation\"\n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name == \"South Korea\"~ \"Republic of Korea\"\n   \n   ,name ==\"Lao People's Democratic Republic\" ~ \"Laos\"\n   \n    ,TRUE ~ name\n  )\n)\n\n\n\n\nCode\n#test=full_join(map_df, per_gdp_usd, by=\"name\")\n\n#left =test %&gt;% filter(is.na(iso3)==TRUE)\n\n#right=test %&gt;% filter(is.na(per_gdp_total)==TRUE)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"name\")\n\n\n\n\nCode\nglimpse(map_df002)\n\n\nRows: 158\nColumns: 12\n$ name                     &lt;chr&gt; \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"A…\n$ geo_point_2d             &lt;chr&gt; \"{ \\\"lon\\\": 20.068384605918776, \\\"lat\\\": 41.1…\n$ iso3                     &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ status                   &lt;chr&gt; \"Member State\", \"Member State\", \"Member State…\n$ color_code               &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ continent                &lt;chr&gt; \"Europe\", \"Africa\", \"Europe\", \"Africa\", \"Amer…\n$ region                   &lt;chr&gt; \"Southern Europe\", \"Northern Africa\", \"Southe…\n$ iso_3166_1_alpha_2_codes &lt;chr&gt; \"AL\", \"DZ\", \"AD\", \"AO\", \"AR\", \"AM\", \"AU\", \"AT…\n$ french_short             &lt;chr&gt; \"Albanie\", \"Algérie\", \"Andorre\", \"Angola\", \"A…\n$ geometry                 &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((20.07142 42..., …\n$ per_gdp_total            &lt;dbl&gt; 1.888210e+10, 1.919130e+11, 3.352033e+09, 1.0…\n$ per_gdp_usd              &lt;dbl&gt; 6643, 4274, 41993, 2999, 13904, 7014, 64003, …\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gdp_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gdp_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_gdp_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$per_gdp_total/1000000), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gdp_usd, opacity = 1.0\n    )\n\n\n\n\n\n\n\n\n9 China one city map\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/citys/440300.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/440300_full.json\")\n\n\n深圳市：\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n\n\n\n\n10 all China each province GPD map\n\n\nCode\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n中国 2022 各省 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('china gdp2022.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nGPD data source:国家统计局数据库\n\n\n11 China one province map each city GPD\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/province/440000.json\") \n\n\n广东省 2021 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('guangdong city gdp2021.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\ndata source:广东统计年鉴2022\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"城市：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"城市：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb*10000000/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nhttps://zh.wikipedia.org/wiki/%E5%B9%BF%E4%B8%9C%E5%90%84%E5%9C%B0%E7%BA%A7%E5%B8%82%E5%9C%B0%E5%8C%BA%E7%94%9F%E4%BA%A7%E6%80%BB%E5%80%BC%E5%88%97%E8%A1%A8\n\n\n12 China province map\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\n\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/china.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nm=leaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n \n\nm\n\n\n\n\n\n\nadd provincial capital\n\n\nCode\nChina=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n\n\nCode\nChina002=China %&gt;% as_data_frame() %&gt;% mutate(\n                                            center2=as.character(center) %&gt;% str_replace('c','')%&gt;% str_replace('[(]','') %&gt;% str_replace('[)]','')\n                                               )\n\n\n\n\nCode\nChina003=China002%&gt;%separate(center2, c(\"x\", \"y\"), \", \")\n\n\n\n\nCode\nChina_point = China003 %&gt;% \n  slice(-35)\n\nm %&gt;% \n  addCircles(data = China_point,\n                  lng = ~as.numeric(x), lat = ~as.numeric(y),color = \"red\",weight = 10,\n                  fillOpacity =2)\n\n\n\n\n\n\n\n\n13 China province and city map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 34\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 119.3183 ymin: 21.75147 xmax: 124.5656 ymax: 25.92592\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 710000 台湾省 121.509062,25.044332 province (((119.5543 23.68248, 119.555 23.…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/province/710000.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 33\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n14 China city and district map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 334\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.5215 ymin: 22.65421 xmax: 114.2603 ymax: 23.14205\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 441900 东莞市 113.746262,23.046237 city  ((114.2292 22.81251, 114.2278 22.813…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.157 ymin: 22.20104 xmax: 113.692 ymax: 22.7726\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 442000 中山市 113.382391,22.521113 city  ((113.5687 22.41193, 113.5666 22.412…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 115.9267 ymin: 20.58265 xmax: 116.9338 ymax: 21.12693\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center               level                            geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                &lt;chr&gt;                  &lt;MULTIPOLYGON [°]&gt;\n1 442100 东沙群岛 116.887312,20.617512 city  (((115.9433 21.09745, 115.95 21.11…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 108.9287 ymin: 19.17894 xmax: 109.7694 ymax: 19.92575\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 460400 儋州市 109.576782,19.517486 city  (((109.4322 19.91302, 109.4253 19.91…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.8483 ymin: 39.65426 xmax: 98.52018 ymax: 39.99979\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center              level                             geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;               &lt;chr&gt;                   &lt;MULTIPOLYGON [°]&gt;\n1 620200 嘉峪关市 98.277304,39.786529 city  (((97.85974 39.7169, 97.85827 39.71…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/citys/620200.json\"\n         ,\"./GeoMapData_CN/citys/460400.json\"\n              ,\"./GeoMapData_CN/citys/442100.json\"\n              ,\"./GeoMapData_CN/citys/442000.json\"\n              ,\"./GeoMapData_CN/citys/441900.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 329\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n15 show all map providers\n\n\nCode\nproviders\n\n\nproviders\n$OpenStreetMap\n[1] \"OpenStreetMap\"\n\n$OpenStreetMap.Mapnik\n[1] \"OpenStreetMap.Mapnik\"\n\n$OpenStreetMap.DE\n[1] \"OpenStreetMap.DE\"\n\n$OpenStreetMap.CH\n[1] \"OpenStreetMap.CH\"\n\n$OpenStreetMap.France\n[1] \"OpenStreetMap.France\"\n\n$OpenStreetMap.HOT\n[1] \"OpenStreetMap.HOT\"\n\n$OpenStreetMap.BZH\n[1] \"OpenStreetMap.BZH\"\n\n$MapTilesAPI\n[1] \"MapTilesAPI\"\n\n$MapTilesAPI.OSMEnglish\n[1] \"MapTilesAPI.OSMEnglish\"\n\n$MapTilesAPI.OSMFrancais\n[1] \"MapTilesAPI.OSMFrancais\"\n\n$MapTilesAPI.OSMEspagnol\n[1] \"MapTilesAPI.OSMEspagnol\"\n\n$OpenSeaMap\n[1] \"OpenSeaMap\"\n\n$OPNVKarte\n[1] \"OPNVKarte\"\n\n$OpenTopoMap\n[1] \"OpenTopoMap\"\n\n$OpenRailwayMap\n[1] \"OpenRailwayMap\"\n\n$OpenFireMap\n[1] \"OpenFireMap\"\n\n$SafeCast\n[1] \"SafeCast\"\n\n$Stadia\n[1] \"Stadia\"\n\n$Stadia.AlidadeSmooth\n[1] \"Stadia.AlidadeSmooth\"\n\n$Stadia.AlidadeSmoothDark\n[1] \"Stadia.AlidadeSmoothDark\"\n\n$Stadia.OSMBright\n[1] \"Stadia.OSMBright\"\n\n$Stadia.Outdoors\n[1] \"Stadia.Outdoors\"\n\n$Stadia.StamenToner\n[1] \"Stadia.StamenToner\"\n\n$Stadia.StamenTonerBackground\n[1] \"Stadia.StamenTonerBackground\"\n\n$Stadia.StamenTonerLines\n[1] \"Stadia.StamenTonerLines\"\n\n$Stadia.StamenTonerLabels\n[1] \"Stadia.StamenTonerLabels\"\n\n$Stadia.StamenTonerLite\n[1] \"Stadia.StamenTonerLite\"\n\n$Stadia.StamenWatercolor\n[1] \"Stadia.StamenWatercolor\"\n\n$Stadia.StamenTerrain\n[1] \"Stadia.StamenTerrain\"\n\n$Stadia.StamenTerrainBackground\n[1] \"Stadia.StamenTerrainBackground\"\n\n$Stadia.StamenTerrainLabels\n[1] \"Stadia.StamenTerrainLabels\"\n\n$Stadia.StamenTerrainLines\n[1] \"Stadia.StamenTerrainLines\"\n\n$Thunderforest\n[1] \"Thunderforest\"\n\n$Thunderforest.OpenCycleMap\n[1] \"Thunderforest.OpenCycleMap\"\n\n$Thunderforest.Transport\n[1] \"Thunderforest.Transport\"\n\n$Thunderforest.TransportDark\n[1] \"Thunderforest.TransportDark\"\n\n$Thunderforest.SpinalMap\n[1] \"Thunderforest.SpinalMap\"\n\n$Thunderforest.Landscape\n[1] \"Thunderforest.Landscape\"\n\n$Thunderforest.Outdoors\n[1] \"Thunderforest.Outdoors\"\n\n$Thunderforest.Pioneer\n[1] \"Thunderforest.Pioneer\"\n\n$Thunderforest.MobileAtlas\n[1] \"Thunderforest.MobileAtlas\"\n\n$Thunderforest.Neighbourhood\n[1] \"Thunderforest.Neighbourhood\"\n\n$CyclOSM\n[1] \"CyclOSM\"\n\n$Jawg\n[1] \"Jawg\"\n\n$Jawg.Streets\n[1] \"Jawg.Streets\"\n\n$Jawg.Terrain\n[1] \"Jawg.Terrain\"\n\n$Jawg.Sunny\n[1] \"Jawg.Sunny\"\n\n$Jawg.Dark\n[1] \"Jawg.Dark\"\n\n$Jawg.Light\n[1] \"Jawg.Light\"\n\n$Jawg.Matrix\n[1] \"Jawg.Matrix\"\n\n$MapBox\n[1] \"MapBox\"\n\n$MapTiler\n[1] \"MapTiler\"\n\n$MapTiler.Streets\n[1] \"MapTiler.Streets\"\n\n$MapTiler.Basic\n[1] \"MapTiler.Basic\"\n\n$MapTiler.Bright\n[1] \"MapTiler.Bright\"\n\n$MapTiler.Pastel\n[1] \"MapTiler.Pastel\"\n\n$MapTiler.Positron\n[1] \"MapTiler.Positron\"\n\n$MapTiler.Hybrid\n[1] \"MapTiler.Hybrid\"\n\n$MapTiler.Toner\n[1] \"MapTiler.Toner\"\n\n$MapTiler.Topo\n[1] \"MapTiler.Topo\"\n\n$MapTiler.Voyager\n[1] \"MapTiler.Voyager\"\n\n$TomTom\n[1] \"TomTom\"\n\n$TomTom.Basic\n[1] \"TomTom.Basic\"\n\n$TomTom.Hybrid\n[1] \"TomTom.Hybrid\"\n\n$TomTom.Labels\n[1] \"TomTom.Labels\"\n\n$Esri\n[1] \"Esri\"\n\n$Esri.WorldStreetMap\n[1] \"Esri.WorldStreetMap\"\n\n$Esri.DeLorme\n[1] \"Esri.DeLorme\"\n\n$Esri.WorldTopoMap\n[1] \"Esri.WorldTopoMap\"\n\n$Esri.WorldImagery\n[1] \"Esri.WorldImagery\"\n\n$Esri.WorldTerrain\n[1] \"Esri.WorldTerrain\"\n\n$Esri.WorldShadedRelief\n[1] \"Esri.WorldShadedRelief\"\n\n$Esri.WorldPhysical\n[1] \"Esri.WorldPhysical\"\n\n$Esri.OceanBasemap\n[1] \"Esri.OceanBasemap\"\n\n$Esri.NatGeoWorldMap\n[1] \"Esri.NatGeoWorldMap\"\n\n$Esri.WorldGrayCanvas\n[1] \"Esri.WorldGrayCanvas\"\n\n$OpenWeatherMap\n[1] \"OpenWeatherMap\"\n\n$OpenWeatherMap.Clouds\n[1] \"OpenWeatherMap.Clouds\"\n\n$OpenWeatherMap.CloudsClassic\n[1] \"OpenWeatherMap.CloudsClassic\"\n\n$OpenWeatherMap.Precipitation\n[1] \"OpenWeatherMap.Precipitation\"\n\n$OpenWeatherMap.PrecipitationClassic\n[1] \"OpenWeatherMap.PrecipitationClassic\"\n\n$OpenWeatherMap.Rain\n[1] \"OpenWeatherMap.Rain\"\n\n$OpenWeatherMap.RainClassic\n[1] \"OpenWeatherMap.RainClassic\"\n\n$OpenWeatherMap.Pressure\n[1] \"OpenWeatherMap.Pressure\"\n\n$OpenWeatherMap.PressureContour\n[1] \"OpenWeatherMap.PressureContour\"\n\n$OpenWeatherMap.Wind\n[1] \"OpenWeatherMap.Wind\"\n\n$OpenWeatherMap.Temperature\n[1] \"OpenWeatherMap.Temperature\"\n\n$OpenWeatherMap.Snow\n[1] \"OpenWeatherMap.Snow\"\n\n$HERE\n[1] \"HERE\"\n\n$HERE.normalDay\n[1] \"HERE.normalDay\"\n\n$HERE.normalDayCustom\n[1] \"HERE.normalDayCustom\"\n\n$HERE.normalDayGrey\n[1] \"HERE.normalDayGrey\"\n\n$HERE.normalDayMobile\n[1] \"HERE.normalDayMobile\"\n\n$HERE.normalDayGreyMobile\n[1] \"HERE.normalDayGreyMobile\"\n\n$HERE.normalDayTransit\n[1] \"HERE.normalDayTransit\"\n\n$HERE.normalDayTransitMobile\n[1] \"HERE.normalDayTransitMobile\"\n\n$HERE.normalDayTraffic\n[1] \"HERE.normalDayTraffic\"\n\n$HERE.normalNight\n[1] \"HERE.normalNight\"\n\n$HERE.normalNightMobile\n[1] \"HERE.normalNightMobile\"\n\n$HERE.normalNightGrey\n[1] \"HERE.normalNightGrey\"\n\n$HERE.normalNightGreyMobile\n[1] \"HERE.normalNightGreyMobile\"\n\n$HERE.normalNightTransit\n[1] \"HERE.normalNightTransit\"\n\n$HERE.normalNightTransitMobile\n[1] \"HERE.normalNightTransitMobile\"\n\n$HERE.reducedDay\n[1] \"HERE.reducedDay\"\n\n$HERE.reducedNight\n[1] \"HERE.reducedNight\"\n\n$HERE.basicMap\n[1] \"HERE.basicMap\"\n\n$HERE.mapLabels\n[1] \"HERE.mapLabels\"\n\n$HERE.trafficFlow\n[1] \"HERE.trafficFlow\"\n\n$HERE.carnavDayGrey\n[1] \"HERE.carnavDayGrey\"\n\n$HERE.hybridDay\n[1] \"HERE.hybridDay\"\n\n$HERE.hybridDayMobile\n[1] \"HERE.hybridDayMobile\"\n\n$HERE.hybridDayTransit\n[1] \"HERE.hybridDayTransit\"\n\n$HERE.hybridDayGrey\n[1] \"HERE.hybridDayGrey\"\n\n$HERE.hybridDayTraffic\n[1] \"HERE.hybridDayTraffic\"\n\n$HERE.pedestrianDay\n[1] \"HERE.pedestrianDay\"\n\n$HERE.pedestrianNight\n[1] \"HERE.pedestrianNight\"\n\n$HERE.satelliteDay\n[1] \"HERE.satelliteDay\"\n\n$HERE.terrainDay\n[1] \"HERE.terrainDay\"\n\n$HERE.terrainDayMobile\n[1] \"HERE.terrainDayMobile\"\n\n$HEREv3\n[1] \"HEREv3\"\n\n$HEREv3.normalDay\n[1] \"HEREv3.normalDay\"\n\n$HEREv3.normalDayCustom\n[1] \"HEREv3.normalDayCustom\"\n\n$HEREv3.normalDayGrey\n[1] \"HEREv3.normalDayGrey\"\n\n$HEREv3.normalDayMobile\n[1] \"HEREv3.normalDayMobile\"\n\n$HEREv3.normalDayGreyMobile\n[1] \"HEREv3.normalDayGreyMobile\"\n\n$HEREv3.normalDayTransit\n[1] \"HEREv3.normalDayTransit\"\n\n$HEREv3.normalDayTransitMobile\n[1] \"HEREv3.normalDayTransitMobile\"\n\n$HEREv3.normalNight\n[1] \"HEREv3.normalNight\"\n\n$HEREv3.normalNightMobile\n[1] \"HEREv3.normalNightMobile\"\n\n$HEREv3.normalNightGrey\n[1] \"HEREv3.normalNightGrey\"\n\n$HEREv3.normalNightGreyMobile\n[1] \"HEREv3.normalNightGreyMobile\"\n\n$HEREv3.normalNightTransit\n[1] \"HEREv3.normalNightTransit\"\n\n$HEREv3.normalNightTransitMobile\n[1] \"HEREv3.normalNightTransitMobile\"\n\n$HEREv3.reducedDay\n[1] \"HEREv3.reducedDay\"\n\n$HEREv3.reducedNight\n[1] \"HEREv3.reducedNight\"\n\n$HEREv3.basicMap\n[1] \"HEREv3.basicMap\"\n\n$HEREv3.mapLabels\n[1] \"HEREv3.mapLabels\"\n\n$HEREv3.trafficFlow\n[1] \"HEREv3.trafficFlow\"\n\n$HEREv3.carnavDayGrey\n[1] \"HEREv3.carnavDayGrey\"\n\n$HEREv3.hybridDay\n[1] \"HEREv3.hybridDay\"\n\n$HEREv3.hybridDayMobile\n[1] \"HEREv3.hybridDayMobile\"\n\n$HEREv3.hybridDayTransit\n[1] \"HEREv3.hybridDayTransit\"\n\n$HEREv3.hybridDayGrey\n[1] \"HEREv3.hybridDayGrey\"\n\n$HEREv3.pedestrianDay\n[1] \"HEREv3.pedestrianDay\"\n\n$HEREv3.pedestrianNight\n[1] \"HEREv3.pedestrianNight\"\n\n$HEREv3.satelliteDay\n[1] \"HEREv3.satelliteDay\"\n\n$HEREv3.terrainDay\n[1] \"HEREv3.terrainDay\"\n\n$HEREv3.terrainDayMobile\n[1] \"HEREv3.terrainDayMobile\"\n\n$FreeMapSK\n[1] \"FreeMapSK\"\n\n$MtbMap\n[1] \"MtbMap\"\n\n$CartoDB\n[1] \"CartoDB\"\n\n$CartoDB.Positron\n[1] \"CartoDB.Positron\"\n\n$CartoDB.PositronNoLabels\n[1] \"CartoDB.PositronNoLabels\"\n\n$CartoDB.PositronOnlyLabels\n[1] \"CartoDB.PositronOnlyLabels\"\n\n$CartoDB.DarkMatter\n[1] \"CartoDB.DarkMatter\"\n\n$CartoDB.DarkMatterNoLabels\n[1] \"CartoDB.DarkMatterNoLabels\"\n\n$CartoDB.DarkMatterOnlyLabels\n[1] \"CartoDB.DarkMatterOnlyLabels\"\n\n$CartoDB.Voyager\n[1] \"CartoDB.Voyager\"\n\n$CartoDB.VoyagerNoLabels\n[1] \"CartoDB.VoyagerNoLabels\"\n\n$CartoDB.VoyagerOnlyLabels\n[1] \"CartoDB.VoyagerOnlyLabels\"\n\n$CartoDB.VoyagerLabelsUnder\n[1] \"CartoDB.VoyagerLabelsUnder\"\n\n$HikeBike\n[1] \"HikeBike\"\n\n$HikeBike.HikeBike\n[1] \"HikeBike.HikeBike\"\n\n$HikeBike.HillShading\n[1] \"HikeBike.HillShading\"\n\n$BasemapAT\n[1] \"BasemapAT\"\n\n$BasemapAT.basemap\n[1] \"BasemapAT.basemap\"\n\n$BasemapAT.grau\n[1] \"BasemapAT.grau\"\n\n$BasemapAT.overlay\n[1] \"BasemapAT.overlay\"\n\n$BasemapAT.terrain\n[1] \"BasemapAT.terrain\"\n\n$BasemapAT.surface\n[1] \"BasemapAT.surface\"\n\n$BasemapAT.highdpi\n[1] \"BasemapAT.highdpi\"\n\n$BasemapAT.orthofoto\n[1] \"BasemapAT.orthofoto\"\n\n$nlmaps\n[1] \"nlmaps\"\n\n$nlmaps.standaard\n[1] \"nlmaps.standaard\"\n\n$nlmaps.pastel\n[1] \"nlmaps.pastel\"\n\n$nlmaps.grijs\n[1] \"nlmaps.grijs\"\n\n$nlmaps.water\n[1] \"nlmaps.water\"\n\n$nlmaps.luchtfoto\n[1] \"nlmaps.luchtfoto\"\n\n$NASAGIBS\n[1] \"NASAGIBS\"\n\n$NASAGIBS.ModisTerraTrueColorCR\n[1] \"NASAGIBS.ModisTerraTrueColorCR\"\n\n$NASAGIBS.ModisTerraBands367CR\n[1] \"NASAGIBS.ModisTerraBands367CR\"\n\n$NASAGIBS.ViirsEarthAtNight2012\n[1] \"NASAGIBS.ViirsEarthAtNight2012\"\n\n$NASAGIBS.ModisTerraLSTDay\n[1] \"NASAGIBS.ModisTerraLSTDay\"\n\n$NASAGIBS.ModisTerraSnowCover\n[1] \"NASAGIBS.ModisTerraSnowCover\"\n\n$NASAGIBS.ModisTerraAOD\n[1] \"NASAGIBS.ModisTerraAOD\"\n\n$NASAGIBS.ModisTerraChlorophyll\n[1] \"NASAGIBS.ModisTerraChlorophyll\"\n\n$NLS\n[1] \"NLS\"\n\n$JusticeMap\n[1] \"JusticeMap\"\n\n$JusticeMap.income\n[1] \"JusticeMap.income\"\n\n$JusticeMap.americanIndian\n[1] \"JusticeMap.americanIndian\"\n\n$JusticeMap.asian\n[1] \"JusticeMap.asian\"\n\n$JusticeMap.black\n[1] \"JusticeMap.black\"\n\n$JusticeMap.hispanic\n[1] \"JusticeMap.hispanic\"\n\n$JusticeMap.multi\n[1] \"JusticeMap.multi\"\n\n$JusticeMap.nonWhite\n[1] \"JusticeMap.nonWhite\"\n\n$JusticeMap.white\n[1] \"JusticeMap.white\"\n\n$JusticeMap.plurality\n[1] \"JusticeMap.plurality\"\n\n$GeoportailFrance\n[1] \"GeoportailFrance\"\n\n$GeoportailFrance.plan\n[1] \"GeoportailFrance.plan\"\n\n$GeoportailFrance.parcels\n[1] \"GeoportailFrance.parcels\"\n\n$GeoportailFrance.orthos\n[1] \"GeoportailFrance.orthos\"\n\n$OneMapSG\n[1] \"OneMapSG\"\n\n$OneMapSG.Default\n[1] \"OneMapSG.Default\"\n\n$OneMapSG.Night\n[1] \"OneMapSG.Night\"\n\n$OneMapSG.Original\n[1] \"OneMapSG.Original\"\n\n$OneMapSG.Grey\n[1] \"OneMapSG.Grey\"\n\n$OneMapSG.LandLot\n[1] \"OneMapSG.LandLot\"\n\n$USGS\n[1] \"USGS\"\n\n$USGS.USTopo\n[1] \"USGS.USTopo\"\n\n$USGS.USImagery\n[1] \"USGS.USImagery\"\n\n$USGS.USImageryTopo\n[1] \"USGS.USImageryTopo\"\n\n$WaymarkedTrails\n[1] \"WaymarkedTrails\"\n\n$WaymarkedTrails.hiking\n[1] \"WaymarkedTrails.hiking\"\n\n$WaymarkedTrails.cycling\n[1] \"WaymarkedTrails.cycling\"\n\n$WaymarkedTrails.mtb\n[1] \"WaymarkedTrails.mtb\"\n\n$WaymarkedTrails.slopes\n[1] \"WaymarkedTrails.slopes\"\n\n$WaymarkedTrails.riding\n[1] \"WaymarkedTrails.riding\"\n\n$WaymarkedTrails.skating\n[1] \"WaymarkedTrails.skating\"\n\n$OpenAIP\n[1] \"OpenAIP\"\n\n$OpenSnowMap\n[1] \"OpenSnowMap\"\n\n$OpenSnowMap.pistes\n[1] \"OpenSnowMap.pistes\"\n\n$AzureMaps\n[1] \"AzureMaps\"\n\n$AzureMaps.MicrosoftImagery\n[1] \"AzureMaps.MicrosoftImagery\"\n\n$AzureMaps.MicrosoftBaseDarkGrey\n[1] \"AzureMaps.MicrosoftBaseDarkGrey\"\n\n$AzureMaps.MicrosoftBaseRoad\n[1] \"AzureMaps.MicrosoftBaseRoad\"\n\n$AzureMaps.MicrosoftBaseHybridRoad\n[1] \"AzureMaps.MicrosoftBaseHybridRoad\"\n\n$AzureMaps.MicrosoftTerraMain\n[1] \"AzureMaps.MicrosoftTerraMain\"\n\n$AzureMaps.MicrosoftWeatherInfraredMain\n[1] \"AzureMaps.MicrosoftWeatherInfraredMain\"\n\n$AzureMaps.MicrosoftWeatherRadarMain\n[1] \"AzureMaps.MicrosoftWeatherRadarMain\"\n\n$SwissFederalGeoportal\n[1] \"SwissFederalGeoportal\"\n\n$SwissFederalGeoportal.NationalMapColor\n[1] \"SwissFederalGeoportal.NationalMapColor\"\n\n$SwissFederalGeoportal.NationalMapGrey\n[1] \"SwissFederalGeoportal.NationalMapGrey\"\n\n$SwissFederalGeoportal.SWISSIMAGE\n[1] \"SwissFederalGeoportal.SWISSIMAGE\"\n\n\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] readxl_1.4.3         openxlsx_4.2.5.2     htmltools_0.5.8.1   \n [4] leaflet.extras_1.0.0 geojsonio_0.11.3     leaflet_2.2.2       \n [7] sf_1.0-16            lubridate_1.9.3      forcats_1.0.0       \n[10] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n[13] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n[16] ggplot2_3.5.1        tidyverse_2.0.0     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5            xfun_0.43               htmlwidgets_1.6.4      \n [4] lattice_0.22-6          tzdb_0.4.0              leaflet.providers_2.0.0\n [7] vctrs_0.6.5             tools_4.3.1             crosstalk_1.2.1        \n[10] generics_0.1.3          curl_5.2.1              proxy_0.4-27           \n[13] fansi_1.0.6             pkgconfig_2.0.3         KernSmooth_2.23-22     \n[16] RColorBrewer_1.1-3      lifecycle_1.0.4         farver_2.1.1           \n[19] compiler_4.3.1          munsell_0.5.1           jqr_1.3.3              \n[22] class_7.3-22            yaml_2.3.8              lazyeval_0.2.2         \n[25] jquerylib_0.1.4         pillar_1.9.0            classInt_0.4-10        \n[28] zip_2.3.1               tidyselect_1.2.1        digest_0.6.35          \n[31] stringi_1.8.4           fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.2               magrittr_2.0.3         \n[37] crul_1.4.2              utf8_1.2.4              e1071_1.7-14           \n[40] withr_3.0.0             scales_1.3.0            sp_2.1-4               \n[43] timechange_0.3.0        rmarkdown_2.26          cellranger_1.1.0       \n[46] hms_1.1.3               evaluate_0.23           knitr_1.45             \n[49] V8_4.4.2                viridisLite_0.4.2       geojson_0.3.5          \n[52] rlang_1.1.3             Rcpp_1.0.12             glue_1.7.0             \n[55] DBI_1.2.2               httpcode_0.3.0          geojsonsf_2.0.3        \n[58] rstudioapi_0.16.0       jsonlite_1.8.8          R6_2.5.1               \n[61] units_0.8-5            \n\n\n\n\n\n16 resouce:\nhttps://rstudio.github.io/leaflet/\nhttps://github.com/Lchiffon/leafletCN\nhttps://github.com/longwosion/geojson-map-china\nhttps://xiangyun.rbind.io/2022/02/draw-china-maps/\nhttps://datav.aliyun.com/portal/school/atlas/area_selector\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "map"
    ]
  },
  {
    "objectID": "other/4 Map/maptools/NEWS.html",
    "href": "other/4 Map/maptools/NEWS.html",
    "title": "Please note that maptools will be retired during October 2023, plan transition at your earliest convenience (see https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs for guidance); some functionality will be moved to sp.",
    "section": "",
    "text": "Please note that maptools will be retired during October 2023, plan transition at your earliest convenience (see https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs for guidance); some functionality will be moved to sp.\n\n\nVersion 1.1-8 (development, rev. 421-)\n\nEnsure that only strings are compared with package versions\nDeprecate functions handling KML, handed off to https://github.com/rsbivand/spkml and seeking new maintainer\nDeprecate methods moved to new suntools package (1.1-9 will stop exporting them); until then use library(\"maptools\", exclude=c(\"crepuscule\", \"solarnoon\", \"solarpos\", \"sunriset\")) to prefer suntools if loading maptools after suntools\n\n\n\nVersion 1.1-7 (2023-05-29, rev. 414-420)\n\nremove gpclib and Rgshhs\nMake retirement in October 2023 explicit, move package start-up messages to load from attach\nelide() deprecated and moved to sp\n\n\n\nVersion 1.1-6 (2022-12-14, rev. 411-413)\n\nCRAN sprintf() warnings\n\n\n\nVersion 1.1-5 (2022-10-22, rev. 402-410)\n\nlineLabel.R and pointLabelLattice.R deprecated, see https://github.com/oscarperpinan/rastervis/issues/93\nfunctions using shapelib fully deprecated\npointLabel() deprecated; moved to car rev. 725\n\n\n\nVersion 1.1-4 (2022-04-17, rev. 401)\n\nremove escaping of underscore in manual pages\n\n\n\nVersion 1.1-3 (2022-03-08, rev. 400)\n\nFix unconditional library(RColor-Brewer) call in help pages\n\n\n\nVersion 1.1-2 (2021-09-07, rev. 392-399)\n\nVersion check for forthcoming GEOS 3.10\n\n\n\nVersion 1.1-1 (2021-03-15, rev. 381-391)\n\nUpgrade spatstat-family reverse dependencies\n\n\n\nVersion 1.0-2 (2020-08-24, rev. 371-380)\n\nNew as.im.RasterLayer() version\nUpdate stored sp objects\n\n\n\nVersion 1.0-1 (2020-05-14, rev. -370)\n\nUpdate for linnet coercion methods\nAdded read support for (very) legacy MAP objects\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "Maptools",
      "Please note that **maptools** will be retired during October 2023, plan transition at your earliest convenience (see https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs for guidance); some functionality will be moved to **sp**."
    ]
  },
  {
    "objectID": "intro/6 data analytic in R book.html",
    "href": "intro/6 data analytic in R book.html",
    "title": "Data analytic in R book",
    "section": "",
    "text": "R for Data Science\nby Garrett Grolemund, Hadley Wickham 2017\n\n\n\nHands on programming with R\nby Garrett Grolemund, Hadley Wickham\n\n\n\nTidy Modeling with R\nby Max Kuhn and Julia Silge\n\n(https://www.tmwr.org/)\n\n\nDeep Learning with R\nby François Chollet,J. J. Allaire\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "Data analytic in R book"
    ]
  },
  {
    "objectID": "Plot/4 shiny photo editor.html",
    "href": "Plot/4 shiny photo editor.html",
    "title": "Shiny in R:photo editor",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/photo_editor/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R:photo editor"
    ]
  },
  {
    "objectID": "Plot/3 shiny weight tracking.html",
    "href": "Plot/3 shiny weight tracking.html",
    "title": "Shiny in R:weight tracking",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/weightshiny/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R:weight tracking"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html",
    "href": "Plot/2 plotly.html",
    "title": "Plotly in R",
    "section": "",
    "text": "Code\nlibrary(gapminder)\nlibrary(plotly)\npackageVersion(\"plotly\")\n\n\n[1] '4.10.4'",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group",
    "href": "Plot/2 plotly.html#color-by-group",
    "title": "Plotly in R",
    "section": "1.1 color by group",
    "text": "1.1 color by group\n\n\nCode\nfig &lt;- plot_ly(data = tips, x = ~total_bill, y = ~tip,color=~sex)\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#size-by-group",
    "href": "Plot/2 plotly.html#size-by-group",
    "title": "Plotly in R",
    "section": "1.2 size by group",
    "text": "1.2 size by group\n\n\nCode\nfig &lt;- plot_ly(data = tips, x = ~total_bill, y = ~tip,color=~sex,size=~size)\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#line-plot",
    "href": "Plot/2 plotly.html#line-plot",
    "title": "Plotly in R",
    "section": "1.3 line Plot",
    "text": "1.3 line Plot\n\n\nCode\ndata001=gapminder\ndata002= data001 %&gt;% group_by(continent,year) %&gt;% summarise(pop=sum(pop))\n\n\n\n\nCode\nfig &lt;- plot_ly(data = data002 %&gt;%filter(continent=='Asia'), x = ~year, y = ~pop,mode = 'lines')\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-1",
    "href": "Plot/2 plotly.html#color-by-group-1",
    "title": "Plotly in R",
    "section": "1.5 color by group",
    "text": "1.5 color by group\n\n\nCode\nfig &lt;- plot_ly(data = data002, x = ~year, y = ~pop,color = ~continent,mode = 'lines')\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#set-bin-number",
    "href": "Plot/2 plotly.html#set-bin-number",
    "title": "Plotly in R",
    "section": "2.1 set bin number",
    "text": "2.1 set bin number\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill, type = \"histogram\",nbinsx = 5 )\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-2",
    "href": "Plot/2 plotly.html#color-by-group-2",
    "title": "Plotly in R",
    "section": "2.2 color by group",
    "text": "2.2 color by group\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\")\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#show-number",
    "href": "Plot/2 plotly.html#show-number",
    "title": "Plotly in R",
    "section": "3.1 show number",
    "text": "3.1 show number\n\n\nCode\nfig &lt;- plot_ly(data=tips2,x = ~sex,y=~total_bill,text=~total_bill, type = \"bar\")\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#horizontal-barplot",
    "href": "Plot/2 plotly.html#horizontal-barplot",
    "title": "Plotly in R",
    "section": "3.2 Horizontal Barplot",
    "text": "3.2 Horizontal Barplot\n\n\nCode\nfig &lt;- plot_ly(data=tips2,y = ~sex,x=~total_bill,color=~sex, type = \"bar\",orientation = 'h')\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#bar-chart-order",
    "href": "Plot/2 plotly.html#bar-chart-order",
    "title": "Plotly in R",
    "section": "3.3 bar chart order",
    "text": "3.3 bar chart order\n\n\nCode\nfig &lt;- plot_ly(data=tips2,x = ~sex,y=~total_bill,color=~sex, type = \"bar\")%&gt;% \n  layout(xaxis = list(categoryorder = \"total ascending\"))\n\nfig\n\n\n\n\n\n\n\n\nCode\nfig &lt;- plot_ly(data=tips2,x = ~sex,y=~total_bill,color=~sex, type = \"bar\")%&gt;% \n  layout(xaxis = list(categoryorder = \"total descending\"))\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-3",
    "href": "Plot/2 plotly.html#color-by-group-3",
    "title": "Plotly in R",
    "section": "4.1 color by group",
    "text": "4.1 color by group\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~sex,y=~total_bill,color=~sex, type = \"box\")\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#color-by-group-4",
    "href": "Plot/2 plotly.html#color-by-group-4",
    "title": "Plotly in R",
    "section": "5.1 color by group",
    "text": "5.1 color by group\n\n\nCode\np=ggplot(tips, aes(day,tip,color=sex)) + geom_jitter(position=position_jitterdodge())\nggplotly(p)",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#add-title",
    "href": "Plot/2 plotly.html#add-title",
    "title": "Plotly in R",
    "section": "7.1 add title",
    "text": "7.1 add title\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\") %&gt;% layout(title = 'new title')\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#adjust-size",
    "href": "Plot/2 plotly.html#adjust-size",
    "title": "Plotly in R",
    "section": "7.2 adjust size",
    "text": "7.2 adjust size\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\"\n               ,width = 500, height = 200)\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#change-x-y-name",
    "href": "Plot/2 plotly.html#change-x-y-name",
    "title": "Plotly in R",
    "section": "7.3 change x y name",
    "text": "7.3 change x y name\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\") %&gt;% layout(title = 'new title'\n                                                                                   ,xaxis = list(title = 'new x')\n                                                                                  ,yaxis = list(title = 'new y') \n                                                                                    )\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#add-footnote",
    "href": "Plot/2 plotly.html#add-footnote",
    "title": "Plotly in R",
    "section": "7.5 add footnote",
    "text": "7.5 add footnote\n\n\nCode\nfig%&gt;% layout(annotations = \n                         list(x = 0, y = -0.1, \n                              text = \"this is footnote\", \n                              showarrow = F, \n                              xref='paper', \n                              yref='paper')\n    )",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#legend",
    "href": "Plot/2 plotly.html#legend",
    "title": "Plotly in R",
    "section": "7.6 legend",
    "text": "7.6 legend\n\n7.6.1 hide legend\n\n\nCode\nfig &lt;- plot_ly(data = data002, x = ~year, y = ~pop,color = ~continent,mode = 'lines') %&gt;% layout(showlegend = FALSE)\nfig\n\n\n\n\n\n\n\n\n7.6.2 show legend and change legend name\n\n\nCode\nfig &lt;- plot_ly(data = data002 %&gt;% filter(continent=='Asia'), x = ~year, y = ~pop,color = ~continent,mode = 'lines',name='Asia pop') %&gt;% layout(showlegend = TRUE)\nfig\n\n\n\n\n\n\n\n\n7.6.3 change legend and change legend Position\n\n\nCode\nfig &lt;- plot_ly(data = data002, x = ~year, y = ~pop,color = ~continent,mode = 'lines') %&gt;% layout(legend = list(orientation = 'h'))\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#create-database-file-pythonsqlite.db-and-copy-mtcars-data-and-iris-data-into-database",
    "href": "data manipulation/5 SQL database.html#create-database-file-pythonsqlite.db-and-copy-mtcars-data-and-iris-data-into-database",
    "title": "SQL database with R",
    "section": "1.1 create database file pythonsqlite.db and copy mtcars data and iris data into database",
    "text": "1.1 create database file pythonsqlite.db and copy mtcars data and iris data into database\n\n\nCode\nmtcars=cbind(newColName = rownames(mtcars), mtcars)\n\n\n\n\nCode\n# Create an ephemeral in-memory RSQLite database\ncon &lt;- dbConnect(RSQLite::SQLite(), \"my_sql_database\")\n\n# view database on IDE\nconnection_view(con)\n\n\n\n\nCode\ndbWriteTable(con, \"mtcars\", mtcars,overwrite=TRUE)\ndbWriteTable(con, \"iris\", iris,overwrite=TRUE)",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#check-all-table-in-database",
    "href": "data manipulation/5 SQL database.html#check-all-table-in-database",
    "title": "SQL database with R",
    "section": "1.2 check all table in database",
    "text": "1.2 check all table in database\n\n\nCode\ndbListTables(con)\n\n\n[1] \"iris\"   \"mtcars\"",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#select",
    "href": "data manipulation/5 SQL database.html#select",
    "title": "SQL database with R",
    "section": "2.1 select",
    "text": "2.1 select\n\n\nCode\nsql =\"SELECT * FROM mtcars LIMIT 3\"\ntable=dbGetQuery(con,sql)\ntable\n\n\n     newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1     Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2 Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3    Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#renaming-column",
    "href": "data manipulation/5 SQL database.html#renaming-column",
    "title": "SQL database with R",
    "section": "2.2 Renaming column",
    "text": "2.2 Renaming column\n\n\nCode\nsql=\"select mpg as new_mpg from mtcars\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n  new_mpg\n1    21.0\n2    21.0\n3    22.8\n4    21.4\n5    18.7\n6    18.1",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#create-column",
    "href": "data manipulation/5 SQL database.html#create-column",
    "title": "SQL database with R",
    "section": "2.3 create column",
    "text": "2.3 create column\n\n\nCode\nsql=\"select mpg+1 as new_mpg,mpg from mtcars\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n  new_mpg  mpg\n1    22.0 21.0\n2    22.0 21.0\n3    23.8 22.8\n4    22.4 21.4\n5    19.7 18.7\n6    19.1 18.1",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#filter-rows",
    "href": "data manipulation/5 SQL database.html#filter-rows",
    "title": "SQL database with R",
    "section": "2.4 Filter rows",
    "text": "2.4 Filter rows\n\n\nCode\nsql=\"select * from mtcars where hp&gt;100\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n4 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n5           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n6        Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\n\n\n\n2.4.1 Filters with AND conditions\n\n\nCode\nsql=\"select * from mtcars where hp&gt;100 and drat&lt;3\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n          newColName  mpg cyl disp  hp drat   wt  qsec vs am gear carb\n1            Valiant 18.1   6  225 105 2.76 3.46 20.22  1  0    3    1\n2 Cadillac Fleetwood 10.4   8  472 205 2.93 5.25 17.98  0  0    3    4\n3   Dodge Challenger 15.5   8  318 150 2.76 3.52 16.87  0  0    3    2\n\n\n\n\n2.4.2 Filters with or conditions\n\n\nCode\nsql=\"select * from mtcars where hp&gt;100 or drat&lt;3\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n4 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n5           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n6        Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#append",
    "href": "data manipulation/5 SQL database.html#append",
    "title": "SQL database with R",
    "section": "2.5 Append",
    "text": "2.5 Append\n\n2.5.1 append by row\n\n\nCode\nsql=\"select * from mtcars union all select * from mtcars \"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n6           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\n\n\n2.5.2 append by column\n\n\n2.5.3 Dropping NA values\n\n\n2.5.4 keep NA values",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#group-by",
    "href": "data manipulation/5 SQL database.html#group-by",
    "title": "SQL database with R",
    "section": "2.6 group by",
    "text": "2.6 group by\n\n2.6.1 average,min,max,sum\n\n\nCode\nsql=\"select AVG(hp),min(hp),max(hp),sum(hp) from mtcars\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n   AVG(hp) min(hp) max(hp) sum(hp)\n1 146.6875      52     335    4694\n\n\n\n\n2.6.2 count record and count distinct record\n\n\nCode\nsql=\"select vs, count(*),count(distinct cyl) from mtcars group by vs\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n  vs count(*) count(distinct cyl)\n1  0       18                   3\n2  1       14                   2",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#order-rows",
    "href": "data manipulation/5 SQL database.html#order-rows",
    "title": "SQL database with R",
    "section": "2.7 order rows",
    "text": "2.7 order rows\n\n\nCode\nsql=\"select * from mtcars order by mpg\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n           newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1  Cadillac Fleetwood 10.4   8  472 205 2.93 5.250 17.98  0  0    3    4\n2 Lincoln Continental 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4\n3          Camaro Z28 13.3   8  350 245 3.73 3.840 15.41  0  0    3    4\n4          Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\n5   Chrysler Imperial 14.7   8  440 230 3.23 5.345 17.42  0  0    3    4\n6       Maserati Bora 15.0   8  301 335 3.54 3.570 14.60  0  1    5    8\n\n\n\n2.7.1 Sort in descending order\n\n\nCode\nsql=\"select * from mtcars order by mpg desc\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n      newColName  mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n1 Toyota Corolla 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n2       Fiat 128 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n3    Honda Civic 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n4   Lotus Europa 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n5      Fiat X1-9 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n6  Porsche 914-2 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n\n\n\n\n2.7.2 Arrange by multiple variables\n\n\nCode\nsql=\"select * from mtcars order by mpg ,cyl\"\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n           newColName  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1  Cadillac Fleetwood 10.4   8  472 205 2.93 5.250 17.98  0  0    3    4\n2 Lincoln Continental 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4\n3          Camaro Z28 13.3   8  350 245 3.73 3.840 15.41  0  0    3    4\n4          Duster 360 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4\n5   Chrysler Imperial 14.7   8  440 230 3.23 5.345 17.42  0  0    3    4\n6       Maserati Bora 15.0   8  301 335 3.54 3.570 14.60  0  1    5    8",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#join",
    "href": "data manipulation/5 SQL database.html#join",
    "title": "SQL database with R",
    "section": "2.8 join",
    "text": "2.8 join\n\n2.8.1 inner_join\n\n\nCode\nsql=\"select a.newColName,a.mpg,b.mpg as new_mpg from mtcars a left join mtcars b on a.newColName=b.newColName\"\n\ntable=dbGetQuery(con,sql)\nhead(table)\n\n\n         newColName  mpg new_mpg\n1         Mazda RX4 21.0    21.0\n2     Mazda RX4 Wag 21.0    21.0\n3        Datsun 710 22.8    22.8\n4    Hornet 4 Drive 21.4    21.4\n5 Hornet Sportabout 18.7    18.7\n6           Valiant 18.1    18.1\n\n\n\n\n2.8.2 full join\n\n\n2.8.3 left join\n\n\n2.8.4 anti join",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#reshape-tables",
    "href": "data manipulation/5 SQL database.html#reshape-tables",
    "title": "SQL database with R",
    "section": "2.9 Reshape tables",
    "text": "2.9 Reshape tables\n\n2.9.1 Gather data long(wide to long)\n\n\n2.9.2 Spread data wide (long to wide)",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#string",
    "href": "data manipulation/5 SQL database.html#string",
    "title": "SQL database with R",
    "section": "2.10 string",
    "text": "2.10 string\n\n2.10.1 upper case\n\n\n2.10.2 lower case\n\n\n2.10.3 match\n\n\n2.10.4 concatenation\n\n\n2.10.5 replace\n\n\n2.10.6 extract",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#date",
    "href": "data manipulation/5 SQL database.html#date",
    "title": "SQL database with R",
    "section": "2.11 date",
    "text": "2.11 date",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#create-table-into-database",
    "href": "data manipulation/5 SQL database.html#create-table-into-database",
    "title": "SQL database with R",
    "section": "2.12 create table into database",
    "text": "2.12 create table into database\n\n\nCode\nsql=\"create table if not exists new_mtcars as select * from mtcars order by mpg ,cyl\"\ndbSendQuery(con,sql)\n\n\n&lt;SQLiteResult&gt;\n  SQL  create table if not exists new_mtcars as select * from mtcars order by mpg ,cyl\n  ROWS Fetched: 0 [complete]\n       Changed: 0\n\n\nCode\ndbListTables(con)\n\n\n[1] \"iris\"       \"mtcars\"     \"new_mtcars\"",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#delete-table-in-database",
    "href": "data manipulation/5 SQL database.html#delete-table-in-database",
    "title": "SQL database with R",
    "section": "2.13 delete table in database",
    "text": "2.13 delete table in database\n\n\nCode\nsql=\"drop table if  exists  new_mtcars\"\ndbSendQuery(con,sql)\n\n\n&lt;SQLiteResult&gt;\n  SQL  drop table if  exists  new_mtcars\n  ROWS Fetched: 0 [complete]\n       Changed: 0\n\n\nCode\ndbListTables(con)\n\n\n[1] \"iris\"   \"mtcars\"",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/5 SQL database.html#edit-table-in-database",
    "href": "data manipulation/5 SQL database.html#edit-table-in-database",
    "title": "SQL database with R",
    "section": "2.14 edit table in database",
    "text": "2.14 edit table in database",
    "crumbs": [
      "data manipulation",
      "SQL database with R"
    ]
  },
  {
    "objectID": "data manipulation/4 resample.html",
    "href": "data manipulation/4 resample.html",
    "title": "resample",
    "section": "",
    "text": "1 k-Fold Cross-Validation\n\n\n\nCode\nk_flod_resample&lt;- vfold_cv(data, v = 10)\nk_flod_resample\n\n\n\n\n2 MONTE CARLO CROSS-VALIDATION\nfor MCCV, this proportion of the data is randomly selected each time. This results in assessment sets that are not mutually exclusive\n\n\nCode\nmc_resample&lt;- mc_cv(data, prop = 9/10, times = 20)\nmc_resample\n\n\n\n\n3 The Bootstrap\nA bootstrap sample of the training set is a sample that is the same size as the training set but is drawn with replacement\n\n\n\nCode\nbootstraps_resample&lt;- bootstraps(data, times = 1000)\nbootstraps_resample\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "data manipulation",
      "resample"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html",
    "href": "data manipulation/1 input ouput.html",
    "title": "input & ouput in R",
    "section": "",
    "text": "Data input and ouput in R\nCode\nlibrary(tidyverse)\nlibrary(openxlsx)\nlibrary(readxl)",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-csv",
    "href": "data manipulation/1 input ouput.html#read-csv",
    "title": "input & ouput in R",
    "section": "1.1 read CSV",
    "text": "1.1 read CSV\n\n\nCode\ndata001=read_csv('data/Book3.csv')\nhead(data001)\n\n\n# A tibble: 2 × 2\n      a b    \n  &lt;dbl&gt; &lt;chr&gt;\n1  1241 rhth \n2 35235 rjyyj\n\n\nread CSV online\n\n\nCode\nurl='https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv'\ndata001=read_csv(url)\nhead(data001)\n\n\n# A tibble: 6 × 32\n  hotel        is_canceled lead_time arrival_date_year arrival_date_month\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;             &lt;dbl&gt; &lt;chr&gt;             \n1 Resort Hotel           0       342              2015 July              \n2 Resort Hotel           0       737              2015 July              \n3 Resort Hotel           0         7              2015 July              \n4 Resort Hotel           0        13              2015 July              \n5 Resort Hotel           0        14              2015 July              \n6 Resort Hotel           0        14              2015 July              \n# ℹ 27 more variables: arrival_date_week_number &lt;dbl&gt;,\n#   arrival_date_day_of_month &lt;dbl&gt;, stays_in_weekend_nights &lt;dbl&gt;,\n#   stays_in_week_nights &lt;dbl&gt;, adults &lt;dbl&gt;, children &lt;dbl&gt;, babies &lt;dbl&gt;,\n#   meal &lt;chr&gt;, country &lt;chr&gt;, market_segment &lt;chr&gt;,\n#   distribution_channel &lt;chr&gt;, is_repeated_guest &lt;dbl&gt;,\n#   previous_cancellations &lt;dbl&gt;, previous_bookings_not_canceled &lt;dbl&gt;,\n#   reserved_room_type &lt;chr&gt;, assigned_room_type &lt;chr&gt;, …",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-excel",
    "href": "data manipulation/1 input ouput.html#read-excel",
    "title": "input & ouput in R",
    "section": "1.2 read excel",
    "text": "1.2 read excel\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\ndata001=read_excel('data/Book1.xlsx')\nhead(data001)\n\n\n# A tibble: 2 × 2\n      a b    \n  &lt;dbl&gt; &lt;chr&gt;\n1  1241 rhth \n2 35235 rjyyj",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-parquet",
    "href": "data manipulation/1 input ouput.html#read-parquet",
    "title": "input & ouput in R",
    "section": "1.3 read parquet",
    "text": "1.3 read parquet\nmust install in this way,otherwise will report error.\n\n\nCode\ninstall.packages(\"arrow\", repos = c(\"https://apache.r-universe.dev\"))\n\n\n\n\nCode\nlibrary(arrow)\narrow_info()\n\n\nArrow package version: 15.0.1\n\nCapabilities:\n               \nacero      TRUE\ndataset    TRUE\nsubstrait FALSE\nparquet    TRUE\njson       TRUE\ns3         TRUE\ngcs        TRUE\nutf8proc   TRUE\nre2        TRUE\nsnappy     TRUE\ngzip       TRUE\nbrotli     TRUE\nzstd       TRUE\nlz4        TRUE\nlz4_frame  TRUE\nlzo       FALSE\nbz2        TRUE\njemalloc   TRUE\nmimalloc   TRUE\n\nMemory:\n                  \nAllocator mimalloc\nCurrent    0 bytes\nMax        0 bytes\n\nRuntime:\n                        \nSIMD Level          none\nDetected SIMD Level none\n\nBuild:\n                                                             \nC++ Library Version                                    15.0.1\nC++ Compiler                                       AppleClang\nC++ Compiler Version                          15.0.0.15000100\nGit ID               5ce6ff434c1e7daaa2d7f134349f3ce4c22683da\n\n\n\n\nCode\ndata001=read_parquet('data/df.parquet')\nhead(data001)\n\n\n# A tibble: 6 × 62\n  FlightDate          Airline Origin Dest  Cancelled Diverted CRSDepTime DepTime\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt;     &lt;lgl&gt;         &lt;int&gt;   &lt;dbl&gt;\n1 2022-04-04 00:00:00 Commut… GJT    DEN   FALSE     FALSE          1133    1123\n2 2022-04-04 00:00:00 Commut… HRL    IAH   FALSE     FALSE           732     728\n3 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1529    1514\n4 2022-04-04 00:00:00 Commut… IAH    GPT   FALSE     FALSE          1435    1430\n5 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1135    1135\n6 2022-04-04 00:00:00 Commut… DEN    TUL   FALSE     FALSE           955     952\n# ℹ 54 more variables: DepDelayMinutes &lt;dbl&gt;, DepDelay &lt;dbl&gt;, ArrTime &lt;dbl&gt;,\n#   ArrDelayMinutes &lt;dbl&gt;, AirTime &lt;dbl&gt;, CRSElapsedTime &lt;dbl&gt;,\n#   ActualElapsedTime &lt;dbl&gt;, Distance &lt;dbl&gt;, Year &lt;int&gt;, Quarter &lt;int&gt;,\n#   Month &lt;int&gt;, DayofMonth &lt;int&gt;, DayOfWeek &lt;int&gt;,\n#   Marketing_Airline_Network &lt;chr&gt;,\n#   Operated_or_Branded_Code_Share_Partners &lt;chr&gt;,\n#   DOT_ID_Marketing_Airline &lt;int&gt;, IATA_Code_Marketing_Airline &lt;chr&gt;, …\n\n\nread parquet zip\n\n\nCode\ndata001=read_parquet('data/df.parquet.gzip')\nhead(data001)\n\n\n# A tibble: 6 × 62\n  FlightDate          Airline Origin Dest  Cancelled Diverted CRSDepTime DepTime\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt;     &lt;lgl&gt;         &lt;int&gt;   &lt;dbl&gt;\n1 2022-04-04 00:00:00 Commut… GJT    DEN   FALSE     FALSE          1133    1123\n2 2022-04-04 00:00:00 Commut… HRL    IAH   FALSE     FALSE           732     728\n3 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1529    1514\n4 2022-04-04 00:00:00 Commut… IAH    GPT   FALSE     FALSE          1435    1430\n5 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1135    1135\n6 2022-04-04 00:00:00 Commut… DEN    TUL   FALSE     FALSE           955     952\n# ℹ 54 more variables: DepDelayMinutes &lt;dbl&gt;, DepDelay &lt;dbl&gt;, ArrTime &lt;dbl&gt;,\n#   ArrDelayMinutes &lt;dbl&gt;, AirTime &lt;dbl&gt;, CRSElapsedTime &lt;dbl&gt;,\n#   ActualElapsedTime &lt;dbl&gt;, Distance &lt;dbl&gt;, Year &lt;int&gt;, Quarter &lt;int&gt;,\n#   Month &lt;int&gt;, DayofMonth &lt;int&gt;, DayOfWeek &lt;int&gt;,\n#   Marketing_Airline_Network &lt;chr&gt;,\n#   Operated_or_Branded_Code_Share_Partners &lt;chr&gt;,\n#   DOT_ID_Marketing_Airline &lt;int&gt;, IATA_Code_Marketing_Airline &lt;chr&gt;, …",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-feather",
    "href": "data manipulation/1 input ouput.html#read-feather",
    "title": "input & ouput in R",
    "section": "1.4 read feather",
    "text": "1.4 read feather\n\n\nCode\nlibrary(feather)\n\ndata001=read_feather('data/feather_file.feather')\nhead(data001)\n\n\n# A tibble: 6 × 62\n  FlightDate          Airline Origin Dest  Cancelled Diverted CRSDepTime DepTime\n  &lt;dttm&gt;              &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;lgl&gt;     &lt;lgl&gt;         &lt;int&gt;   &lt;dbl&gt;\n1 2022-04-04 00:00:00 Commut… GJT    DEN   FALSE     FALSE          1133    1123\n2 2022-04-04 00:00:00 Commut… HRL    IAH   FALSE     FALSE           732     728\n3 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1529    1514\n4 2022-04-04 00:00:00 Commut… IAH    GPT   FALSE     FALSE          1435    1430\n5 2022-04-04 00:00:00 Commut… DRO    DEN   FALSE     FALSE          1135    1135\n6 2022-04-04 00:00:00 Commut… DEN    TUL   FALSE     FALSE           955     952\n# ℹ 54 more variables: DepDelayMinutes &lt;dbl&gt;, DepDelay &lt;dbl&gt;, ArrTime &lt;dbl&gt;,\n#   ArrDelayMinutes &lt;dbl&gt;, AirTime &lt;dbl&gt;, CRSElapsedTime &lt;dbl&gt;,\n#   ActualElapsedTime &lt;dbl&gt;, Distance &lt;dbl&gt;, Year &lt;int&gt;, Quarter &lt;int&gt;,\n#   Month &lt;int&gt;, DayofMonth &lt;int&gt;, DayOfWeek &lt;int&gt;,\n#   Marketing_Airline_Network &lt;chr&gt;,\n#   Operated_or_Branded_Code_Share_Partners &lt;chr&gt;,\n#   DOT_ID_Marketing_Airline &lt;int&gt;, IATA_Code_Marketing_Airline &lt;chr&gt;, …",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#read-json-file-and-convert-into-data-frame",
    "href": "data manipulation/1 input ouput.html#read-json-file-and-convert-into-data-frame",
    "title": "input & ouput in R",
    "section": "1.5 read JSON file and convert into data frame",
    "text": "1.5 read JSON file and convert into data frame\n\n\nCode\nlibrary(jsonlite)\ndata=read_json(\"./data/dataj.json\")\n\n\n\n\nCode\ndata002=(data) %&gt;% as.data.frame()\n\n\n\n\nCode\nglimpse(data002)\n\n\nRows: 1\nColumns: 11\n$ glossary.title                                                     &lt;chr&gt; \"ex…\n$ glossary.GlossDiv.title                                            &lt;chr&gt; \"S\"\n$ glossary.GlossDiv.GlossList.GlossEntry.ID                          &lt;chr&gt; \"SG…\n$ glossary.GlossDiv.GlossList.GlossEntry.SortAs                      &lt;chr&gt; \"SG…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossTerm                   &lt;chr&gt; \"St…\n$ glossary.GlossDiv.GlossList.GlossEntry.Acronym                     &lt;chr&gt; \"SG…\n$ glossary.GlossDiv.GlossList.GlossEntry.Abbrev                      &lt;chr&gt; \"IS…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossDef.para               &lt;chr&gt; \"A …\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossDef.GlossSeeAlso..GML. &lt;chr&gt; \"GM…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossDef.GlossSeeAlso..XML. &lt;chr&gt; \"XM…\n$ glossary.GlossDiv.GlossList.GlossEntry.GlossSee                    &lt;chr&gt; \"ma…",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-csv",
    "href": "data manipulation/1 input ouput.html#write-csv",
    "title": "input & ouput in R",
    "section": "2.1 write csv",
    "text": "2.1 write csv\n\n\nCode\nwrite.csv(data001,'data001 csv output data.csv')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-excel",
    "href": "data manipulation/1 input ouput.html#write-excel",
    "title": "input & ouput in R",
    "section": "2.2 write excel",
    "text": "2.2 write excel\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nwrite.xlsx(data001,'data001 excel output data.xlsx')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-parquet",
    "href": "data manipulation/1 input ouput.html#write-parquet",
    "title": "input & ouput in R",
    "section": "2.3 write parquet",
    "text": "2.3 write parquet\n\n\nCode\nlibrary(arrow)\nwrite_parquet(data001,'data/df.parquet')\n\n\noutput to zip format\n\n\nCode\nwrite_parquet(data001,'data/df.parquet.gzip',compression='gzip')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-feather",
    "href": "data manipulation/1 input ouput.html#write-feather",
    "title": "input & ouput in R",
    "section": "2.4 write feather",
    "text": "2.4 write feather\n\n\nCode\nlibrary(feather)\nwrite_feather(data001,'data/feather_file.feather')",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "data manipulation/1 input ouput.html#write-txt",
    "href": "data manipulation/1 input ouput.html#write-txt",
    "title": "input & ouput in R",
    "section": "2.5 write txt",
    "text": "2.5 write txt\n\n\nCode\ntext=tibble('hello world\nits time!')\n\nwrite_delim(text, \"text.txt\")",
    "crumbs": [
      "data manipulation",
      "input & ouput in R"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html",
    "href": "house price regression model/3 Regression Tidy Modeling.html",
    "title": "Regression model with Recipe",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/3 Regression Tidy Modeling.html#read-data",
    "title": "Regression model with Recipe",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/3 Regression Tidy Modeling.html#data-split",
    "title": "Regression model with Recipe",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\nglimpse(train_df)\n\n\nRows: 1,460\nColumns: 38\n$ Id              &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ MSSubClass      &lt;dbl&gt; 60, 20, 60, 70, 60, 50, 20, 60, 50, 190, 20, 60, 20, 2…\n$ LotFrontage     &lt;dbl&gt; 65, 80, 68, 60, 84, 85, 75, 0, 51, 50, 70, 85, 0, 91, …\n$ LotArea         &lt;dbl&gt; 8450, 9600, 11250, 9550, 14260, 14115, 10084, 10382, 6…\n$ OverallQual     &lt;dbl&gt; 7, 6, 7, 7, 8, 5, 8, 7, 7, 5, 5, 9, 5, 7, 6, 7, 6, 4, …\n$ OverallCond     &lt;dbl&gt; 5, 8, 5, 5, 5, 5, 5, 6, 5, 6, 5, 5, 6, 5, 5, 8, 7, 5, …\n$ YearBuilt       &lt;dbl&gt; 2003, 1976, 2001, 1915, 2000, 1993, 2004, 1973, 1931, …\n$ YearRemodAdd    &lt;dbl&gt; 2003, 1976, 2002, 1970, 2000, 1995, 2005, 1973, 1950, …\n$ MasVnrArea      &lt;dbl&gt; 196, 0, 162, 0, 350, 0, 186, 240, 0, 0, 0, 286, 0, 306…\n$ BsmtFinSF1      &lt;dbl&gt; 706, 978, 486, 216, 655, 732, 1369, 859, 0, 851, 906, …\n$ BsmtFinSF2      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ BsmtUnfSF       &lt;dbl&gt; 150, 284, 434, 540, 490, 64, 317, 216, 952, 140, 134, …\n$ TotalBsmtSF     &lt;dbl&gt; 856, 1262, 920, 756, 1145, 796, 1686, 1107, 952, 991, …\n$ `1stFlrSF`      &lt;dbl&gt; 856, 1262, 920, 961, 1145, 796, 1694, 1107, 1022, 1077…\n$ `2ndFlrSF`      &lt;dbl&gt; 854, 0, 866, 756, 1053, 566, 0, 983, 752, 0, 0, 1142, …\n$ LowQualFinSF    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ GrLivArea       &lt;dbl&gt; 1710, 1262, 1786, 1717, 2198, 1362, 1694, 2090, 1774, …\n$ BsmtFullBath    &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, …\n$ BsmtHalfBath    &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FullBath        &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, …\n$ HalfBath        &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …\n$ BedroomAbvGr    &lt;dbl&gt; 3, 3, 3, 3, 4, 1, 3, 3, 2, 2, 3, 4, 2, 3, 2, 2, 2, 2, …\n$ KitchenAbvGr    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, …\n$ TotRmsAbvGrd    &lt;dbl&gt; 8, 6, 6, 7, 9, 5, 7, 7, 8, 5, 5, 11, 4, 7, 5, 5, 5, 6,…\n$ Fireplaces      &lt;dbl&gt; 0, 1, 1, 1, 1, 0, 1, 2, 2, 2, 0, 2, 0, 1, 1, 0, 1, 0, …\n$ GarageYrBlt     &lt;dbl&gt; 2003, 1976, 2001, 1998, 2000, 1993, 2004, 1973, 1931, …\n$ GarageCars      &lt;dbl&gt; 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 2, …\n$ GarageArea      &lt;dbl&gt; 548, 460, 608, 642, 836, 480, 636, 484, 468, 205, 384,…\n$ WoodDeckSF      &lt;dbl&gt; 0, 298, 0, 0, 192, 40, 255, 235, 90, 0, 0, 147, 140, 1…\n$ OpenPorchSF     &lt;dbl&gt; 61, 0, 42, 35, 84, 30, 57, 204, 0, 4, 0, 21, 0, 33, 21…\n$ EnclosedPorch   &lt;dbl&gt; 0, 0, 0, 272, 0, 0, 0, 228, 205, 0, 0, 0, 0, 0, 176, 0…\n$ `3SsnPorch`     &lt;dbl&gt; 0, 0, 0, 0, 0, 320, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ScreenPorch     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 0, 0, 0, 0, 0…\n$ PoolArea        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ MiscVal         &lt;dbl&gt; 0, 0, 0, 0, 0, 700, 0, 350, 0, 0, 0, 0, 0, 0, 0, 0, 70…\n$ MoSold          &lt;dbl&gt; 2, 5, 9, 2, 12, 10, 8, 11, 4, 1, 2, 7, 9, 8, 5, 7, 3, …\n$ YrSold          &lt;dbl&gt; 2008, 2007, 2008, 2006, 2008, 2009, 2007, 2009, 2008, …\n$ target_variable &lt;dbl&gt; 208500, 181500, 223500, 140000, 250000, 143000, 307000…\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#recipe",
    "title": "Regression model with Recipe",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#prep-the-recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#prep-the-recipe",
    "title": "Regression model with Recipe",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Regression model with Recipe",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "house price regression model/3 Regression Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Regression model with Recipe",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#model",
    "href": "house price regression model/3 Regression Tidy Modeling.html#model",
    "title": "Regression model with Recipe",
    "section": "3.5 model",
    "text": "3.5 model\n\n3.5.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.5.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.5.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/3 Regression Tidy Modeling.html#trainning",
    "title": "Regression model with Recipe",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n3.6.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    180421.70         767.46       -8094.25         903.70        1599.01  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n     26128.59        5018.48        8945.07        2525.17        5672.04  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n      6631.92        1406.69        2868.07             NA       18015.90  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n     20898.31          28.81             NA        5099.47        1079.56  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n      2064.26        -865.84       -7429.07       -2969.90        6013.58  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n      2906.10       -7470.78       13312.87         454.85        2970.22  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n     -1630.78        -296.59        1206.28        2450.60       -2053.73  \n      MiscVal         MoSold         YrSold  \n      -145.90        -645.51       -1011.23  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term         estimate std.error statistic  p.value\n   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)   180422.     1149.   157.    0       \n 2 Id               767.     1165.     0.659 5.10e- 1\n 3 MSSubClass     -8094.     1437.    -5.63  2.29e- 8\n 4 LotFrontage      904.     1270.     0.712 4.77e- 1\n 5 LotArea         1599.     1297.     1.23  2.18e- 1\n 6 OverallQual    26129.     2093.    12.5   2.69e-33\n 7 OverallCond     5018.     1457.     3.44  5.98e- 4\n 8 YearBuilt       8945.     2329.     3.84  1.30e- 4\n 9 YearRemodAdd    2525.     1745.     1.45  1.48e- 1\n10 MasVnrArea      5672.     1375.     4.12  4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.6.2 train lasso model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00  63480\n2   1 10.62  57840\n3   1 19.45  52700\n4   1 26.77  48020\n5   2 32.89  43760\n6   2 39.26  39870\n7   2 44.56  36330\n8   2 48.95  33100\n9   3 52.79  30160\n10  4 56.28  27480\n11  5 59.43  25040\n12  5 62.05  22810\n13  5 64.22  20790\n14  5 66.03  18940\n15  5 67.53  17260\n16  5 68.77  15720\n17  5 69.80  14330\n18  7 70.71  13060\n19  9 71.66  11900\n20 10 72.51  10840\n21 10 73.26   9876\n22 10 73.87   8998\n23 11 74.40   8199\n24 11 74.86   7471\n25 13 75.37   6807\n26 13 75.86   6202\n27 13 76.28   5651\n28 13 76.64   5149\n29 13 76.95   4692\n30 13 77.21   4275\n31 13 77.42   3895\n32 14 77.60   3549\n33 14 77.75   3234\n34 15 77.88   2947\n35 15 77.99   2685\n36 16 78.09   2446\n37 17 78.27   2229\n38 19 78.44   2031\n39 20 78.62   1851\n40 21 78.76   1686\n41 22 78.90   1536\n42 23 79.03   1400\n43 24 79.14   1275\n44 25 79.24   1162\n45 25 79.32   1059\n46 25 79.39    965\n47 26 79.45    879\n48 26 79.50    801\n49 27 79.54    730\n50 28 79.59    665\n51 29 79.62    606\n52 30 79.65    552\n53 30 79.68    503\n54 31 79.70    458\n55 31 79.72    418\n56 31 79.73    381\n57 32 79.74    347\n58 33 79.75    316\n59 33 79.76    288\n60 34 79.77    262\n61 34 79.78    239\n62 33 79.78    218\n63 33 79.79    198\n64 33 79.79    181\n65 33 79.79    165\n66 33 79.80    150\n67 34 79.80    137\n68 35 79.80    125\n69 35 79.80    114\n70 35 79.80    104\n71 35 79.81     94\n72 35 79.81     86\n73 35 79.81     78\n74 35 79.81     71\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term         estimate penalty\n   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)   180422.     0.1\n 2 Id               684.     0.1\n 3 MSSubClass     -7967.     0.1\n 4 LotFrontage      867.     0.1\n 5 LotArea         1564.     0.1\n 6 OverallQual    26220.     0.1\n 7 OverallCond     4883.     0.1\n 8 YearBuilt       8728.     0.1\n 9 YearRemodAdd    2583.     0.1\n10 MasVnrArea      5657.     0.1\n# ℹ 28 more rows\n\n\n\n\n3.6.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       1006353699 \nR squared (OOB):                  0.8438799",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/3 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model with Recipe",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = train_juice) %&gt;%\n  mutate(\n    truth = train_juice$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = train_juice) %&gt;%\n    mutate(\n      truth = train_juice$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = test_proc) %&gt;%\n  mutate(\n    truth = test_proc$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = test_proc) %&gt;%\n    mutate(\n      truth = test_proc$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      36059.\n2 lm    rmse    standard      36055.\n3 rf    rmse    standard      13540.\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      31122.\n2 lm    rmse    standard      31139.\n3 rf    rmse    standard      28348.\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/3 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/3 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Regression model with Recipe",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- rf_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   30645.       10 2324.     Preprocessor1_Model1\n2 rsq     standard       0.859    10    0.0218 Preprocessor1_Model1\n\n\n\n\nCode\nlasso_res &lt;- lasso_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nlasso_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   39201.       10 4620.     Preprocessor1_Model1\n2 rsq     standard       0.769    10    0.0422 Preprocessor1_Model1\n\n\n\n\nCode\nlm_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nlm_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46227.        1      NA Preprocessor1_Model1\n2 rsq     standard       0.830     1      NA Preprocessor1_Model1\n\n\nShow all resample result:\n\n\nCode\nrf_res %&gt;%\n  unnest(.predictions) %&gt;%\n  ggplot(aes(target_variable, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  labs(\n    x = \"Truth\",\n    y = \"Prediction\",\n    color = NULL\n  )\n\n\n\n\n\n\n\n\n\nShow each resample result:\n\n\nCode\nlibrary(gganimate)\n\np=rf_res %&gt;%\n  unnest(.predictions) %&gt;%\n  ggplot(aes(target_variable, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  labs(\n    x = \"Truth\",\n    y = \"Prediction\",\n    color = NULL\n  )+transition_states(id)\n\np",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html",
    "href": "house price regression model/6 Regression Tidy Modeling.html",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning\nadd quick tuning\nadd workflow set and setting different tuning grid for different model",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/6 Regression Tidy Modeling.html#read-data",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/6 Regression Tidy Modeling.html#data-split",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/6 Regression Tidy Modeling.html#recipe",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\n\nCode\ntrained_data_rec &lt;- prep(data_rec, training = data_train)\n\n\n\n\nCode\ntrained_data_rec %&gt;%check_missing(\"LotFrontage\")",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#model",
    "href": "house price regression model/6 Regression Tidy Modeling.html#model",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 50)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\n\n3.2.2 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec =\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"regression\")\n\n\n\n\nCode\ntune_spec %&gt;% extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid = \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.3 lightGBM Boost tree\n\n\nCode\nlightgbm_spec = boost_tree(\n  trees = 100,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"regression\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth    learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          7 0.00953             2.79e- 1    40       0.256    13\n2          6 0.00130             1.47e- 3    16       0.732     4\n3          9 0.0000453           2.17e- 7    36       0.446    25\n4          3 0.0199              2.13e- 8    26       0.773    35\n5         13 0.0793              8.96e- 9    30       0.219    12\n6         10 0.00000000238       1.09e-10    21       0.699    21\n\n\n\n\n3.2.4 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(\n  mtry = tune(), trees = tune(), min_n = tune()\n  )%&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = tune()\n  trees = tune()\n  min_n = tune()\n\nComputational engine: ranger \n\n\n\n\nCode\nrf_grid &lt;- \n  grid_latin_hypercube(\n    min_n(), \n    mtry(range = c(4, 9)), \n    trees(), \n    size = 80)\n\nhead(rf_grid)\n\n\n# A tibble: 6 × 3\n  min_n  mtry trees\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    33     7  1713\n2    29     5  1343\n3    12     6   545\n4    21     6   843\n5    27     5  1485\n6    13     9    48",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/6 Regression Tidy Modeling.html#workflow",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nworkflow_set =\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(\n                  lasso=lasso_tune_spec,\n                  tree  = tune_spec,\n                  lightgbm=lightgbm_spec,\n                  random_forest=rf_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = lasso_grid, id = \"recipe_lasso\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\")  %&gt;% \n  option_add(grid = rf_grid, id = \"recipe_rf\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 4 × 4\n  wflow_id             info             option    result    \n  &lt;chr&gt;                &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_lasso         &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n2 recipe_tree          &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_lightgbm      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n4 recipe_random_forest &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;\n\n\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#training",
    "href": "house price regression model/6 Regression Tidy Modeling.html#training",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 50,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"rmse\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_lightgbm\nPreprocessor1_Model46\nrmse\n2.898681e+04\n3.152131e+03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model46\nrsq\n8.704013e-01\n1.884946e-02\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_random_forest\nPreprocessor1_Model31\nrmse\n2.918897e+04\n3.074054e+03\n10\nrecipe\nrand_forest\n2\n\n\nrecipe_random_forest\nPreprocessor1_Model31\nrsq\n8.693925e-01\n1.953458e-02\n10\nrecipe\nrand_forest\n2\n\n\nrecipe_lasso\nPreprocessor1_Model01\nrmse\n3.878538e+04\n5.169415e+03\n10\nrecipe\nlinear_reg\n3\n\n\nrecipe_lasso\nPreprocessor1_Model01\nrsq\n7.769664e-01\n4.331088e-02\n10\nrecipe\nlinear_reg\n3\n\n\nrecipe_tree\nPreprocessor1_Model06\nrmse\n3.923049e+04\n2.064970e+03\n10\nrecipe\ndecision_tree\n4\n\n\nrecipe_tree\nPreprocessor1_Model06\nrsq\n7.674437e-01\n1.574068e-02\n10\nrecipe\ndecision_tree\n4\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_lightgbm')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_random_forest\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"rmse\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/6 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/6 Regression Tidy Modeling.html#last-fit",
    "title": "Multiple Regression model with Recipe,workflow set,fast tuning",
    "section": "4.1 last fit",
    "text": "4.1 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)\n\n\n\n\nCode\noptions(scipen=10000)\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   28019.    Preprocessor1_Model1\n2 rsq     standard       0.876 Preprocessor1_Model1\n\n\n\n\nCode\n(final_fit%&gt;%collect_predictions()) %&gt;% ggplot(aes(target_variable, .pred))+ geom_abline(lty = 2, color = \"gray80\", size = 1.5) +geom_point(alpha = 0.5)+labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )+scale_x_continuous(labels = scales::comma) +scale_y_continuous(labels = scales::comma) \n\n\n\n\n\n\n\n\n\nmanual calculate RMSE on testing data\n\n\nCode\nfinal_data=final_fit%&gt;%collect_predictions()\n\nfinal_data2=final_data %&gt;% mutate(diff=target_variable-.pred)%&gt;% mutate(diff2=diff^2)\n\na=sum(final_data2$diff2)/nrow(final_data2)\n\nsqrt(a)\n\n\n[1] 28018.9\n\n\nCode\n#glimpse(final_data2)",
    "crumbs": [
      "house price regression model",
      "Multiple Regression model with Recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html",
    "href": "house price regression model/1 Regression Tidy Modeling.html",
    "title": "Regression model",
    "section": "",
    "text": "Load Pacakges & Set Options\nlibrary(themis)\nlibrary(tidyverse)      \nlibrary(tidymodels)     \nlibrary(palmerpenguins) # penguin dataset\nlibrary(gt)             # better tables\nlibrary(bonsai)         # tree-based models\nlibrary(conflicted)     # function conflicts\nlibrary(vetiver)\nlibrary(Microsoft365R)\nlibrary(pins)\ntidymodels_prefer()     # handle conflicts\nconflict_prefer(\"penguins\", \"palmerpenguins\")\noptions(tidymodels.dark = TRUE) # dark mode\ntheme_set(theme_bw()) # set default ggplot2 theme",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/1 Regression Tidy Modeling.html#read-data",
    "title": "Regression model",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/1 Regression Tidy Modeling.html#data-split",
    "title": "Regression model",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/1 Regression Tidy Modeling.html#recipe",
    "title": "Regression model",
    "section": "3.1 recipe",
    "text": "3.1 recipe\ndid not use recipe at this case",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#model",
    "href": "house price regression model/1 Regression Tidy Modeling.html#model",
    "title": "Regression model",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 linear regression using OLS\n\n\nCode\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(engine = \"lm\")\n\nlm_spec\n\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n\n\n\n3.2.2 lasso regression\n\n\nCode\nlasso_spec &lt;- linear_reg(penalty = 0.1, mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\n3.2.3 Random Forest Model\n\n\nCode\nrf_spec &lt;- rand_forest(mode = \"regression\") %&gt;%\n  set_engine(\"ranger\")\n\nrf_spec\n\n\nRandom Forest Model Specification (regression)\n\nComputational engine: ranger",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#trainning",
    "href": "house price regression model/1 Regression Tidy Modeling.html#trainning",
    "title": "Regression model",
    "section": "3.3 trainning",
    "text": "3.3 trainning\n\n3.3.1 train lm model\n\n\nCode\nlm_fit &lt;- lm_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nlm_fit\n\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = target_variable ~ ., data = data)\n\nCoefficients:\n  (Intercept)             Id     MSSubClass    LotFrontage        LotArea  \n    6.786e+05      1.851e+00     -1.899e+02      2.506e+01      1.804e-01  \n  OverallQual    OverallCond      YearBuilt   YearRemodAdd     MasVnrArea  \n    1.890e+04      4.588e+03      2.974e+02      1.226e+02      3.001e+01  \n   BsmtFinSF1     BsmtFinSF2      BsmtUnfSF    TotalBsmtSF     `1stFlrSF`  \n    1.411e+01      8.770e+00      6.529e+00             NA      4.605e+01  \n   `2ndFlrSF`   LowQualFinSF      GrLivArea   BsmtFullBath   BsmtHalfBath  \n    4.830e+01      6.035e-01             NA      9.801e+03      4.500e+03  \n     FullBath       HalfBath   BedroomAbvGr   KitchenAbvGr   TotRmsAbvGrd  \n    3.766e+03     -1.734e+03     -8.997e+03     -1.285e+04      3.689e+03  \n   Fireplaces    GarageYrBlt     GarageCars     GarageArea     WoodDeckSF  \n    4.535e+03     -1.615e+01      1.789e+04      2.146e+00      2.358e+01  \n  OpenPorchSF  EnclosedPorch    `3SsnPorch`    ScreenPorch       PoolArea  \n   -2.548e+01     -5.078e+00      3.999e+01      4.278e+01     -5.265e+01  \n      MiscVal         MoSold         YrSold  \n   -2.539e-01     -2.339e+02     -7.699e+02  \n\n\n\n\nCode\nlm_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 5\n   term           estimate   std.error statistic  p.value\n   &lt;chr&gt;             &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)  678634.    1808073.        0.375 7.07e- 1\n 2 Id                1.85        2.81      0.659 5.10e- 1\n 3 MSSubClass     -190.         33.7      -5.63  2.29e- 8\n 4 LotFrontage      25.1        35.2       0.712 4.77e- 1\n 5 LotArea           0.180       0.146     1.23  2.18e- 1\n 6 OverallQual   18904.       1515.       12.5   2.69e-33\n 7 OverallCond    4588.       1332.        3.44  5.98e- 4\n 8 YearBuilt       297.         77.4       3.84  1.30e- 4\n 9 YearRemodAdd    123.         84.7       1.45  1.48e- 1\n10 MasVnrArea       30.0         7.28      4.12  4.02e- 5\n# ℹ 28 more rows\n\n\n\n\n3.3.2 train lm model\n\n\nCode\nlasso_fit &lt;- lasso_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nlasso_fit\n\n\nparsnip model object\n\n\nCall:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"gaussian\",      alpha = ~1) \n\n   Df  %Dev Lambda\n1   0  0.00  63480\n2   1 10.62  57840\n3   1 19.45  52700\n4   1 26.77  48020\n5   2 32.89  43760\n6   2 39.26  39870\n7   2 44.56  36330\n8   2 48.95  33100\n9   3 52.79  30160\n10  4 56.28  27480\n11  5 59.43  25040\n12  5 62.05  22810\n13  5 64.22  20790\n14  5 66.03  18940\n15  5 67.53  17260\n16  5 68.77  15720\n17  5 69.80  14330\n18  7 70.71  13060\n19  9 71.66  11900\n20 10 72.51  10840\n21 10 73.26   9876\n22 10 73.87   8998\n23 11 74.40   8199\n24 11 74.86   7471\n25 13 75.37   6807\n26 13 75.86   6202\n27 13 76.28   5651\n28 13 76.64   5149\n29 13 76.95   4692\n30 13 77.21   4275\n31 13 77.42   3895\n32 14 77.60   3549\n33 14 77.75   3234\n34 15 77.88   2947\n35 15 77.99   2685\n36 16 78.09   2446\n37 17 78.27   2229\n38 19 78.44   2031\n39 20 78.62   1851\n40 21 78.76   1686\n41 22 78.90   1536\n42 23 79.03   1400\n43 24 79.14   1275\n44 25 79.24   1162\n45 25 79.32   1059\n46 25 79.39    965\n47 26 79.45    879\n48 26 79.50    801\n49 27 79.54    730\n50 28 79.59    665\n51 29 79.62    606\n52 30 79.65    552\n53 30 79.68    503\n54 31 79.70    458\n55 31 79.72    418\n56 31 79.73    381\n57 32 79.74    347\n58 33 79.75    316\n59 33 79.76    288\n60 34 79.77    262\n61 34 79.78    239\n62 33 79.78    218\n63 33 79.79    198\n64 33 79.79    181\n65 33 79.79    165\n66 33 79.80    150\n67 34 79.80    137\n68 35 79.80    125\n69 35 79.80    114\n70 35 79.80    104\n71 35 79.81     94\n72 35 79.81     86\n73 35 79.81     78\n74 35 79.81     71\n\n\n\n\nCode\nlasso_fit %&gt;% tidy()\n\n\n# A tibble: 38 × 3\n   term           estimate penalty\n   &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)  528464.        0.1\n 2 Id                1.65      0.1\n 3 MSSubClass     -187.        0.1\n 4 LotFrontage      24.0       0.1\n 5 LotArea           0.177     0.1\n 6 OverallQual   18970.        0.1\n 7 OverallCond    4464.        0.1\n 8 YearBuilt       290.        0.1\n 9 YearRemodAdd    125.        0.1\n10 MasVnrArea       29.9       0.1\n# ℹ 28 more rows\n\n\n\n\n3.3.3 train random forest model\n\n\nCode\nrf_fit &lt;- rf_spec %&gt;%\n  fit(target_variable ~ ., data = data_train)\n\nrf_fit\n\n\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.threads = 1,      verbose = FALSE, seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      1021 \nNumber of independent variables:  37 \nMtry:                             6 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       959255491 \nR squared (OOB):                  0.8511865",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/1 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nresults_train &lt;- lm_fit %&gt;%\n  predict(new_data = data_train) %&gt;%\n  mutate(\n    truth = data_train$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = data_train) %&gt;%\n    mutate(\n      truth = data_train$target_variable,\n      model = \"rf\"\n    )) %&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = data_train) %&gt;%\n    mutate(\n      truth = data_train$target_variable,\n      model = \"lasso\"\n    ))\n\n\nresults_test &lt;- lm_fit %&gt;%\n  predict(new_data = data_test) %&gt;%\n  mutate(\n    truth = data_test$target_variable,\n    model = \"lm\"\n  ) %&gt;%\n  bind_rows(rf_fit %&gt;%\n    predict(new_data = data_test) %&gt;%\n    mutate(\n      truth = data_test$target_variable,\n      model = \"rf\"\n    ))%&gt;%\n  bind_rows(lasso_fit %&gt;%\n    predict(new_data = data_test) %&gt;%\n    mutate(\n      truth = data_test$target_variable,\n      model = \"lasso\"\n    ))\n\n\n\n\nCode\nresults_train %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      36059.\n2 lm    rmse    standard      36055.\n3 rf    rmse    standard      13542.\n\n\n\n\nCode\nresults_test %&gt;%\n  group_by(model) %&gt;%\n  rmse(truth = truth, estimate = .pred)\n\n\n# A tibble: 3 × 4\n  model .metric .estimator .estimate\n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 lasso rmse    standard      31122.\n2 lm    rmse    standard      31139.\n3 rf    rmse    standard      28428.\n\n\n\n\nCode\nresults_test %&gt;%\n  mutate(train = \"testing\") %&gt;%\n  bind_rows(results_train %&gt;%\n    mutate(train = \"training\")) %&gt;%\n  ggplot(aes(truth, .pred, color = model)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~train) +\n  labs(\n    x = \"Truth\",\n    y = \"Predicted attendance\",\n    color = \"Type of model\"\n  )",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/1 Regression Tidy Modeling.html#resample-with-rf-model",
    "href": "house price regression model/1 Regression Tidy Modeling.html#resample-with-rf-model",
    "title": "Regression model",
    "section": "4.2 resample with rf model",
    "text": "4.2 resample with rf model\n\n\nCode\nset.seed(1234)\nfolds &lt;- vfold_cv(data_train)\n\n\n\n\nCode\nrf_res &lt;- lm_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n\n\n\nCode\nrf_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   46227.        1      NA Preprocessor1_Model1\n2 rsq     standard       0.830     1      NA Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Regression model"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html",
    "href": "house price regression model/4 Regression Tidy Modeling.html",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tuning",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/4 Regression Tidy Modeling.html#read-data",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/4 Regression Tidy Modeling.html#data-split",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/4 Regression Tidy Modeling.html#recipe",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\n\nCode\ndata_rec %&gt;% summary()\n\n\n# A tibble: 38 × 4\n   variable     type      role      source  \n   &lt;chr&gt;        &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 Id           &lt;chr [2]&gt; predictor original\n 2 MSSubClass   &lt;chr [2]&gt; predictor original\n 3 LotFrontage  &lt;chr [2]&gt; predictor original\n 4 LotArea      &lt;chr [2]&gt; predictor original\n 5 OverallQual  &lt;chr [2]&gt; predictor original\n 6 OverallCond  &lt;chr [2]&gt; predictor original\n 7 YearBuilt    &lt;chr [2]&gt; predictor original\n 8 YearRemodAdd &lt;chr [2]&gt; predictor original\n 9 MasVnrArea   &lt;chr [2]&gt; predictor original\n10 BsmtFinSF1   &lt;chr [2]&gt; predictor original\n# ℹ 28 more rows",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#model",
    "href": "house price regression model/4 Regression Tidy Modeling.html#model",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 100)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/4 Regression Tidy Modeling.html#workflow",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(lasso_tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#training",
    "href": "house price regression model/4 Regression Tidy Modeling.html#training",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\n\n\nCode\nlasso_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 200 × 7\n    penalty .metric .estimator      mean     n   std_err .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model001\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model001\n 3 1.26e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model002\n 4 1.26e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model002\n 5 1.59e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model003\n 6 1.59e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model003\n 7 2.01e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model004\n 8 2.01e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model004\n 9 2.54e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model005\n10 2.54e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model005\n# ℹ 190 more rows",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/4 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nautoplot(lasso_res)\n\n\n\n\n\n\n\n\n\nuse best tune model for final fit\n\n\nCode\nlowest_rmse &lt;- lasso_res %&gt;%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n\n\n# A tibble: 1 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/4 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/4 Regression Tidy Modeling.html#last-fit",
    "title": "Regression model with Recipe,workflow,tuning",
    "section": "4.2 last fit",
    "text": "4.2 last fit\n\n\nCode\nfinal_res &lt;- \n  final_wf %&gt;%\n  last_fit(data_split) \n\n\n\n\nCode\nfinal_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html",
    "href": "house price regression model/5 Regression Tidy Modeling.html",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "",
    "text": "using Recipe.\nadd resamples to estimate the performance of our two models\nadd workflow with tunning\nadd quick tunning",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#read-data",
    "href": "house price regression model/5 Regression Tidy Modeling.html#read-data",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#data-split",
    "href": "house price regression model/5 Regression Tidy Modeling.html#data-split",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train  %&gt;% select_if(is.numeric)%&gt;% rename(target_variable=SalePrice)%&gt;% replace(is.na(.), 0)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 1021   38\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 293  38\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 146  38",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#recipe",
    "href": "house price regression model/5 Regression Tidy Modeling.html#recipe",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric(),-all_outcomes())",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#model",
    "href": "house price regression model/5 Regression Tidy Modeling.html#model",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n\n3.2.1 lasso regression\n\n\nCode\nlasso_tune_spec &lt;- linear_reg(penalty = tune(), mixture = 1) %&gt;%\n  set_engine(\"glmnet\")\n\n\n\n\nCode\nlasso_grid &lt;- grid_regular(penalty(), levels = 50)\n\n\n\n\nCode\nlasso_tune_spec\n\n\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#workflow",
    "href": "house price regression model/5 Regression Tidy Modeling.html#workflow",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(lasso_tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#training",
    "href": "house price regression model/5 Regression Tidy Modeling.html#training",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "3.4 training",
    "text": "3.4 training\n\n3.4.1 train lasso model\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nlasso_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = lasso_grid,\n    control   = cntl\n    )\n\n\n\n\nCode\nlasso_res %&gt;% collect_metrics()\n\n\n# A tibble: 100 × 7\n    penalty .metric .estimator      mean     n   std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model01\n 2 1   e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model01\n 3 1.60e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model02\n 4 1.60e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model02\n 5 2.56e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model03\n 6 2.56e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model03\n 7 4.09e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model04\n 8 4.09e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model04\n 9 6.55e-10 rmse    standard   38785.       10 5169.     Preprocessor1_Model05\n10 6.55e-10 rsq     standard       0.777    10    0.0433 Preprocessor1_Model05\n# ℹ 90 more rows",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#evaluate",
    "href": "house price regression model/5 Regression Tidy Modeling.html#evaluate",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nautoplot(lasso_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nglimpse(lasso_res)\n\n\nRows: 10\nColumns: 6\n$ splits       &lt;list&gt; [&lt;vfold_split[919 x 102 x 1021 x 38]&gt;], [&lt;vfold_split[91…\n$ id           &lt;chr&gt; \"Fold02\", \"Fold05\", \"Fold10\", \"Fold09\", \"Fold03\", \"Fold04…\n$ .order       &lt;int&gt; 3, 2, 1, 4, 5, 6, 7, 8, 9, 10\n$ .metrics     &lt;list&gt; [&lt;tbl_df[100 x 5]&gt;], [&lt;tbl_df[100 x 5]&gt;], [&lt;tbl_df[100 x …\n$ .notes       &lt;list&gt; [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;],…\n$ .predictions &lt;list&gt; [&lt;tbl_df[5100 x 5]&gt;], [&lt;tbl_df[5100 x 5]&gt;], [&lt;tbl_df[510…\n\n\n\n\nCode\nlasso_res %&gt;% plot_race()\n\n\n\n\n\n\n\n\n\nuse best tune model for final fit\n\n\nCode\nlowest_rmse &lt;- lasso_res %&gt;%\n  select_best(\"rmse\", maximize = FALSE)\n\nlowest_rmse\n\n\n# A tibble: 1 × 2\n       penalty .config              \n         &lt;dbl&gt; &lt;chr&gt;                \n1 0.0000000001 Preprocessor1_Model01\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(lowest_rmse)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/5 Regression Tidy Modeling.html#last-fit",
    "href": "house price regression model/5 Regression Tidy Modeling.html#last-fit",
    "title": "Regression model with Recipe,workflow,fast tuning",
    "section": "4.2 last fit",
    "text": "4.2 last fit\n\n\nCode\nfinal_res &lt;- \n  final_wf %&gt;%\n  last_fit(data_split) \n\n\n\n\nCode\noptions(scipen=10000)\nfinal_res %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   31122.    Preprocessor1_Model1\n2 rsq     standard       0.844 Preprocessor1_Model1",
    "crumbs": [
      "house price regression model",
      "Regression model with Recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "house price regression model/0 Regression Tidy Modeling.html",
    "href": "house price regression model/0 Regression Tidy Modeling.html",
    "title": "House price data",
    "section": "",
    "text": "1 house price data\n\ndata download form kaggle\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\nData have 1460 record and 81 variable\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n2 Measurement:\n\nMean absolute error (MAE)\n\nThe MAE measures the average magnitude of the errors in a set of forecasts, without considering their direction. It measures accuracy for continuous variables. The equation is given in the library references. Expressed in words, the MAE is the average over the verification sample of the absolute values of the differences between forecast and the corresponding observation. The MAE is a linear score which means that all the individual differences are weighted equally in the average.\n\nRoot Mean Squared Error (RMSE)\n\n\nThe RMSE is a quadratic scoring rule which measures the average magnitude of the error. The equation for the RMSE is given in both of the references. Expressing the formula in words, the difference between forecast and corresponding observed values are each squared and then averaged over the sample. Finally, the square root of the average is taken. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable.\nBoth the MAE and RMSE can range from 0 to ∞. They are negatively-oriented scores: Lower values are better.\n\nR^2 (Coefficient of determination): is between 0 to 1. bigger the better.\n\n\nresidual sum of squares(RSS):\n\ntotal sum of squares(TOT):\n\n\n\n3 read data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")\n\n\n\n\n4 plotting\n\n\nCode\noptions(scipen = 999)\nggplot(train, aes(SalePrice)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n5 EDA\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n1460\n\n\nNumber of columns\n81\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n43\n\n\nnumeric\n38\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMSZoning\n0\n1.00\n2\n7\n0\n5\n0\n\n\nStreet\n0\n1.00\n4\n4\n0\n2\n0\n\n\nAlley\n1369\n0.06\n4\n4\n0\n2\n0\n\n\nLotShape\n0\n1.00\n3\n3\n0\n4\n0\n\n\nLandContour\n0\n1.00\n3\n3\n0\n4\n0\n\n\nUtilities\n0\n1.00\n6\n6\n0\n2\n0\n\n\nLotConfig\n0\n1.00\n3\n7\n0\n5\n0\n\n\nLandSlope\n0\n1.00\n3\n3\n0\n3\n0\n\n\nNeighborhood\n0\n1.00\n5\n7\n0\n25\n0\n\n\nCondition1\n0\n1.00\n4\n6\n0\n9\n0\n\n\nCondition2\n0\n1.00\n4\n6\n0\n8\n0\n\n\nBldgType\n0\n1.00\n4\n6\n0\n5\n0\n\n\nHouseStyle\n0\n1.00\n4\n6\n0\n8\n0\n\n\nRoofStyle\n0\n1.00\n3\n7\n0\n6\n0\n\n\nRoofMatl\n0\n1.00\n4\n7\n0\n8\n0\n\n\nExterior1st\n0\n1.00\n5\n7\n0\n15\n0\n\n\nExterior2nd\n0\n1.00\n5\n7\n0\n16\n0\n\n\nMasVnrType\n8\n0.99\n4\n7\n0\n4\n0\n\n\nExterQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nExterCond\n0\n1.00\n2\n2\n0\n5\n0\n\n\nFoundation\n0\n1.00\n4\n6\n0\n6\n0\n\n\nBsmtQual\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtCond\n37\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtExposure\n38\n0.97\n2\n2\n0\n4\n0\n\n\nBsmtFinType1\n37\n0.97\n3\n3\n0\n6\n0\n\n\nBsmtFinType2\n38\n0.97\n3\n3\n0\n6\n0\n\n\nHeating\n0\n1.00\n4\n5\n0\n6\n0\n\n\nHeatingQC\n0\n1.00\n2\n2\n0\n5\n0\n\n\nCentralAir\n0\n1.00\n1\n1\n0\n2\n0\n\n\nElectrical\n1\n1.00\n3\n5\n0\n5\n0\n\n\nKitchenQual\n0\n1.00\n2\n2\n0\n4\n0\n\n\nFunctional\n0\n1.00\n3\n4\n0\n7\n0\n\n\nFireplaceQu\n690\n0.53\n2\n2\n0\n5\n0\n\n\nGarageType\n81\n0.94\n6\n7\n0\n6\n0\n\n\nGarageFinish\n81\n0.94\n3\n3\n0\n3\n0\n\n\nGarageQual\n81\n0.94\n2\n2\n0\n5\n0\n\n\nGarageCond\n81\n0.94\n2\n2\n0\n5\n0\n\n\nPavedDrive\n0\n1.00\n1\n1\n0\n3\n0\n\n\nPoolQC\n1453\n0.00\n2\n2\n0\n3\n0\n\n\nFence\n1179\n0.19\n4\n5\n0\n4\n0\n\n\nMiscFeature\n1406\n0.04\n4\n4\n0\n4\n0\n\n\nSaleType\n0\n1.00\n2\n5\n0\n9\n0\n\n\nSaleCondition\n0\n1.00\n6\n7\n0\n6\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nId\n0\n1.00\n730.50\n421.61\n1\n365.75\n730.5\n1095.25\n1460\n▇▇▇▇▇\n\n\nMSSubClass\n0\n1.00\n56.90\n42.30\n20\n20.00\n50.0\n70.00\n190\n▇▅▂▁▁\n\n\nLotFrontage\n259\n0.82\n70.05\n24.28\n21\n59.00\n69.0\n80.00\n313\n▇▃▁▁▁\n\n\nLotArea\n0\n1.00\n10516.83\n9981.26\n1300\n7553.50\n9478.5\n11601.50\n215245\n▇▁▁▁▁\n\n\nOverallQual\n0\n1.00\n6.10\n1.38\n1\n5.00\n6.0\n7.00\n10\n▁▂▇▅▁\n\n\nOverallCond\n0\n1.00\n5.58\n1.11\n1\n5.00\n5.0\n6.00\n9\n▁▁▇▅▁\n\n\nYearBuilt\n0\n1.00\n1971.27\n30.20\n1872\n1954.00\n1973.0\n2000.00\n2010\n▁▂▃▆▇\n\n\nYearRemodAdd\n0\n1.00\n1984.87\n20.65\n1950\n1967.00\n1994.0\n2004.00\n2010\n▅▂▂▃▇\n\n\nMasVnrArea\n8\n0.99\n103.69\n181.07\n0\n0.00\n0.0\n166.00\n1600\n▇▁▁▁▁\n\n\nBsmtFinSF1\n0\n1.00\n443.64\n456.10\n0\n0.00\n383.5\n712.25\n5644\n▇▁▁▁▁\n\n\nBsmtFinSF2\n0\n1.00\n46.55\n161.32\n0\n0.00\n0.0\n0.00\n1474\n▇▁▁▁▁\n\n\nBsmtUnfSF\n0\n1.00\n567.24\n441.87\n0\n223.00\n477.5\n808.00\n2336\n▇▅▂▁▁\n\n\nTotalBsmtSF\n0\n1.00\n1057.43\n438.71\n0\n795.75\n991.5\n1298.25\n6110\n▇▃▁▁▁\n\n\n1stFlrSF\n0\n1.00\n1162.63\n386.59\n334\n882.00\n1087.0\n1391.25\n4692\n▇▅▁▁▁\n\n\n2ndFlrSF\n0\n1.00\n346.99\n436.53\n0\n0.00\n0.0\n728.00\n2065\n▇▃▂▁▁\n\n\nLowQualFinSF\n0\n1.00\n5.84\n48.62\n0\n0.00\n0.0\n0.00\n572\n▇▁▁▁▁\n\n\nGrLivArea\n0\n1.00\n1515.46\n525.48\n334\n1129.50\n1464.0\n1776.75\n5642\n▇▇▁▁▁\n\n\nBsmtFullBath\n0\n1.00\n0.43\n0.52\n0\n0.00\n0.0\n1.00\n3\n▇▆▁▁▁\n\n\nBsmtHalfBath\n0\n1.00\n0.06\n0.24\n0\n0.00\n0.0\n0.00\n2\n▇▁▁▁▁\n\n\nFullBath\n0\n1.00\n1.57\n0.55\n0\n1.00\n2.0\n2.00\n3\n▁▇▁▇▁\n\n\nHalfBath\n0\n1.00\n0.38\n0.50\n0\n0.00\n0.0\n1.00\n2\n▇▁▅▁▁\n\n\nBedroomAbvGr\n0\n1.00\n2.87\n0.82\n0\n2.00\n3.0\n3.00\n8\n▁▇▂▁▁\n\n\nKitchenAbvGr\n0\n1.00\n1.05\n0.22\n0\n1.00\n1.0\n1.00\n3\n▁▇▁▁▁\n\n\nTotRmsAbvGrd\n0\n1.00\n6.52\n1.63\n2\n5.00\n6.0\n7.00\n14\n▂▇▇▁▁\n\n\nFireplaces\n0\n1.00\n0.61\n0.64\n0\n0.00\n1.0\n1.00\n3\n▇▇▁▁▁\n\n\nGarageYrBlt\n81\n0.94\n1978.51\n24.69\n1900\n1961.00\n1980.0\n2002.00\n2010\n▁▁▅▅▇\n\n\nGarageCars\n0\n1.00\n1.77\n0.75\n0\n1.00\n2.0\n2.00\n4\n▁▃▇▂▁\n\n\nGarageArea\n0\n1.00\n472.98\n213.80\n0\n334.50\n480.0\n576.00\n1418\n▂▇▃▁▁\n\n\nWoodDeckSF\n0\n1.00\n94.24\n125.34\n0\n0.00\n0.0\n168.00\n857\n▇▂▁▁▁\n\n\nOpenPorchSF\n0\n1.00\n46.66\n66.26\n0\n0.00\n25.0\n68.00\n547\n▇▁▁▁▁\n\n\nEnclosedPorch\n0\n1.00\n21.95\n61.12\n0\n0.00\n0.0\n0.00\n552\n▇▁▁▁▁\n\n\n3SsnPorch\n0\n1.00\n3.41\n29.32\n0\n0.00\n0.0\n0.00\n508\n▇▁▁▁▁\n\n\nScreenPorch\n0\n1.00\n15.06\n55.76\n0\n0.00\n0.0\n0.00\n480\n▇▁▁▁▁\n\n\nPoolArea\n0\n1.00\n2.76\n40.18\n0\n0.00\n0.0\n0.00\n738\n▇▁▁▁▁\n\n\nMiscVal\n0\n1.00\n43.49\n496.12\n0\n0.00\n0.0\n0.00\n15500\n▇▁▁▁▁\n\n\nMoSold\n0\n1.00\n6.32\n2.70\n1\n5.00\n6.0\n8.00\n12\n▃▆▇▃▃\n\n\nYrSold\n0\n1.00\n2007.82\n1.33\n2006\n2007.00\n2008.0\n2009.00\n2010\n▇▇▇▇▅\n\n\nSalePrice\n0\n1.00\n180921.20\n79442.50\n34900\n129975.00\n163000.0\n214000.00\n755000\n▇▅▁▁▁\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "house price regression model",
      "House price data"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-sequence-vector",
    "href": "data manipulation/2 data structure in R.html#create-sequence-vector",
    "title": "Data structure in R",
    "section": "1.1 create sequence vector",
    "text": "1.1 create sequence vector\n\n\nCode\nseq(from = 2, to = 14, by = 2) \n\n\n[1]  2  4  6  8 10 12 14",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-repeat-vector",
    "href": "data manipulation/2 data structure in R.html#create-repeat-vector",
    "title": "Data structure in R",
    "section": "1.2 create repeat vector",
    "text": "1.2 create repeat vector\n\n\nCode\nrep(x = 1.5, times = 4)  \n\n\n[1] 1.5 1.5 1.5 1.5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-random-vector",
    "href": "data manipulation/2 data structure in R.html#create-random-vector",
    "title": "Data structure in R",
    "section": "1.3 create random vector",
    "text": "1.3 create random vector\ncreate 5 random number from 1 to 10 without replacement\n\n\nCode\nsample(1:10,5, replace=F) \n\n\n[1] 4 6 7 9 5\n\n\ncreate 5 random number from 1 to 10 with replacement\n\n\nCode\nsample(1:10,5, replace=T) \n\n\n[1] 4 7 1 4 8\n\n\ncreate 1 random number from 0 to 1 from random uniform distribution\n\n\nCode\nrunif(1, min=0, max=1)\n\n\n[1] 0.4145574\n\n\ngenerate 4 random number that follows the normal distribution with mean being 0 and standard deviation being 1\n\n\nCode\nsn1 &lt;- rnorm(4, mean=0, sd=1) # standard nromal\nsn1\n\n\n[1]  0.02581398  1.12306894 -0.89522470 -0.56427842",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#create-unique-vector",
    "href": "data manipulation/2 data structure in R.html#create-unique-vector",
    "title": "Data structure in R",
    "section": "1.4 create unique vector",
    "text": "1.4 create unique vector\n\n\nCode\nv1=c(1,1,2,2,5,6)\nv1\n\n\n[1] 1 1 2 2 5 6\n\n\n\n\nCode\nunique(v1)\n\n\n[1] 1 2 5 6",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#append-vector",
    "href": "data manipulation/2 data structure in R.html#append-vector",
    "title": "Data structure in R",
    "section": "1.5 append vector",
    "text": "1.5 append vector\n\n\nCode\nx=c(1,2,3)\ny=c(4,5,6)\nz=c(x,y)\nz\n\n\n[1] 1 2 3 4 5 6",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#remove-element-in-vector",
    "href": "data manipulation/2 data structure in R.html#remove-element-in-vector",
    "title": "Data structure in R",
    "section": "1.6 remove element in vector",
    "text": "1.6 remove element in vector\n\n\nCode\nx=c(1,2,3,4,5)\nx\n\n\n[1] 1 2 3 4 5\n\n\n\n1.6.1 remove first one\n\n\nCode\nx[-1]\n\n\n[1] 2 3 4 5\n\n\n\n\n1.6.2 remove last one\n\n\nCode\nx[-length(x)]\n\n\n[1] 1 2 3 4\n\n\n\n\n1.6.3 remove from last second\n\n\nCode\nx[1:(length(x)-2)]\n\n\n[1] 1 2 3\n\n\n\n\n1.6.4 remove from from another vector\n\n\nCode\nremove=c(2,4)\nx[-remove]\n\n\n[1] 1 3 5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#sort-vector",
    "href": "data manipulation/2 data structure in R.html#sort-vector",
    "title": "Data structure in R",
    "section": "1.7 sort vector",
    "text": "1.7 sort vector\n\n\nCode\na=c(2,4,6,1,4)\n\n\n\n\nCode\nsort(a)\n\n\n[1] 1 2 4 4 6\n\n\n\n\nCode\nsort(a,decreasing=TRUE)\n\n\n[1] 6 4 4 2 1",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#vector-length",
    "href": "data manipulation/2 data structure in R.html#vector-length",
    "title": "Data structure in R",
    "section": "1.8 vector length",
    "text": "1.8 vector length\n\n\nCode\nlength(a)\n\n\n[1] 5",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#calculate-vector",
    "href": "data manipulation/2 data structure in R.html#calculate-vector",
    "title": "Data structure in R",
    "section": "1.9 calculate vector",
    "text": "1.9 calculate vector\n\n\nCode\nx=c(1,2,3,4,5)\n\nsum(x)\n\n\n[1] 15",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#select-vector-element",
    "href": "data manipulation/2 data structure in R.html#select-vector-element",
    "title": "Data structure in R",
    "section": "1.10 select vector element",
    "text": "1.10 select vector element\n\n\nCode\nx=c(1,2,3,6,9,10)\n\n\n\n1.10.1 select first\n\n\nCode\nx[1]\n\n\n[1] 1\n\n\n\n\n1.10.2 select last\n\n\n1.10.3 select first to 3th\n\n\nCode\nx[1:3]\n\n\n[1] 1 2 3",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#vector-converting-between-types",
    "href": "data manipulation/2 data structure in R.html#vector-converting-between-types",
    "title": "Data structure in R",
    "section": "1.12 vector Converting between types",
    "text": "1.12 vector Converting between types\n\n1.12.1 to factor\n\n\nCode\nx &lt;- c(\"a\", \"g\", \"b\")\ny=as.factor(x)\ny\n\n\n[1] a g b\nLevels: a b g\n\n\n\n\n1.12.2 to numeric\n\n\nCode\nx &lt;- c('123','44', '222')\ny=as.numeric(x)\ny\n\n\n[1] 123  44 222\n\n\n\n\n1.12.3 to character\n\n\nCode\nx &lt;- c(123123,111,5555)\ny=as.character(x)\ny\n\n\n[1] \"123123\" \"111\"    \"5555\"  \n\n\n\n\n1.12.4 to boolen\n\n\nCode\nx &lt;- c(1,0,1)\ny=as.logical(x)\ny\n\n\n[1]  TRUE FALSE  TRUE",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#vector-to-other-data-format",
    "href": "data manipulation/2 data structure in R.html#vector-to-other-data-format",
    "title": "Data structure in R",
    "section": "1.13 vector to other data format",
    "text": "1.13 vector to other data format\n\n1.13.1 vector to dataframe\n\n\nCode\nName &lt;- c(\"Jhon\", \"Lee\", \"Suzan\", \"Abhinav\", \n          \"Brain\", \"Emma\", \"David\", \"Alice\") \n\n   \nMarks &lt;- c(56, 76, 86, 96, 73, 87, 47, 98) \n    \n\ndata&lt;- data.frame(Name,Marks) \ndata\n\n\n     Name Marks\n1    Jhon    56\n2     Lee    76\n3   Suzan    86\n4 Abhinav    96\n5   Brain    73\n6    Emma    87\n7   David    47\n8   Alice    98\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"data.frame\"\n\n\n\n\n1.13.2 verctor to matrix\n\n\nCode\nv1 &lt;- c(56, 76, 86, 96, 73, 87, 47, 98) \n\n\n\n\nCode\ndata&lt;-matrix(v1,nrow=4)\ndata\n\n\n     [,1] [,2]\n[1,]   56   73\n[2,]   76   87\n[3,]   86   47\n[4,]   96   98\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"matrix\" \"array\" \n\n\nother way:\n\n\nCode\ndata&lt;-matrix(c(v1,v1),ncol = 2)\ndata\n\n\n     [,1] [,2]\n[1,]   56   56\n[2,]   76   76\n[3,]   86   86\n[4,]   96   96\n[5,]   73   73\n[6,]   87   87\n[7,]   47   47\n[8,]   98   98\n\n\n\n\n1.13.3 verctor to list\n\n\nCode\ndata=list(v1)\ndata\n\n\n[[1]]\n[1] 56 76 86 96 73 87 47 98\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"list\"\n\n\neach element in vetor as a element in list\n\n\nCode\ndata=as.list(v1)\ndata\n\n\n[[1]]\n[1] 56\n\n[[2]]\n[1] 76\n\n[[3]]\n[1] 86\n\n[[4]]\n[1] 96\n\n[[5]]\n[1] 73\n\n[[6]]\n[1] 87\n\n[[7]]\n[1] 47\n\n[[8]]\n[1] 98\n\n\n\n\n1.13.4 verctor to array\n3D array\n\n\nCode\nvec1=c(1:5) \n \nvec2=c(6:10) \n \narr=array(c(vec1,vec2),dim=c(2,5,3)) \n \n# printing the array\nclass(arr)\n\n\n[1] \"array\"\n\n\n\n\nCode\narr\n\n\n, , 1\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10\n\n, , 2\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10\n\n, , 3\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#dataframe-to-other-data-format",
    "href": "data manipulation/2 data structure in R.html#dataframe-to-other-data-format",
    "title": "Data structure in R",
    "section": "2.1 dataframe to other data format",
    "text": "2.1 dataframe to other data format\n\n2.1.1 dataframe to matrix\n\n\nCode\nmat &lt;- as.matrix(df)\n\nclass(mat)\n\n\n[1] \"matrix\" \"array\" \n\n\n\n\nCode\nmat\n\n\n     Name    Language Age \n[1,] \"Amiya\" \"R\"      \"22\"\n[2,] \"Raj\"   \"Python\" \"25\"\n[3,] \"Asish\" \"Java\"   \"45\"\n\n\n\n\n2.1.2 dataframe to vector\n\n\nCode\nvec=df[['Name']]\n\nclass(vec)\n\n\n[1] \"character\"\n\n\n\n\nCode\nvec\n\n\n[1] \"Amiya\" \"Raj\"   \"Asish\"\n\n\n\n\n2.1.3 dataframe to list\n\n\nCode\nlist=as.list(df[['Name']])\n\nclass(list)\n\n\n[1] \"list\"\n\n\n\n\nCode\nlist\n\n\n[[1]]\n[1] \"Amiya\"\n\n[[2]]\n[1] \"Raj\"\n\n[[3]]\n[1] \"Asish\"",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#matrix-to-other-data-format",
    "href": "data manipulation/2 data structure in R.html#matrix-to-other-data-format",
    "title": "Data structure in R",
    "section": "3.1 matrix to other data format",
    "text": "3.1 matrix to other data format\n\n3.1.1 matrix to dataframe\n\n\nCode\ndf &lt;- as.data.frame(matrix003)\n\nclass(df)\n\n\n[1] \"data.frame\"\n\n\n\n\nCode\ndf\n\n\n  V1 V2 V3\n1  1  4  9\n2 16 25 36\n3 49 64 81\n\n\n\n\n3.1.2 matrix to vector\n\n\nCode\nvec=as.vector(matrix003)\n\nclass(vec)\n\n\n[1] \"numeric\"\n\n\n\n\nCode\nvec\n\n\n[1]  1 16 49  4 25 64  9 36 81\n\n\n\n\n3.1.3 matrix to list\n\n\nCode\nlist=as.list(matrix003)\n\nclass(list)\n\n\n[1] \"list\"\n\n\n\n\nCode\nlist\n\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 16\n\n[[3]]\n[1] 49\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] 25\n\n[[6]]\n[1] 64\n\n[[7]]\n[1] 9\n\n[[8]]\n[1] 36\n\n[[9]]\n[1] 81",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "data manipulation/5 recipe.html",
    "href": "data manipulation/5 recipe.html",
    "title": "recipe",
    "section": "",
    "text": "1 create recipe step_xxx\n\n\nCode\ntree_rec &lt;- recipe(legal_status ~ ., data = trees_train) %&gt;%\n  \n # update the role for tree_id, since this is a variable we might like to keep around for convenience as an identifier for rows but is not a predictor or outcome. \n  update_role(tree_id, new_role = \"ID\") %&gt;%\n  \n# step_other() to collapse categorical levels for species, caretaker, and the site info. Before this step, there were 300+ species!\n  step_other(species, caretaker, threshold = 0.01) %&gt;%\n  \n# create dummy for nominal data exclude outcome\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  \n# The date column with when each tree was planted may be useful for fitting this model, but probably not the exact date, given how slowly trees grow. Let’s create a year feature from the date, and then remove the original date variable.  \n  step_date(date, features = c(\"year\")) %&gt;%step_rm(date) %&gt;%\n  \n# There are many more DPW maintained trees than not, so let’s downsample the data for training.  \n  step_downsample(legal_status)%&gt;%\n\n# will remove all. predictor variables that contain only a single value\n    step_zv(all_numeric(all_predictors())) %&gt;% \n  \n#  normalize all numeric data\n  step_normalize(all_numeric()) %&gt;% \n\n# use KNN to impute all predictors\nstep_impute_knn(all_predictors()) \n\n\n\n\n2 check recipe check_xxx\n\n\nCode\n#&gt; [1] \"check_class\"      \"check_cols\"       \"check_missing\"   \n#&gt; [4] \"check_name\"       \"check_new_data\"   \"check_new_values\"\n#&gt; [7] \"check_range\"      \"check_type\"\n\n\n\n\n3 roles to select variables\nIn most cases, the right approach for users will be use to use the predictor-specific selectors such as all_numeric_predictors() and all_nominal_predictors().\n\n\nCode\nhas_role(match = \"predictor\")\n\nhas_type(match = \"numeric\")\n\nall_outcomes()\n\nall_predictors()\n\nall_date()\n\nall_date_predictors()\n\nall_datetime()\n\nall_datetime_predictors()\n\nall_double()\n\nall_double_predictors()\n\nall_factor()\n\nall_factor_predictors()\n\nall_integer()\n\nall_integer_predictors()\n\nall_logical()\n\nall_logical_predictors()\n\nall_nominal()\n\nall_nominal_predictors()\n\nall_numeric()\n\nall_numeric_predictors()\n\nall_ordered()\n\nall_ordered_predictors()\n\nall_string()\n\nall_string_predictors()\n\nall_unordered()\n\nall_unordered_predictors()\n\ncurrent_info()\n\n\n\n\n4 reference:\nhttps://recipes.tidymodels.org/reference/has_role.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "data manipulation",
      "recipe"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html",
    "href": "data manipulation/3 data manipulation with tidyverse.html",
    "title": "Data manipulation with tidyverse",
    "section": "",
    "text": "The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.\ndplyr is a grammar of data manipulation, providing a consistent set of verbs that help you solve the most common data manipulation challenges.",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.1 select column",
    "text": "2.1 select column",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#get-column-names",
    "href": "data manipulation/3 data manipulation with tidyverse.html#get-column-names",
    "title": "Data manipulation with tidyverse",
    "section": "2.2 get column names",
    "text": "2.2 get column names\n\n\nCode\nnames(small_mtcars)\n\n\n[1] \"car_name\" \"cyl\"      \"mpg\"      \"hp\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-by-name",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-by-name",
    "title": "Data manipulation with tidyverse",
    "section": "2.3 select by name",
    "text": "2.3 select by name\n\n\nCode\nmtcars %&gt;% select(cyl, mpg,hp) \n\n\n                    cyl  mpg  hp\nMazda RX4             6 21.0 110\nMazda RX4 Wag         6 21.0 110\nDatsun 710            4 22.8  93\nHornet 4 Drive        6 21.4 110\nHornet Sportabout     8 18.7 175\nValiant               6 18.1 105\nDuster 360            8 14.3 245\nMerc 240D             4 24.4  62\nMerc 230              4 22.8  95\nMerc 280              6 19.2 123\nMerc 280C             6 17.8 123\nMerc 450SE            8 16.4 180\nMerc 450SL            8 17.3 180\nMerc 450SLC           8 15.2 180\nCadillac Fleetwood    8 10.4 205\nLincoln Continental   8 10.4 215\nChrysler Imperial     8 14.7 230\nFiat 128              4 32.4  66\nHonda Civic           4 30.4  52\nToyota Corolla        4 33.9  65\nToyota Corona         4 21.5  97\nDodge Challenger      8 15.5 150\nAMC Javelin           8 15.2 150\nCamaro Z28            8 13.3 245\nPontiac Firebird      8 19.2 175\nFiat X1-9             4 27.3  66\nPorsche 914-2         4 26.0  91\nLotus Europa          4 30.4 113\nFord Pantera L        8 15.8 264\nFerrari Dino          6 19.7 175\nMaserati Bora         8 15.0 335\nVolvo 142E            4 21.4 109",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-name-match-with-p",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-name-match-with-p",
    "title": "Data manipulation with tidyverse",
    "section": "2.4 select columns by name match with ‘p’",
    "text": "2.4 select columns by name match with ‘p’",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-index",
    "href": "data manipulation/3 data manipulation with tidyverse.html#select-columns-by-index",
    "title": "Data manipulation with tidyverse",
    "section": "2.5 select columns by index",
    "text": "2.5 select columns by index\n\n2.5.1 select first and 3rd columns\n\n\n2.5.2 select first to 3rd columns",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#drop-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#drop-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.6 drop column",
    "text": "2.6 drop column\n\n\nCode\nsmall_mtcars %&gt;% select(-cyl)\n\n\n           car_name  mpg  hp\n1         Mazda RX4 21.0 110\n2     Mazda RX4 Wag 21.0 110\n3        Datsun 710 22.8  93\n4    Hornet 4 Drive 21.4 110\n5 Hornet Sportabout 18.7 175\n6           Valiant 18.1 105",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#renaming-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#renaming-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.7 Renaming column",
    "text": "2.7 Renaming column\n\n\nCode\nsmall_mtcars %&gt;%rename(new_cyl=cyl)\n\n\n           car_name new_cyl  mpg  hp\n1         Mazda RX4       6 21.0 110\n2     Mazda RX4 Wag       6 21.0 110\n3        Datsun 710       4 22.8  93\n4    Hornet 4 Drive       6 21.4 110\n5 Hornet Sportabout       8 18.7 175\n6           Valiant       6 18.1 105",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#create-column",
    "href": "data manipulation/3 data manipulation with tidyverse.html#create-column",
    "title": "Data manipulation with tidyverse",
    "section": "2.8 Create column",
    "text": "2.8 Create column\n\n2.8.1 Mutate\n\n\nCode\nsmall_mtcars %&gt;%mutate(new_cyl=cyl+1)\n\n\n           car_name cyl  mpg  hp new_cyl\n1         Mazda RX4   6 21.0 110       7\n2     Mazda RX4 Wag   6 21.0 110       7\n3        Datsun 710   4 22.8  93       5\n4    Hornet 4 Drive   6 21.4 110       7\n5 Hornet Sportabout   8 18.7 175       9\n6           Valiant   6 18.1 105       7\n\n\n\n\n2.8.2 if else\n\n\nCode\nsmall_mtcars %&gt;%mutate(new_cly_group=if_else(cyl&gt;6,'big','small'))\n\n\n           car_name cyl  mpg  hp new_cly_group\n1         Mazda RX4   6 21.0 110         small\n2     Mazda RX4 Wag   6 21.0 110         small\n3        Datsun 710   4 22.8  93         small\n4    Hornet 4 Drive   6 21.4 110         small\n5 Hornet Sportabout   8 18.7 175           big\n6           Valiant   6 18.1 105         small\n\n\n\n\n2.8.3 case when\n\n\nCode\nsmall_mtcars %&gt;%mutate(cly_group=case_when(\n    cyl &gt; 6 ~ \"very big\",\n    cyl &gt; 4 ~ \"big\",\n    TRUE ~ \"other\",\n  ))\n\n\n           car_name cyl  mpg  hp cly_group\n1         Mazda RX4   6 21.0 110       big\n2     Mazda RX4 Wag   6 21.0 110       big\n3        Datsun 710   4 22.8  93     other\n4    Hornet 4 Drive   6 21.4 110       big\n5 Hornet Sportabout   8 18.7 175  very big\n6           Valiant   6 18.1 105       big\n\n\n\n\n2.8.4 Transmute,create column and only keep this column\n\n\nCode\nsmall_mtcars %&gt;%transmute(new_cyl=cyl+1)\n\n\n  new_cyl\n1       7\n2       7\n3       5\n4       7\n5       9\n6       7",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#filter-rows",
    "href": "data manipulation/3 data manipulation with tidyverse.html#filter-rows",
    "title": "Data manipulation with tidyverse",
    "section": "2.9 Filter rows",
    "text": "2.9 Filter rows\n\n\nCode\nsmall_mtcars %&gt;%filter(cyl&gt;5)\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3    Hornet 4 Drive   6 21.4 110\n4 Hornet Sportabout   8 18.7 175\n5           Valiant   6 18.1 105\n\n\n\n2.9.1 Filters with AND conditions\n\n\nCode\nsmall_mtcars %&gt;%filter(cyl&gt;5,mpg&gt;20)\n\n\n        car_name cyl  mpg  hp\n1      Mazda RX4   6 21.0 110\n2  Mazda RX4 Wag   6 21.0 110\n3 Hornet 4 Drive   6 21.4 110\n\n\n\n\n2.9.2 Filters with OR conditions\n\n\nCode\nsmall_mtcars %&gt;%filter(cyl&gt;5|mpg&gt;20)\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175\n6           Valiant   6 18.1 105\n\n\n\n\n2.9.3 filter row with index\n\n2.9.3.1 5th rows\n\n\nCode\nsmall_mtcars %&gt;% slice(5)\n\n\n           car_name cyl  mpg  hp\n1 Hornet Sportabout   8 18.7 175\n\n\n\n\n2.9.3.2 1 and 5h rows\n\n\nCode\nsmall_mtcars %&gt;% slice(1:5)\n\n\n           car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175\n\n\n\n\n2.9.3.3 get ramdon 5 rows\n\n\nCode\nsmall_mtcars %&gt;% sample_n(5)\n\n\n        car_name cyl  mpg  hp\n1     Datsun 710   4 22.8  93\n2        Valiant   6 18.1 105\n3  Mazda RX4 Wag   6 21.0 110\n4 Hornet 4 Drive   6 21.4 110\n5      Mazda RX4   6 21.0 110",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#append",
    "href": "data manipulation/3 data manipulation with tidyverse.html#append",
    "title": "Data manipulation with tidyverse",
    "section": "2.10 Append",
    "text": "2.10 Append\n\n2.10.1 append by row\n\n\nCode\nsmall_mtcars %&gt;% rbind(small_mtcars)\n\n\n            car_name cyl  mpg  hp\n1          Mazda RX4   6 21.0 110\n2      Mazda RX4 Wag   6 21.0 110\n3         Datsun 710   4 22.8  93\n4     Hornet 4 Drive   6 21.4 110\n5  Hornet Sportabout   8 18.7 175\n6            Valiant   6 18.1 105\n7          Mazda RX4   6 21.0 110\n8      Mazda RX4 Wag   6 21.0 110\n9         Datsun 710   4 22.8  93\n10    Hornet 4 Drive   6 21.4 110\n11 Hornet Sportabout   8 18.7 175\n12           Valiant   6 18.1 105\n\n\n\n\n2.10.2 append by column\n\n\nCode\nsmall_mtcars %&gt;% cbind(small_mtcars)\n\n\n           car_name cyl  mpg  hp          car_name cyl  mpg  hp\n1         Mazda RX4   6 21.0 110         Mazda RX4   6 21.0 110\n2     Mazda RX4 Wag   6 21.0 110     Mazda RX4 Wag   6 21.0 110\n3        Datsun 710   4 22.8  93        Datsun 710   4 22.8  93\n4    Hornet 4 Drive   6 21.4 110    Hornet 4 Drive   6 21.4 110\n5 Hornet Sportabout   8 18.7 175 Hornet Sportabout   8 18.7 175\n6           Valiant   6 18.1 105           Valiant   6 18.1 105\n\n\n\n\n2.10.3 Sepcial vales\n\n2.10.3.1 NAN\nNaN (“Not a Number”) means 0/0\n\n\nCode\nv1 &lt;- NaN\nv1\n\n\n[1] NaN\n\n\n\n\nCode\nis.na(v1)\n\n\n[1] TRUE\n\n\n\n\n2.10.3.2 NA\nNA (“Not Available”) is generally interpreted as a missing value\n\n\nCode\nv2 &lt;- NA\nv2\n\n\n[1] NA\n\n\n\n\nCode\nis.na(v2)\n\n\n[1] TRUE\n\n\n\n\n2.10.3.3 NULL\nNULL is an object and is returned when an expression or function results in an undefined value. In R language, NULL (capital letters) is a reserved word\n\n\nCode\nv3=NULL\nv3\n\n\nNULL\n\n\n\n\nCode\nis.na(v3)\n\n\nlogical(0)",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#group-by",
    "href": "data manipulation/3 data manipulation with tidyverse.html#group-by",
    "title": "Data manipulation with tidyverse",
    "section": "2.11 group by",
    "text": "2.11 group by\n\n2.11.1 average,min,max,sum\n\n\nCode\nsmall_mtcars %&gt;%group_by(cyl) %&gt;% summarise(avg_mpg=mean(mpg)\n                                            ,min_mpg=min(mpg)\n                                            ,max_mpg=max(mpg)\n                                            ,sum_mpg=sum(mpg))\n\n\n# A tibble: 3 × 5\n    cyl avg_mpg min_mpg max_mpg sum_mpg\n  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1     4    22.8    22.8    22.8    22.8\n2     6    20.4    18.1    21.4    81.5\n3     8    18.7    18.7    18.7    18.7\n\n\n\n\n2.11.2 count record and count distinct record\n\n\nCode\nsmall_mtcars %&gt;%group_by(cyl) %&gt;% summarise(n_mpg=n()\n                                            ,distinct_n_mpg=n_distinct(mpg)\n                                            \n                                            )\n\n\n# A tibble: 3 × 3\n    cyl n_mpg distinct_n_mpg\n  &lt;dbl&gt; &lt;int&gt;          &lt;int&gt;\n1     4     1              1\n2     6     4              3\n3     8     1              1",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#order-rows",
    "href": "data manipulation/3 data manipulation with tidyverse.html#order-rows",
    "title": "Data manipulation with tidyverse",
    "section": "2.12 order rows",
    "text": "2.12 order rows\n\n\nCode\nsmall_mtcars %&gt;%arrange(cyl) \n\n\n           car_name cyl  mpg  hp\n1        Datsun 710   4 22.8  93\n2         Mazda RX4   6 21.0 110\n3     Mazda RX4 Wag   6 21.0 110\n4    Hornet 4 Drive   6 21.4 110\n5           Valiant   6 18.1 105\n6 Hornet Sportabout   8 18.7 175\n\n\n\n2.12.1 Sort in descending order\n\n\nCode\nsmall_mtcars %&gt;%arrange(desc(cyl) )\n\n\n           car_name cyl  mpg  hp\n1 Hornet Sportabout   8 18.7 175\n2         Mazda RX4   6 21.0 110\n3     Mazda RX4 Wag   6 21.0 110\n4    Hornet 4 Drive   6 21.4 110\n5           Valiant   6 18.1 105\n6        Datsun 710   4 22.8  93\n\n\n\n\n2.12.2 Arrange by multiple variables\n\n\nCode\nsmall_mtcars %&gt;%arrange(cyl,mpg)\n\n\n           car_name cyl  mpg  hp\n1        Datsun 710   4 22.8  93\n2           Valiant   6 18.1 105\n3         Mazda RX4   6 21.0 110\n4     Mazda RX4 Wag   6 21.0 110\n5    Hornet 4 Drive   6 21.4 110\n6 Hornet Sportabout   8 18.7 175",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#join",
    "href": "data manipulation/3 data manipulation with tidyverse.html#join",
    "title": "Data manipulation with tidyverse",
    "section": "2.13 join",
    "text": "2.13 join\n\n\nCode\nleft_data=small_mtcars %&gt;% slice(1:2)\nright_data=small_mtcars %&gt;% slice(2:4)\n\n\n\n\nCode\nleft_data\n\n\n       car_name cyl mpg  hp\n1     Mazda RX4   6  21 110\n2 Mazda RX4 Wag   6  21 110\n\n\n\n\nCode\nright_data\n\n\n        car_name cyl  mpg  hp\n1  Mazda RX4 Wag   6 21.0 110\n2     Datsun 710   4 22.8  93\n3 Hornet 4 Drive   6 21.4 110\n\n\n\n2.13.1 inner_join\n\n\nCode\ndata=left_data %&gt;% inner_join(right_data,join_by(car_name== car_name), suffix = c(\"_l\", \"._r\"))\ndata\n\n\n       car_name cyl_l mpg_l hp_l cyl._r mpg._r hp._r\n1 Mazda RX4 Wag     6    21  110      6     21   110\n\n\n\n\n2.13.2 left join\n\n\nCode\ndata=left_data %&gt;% left_join(right_data,join_by(car_name== car_name), suffix = c(\"_l\", \"._r\"))\ndata\n\n\n       car_name cyl_l mpg_l hp_l cyl._r mpg._r hp._r\n1     Mazda RX4     6    21  110     NA     NA    NA\n2 Mazda RX4 Wag     6    21  110      6     21   110\n\n\n\n\n2.13.3 full join\n\n\nCode\ndata=left_data %&gt;% full_join(right_data,join_by(car_name== car_name), suffix = c(\"_l\", \"._r\"))\ndata\n\n\n        car_name cyl_l mpg_l hp_l cyl._r mpg._r hp._r\n1      Mazda RX4     6    21  110     NA     NA    NA\n2  Mazda RX4 Wag     6    21  110      6   21.0   110\n3     Datsun 710    NA    NA   NA      4   22.8    93\n4 Hornet 4 Drive    NA    NA   NA      6   21.4   110\n\n\n\n\n2.13.4 anti join\nanti_join() return all rows from x without a match in y\n\n\nCode\ndata=left_data %&gt;% anti_join(right_data,join_by(car_name== car_name))\ndata\n\n\n   car_name cyl mpg  hp\n1 Mazda RX4   6  21 110",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#reshape-tables",
    "href": "data manipulation/3 data manipulation with tidyverse.html#reshape-tables",
    "title": "Data manipulation with tidyverse",
    "section": "2.14 Reshape tables",
    "text": "2.14 Reshape tables\n\n\nCode\nolddata_wide &lt;- read.table(header=TRUE, text='\n subject sex control cond1 cond2\n       1   M     7.9  12.3  10.7\n       2   F     6.3  10.6  11.1\n       3   F     9.5  13.1  13.8\n       4   M    11.5  13.4  12.9\n')\n\n\n\n\nCode\nolddata_wide\n\n\n  subject sex control cond1 cond2\n1       1   M     7.9  12.3  10.7\n2       2   F     6.3  10.6  11.1\n3       3   F     9.5  13.1  13.8\n4       4   M    11.5  13.4  12.9\n\n\n\n2.14.1 Gather data long(wide to long)\n\n\nCode\ndata_long=olddata_wide %&gt;%\n  pivot_longer(!c(subject,sex), names_to = 'income', values_to = 'DATA')\n\ndata_long\n\n\n# A tibble: 12 × 4\n   subject sex   income   DATA\n     &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1       1 M     control   7.9\n 2       1 M     cond1    12.3\n 3       1 M     cond2    10.7\n 4       2 F     control   6.3\n 5       2 F     cond1    10.6\n 6       2 F     cond2    11.1\n 7       3 F     control   9.5\n 8       3 F     cond1    13.1\n 9       3 F     cond2    13.8\n10       4 M     control  11.5\n11       4 M     cond1    13.4\n12       4 M     cond2    12.9\n\n\n\n\n2.14.2 Spread data wide (long to wide)\n\n\nCode\ndata_wide=data_long %&gt;%\n  pivot_wider(names_from = income, values_from = DATA)\n\ndata_wide\n\n\n# A tibble: 4 × 5\n  subject sex   control cond1 cond2\n    &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1       1 M         7.9  12.3  10.7\n2       2 F         6.3  10.6  11.1\n3       3 F         9.5  13.1  13.8\n4       4 M        11.5  13.4  12.9",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#length",
    "href": "data manipulation/3 data manipulation with tidyverse.html#length",
    "title": "Data manipulation with tidyverse",
    "section": "3.1 length",
    "text": "3.1 length\n\n\nCode\nx &lt;- \"I like horses.\"\nstr_length(x)\n\n\n[1] 14",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#upper-case",
    "href": "data manipulation/3 data manipulation with tidyverse.html#upper-case",
    "title": "Data manipulation with tidyverse",
    "section": "3.2 upper case",
    "text": "3.2 upper case\n\n\nCode\nx &lt;- \"I like horses.\"\n\nstr_to_upper(x)\n\n\n[1] \"I LIKE HORSES.\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#lower-case",
    "href": "data manipulation/3 data manipulation with tidyverse.html#lower-case",
    "title": "Data manipulation with tidyverse",
    "section": "3.3 lower case",
    "text": "3.3 lower case\n\n\nCode\nx &lt;- \"I like horses.\"\n\nstr_to_lower(x)\n\n\n[1] \"i like horses.\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#match",
    "href": "data manipulation/3 data manipulation with tidyverse.html#match",
    "title": "Data manipulation with tidyverse",
    "section": "3.4 match",
    "text": "3.4 match\n\n\nCode\nword_list=c('abc','bbc','appale','bbaa','cc')\n\n\n\n3.4.1 match with ‘a’\n\n\nCode\nword_list %&gt;% str_detect('a')\n\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n\n\n\n3.4.2 match with ‘a’ count\n\n\nCode\nword_list %&gt;% str_count('a')\n\n\n[1] 1 0 2 2 0\n\n\n\n\n3.4.3 index of vector match\n\n\nCode\nword_list %&gt;% str_which('a')\n\n\n[1] 1 3 4\n\n\n\n\n3.4.4 index of each word match (first match)\n\n\nCode\nword_list %&gt;% str_locate('a')\n\n\n     start end\n[1,]     1   1\n[2,]    NA  NA\n[3,]     1   1\n[4,]     3   3\n[5,]    NA  NA\n\n\n\n\n3.4.5 index of each word match (all match)\n\n\nCode\nword_list %&gt;% str_locate_all('a')\n\n\n[[1]]\n     start end\n[1,]     1   1\n\n[[2]]\n     start end\n\n[[3]]\n     start end\n[1,]     1   1\n[2,]     4   4\n\n[[4]]\n     start end\n[1,]     3   3\n[2,]     4   4\n\n[[5]]\n     start end\n\n\n\n\nCode\ntrx='abc1993'\n\nnum=str_match(trx, \"(\\\\d)+\")\n\nnum\n\n\n     [,1]   [,2]\n[1,] \"1993\" \"3\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#concatenation",
    "href": "data manipulation/3 data manipulation with tidyverse.html#concatenation",
    "title": "Data manipulation with tidyverse",
    "section": "3.5 concatenation",
    "text": "3.5 concatenation\n\n\nCode\na='aaaa'\nb='bbbb'\n\n\n\n\nCode\npaste(a,b)\n\n\n[1] \"aaaa bbbb\"\n\n\n\n\nCode\npaste0(a,b)\n\n\n[1] \"aaaabbbb\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#replace",
    "href": "data manipulation/3 data manipulation with tidyverse.html#replace",
    "title": "Data manipulation with tidyverse",
    "section": "3.6 replace",
    "text": "3.6 replace\nstr_replace()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace('b','1')\n\n\n[1] \"a1cb\"\n\n\nstr_replace_all()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace_all('b','1')\n\n\n[1] \"a1c1\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#extract",
    "href": "data manipulation/3 data manipulation with tidyverse.html#extract",
    "title": "Data manipulation with tidyverse",
    "section": "3.8 extract",
    "text": "3.8 extract\n\n\nCode\ndata001=mtcars\ndata001 &lt;- cbind(names = rownames(data001), data001)\n\n\n\n3.8.1 subset string by postion\nextract 2 to 4\n\n\nCode\ndata001$new_names=data001$names %&gt;% str_sub(2,4)\nhead(data001 %&gt;% select(new_names,names))\n\n\n                  new_names             names\nMazda RX4               azd         Mazda RX4\nMazda RX4 Wag           azd     Mazda RX4 Wag\nDatsun 710              ats        Datsun 710\nHornet 4 Drive          orn    Hornet 4 Drive\nHornet Sportabout       orn Hornet Sportabout\nValiant                 ali           Valiant\n\n\n\n\n3.8.2 extracting number from a string\n\n\nCode\ntrx='abc1993 ccc'\n\nnum=str_extract(trx, \"(\\\\d)+\")\n\nnum\n\n\n[1] \"1993\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#date-format",
    "href": "data manipulation/3 data manipulation with tidyverse.html#date-format",
    "title": "Data manipulation with tidyverse",
    "section": "4.1 date format",
    "text": "4.1 date format\ninput as character\n\n\nCode\ndate1='2023-01-01'\nclass(date1)\n\n\n[1] \"character\"\n\n\n\n\nCode\ndate1\n\n\n[1] \"2023-01-01\"\n\n\nconvert into date type with as.Date()\n\n\nCode\ndate2=as.Date('2023-01-01')\nclass(date2)\n\n\n[1] \"Date\"\n\n\n\n\nCode\ndate2\n\n\n[1] \"2023-01-01\"\n\n\nconvert into date type with ymd()\n\n\nCode\ndate3=ymd('2023-01-01')\nclass(date3)\n\n\n[1] \"Date\"\n\n\n\n\nCode\ndate3\n\n\n[1] \"2023-01-01\"\n\n\nget today with today()\n\n\nCode\ntoday()\n\n\n[1] \"2024-06-18\"\n\n\nget local timezone\n\n\nCode\nSys.timezone()\n\n\n[1] \"Asia/Shanghai\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#change-date-format",
    "href": "data manipulation/3 data manipulation with tidyverse.html#change-date-format",
    "title": "Data manipulation with tidyverse",
    "section": "4.2 change date format",
    "text": "4.2 change date format\nmake multiple column character to date with make_date()\n\n\nCode\nflights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_date(year, month, day))\n\n\n# A tibble: 336,776 × 6\n    year month   day  hour minute departure \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;date&gt;    \n 1  2013     1     1     5     15 2013-01-01\n 2  2013     1     1     5     29 2013-01-01\n 3  2013     1     1     5     40 2013-01-01\n 4  2013     1     1     5     45 2013-01-01\n 5  2013     1     1     6      0 2013-01-01\n 6  2013     1     1     5     58 2013-01-01\n 7  2013     1     1     6      0 2013-01-01\n 8  2013     1     1     6      0 2013-01-01\n 9  2013     1     1     6      0 2013-01-01\n10  2013     1     1     6      0 2013-01-01\n# ℹ 336,766 more rows\n\n\n\n\nCode\nflights %&gt;% \n  select(year, month, day, hour, minute) %&gt;% \n  mutate(departure = make_datetime(year, month, day, hour, minute))\n\n\n# A tibble: 336,776 × 6\n    year month   day  hour minute departure          \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dttm&gt;             \n 1  2013     1     1     5     15 2013-01-01 05:15:00\n 2  2013     1     1     5     29 2013-01-01 05:29:00\n 3  2013     1     1     5     40 2013-01-01 05:40:00\n 4  2013     1     1     5     45 2013-01-01 05:45:00\n 5  2013     1     1     6      0 2013-01-01 06:00:00\n 6  2013     1     1     5     58 2013-01-01 05:58:00\n 7  2013     1     1     6      0 2013-01-01 06:00:00\n 8  2013     1     1     6      0 2013-01-01 06:00:00\n 9  2013     1     1     6      0 2013-01-01 06:00:00\n10  2013     1     1     6      0 2013-01-01 06:00:00\n# ℹ 336,766 more rows",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#day-differnce-between-two-dates",
    "href": "data manipulation/3 data manipulation with tidyverse.html#day-differnce-between-two-dates",
    "title": "Data manipulation with tidyverse",
    "section": "4.3 day differnce between two dates",
    "text": "4.3 day differnce between two dates\n\n\nCode\nday1=ymd('2022-01-01')\nday2=ymd('2023-02-03')\n\ndiff=day2-day1\n\n\n\n\nCode\ndiff\n\n\nTime difference of 398 days\n\n\nusing interval() find two dates gap\n\n\nCode\ninterval(day1,day2) %&gt;% as.period()\n\n\n[1] \"1y 1m 2d 0H 0M 0S\"\n\n\nfind day gap\n\n\nCode\ninterval(day1,day2)%/% days(1)\n\n\n[1] 398\n\n\nfind month gap\n\n\nCode\ninterval(day1,day2)%/% months(1)\n\n\n[1] 13\n\n\nfind year gap\n\n\nCode\ninterval(day1,day2)%/% years(1)\n\n\n[1] 1",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#day-and-time",
    "href": "data manipulation/3 data manipulation with tidyverse.html#day-and-time",
    "title": "Data manipulation with tidyverse",
    "section": "4.4 day and time",
    "text": "4.4 day and time\n\n\nCode\nnow_time=now()\nnow_time\n\n\n[1] \"2024-06-18 16:48:43 CST\"\n\n\n\n4.4.1 get year\n\n\nCode\nyear(now_time)\n\n\n[1] 2024\n\n\n\n\n4.4.2 get month\n\n\nCode\nmonth(now_time)\n\n\n[1] 6\n\n\n\n\n4.4.3 get date of the month\n\n\nCode\nmday(now_time)\n\n\n[1] 18\n\n\n\n\n4.4.4 get date of the year\n\n\nCode\nyday(now_time)\n\n\n[1] 170\n\n\n\n\n4.4.5 get date of the week\n\n\nCode\nwday(now_time)\n\n\n[1] 3\n\n\n\n4.4.5.1 get hour\n\n\nCode\nhour(now_time)\n\n\n[1] 16\n\n\n\n\n\n4.4.6 get minute\n\n\nCode\nminute(now_time)\n\n\n[1] 48\n\n\n\n\n4.4.7 get second\n\n\nCode\nsecond(now_time)\n\n\n[1] 43.39117",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#dataframe-to-other-data-format",
    "href": "data manipulation/3 data manipulation with tidyverse.html#dataframe-to-other-data-format",
    "title": "Data manipulation with tidyverse",
    "section": "4.5 dataframe to other data format",
    "text": "4.5 dataframe to other data format\n\n4.5.1 dataframe to vector\n\n\nCode\ndata=small_mtcars$cyl\ndata\n\n\n[1] 6 6 4 6 8 6\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"numeric\"\n\n\n\n\n4.5.2 dataframe to matrix\n\n\nCode\ndata=data.matrix(small_mtcars)\ndata\n\n\n     car_name cyl  mpg  hp\n[1,]        4   6 21.0 110\n[2,]        5   6 21.0 110\n[3,]        1   4 22.8  93\n[4,]        2   6 21.4 110\n[5,]        3   8 18.7 175\n[6,]        6   6 18.1 105\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"matrix\" \"array\" \n\n\n\n\n4.5.3 dataframe to list\n\n\nCode\ndata=as.list(small_mtcars)\ndata\n\n\n$car_name\n[1] \"Mazda RX4\"         \"Mazda RX4 Wag\"     \"Datsun 710\"       \n[4] \"Hornet 4 Drive\"    \"Hornet Sportabout\" \"Valiant\"          \n\n$cyl\n[1] 6 6 4 6 8 6\n\n$mpg\n[1] 21.0 21.0 22.8 21.4 18.7 18.1\n\n$hp\n[1] 110 110  93 110 175 105\n\n\n\n\nCode\nclass(data)\n\n\n[1] \"list\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html",
    "href": "Plot/1 ggplot2.html",
    "title": "ggplot2 in R",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(ggpubr)\nlibrary(ggthemr)\n\nlibrary(ggplot2)\nlibrary(plotly)\n\nlibrary(magick)\npackageVersion(\"ggplot2\")\n\n\n[1] '3.5.1'\nCode\nlibrary(reshape2)\ntips=tips\nhead(tips)\n\n\n  total_bill  tip    sex smoker day   time size\n1      16.99 1.01 Female     No Sun Dinner    2\n2      10.34 1.66   Male     No Sun Dinner    3\n3      21.01 3.50   Male     No Sun Dinner    3\n4      23.68 3.31   Male     No Sun Dinner    2\n5      24.59 3.61 Female     No Sun Dinner    4\n6      25.29 4.71   Male     No Sun Dinner    4\nCode\ndata001=gapminder\nhead(data001)\n\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group",
    "href": "Plot/1 ggplot2.html#color-by-group",
    "title": "ggplot2 in R",
    "section": "1.1 color by group",
    "text": "1.1 color by group\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#size-by-group",
    "href": "Plot/1 ggplot2.html#size-by-group",
    "title": "ggplot2 in R",
    "section": "1.2 size by group",
    "text": "1.2 size by group\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,colour = sex,size=size)) + geom_point()\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#line-plot",
    "href": "Plot/1 ggplot2.html#line-plot",
    "title": "ggplot2 in R",
    "section": "1.3 line Plot",
    "text": "1.3 line Plot\n\n\nCode\ndata002= data001 %&gt;% group_by(continent,year) %&gt;% summarise(pop=sum(pop))\n\n\n\n\nCode\np=ggplot(data002 %&gt;%filter(continent=='Asia'), aes(year, pop)) + geom_line()\np\n\n\n\n\n\n\n\n\n\n\n1.3.1 change line size\n\n\nCode\np=ggplot(data002 %&gt;%filter(continent=='Asia'), aes(year, pop)) + geom_line(size=5)\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-1",
    "href": "Plot/1 ggplot2.html#color-by-group-1",
    "title": "ggplot2 in R",
    "section": "1.4 color by group",
    "text": "1.4 color by group\n\n\nCode\np=ggplot(data002, aes(year, pop,colour = continent)) + geom_line()\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-2",
    "href": "Plot/1 ggplot2.html#color-by-group-2",
    "title": "ggplot2 in R",
    "section": "2.1 color by group",
    "text": "2.1 color by group\n\n\nCode\nggplot(data002, aes(gdpPercap,,fill = continent)) +geom_histogram(position = 'dodge')",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#show-number",
    "href": "Plot/1 ggplot2.html#show-number",
    "title": "ggplot2 in R",
    "section": "3.1 show number",
    "text": "3.1 show number\n\n\nCode\nggplot(data002, aes(x=continent, y=pop)) +\n  geom_bar(stat=\"identity\")+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#change-bar-color",
    "href": "Plot/1 ggplot2.html#change-bar-color",
    "title": "ggplot2 in R",
    "section": "3.2 change bar color",
    "text": "3.2 change bar color\n\n\nCode\nggplot(data002, aes(x=continent, y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)\n\n\n\n\n\n\n\n\n\nCode\n# box plot",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#bar-plot-order",
    "href": "Plot/1 ggplot2.html#bar-plot-order",
    "title": "ggplot2 in R",
    "section": "3.3 bar plot order",
    "text": "3.3 bar plot order\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)\n\n\n\n\n\n\n\n\n\nCode\n# box plot\n\n\n\n\nCode\nggplot(data002, aes(x=reorder(continent,-pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)\n\n\n\n\n\n\n\n\n\nCode\n# box plot",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#horizontal-barplot",
    "href": "Plot/1 ggplot2.html#horizontal-barplot",
    "title": "ggplot2 in R",
    "section": "3.4 Horizontal Barplot",
    "text": "3.4 Horizontal Barplot\n`\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red')+scale_y_continuous(labels = scales::comma)+geom_text(aes(label = pop), vjust = -0.2)+coord_flip()\n\n\n\n\n\n\n\n\n\nCode\n# box plot",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#make-bar-transparency",
    "href": "Plot/1 ggplot2.html#make-bar-transparency",
    "title": "ggplot2 in R",
    "section": "3.5 make bar transparency",
    "text": "3.5 make bar transparency\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",fill='red' ,alpha=0.2)+coord_flip()",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#make-bar-close-to-axis",
    "href": "Plot/1 ggplot2.html#make-bar-close-to-axis",
    "title": "ggplot2 in R",
    "section": "3.6 make bar close to axis",
    "text": "3.6 make bar close to axis\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop)) +\n  geom_bar(stat=\"identity\",alpha=0.2,fill='red')+coord_flip()+scale_y_continuous(expand = expansion(mult = c(0, .1)))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#change-one-bar-color",
    "href": "Plot/1 ggplot2.html#change-one-bar-color",
    "title": "ggplot2 in R",
    "section": "3.7 change one bar color",
    "text": "3.7 change one bar color\n\n\nCode\nggplot(data002, aes(x=reorder(continent,pop), y=pop,fill=factor(ifelse(continent==\"Asia\",\"Highlighted\",\"Normal\")))) +\n  geom_bar(stat=\"identity\",alpha=0.2,show.legend = FALSE)+scale_fill_manual(name = \"continent\", values=c(\"red\",\"grey50\"))+coord_flip()+scale_y_continuous(expand = expansion(mult = c(0, .1)))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-3",
    "href": "Plot/1 ggplot2.html#color-by-group-3",
    "title": "ggplot2 in R",
    "section": "3.8 color by group",
    "text": "3.8 color by group",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#color-by-group-4",
    "href": "Plot/1 ggplot2.html#color-by-group-4",
    "title": "ggplot2 in R",
    "section": "5.1 color by group",
    "text": "5.1 color by group\n\n\nCode\np=ggplot(tips, aes(day,tip,color=sex)) + geom_jitter(position=position_jitterdodge())\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-title",
    "href": "Plot/1 ggplot2.html#add-title",
    "title": "ggplot2 in R",
    "section": "7.1 add title",
    "text": "7.1 add title\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-subtitle",
    "href": "Plot/1 ggplot2.html#add-subtitle",
    "title": "ggplot2 in R",
    "section": "7.2 add subtitle",
    "text": "7.2 add subtitle\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\",subtitle = \"Subtitle of the plot\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-footnote",
    "href": "Plot/1 ggplot2.html#add-footnote",
    "title": "ggplot2 in R",
    "section": "7.3 add footnote",
    "text": "7.3 add footnote\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+labs(caption = \"this is footnote\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#adjust-plot-size",
    "href": "Plot/1 ggplot2.html#adjust-plot-size",
    "title": "ggplot2 in R",
    "section": "7.4 adjust plot size",
    "text": "7.4 adjust plot size\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+theme(\n  plot.margin = margin(2, 2, 5, 5, \"cm\"))\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#adjust-text-size-and-center-title",
    "href": "Plot/1 ggplot2.html#adjust-text-size-and-center-title",
    "title": "ggplot2 in R",
    "section": "7.5 adjust text size and center title",
    "text": "7.5 adjust text size and center title\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ ggtitle(\"tip by sex\")+labs(caption = \"this is footnote\")\n\np+theme(plot.title = element_text(hjust = 0.5),text = element_text(size = 30))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#change-x-y-name",
    "href": "Plot/1 ggplot2.html#change-x-y-name",
    "title": "ggplot2 in R",
    "section": "7.6 change x y name",
    "text": "7.6 change x y name\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+xlab(\"new x name\") + ylab(\"new y name\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-chinese",
    "href": "Plot/1 ggplot2.html#add-chinese",
    "title": "ggplot2 in R",
    "section": "7.7 add chinese",
    "text": "7.7 add chinese\n\n\nCode\nlibrary(showtext)\nshowtext_auto()\n\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"新的 x name\")+ scale_y_continuous(name=\"新的 y name\")\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#x-y-break-and-scales-limit",
    "href": "Plot/1 ggplot2.html#x-y-break-and-scales-limit",
    "title": "ggplot2 in R",
    "section": "7.8 x y break and scales limit",
    "text": "7.8 x y break and scales limit\n\n7.8.1 x scales limit\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\np+ xlim(min=0, 20)\n\n\n\n\n\n\n\n\n\n\n\n7.8.2 y scales limit\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\np+ ylim(0, 100)\n\n\n\n\n\n\n\n\n\n\n\n7.8.3 adding second aix\n\n\nCode\ndata002= data001%&gt;% group_by(year,continent) %&gt;% summarise(pop=sum(pop),lifeExp=mean(lifeExp))%&gt;%filter(continent=='Asia')\n\n\nremove scientific notation\n\n\nCode\ncoeff=1/40000000\n\n\np=ggplot(data002, aes(year, pop)) + geom_col() +\n  geom_line(aes(year,lifeExp/ coeff),size=2, color = \"red\") +scale_y_continuous(\"pop\", sec.axis = sec_axis(~.*coeff, name = \"lifeExp\"),labels = scales::comma)\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-background-image",
    "href": "Plot/1 ggplot2.html#add-background-image",
    "title": "ggplot2 in R",
    "section": "11.2 add background image",
    "text": "11.2 add background image\n\n\nCode\nimg4=image_read(\"bee.png\")\n\n\"bee.png\"\n\n\n[1] \"bee.png\"\n\n\nCode\np=ggplot(tips, aes(tip, total_bill,color=sex)) + background_image(img4) +geom_point()+ scale_x_continuous(name=\"new x name\")+ scale_y_continuous(name=\"new y name\")\n\n\np",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "Plot/5 China accident map.html",
    "href": "Plot/5 China accident map.html",
    "title": "Shiny in R:China accident map",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/China_accident_map/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Shiny in R:China accident map"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-current-directory",
    "href": "intro/1 basic R.html#get-current-directory",
    "title": "Basic R",
    "section": "1.1 get current directory",
    "text": "1.1 get current directory\n\n\nCode\ngetwd()",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-all-file-name-under-current-directory",
    "href": "intro/1 basic R.html#get-all-file-name-under-current-directory",
    "title": "Basic R",
    "section": "1.2 get all file name under current directory",
    "text": "1.2 get all file name under current directory\n\n\nCode\nlist.files()\n\n\n[1] \"1 basic R_files\"               \"1 basic R.qmd\"                \n[3] \"1 basic R.rmarkdown\"           \"1-basic-R.rmarkdown\"          \n[5] \"2 probability.qmd\"             \"5 R boook.qmd\"                \n[7] \"6 data analytic in R book.qmd\" \"hotels.csv\"                   \n[9] \"images\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-all-file-name-under-currrents-parent-directory",
    "href": "intro/1 basic R.html#get-all-file-name-under-currrents-parent-directory",
    "title": "Basic R",
    "section": "1.3 get all file name under currrents parent directory",
    "text": "1.3 get all file name under currrents parent directory\n\n\nCode\nlist.files(\"../\")\n\n\n [1] \"_freeze\"                      \"_publish.yml\"                \n [3] \"_quarto.yml\"                  \"_site\"                       \n [5] \"clustering\"                   \"data manipulation\"           \n [7] \"docs\"                         \"foldableCodeBlcok.lua\"       \n [9] \"hotel classification model\"   \"house price regression model\"\n[11] \"images\"                       \"index_files\"                 \n[13] \"index.qmd\"                    \"intro\"                       \n[15] \"logo.jpg\"                     \"model type\"                  \n[17] \"Multiclass classification\"    \"other\"                       \n[19] \"Plot\"                         \"styles.css\"                  \n[21] \"tensorflow\"                   \"tidymodeling.Rproj\"          \n[23] \"titanic classification model\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#get-file-info",
    "href": "intro/1 basic R.html#get-file-info",
    "title": "Basic R",
    "section": "1.4 get file info",
    "text": "1.4 get file info\n\n\nCode\nfile.info(\"6 data analytic in R book.qmd\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#create-folder",
    "href": "intro/1 basic R.html#create-folder",
    "title": "Basic R",
    "section": "1.5 create folder",
    "text": "1.5 create folder\n\n\nCode\ndir.create('testing_folder')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#delete-folderfile",
    "href": "intro/1 basic R.html#delete-folderfile",
    "title": "Basic R",
    "section": "1.6 delete folder/file",
    "text": "1.6 delete folder/file\n\n\nCode\nfile.remove('testing_folder')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#copy-file",
    "href": "intro/1 basic R.html#copy-file",
    "title": "Basic R",
    "section": "1.7 copy file",
    "text": "1.7 copy file\n\n\nCode\nlibrary(fs)\nfile_copy('test.csv', 'test2.csv')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#download-file-from-internet",
    "href": "intro/1 basic R.html#download-file-from-internet",
    "title": "Basic R",
    "section": "1.8 download file from internet",
    "text": "1.8 download file from internet\n\n\nCode\nurl=\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\"\n\ndownload.file(url = url, destfile = \"hotels.csv\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#for-loop",
    "href": "intro/1 basic R.html#for-loop",
    "title": "Basic R",
    "section": "3.1 for Loop",
    "text": "3.1 for Loop\n\n\nCode\nfor (x in 1:4) {\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n\n\nwith break statement\n\n\nCode\nfor (x in 1:6) {\n  if (x == 4) {break}\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n\n\nwith next statement\n\n\nCode\nfor (x in 1:6) {\n  if (x == 4) {next}\n  print(x)\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 5\n[1] 6",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#error-handling-on-for-loopprint-out-error",
    "href": "intro/1 basic R.html#error-handling-on-for-loopprint-out-error",
    "title": "Basic R",
    "section": "3.2 Error handling on for Loop:print out error",
    "text": "3.2 Error handling on for Loop:print out error\n\n\nCode\nstuff &lt;- list(12, 9, 2, \"cat\", 25, 10, \"bird\")\n#stuff\n\n\n\n\nCode\nloop_num=0\n\nfor (i in 1:6) {\n  loop_num=loop_num+1\n  tryCatch (print(1+i),\n           \n           error = function(e){\n           message(paste(\"An error occurred for loop num\", loop_num,\":\\n\"), e)\n             \n         })\n}\n\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#while-loop",
    "href": "intro/1 basic R.html#while-loop",
    "title": "Basic R",
    "section": "3.3 while Loop",
    "text": "3.3 while Loop\n\n\nCode\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nwith break statement\n\n\nCode\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n  if (i == 4) {break}\n}\n\n\n[1] 1\n[1] 2\n[1] 3\n\n\nwith next statement\n\n\nCode\ni =1\n\nwhile (i &lt; 6) {\n  i &lt;- i + 1\n  if (i == 4){next}\n  print(i)\n}\n\n\n[1] 2\n[1] 3\n[1] 5\n[1] 6",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#error-handling-on-whie-loop-try-when-the-error-gone",
    "href": "intro/1 basic R.html#error-handling-on-whie-loop-try-when-the-error-gone",
    "title": "Basic R",
    "section": "3.4 Error handling on whie Loop: try when the error gone",
    "text": "3.4 Error handling on whie Loop: try when the error gone\n\n\nCode\ni=0\na=0\nwhile (i &lt; 4) {\n  a=a+1\n  print(i)\n  tryCatch({\n  asdfgaergae5gh5hae5h\n    i=i+1\n  },error = function(msg){print('eeeeeeee')\n    i=i-1\n    print(paste0(\"new i : \",i))\n   \n    })\n   if(a&gt;10){break}\n  }\n\n\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"\n[1] 0\n[1] \"eeeeeeee\"\n[1] \"new i : -1\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#without-arguments",
    "href": "intro/1 basic R.html#without-arguments",
    "title": "Basic R",
    "section": "4.1 without Arguments",
    "text": "4.1 without Arguments\n\n\nCode\nmy_function &lt;- function() { \n  print(\"Hello World!\")\n}\n\nmy_function()\n\n\n[1] \"Hello World!\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#with-arguments",
    "href": "intro/1 basic R.html#with-arguments",
    "title": "Basic R",
    "section": "4.2 with Arguments",
    "text": "4.2 with Arguments\n\n\nCode\nadding_ten &lt;- function(x) { \n  a=x+10\n  return(a)\n}\n\nadding_ten(5)\n\n\n[1] 15",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#with-default-arguments",
    "href": "intro/1 basic R.html#with-default-arguments",
    "title": "Basic R",
    "section": "4.3 with default Arguments",
    "text": "4.3 with default Arguments\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  return(a)\n}\n\n#if not define x, then x=10\n\nadding_ten()\n\n\n[1] 20",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-function-arguments",
    "href": "intro/1 basic R.html#check-function-arguments",
    "title": "Basic R",
    "section": "4.4 check function Arguments",
    "text": "4.4 check function Arguments\n\n\nCode\nargs(adding_ten)\n\n\nfunction (x = 10) \nNULL\n\n\nMany functions exhibit variadic behavior. That is, they can accept any num- ber of arguments, and it’s up to the user to decide how many arguments to provide. The functions c, data.frame, and list are all like this. When you call a function like data.frame, you can specify any number of members as arguments.\n\n\nCode\nargs(data.frame)\n\n\nfunction (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, \n    fix.empty.names = TRUE, stringsAsFactors = FALSE) \nNULL",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#warning-in-function",
    "href": "intro/1 basic R.html#warning-in-function",
    "title": "Basic R",
    "section": "4.5 warning in function",
    "text": "4.5 warning in function\nprint out warning\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  if(a&gt;50){\n    warning('its better than 50')\n  }\n  return(a)\n}\n\n\n\n\nCode\nadding_ten(100)\n\n\n[1] 110",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#stop-in-function",
    "href": "intro/1 basic R.html#stop-in-function",
    "title": "Basic R",
    "section": "4.6 stop in function",
    "text": "4.6 stop in function\nprint out stop error message\n\n\nCode\nadding_ten &lt;- function(x=10) { \n  a=x+10\n  if(a&gt;50){\n    stop('its better than 50')\n  }\n  return(a)\n}\n\n\n\n\nCode\nadding_ten(100)",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#use-try-to-by-pass-error",
    "href": "intro/1 basic R.html#use-try-to-by-pass-error",
    "title": "Basic R",
    "section": "4.7 use try to by pass error",
    "text": "4.7 use try to by pass error\n\n\nCode\ntry(adding_ten(100))\n\n\n[1] 110\n\n\nCode\n5+10\n\n\n[1] 15",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-r-version",
    "href": "intro/1 basic R.html#check-r-version",
    "title": "Basic R",
    "section": "6.1 check R version",
    "text": "6.1 check R version\n\n\nCode\nversion\n\n\n               _                           \nplatform       aarch64-apple-darwin20      \narch           aarch64                     \nos             darwin20                    \nsystem         aarch64, darwin20           \nstatus                                     \nmajor          4                           \nminor          3.1                         \nyear           2023                        \nmonth          06                          \nday            16                          \nsvn rev        84548                       \nlanguage       R                           \nversion.string R version 4.3.1 (2023-06-16)\nnickname       Beagle Scouts",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#install-r-package",
    "href": "intro/1 basic R.html#install-r-package",
    "title": "Basic R",
    "section": "6.2 install R package",
    "text": "6.2 install R package\n\n6.2.1 install from Cran\n99% of the time will install pacakge from The Comprehensive R Archive Network(cran).https://cran.r-project.org/\n\n\n\nCode\ninstall.packages('tidyverse')\n\n\n\n\n6.2.2 install from Github\n\n\nCode\npak::pkg_install(\"tidymodels/learntidymodels\")\n\n\n\n\n6.2.3 install from .tar.gz\n\n\nCode\ninstall.packages(\"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\")\n\n\n\n\n6.2.4 install from Bioconductor\n\n\nCode\npak::pkg_install(\"text2vec\")\n\n\n\n\n6.2.5 install from local\n\n\nCode\npak::local_install(\"cli\")",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-one-package-version",
    "href": "intro/1 basic R.html#check-one-package-version",
    "title": "Basic R",
    "section": "6.3 check one package version",
    "text": "6.3 check one package version\n\n\nCode\npackageVersion(\"tidyverse\")\n\n\n[1] '2.0.0'",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-pacakge-relationship",
    "href": "intro/1 basic R.html#check-pacakge-relationship",
    "title": "Basic R",
    "section": "6.4 check pacakge relationship",
    "text": "6.4 check pacakge relationship\n\n\nCode\npak::pkg_deps_explain(\"tibble\", \"rlang\")\n\n\ntibble -&gt; lifecycle -&gt; rlang\ntibble -&gt; pillar -&gt; lifecycle -&gt; rlang\ntibble -&gt; pillar -&gt; rlang\ntibble -&gt; pillar -&gt; vctrs -&gt; lifecycle -&gt; rlang\ntibble -&gt; pillar -&gt; vctrs -&gt; rlang\ntibble -&gt; rlang\ntibble -&gt; vctrs -&gt; lifecycle -&gt; rlang\ntibble -&gt; vctrs -&gt; rlang",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-pacakge-dependencies",
    "href": "intro/1 basic R.html#check-pacakge-dependencies",
    "title": "Basic R",
    "section": "6.5 check pacakge dependencies",
    "text": "6.5 check pacakge dependencies\n\n\nCode\npak::pkg_deps_tree(\"tibble\")\n\n\ntibble 3.2.1 ✨ ⬇ (684.10 kB)\n├─fansi 1.0.6 ✨ ⬇ (381.01 kB)\n├─lifecycle 1.0.4 ✨ ⬇ (124.48 kB)\n│ ├─cli 3.6.2 ✨ ⬇ (1.39 MB)\n│ ├─glue 1.7.0 ✨ ⬇ (159.26 kB)\n│ └─rlang 1.1.4 ✨ ⬇ (1.89 MB)\n├─magrittr 2.0.3 ✨ ⬇ (232.43 kB)\n├─pillar 1.9.0 ✨ ⬇ (648.86 kB)\n│ ├─cli\n│ ├─fansi\n│ ├─glue\n│ ├─lifecycle\n│ ├─rlang\n│ ├─utf8 1.2.4 ✨ ⬇ (206.92 kB)\n│ └─vctrs 0.6.5 ✨ ⬇ (1.88 MB)\n│   ├─cli\n│   ├─glue\n│   ├─lifecycle\n│   └─rlang\n├─pkgconfig 2.0.3 ✨ ⬇ (18.21 kB)\n├─rlang\n└─vctrs\n\nKey:  ✨ new |  ⬇ download",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-current-loaded-package",
    "href": "intro/1 basic R.html#check-current-loaded-package",
    "title": "Basic R",
    "section": "6.6 check current loaded package",
    "text": "6.6 check current loaded package\n\n\nCode\nsessionInfo()\n\n\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     R6_2.5.1          fastmap_1.1.1     xfun_0.43        \n [5] knitr_1.45        htmltools_0.5.8.1 rmarkdown_2.26    ps_1.7.6         \n [9] cli_3.6.2         processx_3.8.4    callr_3.7.6       pak_0.7.2        \n[13] compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1       evaluate_0.23    \n[17] yaml_2.3.8        rlang_1.1.3       jsonlite_1.8.8    htmlwidgets_1.6.4",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-all-package-version",
    "href": "intro/1 basic R.html#check-all-package-version",
    "title": "Basic R",
    "section": "6.7 check all package version",
    "text": "6.7 check all package version\n\n\nCode\nip = as.data.frame(installed.packages()[,c(1,3:4)])\nip = ip[is.na(ip$Priority),1:2,drop=FALSE]\nhead(ip)\n\n\n              Package Version\nabind           abind   1.4-5\nanytime       anytime   0.3.9\napplicable applicable   0.1.0\narchive       archive   1.1.7\narrow           arrow  15.0.1\nash               ash  1.0-15",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#check-package-install-loaciton",
    "href": "intro/1 basic R.html#check-package-install-loaciton",
    "title": "Basic R",
    "section": "6.8 check package install loaciton",
    "text": "6.8 check package install loaciton\n\n\nCode\n.libPaths()\n\n\n[1] \"/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library\"",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#uninstall-pacakge",
    "href": "intro/1 basic R.html#uninstall-pacakge",
    "title": "Basic R",
    "section": "6.9 uninstall pacakge",
    "text": "6.9 uninstall pacakge\n\n\nCode\nremove.packages('xxxxx')",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#centrality-mean-median-mode",
    "href": "intro/1 basic R.html#centrality-mean-median-mode",
    "title": "Basic R",
    "section": "9.1 Centrality: Mean, Median, Mode",
    "text": "9.1 Centrality: Mean, Median, Mode",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#spread-variance-standard-deviation-and-the-interquartile-range",
    "href": "intro/1 basic R.html#spread-variance-standard-deviation-and-the-interquartile-range",
    "title": "Basic R",
    "section": "9.2 Spread: Variance, Standard Deviation, and the Interquartile Range",
    "text": "9.2 Spread: Variance, Standard Deviation, and the Interquartile Range",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#covariance-and-correlation",
    "href": "intro/1 basic R.html#covariance-and-correlation",
    "title": "Basic R",
    "section": "9.3 Covariance and Correlation",
    "text": "9.3 Covariance and Correlation\nWhen analyzing data, it’s often useful to be able to investigate the rela- tionship between two numeric variables to assess trends. For example, you might expect height and weight observations to have a noticeable positive relationship—taller people tend to weigh more. Conversely, you might imag- ine that handspan and length of hair would have less of an association. One of the simplest and most common ways such associations are quantified and compared is through the idea of correlation, for which you need the covariance. The covariance expresses how much two numeric variables “change together” and the nature of that relationship,",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/1 basic R.html#correlationpearsons-product-moment-correlation-coefficient",
    "href": "intro/1 basic R.html#correlationpearsons-product-moment-correlation-coefficient",
    "title": "Basic R",
    "section": "9.4 Correlation,Pearson’s product-moment correlation coefficient",
    "text": "9.4 Correlation,Pearson’s product-moment correlation coefficient\nPearson’s sample correlation coef- ficient ρxy is computed by dividing the sample covariance by the product of the standard deviation of each data set\n\nSome Correlation Example:\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     R6_2.5.1          fastmap_1.1.1     xfun_0.43        \n [5] knitr_1.45        htmltools_0.5.8.1 rmarkdown_2.26    ps_1.7.6         \n [9] cli_3.6.2         processx_3.8.4    callr_3.7.6       pak_0.7.2        \n[13] compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1       evaluate_0.23    \n[17] yaml_2.3.8        rlang_1.1.3       jsonlite_1.8.8    htmlwidgets_1.6.4",
    "crumbs": [
      "Intro",
      "Basic R"
    ]
  },
  {
    "objectID": "intro/5 R boook.html",
    "href": "intro/5 R boook.html",
    "title": "R book",
    "section": "",
    "text": "The Art of R Programming\nby Norman Matloff 2011\n\n\n\nThe book of R\nby Tilman M. Davie 2016\n\n\n\nR in action\nby Robert I. Kabacoff 2011\n\n\n\nR Packages\nby Hadley Wickham Jennifer Bryan\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "R book"
    ]
  },
  {
    "objectID": "other/4 Map/1 China accident map with mapview.html",
    "href": "other/4 Map/1 China accident map with mapview.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nall_data=all_data %&gt;% mutate(text=paste0(incident_type,\" \",\"死亡人数:\",person_death_num,\" 受伤人数:\",person_injury_num)\n                             ,month_year= format_ISO8601(ymd(start_date), precision = \"ym\")\n                             )\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 24\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ text               &lt;chr&gt; \"火灾 死亡人数:3 受伤人数:10\", \"溃水 死亡人数:3 受…\n$ month_year         &lt;chr&gt; \"2024-04\", \"2024-04\", \"2024-01\", \"2024-02\", \"2024-0…\n\n\n\n\nCode\n#write.xlsx(all_data,'all_data.xlsx')\n\n\n\n\n4 chart\ngroup to month\n\n\nCode\nchartdata001=all_data %&gt;% group_by(month_year)  %&gt;%  summarise(person_death_num=sum(person_death_num)\n                                                           ,person_injury_num=sum(person_injury_num)\n                                                           )\n\n\nwide to long\n\n\nCode\nchartdata002=chartdata001 %&gt;%select(month_year,person_death_num,person_injury_num) %&gt;% \n  pivot_longer(!c(month_year), names_to = 'type', values_to = 'DATA')\n\n\n\n\nCode\ngg=ggplot(chartdata001, aes(x=month_year, y=person_death_num,label = person_death_num))+\n  geom_bar(stat=\"identity\",fill='red')+ geom_text(vjust = -1,\n              position = position_dodge(width = 0.9))+ theme_bw()\n\n\nggplotly(gg)\n\n\n\n\n\n\n\n\nCode\ngg=ggplot(chartdata002, aes(fill=type, y=DATA, x=month_year)) +\n    geom_col(position = \"dodge\") +\n    geom_text(aes(label = DATA), vjust = 1.5,\n              position = position_dodge(width = 0.9))+scale_y_log10()+ theme_light()\n\npp=ggplotly(gg)\n\npp\n\n\n\n\n\n\n\n\n5 map\n\n\nCode\nall_data2 =all_data %&gt;%  mutate(report=report %&gt;% str_trunc(100))\n\n\n\n\nCode\n#write.xlsx(all_data2,'all_data2.xlsx')\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(stringr)\n\nmapview(all_data2, map.types='OpenStreetMap',label='text',xcol = \"Longitude\", ycol = \"Latitude\", zcol='incident_type',cex=\"person_death_num\",crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n6 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\nhttps://maps.clb.org.hk/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 Map",
      "China accident map"
    ]
  },
  {
    "objectID": "other/5 other/4 quarto blog.html",
    "href": "other/5 other/4 quarto blog.html",
    "title": "quarto block",
    "section": "",
    "text": "1 add a output folder bottom\n\nadd foldableCodeBlcok.lua into blog root folder\nadd in _quarto.yml\n\nfilters: - fold_results.lua\n\nput following on code chunk\n\n{r, attr.output=‘.details summary=“sessionInfo()”’} #| echo: false sessionInfo()\nreferece:\nhttps://github.com/quarto-dev/quarto-cli/issues/341\nhttps://gist.github.com/atusy/f2b5b992e45c68ab6823499f2339c6e6\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.8.1 rstudioapi_0.16.0 yaml_2.3.8       \n [9] rmarkdown_2.26    knitr_1.45        jsonlite_1.8.8    xfun_0.43        \n[13] digest_0.6.35     rlang_1.1.3       evaluate_0.23    \n\n\n\n\n\n2 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "quarto block"
    ]
  },
  {
    "objectID": "other/5 other/2 translation.html",
    "href": "other/5 other/2 translation.html",
    "title": "Translation",
    "section": "",
    "text": "Code\nlibrary(polyglotr)\n\n\n\n1 Translation word\n\n\nCode\nword_translation &lt;- linguee_word_translation(\"fruit\", source_language = \"en\", target_language = \"zh\")\n\nword_translation\n\n\n[1] \"水果\" \"果香\" \"果子\" \"果品\" \"实\"   \"檎\"  \n\n\n\n\n2 translate sentences\n\n\nCode\ngoogle_get_supported_languages()\n\n\n# A tibble: 134 × 2\n   Language    `ISO-639 code`\n   &lt;chr&gt;       &lt;chr&gt;         \n 1 Afrikaans   af            \n 2 Albanian    sq            \n 3 Amharic     am            \n 4 Arabic      ar            \n 5 Armenian    hy            \n 6 Assamese    as            \n 7 Aymara      ay            \n 8 Azerbaijani az            \n 9 Bambara     bm            \n10 Basque      eu            \n# ℹ 124 more rows\n\n\n\n\nCode\ntexts &lt;- c(\"Hello, how are you?\", \n           \"I love programming!\", \n           \"This is a test.\")\n\nlanguages &lt;- c(\"es\", \"fr\", \"zh-CN\")\n\n\ncreate_translation_table(texts, languages)\n\n\n        original_word                     es                          fr\n1 Hello, how are you?     ¿Hola, cómo estás? Bonjour comment allez-vous?\n2 I love programming! ¡Me encanta programar!  J'adore la programmation !\n3     This is a test.    Esto es una prueba.              C'est un test.\n           zh-CN\n1       你好吗？\n2   我喜欢编程！\n3 这是一个测试。\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "Translation"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/2 one bottle review.html",
    "href": "other/2 Web scraping on whiskybase.com/2 one bottle review.html",
    "title": "on bottle review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/whisky/147142/macallan-12-year-old'\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ntext=page%&gt;% html_nodes(\"*\")%&gt;% html_text2()\n\n\n\n\nCode\nhead(text)\n\n\n[1] \"document.documentElement.className += 'js' Macallan 12-year-old - Ratings and reviews - Whiskybase {\\\"@context\\\":\\\"https:\\\\/\\\\/schema.org\\\\/\\\",\\\"@type\\\":\\\"Product\\\",\\\"name\\\":\\\"Macallan 12-year-old\\\",\\\"sku\\\":147142,\\\"brand\\\":{\\\"@type\\\":\\\"Brand\\\",\\\"name\\\":\\\"Macallan\\\"},\\\"gtin\\\":\\\"5010314017408\\\",\\\"gtin13\\\":\\\"5010314017408\\\",\\\"image\\\":\\\"https:\\\\/\\\\/static.whiskybase.com\\\\/storage\\\\/whiskies\\\\/1\\\\/4\\\\/7142\\\\/304090-normal.png\\\",\\\"offers\\\":{\\\"@type\\\":\\\"AggregateOffer\\\",\\\"lowPrice\\\":68.5799999999999982946974341757595539093017578125,\\\"highPrice\\\":288.41000000000002501110429875552654266357421875,\\\"priceCurrency\\\":\\\"EUR\\\",\\\"offerCount\\\":26},\\\"aggregateRating\\\":{\\\"@type\\\":\\\"AggregateRating\\\",\\\"bestRating\\\":100,\\\"worstRating\\\":0,\\\"ratingValue\\\":84.5499999999999971578290569595992565155029296875,\\\"reviewCount\\\":238},\\\"description\\\":\\\"Macallan 12-year-old 12 yr. The strength of this whisky is 40.0 % Vol. A bottle from Macallan\\\"}window.__exc = { e: [], a: function(e) { return window.application ? window.application.exec(e) : __exc.e.push(e) } } (function(c, l, a, r, i, t, y) { c[a] = c[a] || function() { (c[a].q = c[a].q || []).push(arguments) }; t = l.createElement(r); t.async = 1; t.src = \\\"https://www.clarity.ms/tag/\\\" + i; y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y); })(window, document, \\\"clarity\\\", \\\"script\\\", \\\"cdpmv56i88\\\");\"\n[2] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[3] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[4] \"document.documentElement.className += 'js'\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n[6] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n\n\n\n\nCode\nwrite_delim(tibble(text), \"./data/text.txt\")\n\n\n\n\nCode\nrating_people_num_list=c()\navg_price_list=c()\nlowest_price_list=c()\ncask_type_list=c() \npic_link_list=c()\nwb_id=c()\nstart_time=now()\ncask_number_list=c()\nnumber_of_bottle_list=c()\nscore_list=c()\nbottler_list=c()\nbottle_list=c()\nstrength_list=c()\n\norder_num=1\n\n\n\n\nCode\n###################### score\nbottle=(page%&gt;% html_nodes('h1')%&gt;% html_text())[1]\nbottle=bottle %&gt;% str_remove_all('\\n') %&gt;% str_remove_all('\\t')\nprint(paste0(\"bottle: \",(bottle)[1]))\n\n\n[1] \"bottle: Macallan12-year-old\"\n\n\nCode\nbottle_list=c(bottle_list,bottle)\n\n\n###################### score\nscore=(page%&gt;% html_nodes('.votes-rating-current')%&gt;% html_text())[1]\nprint(paste0(\"score: \",score))\n\n\n[1] \"score: 84.55\"\n\n\nCode\nscore_list=c(score_list,score)\n\n####################### rating_people_num\nrating_people_num=page%&gt;% html_nodes('.votes-count')%&gt;% html_text()\nprint(rating_people_num)[1]\n\n\n[1] \"238\" \"238\"\n\n\n[1] \"238\"\n\n\nCode\nrating_people_num_list=c(rating_people_num_list,rating_people_num[1])\n\n\n##################### lowest price\nlowest_price=page%&gt;% html_nodes('.wb--shop-links-panel--price')%&gt;% html_text()\nlowest_price2=if(identical(lowest_price, character(0))==TRUE){0}else{lowest_price}\nprint(lowest_price2)\n\n\n[1] \"€ 78.00\"\n\n\nCode\nlowest_price_list=c(lowest_price_list,lowest_price2)\n\n############################# average price\navg_price=page%&gt;% html_nodes('p+ p')%&gt;% html_text()\navg_price6=case_when(str_detect(avg_price, \"[0-9]\")==TRUE~avg_price,.default='')\nprint(paste('price is :',avg_price6[1]))\n\n\n[1] \"price is : € 128.49\"\n\n\nCode\navg_price_list=c(avg_price_list,avg_price6[1])\n\n################################## cask type\nbottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\nbottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\nbottle_name_value=data.frame(bottle_name,bottle_value)\ncask=bottle_name_value%&gt;% filter(bottle_name=='Cask Type') %&gt;% select(bottle_value)\ncask2=if(nrow(cask)==0){'unknow cask'}else{ unname(unlist(cask[1,]))}\nprint(cask2)\n\n\n[1] \"Sherry Seasoned Oak casks from Jerez\"\n\n\nCode\ncask_type_list=c(cask_type_list,cask2)\n\n################################## Bottler\n#bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n#bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n#bottle_name_value=data.frame(bottle_name,bottle_value)\nbottler=bottle_name_value%&gt;% filter(bottle_name=='Bottler') %&gt;% select(bottle_value)\nbottler=if(nrow(bottler)==0){'unknow Bottler'}else{ unname(unlist(bottler[1,]))}\nprint(bottler)\n\n\n[1] \"Distillery Bottling\"\n\n\nCode\nbottler_list=c(bottler_list,bottler)\n\n################################## strength\n#bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n#bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n#bottle_name_value=data.frame(bottle_name,bottle_value)\nstrength=bottle_name_value%&gt;% filter(bottle_name=='Strength') %&gt;% select(bottle_value)\nstrength=if(nrow(strength)==0){'unknow strength'}else{ unname(unlist(strength[1,]))}\nprint(strength)\n\n\n[1] \"40.0 % Vol.\"\n\n\nCode\nstrength_list=c(strength_list,strength)\n\n\n  \n##################### number_of_bottle \nnumber_of_bottle1=bottle_name_value%&gt;% filter(bottle_name=='Number of bottles') %&gt;% select(bottle_value)\nnumber_of_bottle2=if(nrow(number_of_bottle1)==0){'unknow Number of bottles'}else{ unname(unlist(number_of_bottle1[1,]))}\n  \nprint(number_of_bottle2)\n\n\n[1] \"unknow Number of bottles\"\n\n\nCode\nnumber_of_bottle_list=c(number_of_bottle_list,number_of_bottle2)\n  \n##################### Casknumber \ncask_number1=bottle_name_value%&gt;% filter(bottle_name=='Casknumber') %&gt;% select(bottle_value)\ncask_number2=if(nrow(cask_number1)==0){'unknow Casknumber'}else{ unname(unlist(cask_number1[1,]))}\n  \nprint(paste('casknumber:',cask_number2))\n\n\n[1] \"casknumber: unknow Casknumber\"\n\n\nCode\ncask_number_list=c(cask_number_list,cask_number2)\n  \n  \n########################################### wb id \nid_name=page%&gt;% html_nodes(' #whisky-details dd:nth-child(2)')%&gt;% html_text()\nprint(id_name)\n\n\n[1] \"WB147142\"\n\n\nCode\nwb_id=c(wb_id,id_name)\n  \n####### check \n  \nid_num=as.numeric(str_replace(id_name,'WB',''))\nprint(id_num)\n\n\n[1] 147142\n\n\nCode\na=(str_split(url,'/')[[1]])\nb=as.numeric(a[length(a)-1])\nprint(paste(\"wb id from link\",b))\n\n\n[1] \"wb id from link 147142\"\n\n\nCode\nprint(paste(\"wb id from page\",id_num))\n\n\n[1] \"wb id from page 147142\"\n\n\nCode\nif(id_num!=b){\n    print(i)\n    print('############## error !!!!!!!!##################')\n    break\n}\n##################     pic link   #######################\npic_link=(page%&gt;% html_nodes('.photo')%&gt;% html_attr('href'))[1]\npic_link2=if(identical(pic_link, character(0))==TRUE){0}else{pic_link}\n  \nprint(pic_link2)\n\n\n[1] \"https://static.whiskybase.com/storage/whiskies/1/4/7142/304090-big.jpg\"\n\n\nCode\npic_link_list=c(pic_link_list,pic_link2)\n#########################################################  \n\n\n\n\nCode\ndata=cbind(bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,url) %&gt;% as_tibble()\n\n\n\n\nCode\nglimpse(data)\n\n\nRows: 1\nColumns: 13\n$ bottle_list            &lt;chr&gt; \"Macallan12-year-old\"\n$ score_list             &lt;chr&gt; \"84.55\"\n$ rating_people_num_list &lt;chr&gt; \"238\"\n$ lowest_price_list      &lt;chr&gt; \"€ 78.00\"\n$ avg_price_list         &lt;chr&gt; \"€ 128.49\"\n$ cask_type_list         &lt;chr&gt; \"Sherry Seasoned Oak casks from Jerez\"\n$ number_of_bottle_list  &lt;chr&gt; \"unknow Number of bottles\"\n$ bottler_list           &lt;chr&gt; \"Distillery Bottling\"\n$ strength_list          &lt;chr&gt; \"40.0 % Vol.\"\n$ cask_number_list       &lt;chr&gt; \"unknow Casknumber\"\n$ wb_id                  &lt;chr&gt; \"WB147142\"\n$ pic_link_list          &lt;chr&gt; \"https://static.whiskybase.com/storage/whiskies…\n$ url                    &lt;chr&gt; \"https://www.whiskybase.com/whiskies/whisky/147…\n\n\n\n1 output\n\n\nCode\nwrite.xlsx(data,'./output/one_page_review.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "on bottle review"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/5 all bottle from a distillery.html",
    "href": "other/2 Web scraping on whiskybase.com/5 all bottle from a distillery.html",
    "title": "All bottle from a distillery review",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\n\n\n\n\nCode\nurl='https://www.whiskybase.com/whiskies/distillery/257/kawasaki'\npage=read_html(url)\nelement=page %&gt;% \n  html_nodes(\"*\") %&gt;% \n  html_attr(\"class\") %&gt;% \n  unique()\n\n\n\n\nCode\ndata=page%&gt;% html_nodes(\"table\")%&gt;%html_table(fill = TRUE) %&gt;% as.data.frame() %&gt;% clean_names()\n\n\n\n\nCode\nbottle_link= page%&gt;%html_nodes(\".clickable\")%&gt;% html_attr('href')\n\n\n\n\nCode\nnames(data)\n\n\n\n\nCode\ndata2=data %&gt;% mutate(var_2=str_trim(var_2),l=ifelse(var_2=='',1,0)) %&gt;% filter(l==1) %&gt;% mutate(bottle_link=bottle_link) %&gt;% select(name,stated_age,strength,bottled,casknumber,rating,bottle_link)\n\n\noutput\n\n\nCode\nwrite.xlsx(data2,'./output/all bottler under one distillery.xlsx')\n\n\n\n1 add detail\n\n\nCode\ndata002=read_excel('./output/all bottler under one distillery.xlsx')\n\n\n\n\nCode\nrating_people_num_list=c()\navg_price_list=c()\nlowest_price_list=c()\ncask_type_list=c() \npic_link_list=c()\nwb_id=c()\nstart_time=now()\ncask_number_list=c()\nnumber_of_bottle_list=c()\nscore_list=c()\nbottler_list=c()\nbottle_list=c()\nstrength_list=c()\nbottle_link_list=c()\norder_num=0\n\n\n\n\nCode\nfor (i in data002$bottle_link){\n    Sys.sleep(runif(n=1, min=0.1, max=0.5))\n    order_num=order_num+1\n    tryCatch({\n    \n    print(paste('#############',order_num,'bottle ######################################## '))\n    print(i)\n    url=i\n    page = read_html(url)\n  }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n    #################### bottle_link_list\n    \n    bottle_link_list=c(bottle_link_list,i)\n      \n    ###################### score\n    bottle=(page%&gt;% html_nodes('h1')%&gt;% html_text())[1]\n    bottle=bottle %&gt;% str_remove_all('\\n') %&gt;% str_remove_all('\\t')\n    print(paste0(\"bottle: \",(bottle)[1]))\n    bottle_list=c(bottle_list,bottle)\n    \n    \n    ###################### score\n    score=(page%&gt;% html_nodes('.votes-rating-current')%&gt;% html_text())[1]\n    print(paste0(\"score: \",score))\n    score_list=c(score_list,score)\n    \n    ####################### rating_people_num\n    rating_people_num=page%&gt;% html_nodes('.votes-count')%&gt;% html_text()\n    print(rating_people_num)[1]\n    rating_people_num_list=c(rating_people_num_list,rating_people_num[1])\n    \n    \n    ##################### lowest price\n    lowest_price=page%&gt;% html_nodes('.wb--shop-links-panel--price')%&gt;% html_text()\n    lowest_price2=if(identical(lowest_price, character(0))==TRUE){0}else{lowest_price}\n    print(lowest_price2)\n    lowest_price_list=c(lowest_price_list,lowest_price2)\n    \n    ############################# average price\n    avg_price=page%&gt;% html_nodes('p+ p')%&gt;% html_text()\n    avg_price6=case_when(str_detect(avg_price, \"[0-9]\")==TRUE~avg_price,.default='')\n    print(paste('price is :',avg_price6[1]))\n    avg_price_list=c(avg_price_list,avg_price6[1])\n    \n    ################################## cask type\n    bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    bottle_name_value=data.frame(bottle_name,bottle_value)\n    cask=bottle_name_value%&gt;% filter(bottle_name=='Cask Type') %&gt;% select(bottle_value)\n    cask2=if(nrow(cask)==0){'unknow cask'}else{ unname(unlist(cask[1,]))}\n    print(cask2)\n    cask_type_list=c(cask_type_list,cask2)\n    \n    ################################## Bottler\n    #bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    #bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    #bottle_name_value=data.frame(bottle_name,bottle_value)\n    bottler=bottle_name_value%&gt;% filter(bottle_name=='Bottler') %&gt;% select(bottle_value)\n    bottler=if(nrow(bottler)==0){'unknow Bottler'}else{ unname(unlist(bottler[1,]))}\n    print(bottler)\n    bottler_list=c(bottler_list,bottler)\n    \n    ################################## strength\n    #bottle_name=page%&gt;% html_nodes('#whisky-details dt')%&gt;% html_text()\n    #bottle_value=page%&gt;% html_nodes('#whisky-details dt+ dd')%&gt;% html_text()\n    #bottle_name_value=data.frame(bottle_name,bottle_value)\n    strength=bottle_name_value%&gt;% filter(bottle_name=='Strength') %&gt;% select(bottle_value)\n    strength=if(nrow(strength)==0){'unknow strength'}else{ unname(unlist(strength[1,]))}\n    print(strength)\n    strength_list=c(strength_list,strength)\n    \n    \n      \n    ##################### number_of_bottle \n    number_of_bottle1=bottle_name_value%&gt;% filter(bottle_name=='Number of bottles') %&gt;% select(bottle_value)\n    number_of_bottle2=if(nrow(number_of_bottle1)==0){'unknow Number of bottles'}else{ unname(unlist(number_of_bottle1[1,]))}\n      \n    print(number_of_bottle2)\n    number_of_bottle_list=c(number_of_bottle_list,number_of_bottle2)\n      \n    ##################### Casknumber \n    cask_number1=bottle_name_value%&gt;% filter(bottle_name=='Casknumber') %&gt;% select(bottle_value)\n    cask_number2=if(nrow(cask_number1)==0){'unknow Casknumber'}else{ unname(unlist(cask_number1[1,]))}\n      \n    print(paste('casknumber:',cask_number2))\n    cask_number_list=c(cask_number_list,cask_number2)\n      \n      \n    ########################################### wb id \n    id_name=page%&gt;% html_nodes(' #whisky-details dd:nth-child(2)')%&gt;% html_text()\n    print(id_name)\n    wb_id=c(wb_id,id_name)\n      \n    ####### check \n      \n    id_num=as.numeric(str_replace(id_name,'WB',''))\n    print(id_num)\n      \n    a=(str_split(url,'/')[[1]])\n    b=as.numeric(a[length(a)-1])\n    #print(paste(\"wb id from link\",b))\n    #print(paste(\"wb id from page\",id_num))\n    if(id_num!=b){\n        print(i)\n        print('############## error !!!!!!!!##################')\n        break\n    }\n    ##################     pic link   #######################\n    pic_link=(page%&gt;% html_nodes('.photo')%&gt;% html_attr('href'))[1]\n    pic_link2=if(identical(pic_link, character(0))==TRUE){0}else{pic_link}\n      \n    print(pic_link2)\n    pic_link_list=c(pic_link_list,pic_link2)\n    \n ######### output to excel on every 10 bottle\n  if(order_num%%10==0){\n    data003=cbind((data002[1:order_num,]),bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,bottle_link_list)%&gt;% as_tibble()\n    \n    \n    write_xlsx(data003,'./output/all bottel under one distillery with detail.xlsx')\n  }\n}\n#########################################################  \n\n\n\n\nCode\ndata003=cbind(data002,bottle_list,score_list,rating_people_num_list,lowest_price_list,avg_price_list,cask_type_list,number_of_bottle_list,bottler_list,strength_list,cask_number_list,wb_id,pic_link_list,bottle_link_list) %&gt;% as_tibble()\n\nwrite_xlsx(data003,'./output/all bottel under one distillery with detail.xlsx')\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "All bottle from a distillery review"
    ]
  },
  {
    "objectID": "other/2 Web scraping on whiskybase.com/1 whiskybase data.html",
    "href": "other/2 Web scraping on whiskybase.com/1 whiskybase data.html",
    "title": "Whiskybase data",
    "section": "",
    "text": "1 whiskybase data\nhttps://www.whiskybase.com/\n\nFounded in the Netherlands in 2007, we’re the world’s premier provider of whisky data, shopping, and whisky-related services. We reach whisky enthusiasts and whisky professionals in nearly every country at all stages of their whisky journey.\nMillions of people use Whiskybase.com to look up their whisky bottles, organize a collection, plan a whisky event, or document their whisky experiences by adding ratings, reviews, and more to our whisky database, the world’s largest.\n\n\n2 package\nrvest chromote selenium selenider\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "2 Web scraping on whiskybase.com",
      "Whiskybase data"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/2 whiskyfun one page.html",
    "href": "other/3 Web scraping on whiskyfun.com/2 whiskyfun one page.html",
    "title": "on page",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 review page\n\n\nCode\nreview_url='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\n\n#review_url='https://www.whiskynotes.be/2011/port-ellen/port-ellen-10th-release-1978/'\n\n\n\n\n2 read in html\n\n\nCode\nreview_page &lt;- read_html(review_url)\n\n\n\n\n3 bottle_review\n\n\nCode\nbottle_review=review_page  %&gt;% html_elements(\"p , .textegrandfoncegras , .textegrandfoncegras .TextenormalNEW , .Textenormal .textenormalgras , .Textenormal .TextenormalNEW , td.TextenormalNEW\") %&gt;% html_text2()\n# remove space element\n\nbottle_review1=bottle_review[bottle_review %&gt;% str_detect('SGP:')] \n\nbottle_review2=bottle_review1[bottle_review1 %&gt;% str_detect('Nose:')] \n\nbottle_review2=bottle_review2%&gt;% str_replace(\"Palate:\", \"Mouth\")%&gt;% str_replace(\"–\", \"-\")\n\n\nss=head(bottle_review2)\n\n\n\n\n4 bottle_name\n\n\nCode\nbottle_name=str_extract(bottle_review2, \n regex( \"[^)]+\")\n    )\nbottle_name=paste0(bottle_name,\")\")\nlength(bottle_name)\n\n\n\n\n5 bottle_score\n\n\nCode\nres &lt;- str_match(bottle_review2, \"SGP:\\\\s*(.*?)\\\\s*points\")\n\nbottle_score=paste(\"SGP:\",res[,2],\" points\")\n\nlength(bottle_score)\n\n\n\n\n6 bottle__final_score\n\n\nCode\nres &lt;- str_match(bottle_score, \" - \\\\s*(.*?)\\\\s*points\")\n\nbottle_final_score=res[,2]\n\nlength(bottle_final_score)\n\n\n\n\nCode\nbottle_score[91]\nbottle_final_score[91]\n\n\n\n\nCode\nbottle_score[92]\nbottle_final_score[92]\n\n\n\n\n7 Nose\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Nose:\\\\s*(.*?)\\\\s*Mouth\")\n\nbottle_name_nose=paste(\"Nose:\",res[,2])\n\nlength(bottle_name_nose)\n\n\n\n\n8 Mouth\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Mouth\\\\s*(.*?)\\\\s*Finish:\")\n\nbottle_name_mouth=paste(\"Mouth:\",res[,2])\n\nlength(bottle_name_mouth)\n\n\n\n\n9 Colour\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Colour\\\\s*(.*?)\\\\s*\\\\.\")\n\nbottle_name_colour=paste(\"Colour \",res[,2])\n\nlength(bottle_name_colour)\n\n\n\n\n10 bottle_name_finish\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Finish:\\\\s*(.*?)\\\\s*Comments:\")\nbottle_name_finish=paste(\"Finish:\",res[,2])\n\nlength(bottle_name_finish)\n\n\n\n\n11 bottle_name_comments\n\n\nCode\nres &lt;- str_match(bottle_review2, \"Comments:\\\\s*(.*?)\\\\s*SGP:\")\nbottle_name_comments=paste(\"Comments:\",res[,2])\n\nlength(bottle_name_comments)\n\n\n\n\n12 combine\n\n\nCode\ndata=tibble(bottle_name,bottle_name_nose,bottle_name_mouth,bottle_name_finish,bottle_name_colour,bottle_name_comments,bottle_score,bottle_final_score,review_url)\n\nhead(data)\n\n\n\n\n13 output\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(data, file = \"./output/whiskyfun one page.xlsx\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "on page"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/3 whiskyfun all page link.html",
    "href": "other/3 Web scraping on whiskyfun.com/3 whiskyfun all page link.html",
    "title": "All page link frist time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(curl)\nlibrary(stringr)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n\n1 all review page\n\n\n2 first page\n\n\nCode\nfirst_url='https://www.whiskyfun.com'\nfirst_page=read_html(first_url)\n\n\n\n\nCode\nlast_page &lt;- first_page %&gt;%\n  html_elements(css = \"a.textegrandfoncegras\")%&gt;% html_attr(\"href\")\n\nlast_page\n\n\n\n\n3 start to download 500 pages\n\n\nCode\n#last_page='https://www.whiskyfun.com/archivemarch24-2-Port-Ellen-Glen-Grant.html'\nlast_page='https://www.whiskyfun.com'\nlast_page=\"https://www.whiskyfun.com/ArchiveOctober04-2.html\"\npage_list=c()\na=0\n  \nfor (i in seq(1:500)){\n  print(i)\n  ###################### each page max try 10 times \n  tryCatch({\n    #page=read_html(last_page)\n    page=read_html(curl(last_page, handle = curl::new_handle(\"useragent\" = \"Mozilla/5.0\")))\n    i=i+1\n    \n  Sys.sleep(runif(n=1, min=0.1, max=0.3))\n },error = function(msg){print('eeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee')\n    i=i-1\n    print(paste0(\"new i : \",i))\n    a=a+1\n    })\n   if(a&gt;10){break}\n  \n  ##############################################\n  #if (last_page %&gt;% is.na()==TRUE){break}\n\n  ### first page\n   if(last_page=='https://www.whiskyfun.com'){\n    last_page &lt;- (page %&gt;%html_elements(css = \"a.textegrandfoncegras\")%&gt;%html_attr(\"href\"))[1]\n    \n  #### all other     \n    }else {\n  last_page &lt;- (page %&gt;%html_elements(css = \"font:nth-child(1) strong a\")%&gt;%html_attr(\"href\"))[1]\n   ###  before 2004 oct\n  if(last_page %&gt;% is.na()==TRUE){\n    last_page &lt;- (page %&gt;%html_elements(css = \"font:nth-child(1) b a\")%&gt;%html_attr(\"href\"))[1]\n  }\n    }\n  \n  if(last_page%&gt;% str_sub(1,26)=='https://www.whiskyfun.com/'){\n    last_page=last_page}else{\n  last_page=paste0('https://www.whiskyfun.com/',last_page)\n    }\n  \n  print(last_page)\n  if (last_page %in% page_list|last_page==\"https://www.whiskyfun.com/http://www.lambchop.net/\"){break}\n  page_list=c(page_list,last_page)\n  Sys.sleep(runif(n=1, min=0.1, max=0.8))\n  \n  \n  }\n\n\n\n\n4 add first page\n\n\nCode\npage_list_data=page_list %&gt;% tibble()\n\n\n\n\n5 ouput\n\n\nCode\nlibrary(openxlsx)\nwrite.xlsx(page_list_data, file = \"./output/wf_all_page_review_v2.xlsx\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page link frist time"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/7 clean up.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/7 clean up.html",
    "title": "clean up",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(janitor)\nlibrary(writexl)\nlibrary(lubridate)\n\n\n\n1 input data\n\n\nCode\ndata001=read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\n2 clean data\n\n\nCode\ndata002=data001 %&gt;% clean_names()\n\n\n\n\nCode\nglimpse(data002)\n\n\n\n\nCode\ndata003=data002 %&gt;%  mutate(published_date=dmy(page_published_date)\n                            ,year=year(published_date)\n                            ,score=as.numeric(all_page_score)\n                            ,high_score=if_else(score&gt;=90,1,0)\n                             ,score_group=case_when(\n                                        score &gt;= 90 ~ \"1.&gt;=90\",\n                                        score &gt; 85 ~ \"2. &gt;=85\",\n                                          TRUE ~ \"3. &lt;85\")\n                            ,bottle_name=bottle_name%&gt;% str_replace('allt-à-bhainne','Allt-a-Bhainne')%&gt;% str_replace('Allt-a-Bhaine','Allt-a-Bhainne') %&gt;% str_to_lower()\n                            )%&gt;% filter(score&gt;0\n                                        ,score&lt;=100\n                                        ,!page_class %in% c(\"* Armagnac\",\"* Cognac\",\"* Rum\",\"* Armagnac-* Cognac\",\"* Other spirits\",\"* Distillery visits\",\"\")\n                                        ,bottle_review_nose!='no comment'\n                                        ,bottle_review_mouth!='no comment'\n                                        ,bottle_review_finish!='no comment')%&gt;% arrange(score)\n\n\n\nglimpse(data003)\n\n\n\n\nCode\np=ggplot(data003, aes(year,score,group=year)) + geom_boxplot()\np\n\n\n\n\nCode\nsummary001=data003 %&gt;% group_by(year) %&gt;% summarise(bottles=n(),avg_score=mean(score),high=sum(high_score)\n                                                 \n                                                 ,high_pct=sum(high_score)/n()\n                                                 )\nsummary001\n\n\n\n\nCode\nall_distrillery_from_wb=read_xlsx('data/all distrillery from wb.xlsx') %&gt;% mutate(name=Name %&gt;% str_replace('Isle of Jura','jura')  %&gt;% str_replace('Teeling Whiskey Distillery','Teeling') %&gt;% str_replace('Distillery','')%&gt;% str_replace('(Closed)','') %&gt;% str_replace('St. Magdalene','St Magdalene') %&gt;% str_trim()%&gt;% str_to_lower()\n                                                                              ) \n\n\n\n\nCode\nkeywords &lt;- as.character(all_distrillery_from_wb$name)\n\n\n\n\nCode\ndata004=data003[grepl(paste(keywords, collapse=\"|\"), data003$bottle_name),]\n\n\n\n\nCode\ndata005=str_extract_all(tolower(data003$bottle_name),paste(keywords,collapse  = \"|\"))\n\n\nkeep first match\n\n\nCode\ndata006=lapply(data005, `[`, 1)\n\n\n\n\nCode\ndata006[lengths(data006)==0] &lt;- NA\ndata007=unlist(data006)\n\n\n\n\nCode\ndata008=data003 %&gt;% mutate(distillery_name=data007)\n\n\n\n\nCode\nlibrary(\"ggthemes\")\nlibrary(\"scales\")\nlibrary(showtext)\nshowtext_auto()\n\ncoeff &lt;- 5\n\np=ggplot(summary001, aes(year,avg_score)) + geom_line(size=2) +\n  geom_col(aes(year,bottles/ coeff), fill = \"blue\")+scale_y_continuous(\"平均分\",limits=c(0,100), sec.axis = sec_axis(~.*coeff, name = \"评分酒款数量\",breaks = seq(0, 500, by = 100)))+labs(caption = \"2010-01 to 2024-04\")+ ggtitle(\"whiskynote.be\")+ xlim(min=2009, 2025)\np+theme_economist()+scale_x_continuous(breaks=pretty_breaks(n = 20))+scale_y_continuous(breaks=pretty_breaks(n = 20))\n\n\n\n\nCode\nsummary002=data003 %&gt;% group_by(year,score_group) %&gt;% \n  summarise(bottles=n())%&gt;% \n  mutate(score_group=score_group %&gt;% as.factor()) %&gt;% group_by(year) %&gt;% mutate(share=round(bottles/sum(bottles),2))\n\nsummary002\n\n\n\n\nCode\nlibrary(\"ggthemes\")\nlibrary(\"scales\")\nlibrary(showtext)\nshowtext_auto()\n\n\np=ggplot(summary002, aes(y=share, x=year,colour=score_group)) + \n    geom_line()\n\np+theme_economist()+scale_x_continuous(breaks=pretty_breaks(n = 20))+scale_y_continuous(breaks=pretty_breaks(n = 10))\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "clean up"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/1 whiskynote data.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/1 whiskynote data.html",
    "title": "Whiskynotes.be data",
    "section": "",
    "text": "1 whiskynotes.be data\nhttps://www.whiskynotes.be/\n\nWhiskyNotes is a personal collection of impressions, written while searching for the ultimate single malt whisky. A work in progress, and a continuous exercise for the senses.\nI started it in 2008 while living in Spain for a couple of years. I had discovered whisky a few years earlier but suddenly I was cut off from festivals, shops and whisky friends in my home country. A whisky blog seemed a good way of keeping in touch. It quickly gained a following, first in Belgium but now from all over the world.\n\n\n2 rvest package\nrvest helps you scrape (or harvest) data from web pages. It is designed to work with magrittr to make it easy to express common web scraping tasks, inspired by libraries like beautiful soup and RoboBrowser.\nIf you’re scraping multiple pages, I highly recommend using rvest in concert with polite. The polite package ensures that you’re respecting the robots.txt and not hammering the site with too many requests.\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n\nCode\npackageVersion(\"rvest\")\n\n\n[1] '1.0.4'\n\n\n\n\n3 reference:\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Whiskynotes.be data"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html",
    "title": "Keras regression model",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#total",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#total",
    "title": "Keras regression model",
    "section": "4.1 total",
    "text": "4.1 total\n\n\nCode\nlen(padded)\nlen(review_flag_final)\n\n\n4633",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#train",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#train",
    "title": "Keras regression model",
    "section": "4.2 train",
    "text": "4.2 train\n\n\nCode\nlen(padded_train)\nlen(review_flag_final_train)\n\n\n4000",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#test",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#test",
    "title": "Keras regression model",
    "section": "4.3 test",
    "text": "4.3 test\n\n\nCode\nlen(padded_test)\nlen(review_flag_final_test)\n\n\n633\n\n\n\n\nCode\nsum(review_flag_final_test)\n\n\n158",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#if-all-guess-lower-than-90-points-then-0.72-accuracy",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#if-all-guess-lower-than-90-points-then-0.72-accuracy",
    "title": "Keras regression model",
    "section": "4.4 if all guess lower than 90 points then 0.72 accuracy",
    "text": "4.4 if all guess lower than 90 points then 0.72 accuracy\n\n\nCode\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)\n\n\n0.7503949447077409",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#train-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#train-model",
    "title": "Keras regression model",
    "section": "6.1 train model",
    "text": "6.1 train model\n\n\nCode\n# Train the model\nhistory = model_dnn.fit(x=padded_train, y=review_socre_final_train,validation_data=(padded_test, review_socre_final_test),epochs=200,verbose=0 )\n\n#history = model_dnn.fit(x=padded_train, y=review_socre_final_train,validation_split=0.2,epochs=20)\n\n\n\n\nCode\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nmae = history.history['mae']\nval_mae = history.history['val_mae']\n\nepochs = range(len(val_loss))\n\n\n\n\nCode\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# import matplotlib.image as mpimg\n# import matplotlib.pyplot as plt\n# #------------------------------------------------\n# # Plot training and validation loss per epoch\n# #------------------------------------------------\n# \n# plt.plot(epochs, mae, 'r', label='Training mae')\n# plt.plot(epochs, val_mae, 'b', label='Validation mae')\n# plt.title('DNN model Training and validation mae')\n# plt.legend()\n# \n# plt.show()\n\n\n\n\nCode\n# Only plot the last 80% of the epochs\nzoom_split = int(epochs[-1] * 0.2)\nepochs_zoom = epochs[zoom_split:]\nval_loss_zoom = val_loss[zoom_split:]\nloss_zoom = loss[zoom_split:]\n\n# Plot zoomed mae and loss\nplt.plot(epochs_zoom, loss_zoom, 'r', label='Training Loss')\nplt.plot(epochs_zoom, val_loss_zoom, 'b', label='Validation Loss')\nplt.title('DNN model Training and validation loss')\nplt.legend()\n\nplt.show()",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#predication",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#predication",
    "title": "Keras regression model",
    "section": "6.2 predication",
    "text": "6.2 predication\n\n\nCode\nx = padded_test\ny = model_dnn.predict(x)\n\n\n 1/20 ━━━━━━━━━━━━━━━━━━━━ 0s 27ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20/20 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step \n\n\n\n\nCode\nlen(padded_test)\nlen(y)\nlen(review_socre_final_test)\n\n\n633\n\n\n\n\nCode\nreview_socre_final_test.shape\n\n\n(633,)\n\n\n\n\nCode\ny.shape\n\n\n(633, 1)\n\n\n\n\nCode\ny2 = y.flatten()\n\n\n\n\nCode\ny2.shape\n\n\n(633,)\n\n\n\n\nCode\ndataset = pd.DataFrame({'real': review_socre_final_test, 'predic': list(y2)}, columns=['real', 'predic'])\n\n\n\n\nCode\ndataset['predic']=round(dataset['predic'])\ndataset['predic']=round(dataset['predic'])\n\n\n\n\nCode\ndataset=dataset&gt;&gt; mutate(predic=if_else(_.predic &lt;70, 70, _.predic)\n                          ,dummy_pred=86\n                         ,diff=_.predic-_.real \n                         ,dummy_diff=_.dummy_pred-_.real\n                          )&gt;&gt; mutate(predic=if_else(_.predic &gt;100,100, _.predic)\n                                     ,predic_class=if_else(_.predic &gt;=90,1, 0)\n                                    ,real_class=if_else(_.real&gt;=90,1, 0)\n                                    ,dummy_class=0\n                          )\n                          \ndataset002 = pd.concat([data002[4000:].reset_index(drop=True),dataset.reset_index(drop=True)], axis=1)                    \n\n\n\n\nCode\ndataset002.to_excel('pred.xlsx')",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#load-model",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras regression model.html#load-model",
    "title": "Keras regression model",
    "section": "8.1 load model",
    "text": "8.1 load model\n\n\nCode\nnew_model = tf.keras.models.load_model('whiskynote_score_dnn.keras')\n\n\n\n\nCode\nnew_model.summary()\n\n\nModel: \"sequential_2\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_2 (Embedding)         │ (32, 300, 32)          │       224,000 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d_2      │ (32, 32)               │             0 │\n│ (GlobalAveragePooling1D)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (Dense)                 │ (32, 32)               │         1,056 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (Dense)                 │ (32, 24)               │           792 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_10 (Dense)                │ (32, 24)               │           600 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_11 (Dense)                │ (32, 1)                │            25 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 679,421 (2.59 MB)\n\n\n\n Trainable params: 226,473 (884.66 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n Optimizer params: 452,948 (1.73 MB)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras regression model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/8 summary in python.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/8 summary in python.html",
    "title": "Summary in Python",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n\n\n\n1 read in data\n\n\nCode\nimport pandas as pd\ndata=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\nCode\nlist(data)\n\n\n['bottle_name',\n 'bottle_review_Nose',\n 'bottle_review_Mouth',\n 'bottle_review_Finish',\n 'all_page_score',\n 'page_class',\n 'page_published_date',\n 'page_title',\n 'review_url']\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 4934 entries, 0 to 4933\nData columns (total 9 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4934 non-null   object\n 1   bottle_review_Nose    4934 non-null   object\n 2   bottle_review_Mouth   4934 non-null   object\n 3   bottle_review_Finish  4934 non-null   object\n 4   all_page_score        4934 non-null   int64 \n 5   page_class            4934 non-null   object\n 6   page_published_date   4934 non-null   object\n 7   page_title            4934 non-null   object\n 8   review_url            4934 non-null   object\ndtypes: int64(1), object(8)\nmemory usage: 347.1+ KB\n\n\n\n\nCode\nimport re\ndata001=data&gt;&gt; filter(_.all_page_score &gt;0\n                      ,_.all_page_score &lt;100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) &gt;&gt;mutate(\n                      review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )&gt;&gt;mutate(review=_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',','').str.replace('(','').str.replace(')','').str.replace('-','').str.replace('apples','apple').str.replace('oranges','orange').str.replace('sweetness','sweet').str.replace('fruits','fruit'))&gt;&gt;mutate(review_len=_.review.str.count(' ') + 1)\n\n\n\n\nCode\ndata001['review_flag']= np.where(data001['all_page_score']&gt;=90, 1, 0)\n\n\n\n\n2 shuffle data\n\n\nCode\ndata002=data001.sample(frac=1)\n\n\n\n\nCode\ndata002.to_excel('data002.xlsx')\n\n\n\n\nCode\ndata002.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 4668 entries, 1260 to 2222\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   bottle_name           4668 non-null   object\n 1   bottle_review_Nose    4668 non-null   object\n 2   bottle_review_Mouth   4668 non-null   object\n 3   bottle_review_Finish  4668 non-null   object\n 4   all_page_score        4668 non-null   int64 \n 5   page_class            4668 non-null   object\n 6   page_published_date   4668 non-null   object\n 7   page_title            4668 non-null   object\n 8   review_url            4668 non-null   object\n 9   review                4668 non-null   object\n 10  review_len            4668 non-null   int64 \n 11  review_flag           4668 non-null   int64 \ndtypes: int64(3), object(9)\nmemory usage: 474.1+ KB\n\n\n\n\n3 Removing stop words with SkLearn\n\n\nCode\nimport nltk\nimport ssl\n\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    pass\nelse:\n    ssl._create_default_https_context = _create_unverified_https_context\n\nnltk.download('stopwords')\n\n\nTrue\n\n\n\n\nCode\nfrom stop_words import get_stop_words\nfrom nltk.corpus import stopwords\n\nstop_words = list(get_stop_words('en'))         #About 900 stopwords\nnltk_words = list(stopwords.words('english')) #About 150 stopwords\nstop_words.extend(nltk_words)\n\n\n\n\nCode\nfrom nltk.corpus import stopwords\nimport string\n\nreview=data002[\"review\"]\n#stop_words = set(stopwords.words(\"english\"))\nexclude = set(string.punctuation)\n\ndef remove_stopwords(data):\n    output_array=[]\n    for sentence in data:\n        temp_list=[]\n        for word in sentence.split():\n            if word.lower() not in stop_words and word.lower() not in exclude :\n                temp_list.append(word)\n        output_array.append(' '.join(temp_list))\n    return output_array\n\nreview_remove_stop_word=remove_stopwords(review)\n\n\n\n\nCode\ntemp_list=[]\nfor sentence in review_remove_stop_word:\n        for word in sentence.split():\n          temp_list.append(word)\n\n\n\n\nCode\nfrom collections import Counter\ncounts = Counter(temp_list)\ndf = pd.DataFrame(list(counts.items()), columns=['Key', 'Values'])\n\n\n\n\nCode\ndf.to_excel('res.xlsx')\n\n\n\n\nCode\ndf002=df&gt;&gt;arrange(-_.Values) &gt;&gt;filter(_.Key!='notes'\n,_.Key!='well'\n,_.Key!='long'\n,_.Key!='quite'\n,_.Key!='hints'\n,_.Key!='hint'\n,_.Key!='light'\n,_.Key!='little'\n,_.Key!='slightly'\n,_.Key!='nice'\n,_.Key!='still'\n,_.Key!='medium'\n,_.Key!='subtle'\n,_.Key!='rather'\n,_.Key!='note'\n,_.Key!='also'\n,_.Key!='there’s'\n,_.Key!='background'\n,_.Key!='end'\n,_.Key!='side'\n,_.Key!='plenty'\n,_.Key!='towards'\n,_.Key!='bit'\n,_.Key!='dark'\n,_.Key!='really'\n,_.Key!='even'\n,_.Key!='like'\n,_.Key!='it’s'\n)\n\ndf003=df002[0:30]\n\n\n\n\n4 Word cloud 1 from data frame english\n\n\nCode\nd = {}\nfor a, x in df003.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(background_color = \"#FFFFFF\", contour_width = 2,\n     contour_color = '#FFFFFF')\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_en.png')\n\n\n\n\n\n\n\n\n\n\n\n5 translate to chinese\n\n\nCode\n#from translate import Translator\nfrom deep_translator import GoogleTranslator\n\nen=df003['Key'].tolist()\n\n\ncn_list=[]\nfor word in en:\n  result = GoogleTranslator(source='auto', target='zh-CN').translate(word) \n  cn_list.append(result)\n  \ncn_list\n\n\n['甜的',\n '水果',\n '橡木',\n '香草',\n '苹果',\n '橙子',\n '胡椒',\n '果味的',\n '蜂蜜',\n '草药的',\n '巧克力',\n '姜',\n '柠檬',\n '木头',\n '抽烟',\n '甘草',\n '薄荷',\n '烟草',\n '绿色的',\n '茶',\n '柚子',\n '肉桂',\n '新鲜的',\n '柑橘',\n '干的',\n '香料',\n '雪莉酒',\n '菠萝',\n '葡萄干',\n '长满青草的']\n\n\n\n\nCode\ndf003.to_excel('df003.xlsx',index=False)\ndf004_cn=df003.copy()\ndf004_cn['Key']=cn_list\ndf004_cn.to_excel('df004_cn.xlsx',index=False)\n\n\n\n\n6 word cloud 2 chinese\n\n\nCode\nd = {}\nfor a, x in df004_cn.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"#FFFFFF\", contour_width = 2,\n     contour_color = '#FFFFFF')\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\nwordcloud.to_file('wordcloud_cn.png')\n\n\n\n\n\n\n\n\n\n\n\n7 word cloud 3 chinese glass\n\n\nCode\nimport cv2\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\nimport numpy as np\nfrom sklearn.cluster import KMeans\nfrom skimage.io import imread, imsave\nfrom skimage import util, data, transform\nfrom skimage.transform import rescale, resize, downscale_local_mean\n\n\nsample_img = imread('Glencairn.png')\nsample_img_resize=util.img_as_ubyte(transform.rescale(sample_img, 3))\nsample_img.shape\n\nsample_img_resize.shape\n\n\n(2328, 2892, 12)\n\n\n\n\nCode\n#image = Image.open('glass.png')\n#new_image = image.resize((3000, 3000))\n#meta_mask = np.array(new_image)\n\nsample_img_resize[sample_img_resize&gt;240] = 255\n\n\n#imsave(\"glass_new.png\", sample_img_resize)\n\n\n\n\nCode\nd = {}\nfor a, x in df004_cn.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"white\", contour_width = 2,mask = sample_img_resize)\n\n\n\nwordcloud.generate_from_frequencies(frequencies=d)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_cn_bottle.png')\n\n\n\n\n\n\n\n\n\n\n\n8 word cloud 4 English glass\n\n\nCode\nd = {}\nfor a, x in df003.values:\n    d[a] = x\n\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\nwordcloud = WordCloud(font_path='simfang.ttf',background_color = \"white\", contour_width = 2,mask = sample_img_resize)\n\n\n\nwordcloud.generate_from_frequencies(frequencies=d)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file('wordcloud_en_bottle.png')\n\n\n\n\n\n\n\n\n\n\n\n9 Chart 1\nusing seaborn\n\n\nCode\nplt.figure(figsize=(10, 6))\n\nplt.rcParams['font.family'] = ['Arial Unicode MS'] #用来正常显示中文标签\nplt.rcParams['axes.unicode_minus'] = False #用来正常显示负号\n \nsns.set_style('whitegrid',{'font.sans-serif':['Arial Unicode MS','Arial']})\n\nax=sns.barplot(df004_cn, x=\"Values\", y=\"Key\", legend=False,orient = 'h')\n\nax.set_title(\"各风味出现频率\")\nax.set(xlabel='出现次数', ylabel='风味')\nfor i in ax.containers:\n    ax.bar_label(i,)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n10 Chart 2 combine image and seaborn\nusing plotly\n\n\nCode\nimport plotly.express as px\nfrom PIL import Image\npyLogo = Image.open(\"en_glass.png\")\n\n\nfig=px.bar(df004_cn,x=\"Values\", y=\"Key\",orientation='h',text=\"Values\",title=\"各风味出现频率\"\n,labels={\"Values\": \"出现次数\",\n         \"Key\": \"风味\"\n         }\n)\n\n\n# Add images\nfig.add_layout_image(\n        dict(\n            source=pyLogo \n            ,x=0.6\n            ,y=0.8\n            ,sizex=1\n            ,sizey=0.8\n            #,sizing=\"stretch\"\n            ,opacity=0.8\n            ,layer=\"above\")\n)\n\n# # Set templates\nfig.update_layout(template=\"plotly_white\")\nfig.update_layout(yaxis=dict(autorange=\"reversed\"),height=600)\n\n\nfig.show()\n\n\n                                                \n\n\n\n\n11 resource:\nhttps://medium.com/@m3redithw/wordclouds-with-python-c287887acc8b\nhttps://github.com/nidhaloff/deep-translator\nhttps://cran.r-project.org/web/packages/polyglotr/vignettes/polyglotr.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Summary in Python"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html",
    "title": "XGboost classification model",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "XGboost classification model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#total",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#total",
    "title": "XGboost classification model",
    "section": "4.1 total",
    "text": "4.1 total\n\n\nCode\nlen(padded)\nlen(review_flag_final)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "XGboost classification model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#train",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#train",
    "title": "XGboost classification model",
    "section": "4.2 train",
    "text": "4.2 train\n\n\nCode\nlen(padded_train)\nlen(review_flag_final_train)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "XGboost classification model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#test",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#test",
    "title": "XGboost classification model",
    "section": "4.3 test",
    "text": "4.3 test\n\n\nCode\nlen(padded_test)\nlen(review_flag_final_test)\n\n\n\n\nCode\nsum(review_flag_final_test)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "XGboost classification model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#if-all-guess-lower-than-90-points-then-0.75-accuracy",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 XGboost classification model.html#if-all-guess-lower-than-90-points-then-0.75-accuracy",
    "title": "XGboost classification model",
    "section": "4.4 if all guess lower than 90 points then 0.75 accuracy",
    "text": "4.4 if all guess lower than 90 points then 0.75 accuracy\n\n\nCode\n(len(review_flag_final_test)-sum(review_flag_final_test))/len(review_flag_final_test)",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "XGboost classification model"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/5 web scraping with rvest all first time.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/5 web scraping with rvest all first time.html",
    "title": "All year all topic first time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\n\n\n\n1 one page function\n\n\nCode\nsource('one_page.r')\n\n\n\n\n2 read in all link\n\n\nCode\nlibrary(readxl)\ntopic_link=read_excel('./output/all year page2.xlsx',sheet='topic')\n\n\n\n\nCode\nglimpse(topic_link)\n\n\nexclude news\n\n\nCode\nnews=topic_link$topic_link_list %&gt;% str_detect('/whisky-news/')\n\n\n\n\nCode\ntopic_link002=topic_link$topic_link_list[!news]\n\n\n\n\nCode\nlength(topic_link002)\n\n\n\n\n3 start downlaod all page on first first try\n\n\nCode\n#test=one_page_function('https://www.whiskynotes.be/2020/irish-whiskey/teeling-1996-fill-your-own-teeling-chinkapin-oak-single-pot-still-distillery-exclusive/')%&gt;% mutate(loop_num=3)\n\n\n\n\nCode\nsink(\"log3.txt\", append=FALSE, split=TRUE)  # for screen and log\n\nlibrary(openxlsx)\n\npage=topic_link002\n\n\nall_page_review_list=data.frame()\n\nstart_time=Sys.time()\nprint(paste0(\"Start time: \", start_time))\n\nloop_num=0\n\nfor (i in page){\n   tryCatch({\n#############################     \n   loop_num=loop_num+1\n   print(paste0(\"################ Running loop No.\",which(page==i)))\n         \n   print(paste0(\"current time: \", Sys.time()))\n   \n   output=one_page_function(i) %&gt;% mutate(loop_num=loop_num)\n\n   all_page_review_list=rbind(all_page_review_list,output)\n   \n   print(paste0(\"Used time: \", Sys.time()-start_time))\n   # ouput every 20 page\n   if (loop_num%%20==0){\n      print(paste0(\"############################## output to excel: \", loop_num))\n      write.xlsx(all_page_review_list,'./output/all_page_bottle_list3.xlsx')\n     }\n    \n   \n#############################        \n    }, error=function(e){cat(\"ERROR :\",conditionMessage(e), \"\\n\")})\n}\n\nend_time=Sys.time()\nprint(paste0(\"End time: \", end_time))\nprint(paste0(\"total used time: \", end_time-start_time))\n\nwrite.xlsx(all_page_review_list,'./output/all_page_bottle_list3.xlsx')\n\nsink()\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "All year all topic first time"
    ]
  },
  {
    "objectID": "other/1 Web scraping on www.whiskynotes.be/9 Keras classification n model.html",
    "href": "other/1 Web scraping on www.whiskynotes.be/9 Keras classification n model.html",
    "title": "Keras classification model",
    "section": "",
    "text": "Code\nimport tensorflow as tf\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nfrom siuba.siu import call\nfrom siuba import _, mutate, filter, group_by, summarize,show_query\nfrom siuba import *\n\nfrom siuba.data import mtcars,penguins\n\n\n\n\nCode\nimport tensorflow as tf\ntf.__version__\n\n\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\n\n\n\nCode\nimport pandas as pd\ndf_raw=pd.read_excel('./output/all_page_bottle_list_all.xlsx')\n\n\n\n\nCode\nimport re\ndf=df_raw&gt;&gt; filter(_.all_page_score &gt;=70\n                      ,_.all_page_score &lt;100\n                      ,_.bottle_review_Nose !='no comment'\n                      ,_.bottle_review_Mouth !='no comment'\n                      ,_.bottle_review_Finish !='no comment'\n                      ) &gt;&gt;mutate(\n                         label=if_else(_.all_page_score&gt;=90,1,0)\n                      ,review=_.bottle_review_Nose+_.bottle_review_Mouth+_.bottle_review_Finish\n                      )&gt;&gt;mutate(review=_.bottle_name+_.review.str.lower().str.replace('nose:','').str.replace('mouth:','').str.replace('finish:','').str.replace('.','').str.replace(',','').str.replace('(','').str.replace(')','').str.replace('-','').str.replace('apples','apple').str.replace('oranges','orange').str.replace('sweetness','sweet').str.replace('fruits','fruit'))&gt;&gt;mutate(review_len=_.review.str.count(' ')+1) &gt;&gt;mutate(description=_.review)\n\n\n\n\nCode\ndf = df[[\"description\", \"label\"]]\n\n\n\n\nCode\ndf = df.dropna(subset=[\"description\", \"label\"])\n\n\n\n\nCode\ndf.label = df.label.astype(int)\n\n\n\n\nCode\ndf.head()\n\n\n\n\nCode\ndf.info()\n\n\n\n1 split data\n\n\nCode\ntrain, val, test = np.split(df.sample(frac=1), [int(0.8*len(df)), int(0.9*len(df))])\n\n\n\n\nCode\ndef df_to_dataset(dataframe, shuffle=True, batch_size=1024):\n  df = dataframe.copy()\n  labels = df.pop('label')\n  df = df[\"description\"]\n  ds = tf.data.Dataset.from_tensor_slices((df, labels))\n  if shuffle:\n    ds = ds.shuffle(buffer_size=len(dataframe))\n  ds = ds.batch(batch_size)\n  ds = ds.prefetch(tf.data.AUTOTUNE)\n  return ds\n\n\n\n\nCode\ntrain_data = df_to_dataset(train)\nvalid_data = df_to_dataset(val)\ntest_data = df_to_dataset(test)\n\n\n\n\nCode\nembedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\nhub_layer = hub.KerasLayer(embedding, dtype=tf.string, trainable=True)\n\n\n\n\nCode\nhub_layer(list(train_data)[0][0])\n\n\n\n\nCode\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.4))\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.4))\nmodel.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n\n\n\n\nCode\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=['accuracy'])\n\n\n\n\nCode\nmodel.evaluate(train_data)\n\n\n\n\n2 resource:\nhttps://colab.research.google.com/drive/1yO7EgCYSN3KW8hzDTz809nzNmacjBBXX?usp=sharing#scrollTo=7nYrbpVd96kr\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "1 Web scraping on www.whiskynotes.be",
      "Keras classification model"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#download-data",
    "href": "clustering/1 k mean Clustering.html#download-data",
    "title": "K mean Clustering",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/datasets/shwetabh123/mall-customer",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#input-data",
    "href": "clustering/1 k mean Clustering.html#input-data",
    "title": "K mean Clustering",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\ndf_train=read.csv('./data/Mall_Customers.csv')\n\n\n\n\nCode\nnames(df_train)\n\n\n[1] \"CustomerID\"             \"Genre\"                  \"Age\"                   \n[4] \"Annual.Income..k..\"     \"Spending.Score..1.100.\"\n\n\n\n\nCode\ndf_train=df_train %&gt;% clean_names()\n\n\n\n\nCode\nnames(df_train)\n\n\n[1] \"customer_id\"          \"genre\"                \"age\"                 \n[4] \"annual_income_k\"      \"spending_score_1_100\"",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#data-eda",
    "href": "clustering/1 k mean Clustering.html#data-eda",
    "title": "K mean Clustering",
    "section": "2.3 data EDA",
    "text": "2.3 data EDA",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#annual_income_k",
    "href": "clustering/1 k mean Clustering.html#annual_income_k",
    "title": "K mean Clustering",
    "section": "6.1 ‘annual_income_k’",
    "text": "6.1 ‘annual_income_k’\n\n\nCode\np=ggplot(df_train3, aes(cluster,annual_income_k,fill=cluster)) + geom_boxplot()\np",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#spending_score_1_100",
    "href": "clustering/1 k mean Clustering.html#spending_score_1_100",
    "title": "K mean Clustering",
    "section": "6.2 ‘spending_score_1_100’",
    "text": "6.2 ‘spending_score_1_100’\n\n\nCode\np=ggplot(df_train3, aes(cluster,spending_score_1_100,fill=cluster)) + geom_boxplot()\np",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/1 k mean Clustering.html#age",
    "href": "clustering/1 k mean Clustering.html#age",
    "title": "K mean Clustering",
    "section": "6.3 Age",
    "text": "6.3 Age",
    "crumbs": [
      "Clustering",
      "K mean Clustering"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#download-data",
    "href": "clustering/0 Mall Customers.html#download-data",
    "title": "Mall Customers Dataset",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/datasets/shwetabh123/mall-customer",
    "crumbs": [
      "Clustering",
      "Mall Customers Dataset"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#input-data",
    "href": "clustering/0 Mall Customers.html#input-data",
    "title": "Mall Customers Dataset",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\ndf_train=read.csv('./data/Mall_Customers.csv')\n\n\n\n\nCode\nhead(df_train)\n\n\n  CustomerID  Genre Age Annual.Income..k.. Spending.Score..1.100.\n1          1   Male  19                 15                     39\n2          2   Male  21                 15                     81\n3          3 Female  20                 16                      6\n4          4 Female  23                 16                     77\n5          5 Female  31                 17                     40\n6          6 Female  22                 17                     76",
    "crumbs": [
      "Clustering",
      "Mall Customers Dataset"
    ]
  },
  {
    "objectID": "clustering/0 Mall Customers.html#data-eda",
    "href": "clustering/0 Mall Customers.html#data-eda",
    "title": "Mall Customers Dataset",
    "section": "2.3 data EDA",
    "text": "2.3 data EDA\n\n\nCode\nglimpse(df_train)\n\n\nRows: 200\nColumns: 5\n$ CustomerID             &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, …\n$ Genre                  &lt;chr&gt; \"Male\", \"Male\", \"Female\", \"Female\", \"Female\", \"…\n$ Age                    &lt;int&gt; 19, 21, 20, 23, 31, 22, 35, 23, 64, 30, 67, 35,…\n$ Annual.Income..k..     &lt;int&gt; 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 19,…\n$ Spending.Score..1.100. &lt;int&gt; 39, 81, 6, 77, 40, 76, 6, 94, 3, 72, 14, 99, 15…\n\n\n\n\nCode\nlibrary(skimr)\n\nskim(df_train)\n\n\n\nData summary\n\n\nName\ndf_train\n\n\nNumber of rows\n200\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGenre\n0\n1\n4\n6\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nCustomerID\n0\n1\n100.50\n57.88\n1\n50.75\n100.5\n150.25\n200\n▇▇▇▇▇\n\n\nAge\n0\n1\n38.85\n13.97\n18\n28.75\n36.0\n49.00\n70\n▆▇▅▃▂\n\n\nAnnual.Income..k..\n0\n1\n60.56\n26.26\n15\n41.50\n61.5\n78.00\n137\n▆▇▇▂▁\n\n\nSpending.Score..1.100.\n0\n1\n50.20\n25.82\n1\n34.75\n50.0\n73.00\n99\n▃▃▇▃▃",
    "crumbs": [
      "Clustering",
      "Mall Customers Dataset"
    ]
  },
  {
    "objectID": "clustering/3 k mode Clustering.html",
    "href": "clustering/3 k mode Clustering.html",
    "title": "k mode Clustering",
    "section": "",
    "text": "Coming soon\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Clustering",
      "k mode Clustering"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html",
    "href": "titanic classification model/5 classification Tidy Modeling.html",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/5 classification Tidy Modeling.html#read-data",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/5 classification Tidy Modeling.html#data-split",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/5 classification Tidy Modeling.html#recipe",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#model",
    "href": "titanic classification model/5 classification Tidy Modeling.html#model",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          6   3.33e- 5       2.32e+ 1    34       0.746     2\n2          6   6.19e- 4       2.32e- 2    22       0.580     5\n3          5   3.66e- 2       4.50e-10    24       0.949     1\n4          9   9.47e-10       2.06e- 5     2       0.340    11\n5          9   9.81e- 2       5.39e- 8     7       0.787     3\n6         12   2.50e- 6       6.99e- 3    16       0.151     5\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth   learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;        &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         12 0.00000156         6.09e-10    14       0.917     6\n2          3 0.0134             5.25e- 6    22       0.151     1\n3          2 0.0000000634       1.79e-10    15       0.132     5\n4          6 0.0206             1.84e- 5    19       0.863     9\n5          6 0.00000358         4.57e- 1    38       0.818     8\n6          4 0.00384            3.55e- 4    15       0.552     4",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#workflow-set",
    "href": "titanic classification model/5 classification Tidy Modeling.html#workflow-set",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_race(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_lightgbm\nPreprocessor1_Model11\naccuracy\n0.7301587\nNA\n1\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model11\nroc_auc\n0.8858093\nNA\n1\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model09\naccuracy\n0.7704813\n0.01220734\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_xgb\nPreprocessor1_Model09\nroc_auc\n0.8316034\n0.01125249\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model20\naccuracy\n0.7721710\n0.01523136\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model20\nroc_auc\n0.8284261\n0.01503274\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7063236\n0.01911126\n10\nrecipe\nnearest_neighbor\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7420401\n0.01885929\n10\nrecipe\nnearest_neighbor\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7398105\n0.01844242\n10\nrecipe\nlogistic_reg\n5\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7301929\n0.03339075\n10\nrecipe\nlogistic_reg\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\n\n\nCode\nxgb_model_set_res=model_set_res %&gt;% extract_workflow_set_result(id= 'recipe_xgb')\n\n\n\n\nCode\nglimpse(xgb_model_set_res)\n\n\nRows: 10\nColumns: 5\n$ splits       &lt;list&gt; [&lt;vfold_split[560 x 63 x 623 x 11]&gt;], [&lt;vfold_split[560 …\n$ id           &lt;chr&gt; \"Fold01\", \"Fold02\", \"Fold03\", \"Fold04\", \"Fold05\", \"Fold06…\n$ .metrics     &lt;list&gt; [&lt;tbl_df[40 x 10]&gt;], [&lt;tbl_df[40 x 10]&gt;], [&lt;tbl_df[40 x …\n$ .notes       &lt;list&gt; [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;], [&lt;tbl_df[0 x 3]&gt;],…\n$ .predictions &lt;list&gt; [&lt;tbl_df[1260 x 12]&gt;], [&lt;tbl_df[1260 x 12]&gt;], [&lt;tbl_df[1…\n\n\n\n\nCode\n#xgb_model_set_res %&gt;% plot_race()\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/5 classification Tidy Modeling.html#last-fit",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/5 classification Tidy Modeling.html#evaluate",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.827 Preprocessor1_Model1\n2 roc_auc  binary         0.915 Preprocessor1_Model1\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.827\n2 recall    binary         0.982\n3 precision binary         0.793\n4 f_meas    binary         0.877\n5 kap       binary         0.593\n6 sens      binary         0.982\n7 spec      binary         0.561\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 14.8 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.080098505877286, max_depth = 12L, \n    gamma = 5.39858008778608e-07, colsample_bytree = 1, colsample_bynode = 0.645669291338583, \n    min_child_weight = 9L, subsample = 0.771166819442296), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.080098505877286\", max_depth = \"12\", gamma = \"5.39858008778608e-07\", colsample_bytree = \"1\", colsample_bynode = \"0.645669291338583\", min_child_weight = \"9\", subsample = \"0.771166819442296\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 127 \nniter: 10\nnfeatures : 127 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6633661\n        2        0.6379807\n---                       \n        9        0.5294025\n       10        0.5201621\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/5 classification Tidy Modeling.html#save-model",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.04 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/5 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/5 classification Tidy Modeling.html#make-predication",
    "title": "Multiple classification model with Recipe,workflow set,fast tunning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 0          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 53 14\n         1  4 18\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.798\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              67\n2 1              22\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 53 14\n         1  4 18",
    "crumbs": [
      "titanic classification model",
      "Multiple classification model with Recipe,workflow set,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html",
    "href": "titanic classification model/2 classification Tidy Modeling.html",
    "title": "Classification model with Recipe",
    "section": "",
    "text": "Level 3 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/2 classification Tidy Modeling.html#read-data",
    "title": "Classification model with Recipe",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/2 classification Tidy Modeling.html#eda",
    "title": "Classification model with Recipe",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/2 classification Tidy Modeling.html#plotting",
    "title": "Classification model with Recipe",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/2 classification Tidy Modeling.html#data-split",
    "title": "Classification model with Recipe",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#recipe",
    "title": "Classification model with Recipe",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#prep-the-recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#prep-the-recipe",
    "title": "Classification model with Recipe",
    "section": "3.2 prep the recipe",
    "text": "3.2 prep the recipe\n\n\nCode\ndata_rec=data_rec %&gt;% prep()\n\n\n\n\nCode\ndata_rec",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#bake-the-train-data-with-preded-recipe",
    "title": "Classification model with Recipe",
    "section": "3.3 bake the train data with preded recipe",
    "text": "3.3 bake the train data with preded recipe\n\n\nCode\ntrain_proc &lt;- bake(data_rec, new_data = data_train)\n\n\n\n\nCode\ntrain_proc2 &lt;- bake(data_rec, new_data = NULL)\n\n\n\n\nCode\ntrain_juice &lt;-juice(data_rec)\n\n\nthe difference between train_proc and train_juice is that the train_juice is been down sample.\n\n\nCode\ndim(train_proc)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_proc2)\n\n\n[1] 623 128\n\n\n\n\nCode\ndim(train_juice)\n\n\n[1] 623 128\n\n\n\n\nCode\ntrain_proc %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\nthe juice and train_proc2 target is down sample to 1:1\n\n\nCode\ntrain_proc2 %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244\n\n\n\n\nCode\ntrain_juice %&gt;%\n  count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 379\n2 1                 244",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "href": "titanic classification model/2 classification Tidy Modeling.html#bake-the-test-data-with-preded-recipe",
    "title": "Classification model with Recipe",
    "section": "3.4 bake the test data with preded recipe",
    "text": "3.4 bake the test data with preded recipe\n\n\nCode\ntest_proc &lt;- bake(data_rec, new_data = data_test)\n\n\n\n\nCode\ntest_proc %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                 113\n2 1                  66\n\n\n\n\nCode\ndata_valid %&gt;%count(target_variable)\n\n\n# A tibble: 2 × 2\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nvalid_proc &lt;- bake(data_rec, new_data = data_valid)\n\n\njuice(pre_recipe,data=NULL) is same as bake(pre_recipe,data=hotel_train) for training data (excepted down sample)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#model",
    "href": "titanic classification model/2 classification Tidy Modeling.html#model",
    "title": "Classification model with Recipe",
    "section": "3.5 model",
    "text": "3.5 model\ntree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\nKNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#trainning",
    "href": "titanic classification model/2 classification Tidy Modeling.html#trainning",
    "title": "Classification model with Recipe",
    "section": "3.6 trainning",
    "text": "3.6 trainning\n\n\nCode\nknn_fit &lt;- knn_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\nknn_fit\n\n\nparsnip model object\n\n\nCall:\nkknn::train.kknn(formula = target_variable ~ ., data = data,     ks = min_rows(5, data, 5))\n\nType of response variable: nominal\nMinimal misclassification: 0.2536116\nBest kernel: optimal\nBest k: 5\n\n\n\n\nCode\ntree_fit &lt;- tree_spec %&gt;%\n  fit(target_variable ~ ., data = train_juice)\n\ntree_fit\n\n\nparsnip model object\n\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n  1) root 623 244 0 (0.60834671 0.39165329)  \n    2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n      4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237) *\n      5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n    3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n      6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n       12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n       13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n         26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n           52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n           53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n            106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609) *\n            107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n         27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970) *\n      7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/2 classification Tidy Modeling.html#evaluate",
    "title": "Classification model with Recipe",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\n#mc_cv default is 25\nset.seed(1234)\nvalidation_splits &lt;- mc_cv(train_juice, prop = 0.9, strata = target_variable\n                           #,times=3\n                           )\nvalidation_splits\n\n\n# Monte Carlo cross-validation (0.9/0.1) with 25 resamples  using stratification \n# A tibble: 25 × 2\n   splits           id        \n   &lt;list&gt;           &lt;chr&gt;     \n 1 &lt;split [560/63]&gt; Resample01\n 2 &lt;split [560/63]&gt; Resample02\n 3 &lt;split [560/63]&gt; Resample03\n 4 &lt;split [560/63]&gt; Resample04\n 5 &lt;split [560/63]&gt; Resample05\n 6 &lt;split [560/63]&gt; Resample06\n 7 &lt;split [560/63]&gt; Resample07\n 8 &lt;split [560/63]&gt; Resample08\n 9 &lt;split [560/63]&gt; Resample09\n10 &lt;split [560/63]&gt; Resample10\n# ℹ 15 more rows\n\n\nKKN:\n\n\nCode\nknn_res &lt;- knn_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\nknn_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.726    25 0.0118  Preprocessor1_Model1\n2 roc_auc  binary     0.773    25 0.00998 Preprocessor1_Model1\n\n\nTree model:\n\n\nCode\ntree_res &lt;- tree_spec %&gt;% fit_resamples(\n  target_variable ~ .,\n  validation_splits,\n  control = control_resamples(save_pred = TRUE)\n)\n\ntree_res %&gt;%collect_metrics()\n\n\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary     0.788    25  0.0115 Preprocessor1_Model1\n2 roc_auc  binary     0.815    25  0.0117 Preprocessor1_Model1\n\n\n\n\nCode\nknn_res %&gt;%\n  unnest(.predictions) %&gt;%\n  mutate(model = \"kknn\") %&gt;%\n  bind_rows(tree_res %&gt;%\n    unnest(.predictions) %&gt;%\n    mutate(model = \"rpart\")) %&gt;%\n  group_by(model) %&gt;%\n  roc_curve(target_variable, .pred_0) %&gt;%\n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line(size = 1.5) +\n  geom_abline(\n    lty = 2, alpha = 0.5,\n    color = \"gray50\",\n    size = 1.2\n  )",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/2 classification Tidy Modeling.html#save-model",
    "title": "Classification model with Recipe",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(tree_fit)\n\n\n847.94 kB\n\n\nCode\nobj_size(knn_fit)\n\n\n817.13 kB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(knn_fit)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 2 classification KNN hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/2 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/2 classification Tidy Modeling.html#make-predication",
    "title": "Classification model with Recipe",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 2 classification KNN hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,valid_proc)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 0          \n3 1          \n4 0          \n5 1          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(valid_proc,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.730\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              53\n2 1              36\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 43 10\n         1 14 22",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html",
    "href": "titanic classification model/4 classification Tidy Modeling.html",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "",
    "text": "Level 5 classification Tidy Modeling:",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#read-data",
    "href": "titanic classification model/4 classification Tidy Modeling.html#read-data",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.1 read data",
    "text": "2.1 read data\nhttps://www.kaggle.com/competitions/titanic/data\n\n\nCode\nlibrary(tidyverse)\ntrain = read_csv(\"data/train.csv\")\n\ntest=read_csv(\"data/test.csv\")",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#eda",
    "href": "titanic classification model/4 classification Tidy Modeling.html#eda",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.2 EDA",
    "text": "2.2 EDA\n\n\nCode\nglimpse(train)\n\n\nRows: 891\nColumns: 12\n$ PassengerId &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ Survived    &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1…\n$ Pclass      &lt;dbl&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3…\n$ Name        &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Fl…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"female\", \"female\", \"male\", \"male\", \"mal…\n$ Age         &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, …\n$ SibSp       &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"37…\n$ Fare        &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,…\n$ Cabin       &lt;chr&gt; NA, \"C85\", NA, \"C123\", NA, NA, \"E46\", NA, NA, NA, \"G6\", \"C…\n$ Embarked    &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\"…\n\n\n\n\nCode\nglimpse(test)\n\n\nRows: 418\nColumns: 11\n$ PassengerId &lt;dbl&gt; 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903…\n$ Pclass      &lt;dbl&gt; 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3…\n$ Name        &lt;chr&gt; \"Kelly, Mr. James\", \"Wilkes, Mrs. James (Ellen Needs)\", \"M…\n$ Sex         &lt;chr&gt; \"male\", \"female\", \"male\", \"male\", \"female\", \"male\", \"femal…\n$ Age         &lt;dbl&gt; 34.5, 47.0, 62.0, 27.0, 22.0, 14.0, 30.0, 26.0, 18.0, 21.0…\n$ SibSp       &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0…\n$ Parch       &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Ticket      &lt;chr&gt; \"330911\", \"363272\", \"240276\", \"315154\", \"3101298\", \"7538\",…\n$ Fare        &lt;dbl&gt; 7.8292, 7.0000, 9.6875, 8.6625, 12.2875, 9.2250, 7.6292, 2…\n$ Cabin       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"B45\", NA,…\n$ Embarked    &lt;chr&gt; \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\"…\n\n\n\n\nCode\ntrain %&gt;%\n  count(Survived)\n\n\n# A tibble: 2 × 2\n  Survived     n\n     &lt;dbl&gt; &lt;int&gt;\n1        0   549\n2        1   342",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#plotting",
    "href": "titanic classification model/4 classification Tidy Modeling.html#plotting",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.3 plotting",
    "text": "2.3 plotting\n\n\nCode\nlibrary(skimr)\n\nskim(train)\n\n\n\nData summary\n\n\nName\ntrain\n\n\nNumber of rows\n891\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nName\n0\n1.00\n12\n82\n0\n891\n0\n\n\nSex\n0\n1.00\n4\n6\n0\n2\n0\n\n\nTicket\n0\n1.00\n3\n18\n0\n681\n0\n\n\nCabin\n687\n0.23\n1\n15\n0\n147\n0\n\n\nEmbarked\n2\n1.00\n1\n1\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nPassengerId\n0\n1.0\n446.00\n257.35\n1.00\n223.50\n446.00\n668.5\n891.00\n▇▇▇▇▇\n\n\nSurvived\n0\n1.0\n0.38\n0.49\n0.00\n0.00\n0.00\n1.0\n1.00\n▇▁▁▁▅\n\n\nPclass\n0\n1.0\n2.31\n0.84\n1.00\n2.00\n3.00\n3.0\n3.00\n▃▁▃▁▇\n\n\nAge\n177\n0.8\n29.70\n14.53\n0.42\n20.12\n28.00\n38.0\n80.00\n▂▇▅▂▁\n\n\nSibSp\n0\n1.0\n0.52\n1.10\n0.00\n0.00\n0.00\n1.0\n8.00\n▇▁▁▁▁\n\n\nParch\n0\n1.0\n0.38\n0.81\n0.00\n0.00\n0.00\n0.0\n6.00\n▇▁▁▁▁\n\n\nFare\n0\n1.0\n32.20\n49.69\n0.00\n7.91\n14.45\n31.0\n512.33\n▇▁▁▁▁",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#data-split",
    "href": "titanic classification model/4 classification Tidy Modeling.html#data-split",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "2.4 data split",
    "text": "2.4 data split\n\n\nPrepare & Split Data\ntrain_df &lt;- train %&gt;%mutate(Survived=as.factor(Survived)) %&gt;% select(-Name) %&gt;% \n\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=Survived)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=train_df, prop = c(0.7,0.1))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 623  11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 179  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 89 11",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#recipe",
    "href": "titanic classification model/4 classification Tidy Modeling.html#recipe",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5) %&gt;%\n  #step_downsample(target_variable) %&gt;%\n  #step_novel(Ticket) %&gt;%\n  step_rm(Ticket) %&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#model",
    "href": "titanic classification model/4 classification Tidy Modeling.html#model",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.604226e-02, 1.240402e-07, 2.627129e-08, 9.554920e-09, 4.573048e-07, 4.382004e-07, 7.226307e-10, 5.853203e-03, 3.898687e-03, 6.021893e-02, 2.083316e-02, 1.088783e-05, 5.4962…\n$ tree_depth      &lt;int&gt; 8, 7, 6, 4, 12, 4, 11, 5, 3, 11, 15, 1, 5, 13, 8, 12, 10, 11, 9, 4, 7, 10, 3, 6, 15, 4, 9, 10, 4, 2, 1, 4, 14, 4, 11, 8, 12, 6, 10, 12, 13, 13, 7, 7, 2, 12, 4, 3, 2, 8, 13, 3…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    13\n 4          4    15\n 5          5    14\n 6          6    15\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    15\n13         13    14\n14         14    14\n15         15     7",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#workflow",
    "href": "titanic classification model/4 classification Tidy Modeling.html#workflow",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\nusing control_race instead of control_grid\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "href": "titanic classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 352 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.0160                 8 accuracy binary     0.774    10  0.0160 Preproces…\n 2   0.0160                 8 roc_auc  binary     0.799    10  0.0139 Preproces…\n 3   0.000000124            7 accuracy binary     0.772    10  0.0137 Preproces…\n 4   0.000000124            7 roc_auc  binary     0.821    10  0.0177 Preproces…\n 5   0.00000000955          4 accuracy binary     0.788    10  0.0179 Preproces…\n 6   0.00000000955          4 roc_auc  binary     0.818    10  0.0150 Preproces…\n 7   0.000000457           12 accuracy binary     0.771    10  0.0136 Preproces…\n 8   0.000000457           12 roc_auc  binary     0.817    10  0.0202 Preproces…\n 9   0.000000438            4 accuracy binary     0.785    10  0.0164 Preproces…\n10   0.000000438            4 roc_auc  binary     0.817    10  0.0149 Preproces…\n# ℹ 342 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1        2.38e- 8         12 roc_auc binary     0.829    10  0.0144 Preprocesso…\n2        5.87e- 7         12 roc_auc binary     0.827    10  0.0156 Preprocesso…\n3        1.61e- 6         12 roc_auc binary     0.827    10  0.0154 Preprocesso…\n4        1.50e- 5         15 roc_auc binary     0.826    10  0.0151 Preprocesso…\n5        8.95e-10         13 roc_auc binary     0.826    10  0.0164 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1    0.0000000238         12 Preprocessor1_Model040\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 2.37513046201816e-08\n  tree_depth = 12\n\nComputational engine: rpart",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#last-fit",
    "href": "titanic classification model/4 classification Tidy Modeling.html#last-fit",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#evaluate",
    "href": "titanic classification model/4 classification Tidy Modeling.html#evaluate",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.816 Preprocessor1_Model1\n2 roc_auc  binary         0.885 Preprocessor1_Model1\n\n\nAccuracy = (TN + TP)/(TN+TP+FN+FP) = (Number of correct assessments)/Number of all assessments)\nSensitivity = TP/(TP + FN) = (Number of true positive assessment)/(Number of all positive assessment)\nSpecificity = TN/(TN + FP) = (Number of true negative assessment)/(Number of all negative assessment)\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.816\n2 recall    binary         0.903\n3 precision binary         0.823\n4 f_meas    binary         0.861\n5 kap       binary         0.590\n6 sens      binary         0.903\n7 spec      binary         0.667\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% rename(.pred_T = 2, .pred_F = 3) %&gt;% \n  roc_curve(target_variable, .pred_T) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_impute_knn()\n• step_rm()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 623 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 623 244 0 (0.60834671 0.39165329)  \n     2) Sex_male&gt;=-0.3181194 406  84 0 (0.79310345 0.20689655)  \n       4) Age&gt;=-1.700165 388  70 0 (0.81958763 0.18041237)  \n         8) Pclass&gt;=-0.9236371 305  39 0 (0.87213115 0.12786885)  \n          16) Fare&lt; 0.4362002 295  35 0 (0.88135593 0.11864407)  \n            32) Cabin_E121&gt;=1.925855 26   0 0 (1.00000000 0.00000000) *\n            33) Cabin_E121&lt; 1.925855 269  35 0 (0.86988848 0.13011152)  \n              66) Age&gt;=-0.6289231 209  23 0 (0.88995215 0.11004785) *\n              67) Age&lt; -0.6289231 60  12 0 (0.80000000 0.20000000)  \n               134) Embarked_S&gt;=-0.4915368 49   7 0 (0.85714286 0.14285714)  \n                 268) PassengerId&gt;=0.8547689 16   0 0 (1.00000000 0.00000000) *\n                 269) PassengerId&lt; 0.8547689 33   7 0 (0.78787879 0.21212121)  \n                   538) Fare&lt; -0.543308 8   0 0 (1.00000000 0.00000000) *\n                   539) Fare&gt;=-0.543308 25   7 0 (0.72000000 0.28000000)  \n                    1078) Fare&gt;=-0.5171166 18   3 0 (0.83333333 0.16666667) *\n                    1079) Fare&lt; -0.5171166 7   3 1 (0.42857143 0.57142857) *\n               135) Embarked_S&lt; -0.4915368 11   5 0 (0.54545455 0.45454545) *\n          17) Fare&gt;=0.4362002 10   4 0 (0.60000000 0.40000000) *\n         9) Pclass&lt; -0.9236371 83  31 0 (0.62650602 0.37349398)  \n          18) PassengerId&lt; -1.024023 15   1 0 (0.93333333 0.06666667) *\n          19) PassengerId&gt;=-1.024023 68  30 0 (0.55882353 0.44117647)  \n            38) Age&gt;=0.4276941 48  17 0 (0.64583333 0.35416667)  \n              76) SibSp&lt; -0.03494193 34   9 0 (0.73529412 0.26470588)  \n               152) Fare&gt;=0.01793593 7   0 0 (1.00000000 0.00000000) *\n               153) Fare&lt; 0.01793593 27   9 0 (0.66666667 0.33333333)  \n                 306) Fare&lt; -0.05252826 20   5 0 (0.75000000 0.25000000) *\n                 307) Fare&gt;=-0.05252826 7   3 1 (0.42857143 0.57142857) *\n              77) SibSp&gt;=-0.03494193 14   6 1 (0.42857143 0.57142857) *\n            39) Age&lt; 0.4276941 20   7 1 (0.35000000 0.65000000) *\n       5) Age&lt; -1.700165 18   4 1 (0.22222222 0.77777778) *\n     3) Sex_male&lt; -0.3181194 217  57 1 (0.26267281 0.73732719)  \n       6) Pclass&gt;=0.2640325 91  42 0 (0.53846154 0.46153846)  \n        12) Fare&gt;=-0.1653079 16   1 0 (0.93750000 0.06250000) *\n        13) Fare&lt; -0.1653079 75  34 1 (0.45333333 0.54666667)  \n          26) Embarked_S&gt;=-0.4915368 42  18 0 (0.57142857 0.42857143)  \n            52) Fare&gt;=-0.3321481 9   2 0 (0.77777778 0.22222222) *\n            53) Fare&lt; -0.3321481 33  16 0 (0.51515152 0.48484848)  \n             106) Fare&lt; -0.4658063 23   8 0 (0.65217391 0.34782609)  \n               212) PassengerId&lt; 0.1220595 14   3 0 (0.78571429 0.21428571) *\n               213) PassengerId&gt;=0.1220595 9   4 1 (0.44444444 0.55555556) *\n             107) Fare&gt;=-0.4658063 10   2 1 (0.20000000 0.80000000) *\n          27) Embarked_S&lt; -0.4915368 33  10 1 (0.30303030 0.69696970)  \n            54) Cabin_G6&lt; 1.120627 13   6 0 (0.53846154 0.46153846) *\n            55) Cabin_G6&gt;=1.120627 20   3 1 (0.15000000 0.85000000) *\n       7) Pclass&lt; 0.2640325 126   8 1 (0.06349206 0.93650794) *\n\n...\nand 0 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#save-model",
    "href": "titanic classification model/4 classification Tidy Modeling.html#save-model",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.14 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "titanic classification model/4 classification Tidy Modeling.html#make-predication",
    "href": "titanic classification model/4 classification Tidy Modeling.html#make-predication",
    "title": "Classification model with Recipe,workflow,fast tunning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 0          \n2 1          \n3 1          \n4 0          \n5 0          \n6 0          \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 47 13\n         1 10 19\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.742\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 0                  57\n2 1                  32\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 0              60\n2 1              29\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction  0  1\n         0 47 13\n         1 10 19",
    "crumbs": [
      "titanic classification model",
      "Classification model with Recipe,workflow,fast tunning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html",
    "href": "hotel classification model/5 classification Tidy Modeling.html",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "",
    "text": "Level 5 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/5 classification Tidy Modeling.html#read-data",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/5 classification Tidy Modeling.html#data-split",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/5 classification Tidy Modeling.html#recipe",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#model",
    "href": "hotel classification model/5 classification Tidy Modeling.html#model",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\ndecision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\nnum_leaves()\n\n\nNumber of Leaves (quantitative)\nRange: [5, 100]\n\n\ntunning grid\n\n\nCode\ngrid_tune &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 200)\n\n\n\n\nCode\ngrid_tune |&gt; glimpse(width = 200)\n\n\nRows: 200\nColumns: 2\n$ cost_complexity &lt;dbl&gt; 1.261316e-07, 1.039957e-04, 5.167414e-03, 3.694176e-04, 2.289054e-09, 1.567029e-04, 3.242447e-03, 4.373541e-09, 1.341326e-07, 5.984753e-03, 2.577958e-03, 1.130172e-09, 8.8965…\n$ tree_depth      &lt;int&gt; 7, 10, 3, 6, 3, 4, 13, 11, 15, 1, 11, 7, 4, 12, 8, 8, 9, 14, 10, 5, 4, 4, 7, 12, 2, 7, 13, 2, 14, 10, 13, 5, 14, 10, 13, 9, 15, 11, 14, 2, 8, 11, 5, 2, 11, 3, 1, 13, 10, 4, 1…\n\n\n\n\nCode\ngrid_tune %&gt;% count(tree_depth)\n\n\n# A tibble: 15 × 2\n   tree_depth     n\n        &lt;int&gt; &lt;int&gt;\n 1          1     7\n 2          2    15\n 3          3    14\n 4          4    14\n 5          5    15\n 6          6    14\n 7          7    14\n 8          8    14\n 9          9    14\n10         10    15\n11         11    14\n12         12    14\n13         13    15\n14         14    14\n15         15     7",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#workflow",
    "href": "hotel classification model/5 classification Tidy Modeling.html#workflow",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nlibrary(finetune)\ncntl &lt;- control_race(save_pred     = TRUE,\n                          save_workflow = TRUE)\n\n\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/5 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\nusing tune_race_anova() instead of tune_grid()\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\ntree_res = model_workflow %&gt;% \n  tune_race_anova(\n    resamples = folds,\n    grid = grid_tune,\n    control   = cntl\n    )\n\n\n\n\nCode\nautoplot(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_race(tree_res)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 220 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1   0.000000126            7 accuracy binary     0.754    10 0.00567 Preproces…\n 2   0.000000126            7 roc_auc  binary     0.806    10 0.00583 Preproces…\n 3   0.000104              10 accuracy binary     0.762    10 0.00753 Preproces…\n 4   0.000104              10 roc_auc  binary     0.815    10 0.00545 Preproces…\n 5   0.000369               6 accuracy binary     0.745    10 0.00758 Preproces…\n 6   0.000369               6 roc_auc  binary     0.804    10 0.00577 Preproces…\n 7   0.00000000437         11 accuracy binary     0.756    10 0.00610 Preproces…\n 8   0.00000000437         11 roc_auc  binary     0.817    10 0.00538 Preproces…\n 9   0.000000134           15 accuracy binary     0.751    10 0.00305 Preproces…\n10   0.000000134           15 roc_auc  binary     0.815    10 0.00499 Preproces…\n# ℹ 210 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best()\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;       \n1        4.37e- 9         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n2        4.32e- 5         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n3        1.09e-10         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n4        1.45e- 9         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n5        7.52e- 8         11 roc_auc binary     0.817    10 0.00538 Preprocesso…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best()\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config               \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                 \n1   0.00000000437         11 Preprocessor1_Model008\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 4.37354062320283e-09\n  tree_depth = 11\n\nComputational engine: rpart",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/5 classification Tidy Modeling.html#last-fit",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/5 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.765 Preprocessor1_Model1\n2 roc_auc  binary         0.811 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.765\n2 recall    binary         0.701\n3 precision binary         0.208\n4 f_meas    binary         0.320\n5 kap       binary         0.226\n6 sens      binary         0.701\n7 spec      binary         0.770\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5708 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 5708 2854 children (0.500000000 0.500000000)  \n     2) adr&gt;=0.1217285 2186  515 children (0.764409881 0.235590119)  \n       4) adr&gt;=0.795892 1118  149 children (0.866726297 0.133273703)  \n         8) adults&lt; 1.258765 992  110 children (0.889112903 0.110887097)  \n          16) hotel_Resort.Hotel&lt; 0.2015753 489   29 children (0.940695297 0.059304703)  \n            32) arrival_date_month_September&lt; 1.809553 451   20 children (0.955654102 0.044345898)  \n              64) adr&gt;=1.310769 220    2 children (0.990909091 0.009090909) *\n              65) adr&lt; 1.310769 231   18 children (0.922077922 0.077922078)  \n               130) adr&lt; 1.227981 210   12 children (0.942857143 0.057142857) *\n               131) adr&gt;=1.227981 21    6 children (0.714285714 0.285714286)  \n                 262) arrival_date_month_August&gt;=0.8845497 10    0 children (1.000000000 0.000000000) *\n                 263) arrival_date_month_August&lt; 0.8845497 11    5 none (0.454545455 0.545454545) *\n            33) arrival_date_month_September&gt;=1.809553 38    9 children (0.763157895 0.236842105)  \n              66) total_of_special_requests&gt;=-0.4338162 29    3 children (0.896551724 0.103448276) *\n              67) total_of_special_requests&lt; -0.4338162 9    3 none (0.333333333 0.666666667) *\n          17) hotel_Resort.Hotel&gt;=0.2015753 503   81 children (0.838966203 0.161033797)  \n            34) adr&gt;=1.806699 184   13 children (0.929347826 0.070652174) *\n            35) adr&lt; 1.806699 319   68 children (0.786833856 0.213166144)  \n              70) arrival_date_month_August&lt; 0.8845497 189   28 children (0.851851852 0.148148148)  \n               140) arrival_date_month_July&lt; 1.00281 69    4 children (0.942028986 0.057971014) *\n               141) arrival_date_month_July&gt;=1.00281 120   24 children (0.800000000 0.200000000)  \n                 282) adr&gt;=1.003498 96   16 children (0.833333333 0.166666667) *\n                 283) adr&lt; 1.003498 24    8 children (0.666666667 0.333333333)  \n                   566) adr&lt; 0.8813067 9    0 children (1.000000000 0.000000000) *\n                   567) adr&gt;=0.8813067 15    7 none (0.466666667 0.533333333) *\n              71) arrival_date_month_August&gt;=0.8845497 130   40 children (0.692307692 0.307692308)  \n               142) required_car_parking_spaces_parking&gt;=1.047041 45    9 children (0.800000000 0.200000000) *\n               143) required_car_parking_spaces_parking&lt; 1.047041 85   31 children (0.635294118 0.364705882)  \n                 286) stays_in_weekend_nights&gt;=0.53872 54   16 children (0.703703704 0.296296296)  \n                   572) adr&gt;=0.9636965 40    9 children (0.775000000 0.225000000)  \n                    1144) stays_in_week_nights&lt; 1.62789 33    5 children (0.848484848 0.151515152) *\n                    1145) stays_in_week_nights&gt;=1.62789 7    3 none (0.428571429 0.571428571) *\n                   573) adr&lt; 0.9636965 14    7 children (0.500000000 0.500000000) *\n                 287) stays_in_weekend_nights&lt; 0.53872 31   15 children (0.516129032 0.483870968)  \n                   574) adr&gt;=1.17385 21    8 children (0.619047619 0.380952381)  \n                    1148) adr&lt; 1.37684 7    0 children (1.000000000 0.000000000) *\n                    1149) adr&gt;=1.37684 14    6 none (0.428571429 0.571428571) *\n                   575) adr&lt; 1.17385 10    3 none (0.300000000 0.700000000) *\n         9) adults&gt;=1.258765 126   39 children (0.690476190 0.309523810)  \n          18) adr&gt;=1.235145 83   14 children (0.831325301 0.168674699)  \n            36) adr&gt;=1.476344 62    7 children (0.887096774 0.112903226)  \n              72) arrival_date_month_August&lt; 0.8845497 40    2 children (0.950000000 0.050000000) *\n              73) arrival_date_month_August&gt;=0.8845497 22    5 children (0.772727273 0.227272727)  \n               146) stays_in_week_nights&lt; 0.5290259 13    0 children (1.000000000 0.000000000) *\n               147) stays_in_week_nights&gt;=0.5290259 9    4 none (0.444444444 0.555555556) *\n\n...\nand 200 more lines.\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/5 classification Tidy Modeling.html#save-model",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.53 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 5 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/5 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/5 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model with recipe,workflow,fast tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 5 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 none       \n3 none       \n4 none       \n5 none       \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      574 2043\n  none          247 7136\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.771\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          821\n2 none             9179\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2617\n2 none         7383\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      574 2043\n  none          247 7136",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html",
    "href": "hotel classification model/6 classification Tidy Modeling.html",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:\nlogistic glm model\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\nKNN model with knn engine(knn_spec)\ntuning XG boost model (tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)\ntuning light gbm boost model(tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/6 classification Tidy Modeling.html#read-data",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/6 classification Tidy Modeling.html#data-split",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/6 classification Tidy Modeling.html#recipe",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#model",
    "href": "hotel classification model/6 classification Tidy Modeling.html#model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\n\n\nCode\nglm_spec &lt;-\n  logistic_reg(penalty = 1) |&gt;\n  set_engine(\"glm\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          2   3.42e- 6       8.02e- 9    32       0.734     3\n2          7   4.05e- 5       2.42e- 1    25       0.393     7\n3         14   4.98e- 4       5.17e-10     4       0.465     3\n4         12   4.33e- 8       8.46e- 7     8       0.485     9\n5         10   4.00e-10       2.81e- 5    14       0.387     9\n6          7   7.24e- 5       8.03e- 2     9       0.105    11\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         10   1.14e-10       1.09e- 3    13       0.682     1\n2          6   1.25e- 5       1.81e+ 1    19       0.265     6\n3          2   3.59e- 6       1.55e- 5    18       0.860     8\n4          3   5.01e- 8       2.34e-10    20       0.108     6\n5         15   2.98e- 2       2.05e- 6    21       0.341     5\n6         13   2.28e- 3       2.52e- 7    34       0.124     4",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#workflow-set",
    "href": "hotel classification model/6 classification Tidy Modeling.html#workflow-set",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;% option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/6 classification Tidy Modeling.html#training-and-tunning",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 20,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"roc_auc\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_xgb\nPreprocessor1_Model19\naccuracy\n0.7659429\n0.002672714\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model19\nroc_auc\n0.8351222\n0.003292009\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\naccuracy\n0.7679429\n0.003942857\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nroc_auc\n0.8328707\n0.003144983\n10\nrecipe\nboost_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\naccuracy\n0.7465143\n0.007227285\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_tree\nPreprocessor1_Model02\nroc_auc\n0.8179011\n0.004984221\n10\nrecipe\ndecision_tree\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.7581714\n0.001141428\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7979514\n0.004063108\n10\nrecipe\nlogistic_reg\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.7366857\n0.001567354\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7849985\n0.004460053\n10\nrecipe\nnearest_neighbor\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/6 classification Tidy Modeling.html#last-fit",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/6 classification Tidy Modeling.html#evaluate",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.754 Preprocessor1_Model1\n2 roc_auc  binary         0.774 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  binary         0.754\n2 recall    binary         0.690\n3 precision binary         0.201\n4 f_meas    binary         0.311\n5 kap       binary         0.213\n6 sens      binary         0.690\n7 spec      binary         0.760\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 11.6 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.00470774296245284, max_depth = 1L, \n    gamma = 5.1538567202903, colsample_bytree = 1, colsample_bynode = 0.454545454545455, \n    min_child_weight = 18L, subsample = 0.133142875451595), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.00470774296245284\", max_depth = \"1\", gamma = \"5.1538567202903\", colsample_bytree = \"1\", colsample_bynode = \"0.454545454545455\", min_child_weight = \"18\", subsample = \"0.133142875451595\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 22 \nniter: 10\nnfeatures : 22 \nevaluation_log:\n     iter training_logloss\n    &lt;num&gt;            &lt;num&gt;\n        1        0.6924354\n        2        0.6924197\n---                       \n        9        0.6891105\n       10        0.6889369\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/6 classification Tidy Modeling.html#save-model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.44 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/6 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/6 classification Tidy Modeling.html#make-predication",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 none       \n2 children   \n3 children   \n4 none       \n5 children   \n6 none       \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      541 2217\n  none          244 6998\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.754\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          785\n2 none             9215\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2758\n2 none         7242\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      541 2217\n  none          244 6998",
    "crumbs": [
      "hotel classification model",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html",
    "href": "hotel classification model/4 classification Tidy Modeling.html",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "",
    "text": "Level 4 classification Tidy Modeling with 1 tuning model and 1 recipe :\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth) with tune_grid()",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#read-data",
    "href": "hotel classification model/4 classification Tidy Modeling.html#read-data",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\nhotels &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv\")\n\n\nhotel_stays &lt;- hotels %&gt;%\n  filter(is_canceled == 0) %&gt;%\n  mutate(\n    children = case_when(\n      children + babies &gt; 0 ~ \"children\",\n      TRUE ~ \"none\"\n    ),\n    required_car_parking_spaces = case_when(\n      required_car_parking_spaces &gt; 0 ~ \"parking\",\n      TRUE ~ \"none\"\n    )\n  ) %&gt;%\n  select(-is_canceled, -reservation_status, -babies)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#data-split",
    "href": "hotel classification model/4 classification Tidy Modeling.html#data-split",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nPrepare & Split Data\nall_hotels_df &lt;- hotel_stays %&gt;%\n  select(\n    children, hotel, arrival_date_month, meal, adr, adults,\n    required_car_parking_spaces, total_of_special_requests,\n    stays_in_week_nights, stays_in_weekend_nights\n  ) %&gt;%\n  mutate_if(is.character, factor) %&gt;% rename(target_variable=children) %&gt;% mutate(rownum= row_number())\n\nhotels_df=all_hotels_df%&gt;% sample_n(50000) \n\nhold_hotels_df &lt;- anti_join(all_hotels_df, hotels_df, by='rownum')\n\n\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n#hotels_df=hotels_df %&gt;% select(-rownum)\n#all_hotels_df=all_hotels_df %&gt;% select(-rownum)\n\n\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=hotels_df, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 35000    11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 5000   11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 10000    11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train,v=10)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#recipe",
    "href": "hotel classification model/4 classification Tidy Modeling.html#recipe",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(rownum) %&gt;% \n  step_downsample(target_variable) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#model",
    "href": "hotel classification model/4 classification Tidy Modeling.html#model",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.2 model",
    "text": "3.2 model\ntree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec\n\n\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n\n\n\n\nCode\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n\ntree_grid\n\n\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             &lt;dbl&gt;      &lt;int&gt;\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# ℹ 15 more rows\n\n\n\n\nCode\ntree_grid %&gt;% count(tree_depth)\n\n\n# A tibble: 5 × 2\n  tree_depth     n\n       &lt;int&gt; &lt;int&gt;\n1          1     5\n2          4     5\n3          8     5\n4         11     5\n5         15     5",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#workflow",
    "href": "hotel classification model/4 classification Tidy Modeling.html#workflow",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.3 workflow",
    "text": "3.3 workflow\n\n\nCode\nmodel_workflow =\n  workflow() %&gt;% \n  add_model(tune_spec) %&gt;% \n  add_recipe(data_rec)\n\n\n\n\nCode\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "href": "hotel classification model/4 classification Tidy Modeling.html#training-and-tunning",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\ntree_res = model_workflow %&gt;% \n  tune_grid(\n    resamples = folds,\n    grid = tree_grid,\n    control   = cntl,\n    )\n\n\n\n\nCode\ntree_res\n\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 5\n   splits               id     .metrics          .notes           .predictions\n   &lt;list&gt;               &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;           &lt;list&gt;      \n 1 &lt;split [31500/3500]&gt; Fold01 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 2 &lt;split [31500/3500]&gt; Fold02 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 3 &lt;split [31500/3500]&gt; Fold03 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 4 &lt;split [31500/3500]&gt; Fold04 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 5 &lt;split [31500/3500]&gt; Fold05 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 6 &lt;split [31500/3500]&gt; Fold06 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 7 &lt;split [31500/3500]&gt; Fold07 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 8 &lt;split [31500/3500]&gt; Fold08 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n 9 &lt;split [31500/3500]&gt; Fold09 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n10 &lt;split [31500/3500]&gt; Fold10 &lt;tibble [50 × 6]&gt; &lt;tibble [0 × 3]&gt; &lt;tibble&gt;    \n\n\n\n\nCode\ntree_res %&gt;% \n  collect_metrics()\n\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;     \n 1    0.0000000001          1 accuracy binary     0.806    10 0.0108  Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 3    0.0000000178          1 accuracy binary     0.806    10 0.0108  Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 5    0.00000316            1 accuracy binary     0.806    10 0.0108  Preproces…\n 6    0.00000316            1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 7    0.000562              1 accuracy binary     0.806    10 0.0108  Preproces…\n 8    0.000562              1 roc_auc  binary     0.686    10 0.00390 Preproces…\n 9    0.1                   1 accuracy binary     0.806    10 0.0108  Preproces…\n10    0.1                   1 roc_auc  binary     0.686    10 0.00390 Preproces…\n# ℹ 40 more rows\n\n\n\n\nCode\ntree_res %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\n\n\n\n\nCode\ntree_res %&gt;%\n  show_best(\"accuracy\")\n\n\n# A tibble: 5 × 8\n  cost_complexity tree_depth .metric  .estimator  mean     n std_err .config    \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n1    0.0000000001          1 accuracy binary     0.806    10  0.0108 Preprocess…\n2    0.0000000178          1 accuracy binary     0.806    10  0.0108 Preprocess…\n3    0.00000316            1 accuracy binary     0.806    10  0.0108 Preprocess…\n4    0.000562              1 accuracy binary     0.806    10  0.0108 Preprocess…\n5    0.1                   1 accuracy binary     0.806    10  0.0108 Preprocess…\n\n\n\n\nCode\nbest_tree &lt;- tree_res %&gt;%\n  select_best(\"accuracy\")\n\nbest_tree\n\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1    0.0000000001          1 Preprocessor1_Model01\n\n\n\n\nCode\nfinal_wf &lt;- \n  model_workflow %&gt;% \n  finalize_workflow(best_tree)\n\n\nfinal_wf\n\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 1\n\nComputational engine: rpart",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#last-fit",
    "href": "hotel classification model/4 classification Tidy Modeling.html#last-fit",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;- \n  final_wf %&gt;%\n  last_fit(data_split)",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#evaluate",
    "href": "hotel classification model/4 classification Tidy Modeling.html#evaluate",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy binary         0.789 Preprocessor1_Model1\n2 roc_auc  binary         0.701 Preprocessor1_Model1\n\n\n\n\nCode\nfinal_fit %&gt;%\n  collect_predictions() %&gt;% \n  roc_curve(target_variable, .pred_children) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_rm()\n• step_downsample()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 5754 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n1) root 5754 2877 children (0.5000000 0.5000000)  \n  2) adr&gt;=0.1165396 2235  553 children (0.7525727 0.2474273) *\n  3) adr&lt; 0.1165396 3519 1195 none (0.3395851 0.6604149) *\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#save-model",
    "href": "hotel classification model/4 classification Tidy Modeling.html#save-model",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n3.48 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 4 classification decision tree hotel model.RDS')",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "hotel classification model/4 classification Tidy Modeling.html#make-predication",
    "href": "hotel classification model/4 classification Tidy Modeling.html#make-predication",
    "title": "Classification Model with recipe,workflow,tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 4 classification decision tree hotel model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 children   \n2 none       \n3 none       \n4 none       \n5 children   \n6 children   \n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      467 1879\n  none          288 7366\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.783\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   target_variable [2]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 children          755\n2 none             9245\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 2 × 2\n# Groups:   .pred_class [2]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 children     2346\n2 none         7654\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction children none\n  children      467 1879\n  none          288 7366",
    "crumbs": [
      "hotel classification model",
      "Classification Model with recipe,workflow,tuning"
    ]
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html",
    "href": "tensorflow/Level 1 Regression tensorflow.html",
    "title": "Level 1 Regression Tensorflow model",
    "section": "",
    "text": "Code\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n\n\nCode\nprint(\"TensorFlow v\" + tf.__version__)\nprint(\"TensorFlow Decision Forests v\" + tfdf.__version__)\n\n\nTensorFlow v2.16.1\nTensorFlow Decision Forests v1.9.0"
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#read-data",
    "href": "tensorflow/Level 1 Regression tensorflow.html#read-data",
    "title": "Level 1 Regression Tensorflow model",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\ntrain_file_path = \"data/train.csv\"\ndataset_df = pd.read_csv(train_file_path)\nprint(\"Full train dataset shape is {}\".format(dataset_df.shape))\n\n\nFull train dataset shape is (1460, 81)\n\n\n\n\nCode\ndataset_df.head(3)\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n\n\n3 rows × 81 columns\n\n\n\n\n\n\nCode\ndataset_df = dataset_df.drop('Id', axis=1)\ndataset_df.head(3)\n\n\n\n\n\n\n\n\n\n\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\nLotConfig\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\nInside\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\nFR2\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\nInside\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n\n\n3 rows × 80 columns\n\n\n\n\n\n\nCode\ndataset_df.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 80 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   MSSubClass     1460 non-null   int64  \n 1   MSZoning       1460 non-null   object \n 2   LotFrontage    1201 non-null   float64\n 3   LotArea        1460 non-null   int64  \n 4   Street         1460 non-null   object \n 5   Alley          91 non-null     object \n 6   LotShape       1460 non-null   object \n 7   LandContour    1460 non-null   object \n 8   Utilities      1460 non-null   object \n 9   LotConfig      1460 non-null   object \n 10  LandSlope      1460 non-null   object \n 11  Neighborhood   1460 non-null   object \n 12  Condition1     1460 non-null   object \n 13  Condition2     1460 non-null   object \n 14  BldgType       1460 non-null   object \n 15  HouseStyle     1460 non-null   object \n 16  OverallQual    1460 non-null   int64  \n 17  OverallCond    1460 non-null   int64  \n 18  YearBuilt      1460 non-null   int64  \n 19  YearRemodAdd   1460 non-null   int64  \n 20  RoofStyle      1460 non-null   object \n 21  RoofMatl       1460 non-null   object \n 22  Exterior1st    1460 non-null   object \n 23  Exterior2nd    1460 non-null   object \n 24  MasVnrType     588 non-null    object \n 25  MasVnrArea     1452 non-null   float64\n 26  ExterQual      1460 non-null   object \n 27  ExterCond      1460 non-null   object \n 28  Foundation     1460 non-null   object \n 29  BsmtQual       1423 non-null   object \n 30  BsmtCond       1423 non-null   object \n 31  BsmtExposure   1422 non-null   object \n 32  BsmtFinType1   1423 non-null   object \n 33  BsmtFinSF1     1460 non-null   int64  \n 34  BsmtFinType2   1422 non-null   object \n 35  BsmtFinSF2     1460 non-null   int64  \n 36  BsmtUnfSF      1460 non-null   int64  \n 37  TotalBsmtSF    1460 non-null   int64  \n 38  Heating        1460 non-null   object \n 39  HeatingQC      1460 non-null   object \n 40  CentralAir     1460 non-null   object \n 41  Electrical     1459 non-null   object \n 42  1stFlrSF       1460 non-null   int64  \n 43  2ndFlrSF       1460 non-null   int64  \n 44  LowQualFinSF   1460 non-null   int64  \n 45  GrLivArea      1460 non-null   int64  \n 46  BsmtFullBath   1460 non-null   int64  \n 47  BsmtHalfBath   1460 non-null   int64  \n 48  FullBath       1460 non-null   int64  \n 49  HalfBath       1460 non-null   int64  \n 50  BedroomAbvGr   1460 non-null   int64  \n 51  KitchenAbvGr   1460 non-null   int64  \n 52  KitchenQual    1460 non-null   object \n 53  TotRmsAbvGrd   1460 non-null   int64  \n 54  Functional     1460 non-null   object \n 55  Fireplaces     1460 non-null   int64  \n 56  FireplaceQu    770 non-null    object \n 57  GarageType     1379 non-null   object \n 58  GarageYrBlt    1379 non-null   float64\n 59  GarageFinish   1379 non-null   object \n 60  GarageCars     1460 non-null   int64  \n 61  GarageArea     1460 non-null   int64  \n 62  GarageQual     1379 non-null   object \n 63  GarageCond     1379 non-null   object \n 64  PavedDrive     1460 non-null   object \n 65  WoodDeckSF     1460 non-null   int64  \n 66  OpenPorchSF    1460 non-null   int64  \n 67  EnclosedPorch  1460 non-null   int64  \n 68  3SsnPorch      1460 non-null   int64  \n 69  ScreenPorch    1460 non-null   int64  \n 70  PoolArea       1460 non-null   int64  \n 71  PoolQC         7 non-null      object \n 72  Fence          281 non-null    object \n 73  MiscFeature    54 non-null     object \n 74  MiscVal        1460 non-null   int64  \n 75  MoSold         1460 non-null   int64  \n 76  YrSold         1460 non-null   int64  \n 77  SaleType       1460 non-null   object \n 78  SaleCondition  1460 non-null   object \n 79  SalePrice      1460 non-null   int64  \ndtypes: float64(3), int64(34), object(43)\nmemory usage: 912.6+ KB"
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#data-pre",
    "href": "tensorflow/Level 1 Regression tensorflow.html#data-pre",
    "title": "Level 1 Regression Tensorflow model",
    "section": "2.2 data pre",
    "text": "2.2 data pre\n\n\nCode\nimport numpy as np\ndef split_dataset(dataset, test_ratio=0.30):\n  test_indices = np.random.rand(len(dataset)) &lt; test_ratio\n  return dataset[~test_indices], dataset[test_indices]\n\ntrain_ds_pd, valid_ds_pd = split_dataset(dataset_df)\nprint(\"{} examples in training, {} examples in testing.\".format(\n    len(train_ds_pd), len(valid_ds_pd)))\n\n\n1012 examples in training, 448 examples in testing.\n\n\n\n\nCode\nlabel = 'SalePrice'\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)\nvalid_ds = tfdf.keras.pd_dataframe_to_tf_dataset(valid_ds_pd, label=label, task = tfdf.keras.Task.REGRESSION)"
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#define-model-keras-random-forest",
    "href": "tensorflow/Level 1 Regression tensorflow.html#define-model-keras-random-forest",
    "title": "Level 1 Regression Tensorflow model",
    "section": "3.1 define model Keras random forest",
    "text": "3.1 define model Keras random forest\n\n\nCode\ntfdf.keras.get_all_models()\n\n\n[tensorflow_decision_forests.keras.RandomForestModel,\n tensorflow_decision_forests.keras.GradientBoostedTreesModel,\n tensorflow_decision_forests.keras.CartModel,\n tensorflow_decision_forests.keras.DistributedGradientBoostedTreesModel]\n\n\n\n\nCode\nrf = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\nrf.compile(metrics=[\"mse\"]) # Optional, you can use this to include a list of eval metrics\n\n\nUse /var/folders/v3/pzt9c47n1nbcsmybsg_w0lhw0000gn/T/tmpfvd0haib as temporary training directory"
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#train-model",
    "href": "tensorflow/Level 1 Regression tensorflow.html#train-model",
    "title": "Level 1 Regression Tensorflow model",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nrf.fit(x=train_ds)\n\n\nReading training dataset...\nTraining dataset read in 0:00:01.592298. Found 1012 examples.\nTraining model...\nModel trained in 0:00:00.488444\nCompiling model...\nModel compiled.\n\n\n&lt;tf_keras.src.callbacks.History at 0x10572d850&gt;\n\n\n\n\nCode\ntfdf.model_plotter.plot_model_in_colab(rf, tree_idx=0, max_depth=3)\n\n\n\n\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\nlogs = rf.make_inspector().training_logs()\nplt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"RMSE (out-of-bag)\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\ninspector = rf.make_inspector()\ninspector.evaluation()\n\n\nEvaluation(num_examples=1012, accuracy=None, loss=None, rmse=29144.798502788246, ndcg=None, aucs=None, auuc=None, qini=None)\n\n\n\n\nCode\nevaluation = rf.evaluate(x=valid_ds,return_dict=True)\n\nfor name, value in evaluation.items():\n  print(f\"{name}: {value:.4f}\")\n\n\n1/1 [==============================] - ETA: 0s - loss: 0.0000e+00 - mse: 912837952.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - mse: 912837952.0000\nloss: 0.0000\nmse: 912837952.0000\n\n\n\n\nCode\nfor name, value in evaluation.items():\n  mse=value\n\n\nRMSE\n\n\nCode\nimport math\nmath.sqrt(mse)\n\n\n30213.208237458002"
  },
  {
    "objectID": "tensorflow/Level 1 Regression tensorflow.html#variable-importances",
    "href": "tensorflow/Level 1 Regression tensorflow.html#variable-importances",
    "title": "Level 1 Regression Tensorflow model",
    "section": "3.3 Variable importances",
    "text": "3.3 Variable importances\n\n\nCode\nprint(f\"Available variable importances:\")\nfor importance in inspector.variable_importances().keys():\n  print(\"\\t\", importance)\n\n\nAvailable variable importances:\n     INV_MEAN_MIN_DEPTH\n     NUM_NODES\n     NUM_AS_ROOT\n     SUM_SCORE"
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html",
    "href": "Multiclass classification/6 multclass classification.html",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "",
    "text": "Level 6 classification Tidy Modeling:\nlogistic glm model\ntuning decision tree model with rpart engine(tunning:cost_complexity,tree_depth)\nKNN model with knn engine(knn_spec)\ntuning XG boost model (tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)\ntuning light gbm boost model(tunning:tree_depth , min_n,loss_reduction ,sample_size , mtry,learn_rate)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#read-data",
    "href": "Multiclass classification/6 multclass classification.html#read-data",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\n\n\n\n\nCode\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\n#%&gt;% filter(target_variable %in% c('A','B'))\ndf_test=df_test_raw\n\n\n\n\nCode\nglimpse(df_train)\n\n\nRows: 8,068\nColumns: 11\n$ ID              &lt;dbl&gt; 462809, 462643, 466315, 461735, 462669, 461319, 460156…\n$ Gender          &lt;chr&gt; \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", …\n$ Ever_Married    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"…\n$ Age             &lt;dbl&gt; 22, 38, 67, 67, 40, 56, 32, 33, 61, 55, 26, 19, 19, 70…\n$ Graduated       &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", …\n$ Profession      &lt;chr&gt; \"Healthcare\", \"Engineer\", \"Engineer\", \"Lawyer\", \"Enter…\n$ Work_Experience &lt;dbl&gt; 1, NA, 1, 0, NA, 0, 1, 1, 0, 1, 1, 4, 0, NA, 0, 1, 9, …\n$ Spending_Score  &lt;chr&gt; \"Low\", \"Average\", \"Low\", \"High\", \"High\", \"Average\", \"L…\n$ Family_Size     &lt;dbl&gt; 4, 3, 1, 2, 6, 2, 3, 3, 3, 4, 3, 4, NA, 1, 1, 2, 5, 6,…\n$ Var_1           &lt;chr&gt; \"Cat_4\", \"Cat_4\", \"Cat_6\", \"Cat_6\", \"Cat_6\", \"Cat_6\", …\n$ target_variable &lt;fct&gt; D, A, B, B, A, C, C, D, D, C, A, D, D, A, B, C, D, B, …",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#data-split",
    "href": "Multiclass classification/6 multclass classification.html#data-split",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 5647   11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 807  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 1614   11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#recipe",
    "href": "Multiclass classification/6 multclass classification.html#recipe",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  step_rm(ID) %&gt;% \n  #step_downsample(target_variable) %&gt;%\n  step_impute_median(all_numeric(), -all_outcomes())%&gt;% \n  step_impute_mode(all_nominal(), -all_outcomes())%&gt;% \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#model",
    "href": "Multiclass classification/6 multclass classification.html#model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 decision tree model with cost_complexity and tree_depth to tune\n\n\nCode\ntune_spec &lt;- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"classification\")\n\n\n\n\nCode\ntune_spec |&gt; \n  extract_parameter_set_dials()\n\n\nCollection of 2 parameters for tuning\n\n      identifier            type    object\n cost_complexity cost_complexity nparam[+]\n      tree_depth      tree_depth nparam[+]\n\n\n\n\nCode\ndecision_tree_tune_grid &lt;- \n  tune_spec |&gt; \n  extract_parameter_set_dials() |&gt; \n  grid_latin_hypercube(size = 100)\n\n\n\n\n3.2.2 logistic glm model\nusing multinom_reg() since its multiclass classification\n\n\nCode\nglm_spec &lt;-\n  multinom_reg() |&gt;\n  set_engine(\"nnet\")\n\n\n\n\n3.2.3 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\nknn_spec\n\n\nK-Nearest Neighbor Model Specification (classification)\n\nComputational engine: kknn \n\n\n\n\n3.2.4 XG Boost tree\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=10)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          1   2.47e- 6       4.50e- 4    20       0.398    11\n2         15   1.41e- 7       1.35e-10     5       0.219     9\n3          7   1.51e- 8       1.89e- 3    27       0.942     2\n4         13   1.59e- 4       2.10e- 8    36       0.319     4\n5          8   2.73e- 2       5.16e- 1    33       0.183     6\n6          9   1.93e-10       5.17e- 5    10       0.905     3\n\n\n\n\n3.2.5 lightGBM Boost tree\n\n\nCode\nlightgbm_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),   mtry=tune(),     ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"lightgbm\") %&gt;%\n  set_mode(\"classification\")\n\nlightgbm_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: lightgbm \n\n\n\n\nCode\nlightgbm_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=10)\n\nhead(lightgbm_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth    learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;         &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1         13 0.00297         0.0000286       32       0.737     6\n2         11 0.00000110      0.0119          24       0.982     9\n3          5 0.00000671      0.0000000109    11       0.709     2\n4          4 0.00000000266   0.00140         34       0.619     9\n5          5 0.0000000602   24.2              6       0.432     4\n6          7 0.000112        0.000470         3       0.257     6",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#workflow-set",
    "href": "Multiclass classification/6 multclass classification.html#workflow-set",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.3 workflow set",
    "text": "3.3 workflow set\n\n\nCode\nlibrary(finetune)\ncntl   &lt;- control_grid(save_pred     = TRUE,\n                       save_workflow = TRUE)\n\n\nusing workflow set instead of workflow to combine many models.\n\n\nCode\nworkflow_set &lt;-\n  workflow_set(\n    preproc = list(data_rec),\n    models = list(glm   = glm_spec,\n                  tree  = tune_spec,\n                  knn=knn_spec,\n                  xgb=xgb_spec,\n                  lightgbm=lightgbm_spec\n                  )\n  ) %&gt;%\n  #option_add(grid = decision_tree_tune_grid, id = \"recipe_tree\")  %&gt;% \n  option_add(grid = xgb_tune_grid, id = \"recipe_xgb\")  %&gt;% \n  option_add(grid = lightgbm_grid, id = \"recipe_lightgbm\") \n\n\n\n\nCode\nworkflow_set %&gt;%\n  option_add_parameters()\n\n\n# A workflow set/tibble: 5 × 4\n  wflow_id        info             option    result    \n  &lt;chr&gt;           &lt;list&gt;           &lt;list&gt;    &lt;list&gt;    \n1 recipe_glm      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n2 recipe_tree     &lt;tibble [1 × 4]&gt; &lt;opts[1]&gt; &lt;list [0]&gt;\n3 recipe_knn      &lt;tibble [1 × 4]&gt; &lt;opts[0]&gt; &lt;list [0]&gt;\n4 recipe_xgb      &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;\n5 recipe_lightgbm &lt;tibble [1 × 4]&gt; &lt;opts[2]&gt; &lt;list [0]&gt;",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#training-and-tunning",
    "href": "Multiclass classification/6 multclass classification.html#training-and-tunning",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.4 training and tunning",
    "text": "3.4 training and tunning\n\n\nCode\nlibrary(finetune)\ndoParallel::registerDoParallel()\n\nmodel_set_res = workflow_set  %&gt;% \n  workflow_map(\n              grid = 10,\n               resamples = folds,\n               control = cntl\n  )\n\n\n\n\nCode\nrank_results(model_set_res,\n             rank_metric = \"accuracy\",\n             select_best = TRUE)  %&gt;% \n  gt()\n\n\n\n\n\n\n\n\n\nwflow_id\n.config\n.metric\nmean\nstd_err\nn\npreprocessor\nmodel\nrank\n\n\n\n\nrecipe_xgb\nPreprocessor1_Model06\naccuracy\n0.5082270\n8.273046e-03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model06\nbrier_class\n0.3732666\n3.222901e-05\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_xgb\nPreprocessor1_Model06\nroc_auc\n0.7630375\n3.825994e-03\n10\nrecipe\nboost_tree\n1\n\n\nrecipe_tree\nPreprocessor1_Model02\naccuracy\n0.5080500\n6.889790e-03\n10\nrecipe\ndecision_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\nbrier_class\n0.3078043\n2.744968e-03\n10\nrecipe\ndecision_tree\n2\n\n\nrecipe_tree\nPreprocessor1_Model02\nroc_auc\n0.7479156\n5.425592e-03\n10\nrecipe\ndecision_tree\n2\n\n\nrecipe_glm\nPreprocessor1_Model1\naccuracy\n0.5032753\n8.839371e-03\n10\nrecipe\nmultinom_reg\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\nbrier_class\n0.3048293\n2.551260e-03\n10\nrecipe\nmultinom_reg\n3\n\n\nrecipe_glm\nPreprocessor1_Model1\nroc_auc\n0.7542779\n5.770592e-03\n10\nrecipe\nmultinom_reg\n3\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\naccuracy\n0.4779517\n9.344905e-03\n10\nrecipe\nboost_tree\n4\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nbrier_class\n0.3417080\n1.534749e-03\n10\nrecipe\nboost_tree\n4\n\n\nrecipe_lightgbm\nPreprocessor1_Model05\nroc_auc\n0.7263411\n6.250417e-03\n10\nrecipe\nboost_tree\n4\n\n\nrecipe_knn\nPreprocessor1_Model1\naccuracy\n0.4521041\n5.486483e-03\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nbrier_class\n0.3802044\n2.918211e-03\n10\nrecipe\nnearest_neighbor\n5\n\n\nrecipe_knn\nPreprocessor1_Model1\nroc_auc\n0.7039305\n3.245546e-03\n10\nrecipe\nnearest_neighbor\n5\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot()\n\n\n\n\n\n\n\n\n\n\n\nCode\nmodel_set_res |&gt; autoplot( id= 'recipe_xgb')\n\n\n\n\n\n\n\n\n\nselect best model:logistic glm model\n\n\nCode\nbest_model_id &lt;- \"recipe_xgb\"\n\n\nselect best parameters\n\n\nCode\nbest_fit &lt;-\n  model_set_res |&gt;\n  extract_workflow_set_result(best_model_id) |&gt;\n  select_best(metric = \"accuracy\")\n\n\n\n\nCode\n# create workflow for best model\nfinal_workflow &lt;-\n  model_set_res |&gt;\n  extract_workflow(best_model_id) |&gt;\n  finalize_workflow(best_fit)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#last-fit",
    "href": "Multiclass classification/6 multclass classification.html#last-fit",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "3.5 last fit",
    "text": "3.5 last fit\n\n\nCode\nfinal_fit &lt;-\n  final_workflow |&gt;\n  last_fit(data_split)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#evaluate",
    "href": "Multiclass classification/6 multclass classification.html#evaluate",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.1 Evaluate",
    "text": "4.1 Evaluate\n\n\nCode\nfinal_fit %&gt;%\n  collect_metrics()\n\n\n# A tibble: 3 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    multiclass     0.550 Preprocessor1_Model1\n2 roc_auc     hand_till      0.787 Preprocessor1_Model1\n3 brier_class multiclass     0.373 Preprocessor1_Model1\n\n\n\n\nCode\nall_metrics &lt;- metric_set(accuracy, recall, precision, f_meas, kap, sens, spec)\n\na=final_fit %&gt;% collect_predictions()\n\nall_metrics(a, truth = target_variable,estimate = .pred_class)\n\n\n# A tibble: 7 × 3\n  .metric   .estimator .estimate\n  &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy  multiclass     0.550\n2 recall    macro          0.536\n3 precision macro          0.533\n4 f_meas    macro          0.530\n5 kap       multiclass     0.396\n6 sens      macro          0.536\n7 spec      macro          0.850\n\n\n\n\nCode\n#final_fit %&gt;%\n#  collect_predictions() %&gt;% \n # roc_curve(target_variable, .pred_children) %&gt;% \n # autoplot()\n\n\n\n\nCode\nfinal_tree &lt;- extract_workflow(final_fit)\nfinal_tree\n\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_rm()\n• step_impute_median()\n• step_impute_mode()\n• step_dummy()\n• step_zv()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 187.5 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.00188744903053763, max_depth = 14L, \n    gamma = 1.47066004807873, colsample_bytree = 1, colsample_bynode = 0.545454545454545, \n    min_child_weight = 5L, subsample = 0.300618941169232), data = x$data, \n    nrounds = 10, watchlist = x$watchlist, verbose = 0, nthread = 1, \n    objective = \"multi:softprob\", num_class = 4L)\nparams (as set within xgb.train):\n  eta = \"0.00188744903053763\", max_depth = \"14\", gamma = \"1.47066004807873\", colsample_bytree = \"1\", colsample_bynode = \"0.545454545454545\", min_child_weight = \"5\", subsample = \"0.300618941169232\", nthread = \"1\", objective = \"multi:softprob\", num_class = \"4\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 22 \nniter: 10\nnfeatures : 22 \nevaluation_log:\n     iter training_mlogloss\n    &lt;num&gt;             &lt;num&gt;\n        1          1.385471\n        2          1.384689\n---                        \n        9          1.379286\n       10          1.378525\n\n\n\n\nCode\nlibrary(vip)\n\nfinal_tree %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#save-model",
    "href": "Multiclass classification/6 multclass classification.html#save-model",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.2 save model",
    "text": "4.2 save model\ncheck model size\n\n\nCode\nlibrary(lobstr)\nobj_size(final_tree)\n\n\n1.84 MB\n\n\nbundle and save model\n\n\nCode\nlibrary(bundle)\nmodel_bundle &lt;- bundle(final_tree)\n\n\n\n\nCode\nsaveRDS(model_bundle,'level 6 multclass classification model.RDS')",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/6 multclass classification.html#make-predication",
    "href": "Multiclass classification/6 multclass classification.html#make-predication",
    "title": "Multiple Classification Model with recipe,workflow set,fast tuning",
    "section": "4.3 make predication",
    "text": "4.3 make predication\nload model and unbundle\n\n\nCode\nmodel=readRDS('level 6 multclass classification model.RDS')\n\nmodel &lt;- unbundle(model)\n\n\n\n\nCode\nfinal_prediction=predict(model,data_valid)\n\nhead(final_prediction)\n\n\n# A tibble: 6 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 B          \n2 C          \n3 D          \n4 D          \n5 D          \n6 C          \n\n\n\n\nCode\nfinal_prediction %&gt;%group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 4 × 2\n# Groups:   .pred_class [4]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 A             448\n2 B             229\n3 C             399\n4 D             538\n\n\n\n\nCode\nfinal_prediction_data=cbind(data_valid,final_prediction)\n\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   A   B   C   D\n         A 185 100  58 105\n         B  54  91  60  24\n         C  57 115 217  10\n         D  96  56  65 321\n\n\n\n\nCode\naccuracy(final_prediction_data, truth = target_variable, estimate = .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.504\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(target_variable)%&gt;% count()\n\n\n# A tibble: 4 × 2\n# Groups:   target_variable [4]\n  target_variable     n\n  &lt;fct&gt;           &lt;int&gt;\n1 A                 392\n2 B                 362\n3 C                 400\n4 D                 460\n\n\n\n\nCode\nfinal_prediction_data %&gt;% group_by(.pred_class) %&gt;% count()\n\n\n# A tibble: 4 × 2\n# Groups:   .pred_class [4]\n  .pred_class     n\n  &lt;fct&gt;       &lt;int&gt;\n1 A             448\n2 B             229\n3 C             399\n4 D             538\n\n\n\n\nCode\nconf_mat(final_prediction_data, truth = target_variable,\n    estimate = .pred_class)\n\n\n          Truth\nPrediction   A   B   C   D\n         A 185 100  58 105\n         B  54  91  60  24\n         C  57 115 217  10\n         D  96  56  65 321",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow set,fast tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html",
    "href": "Multiclass classification/3 multclass classification.html",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "",
    "text": "classification Tidy Modeling with 2 model and 1 recipe:\ndecision tree model with rpart engine(tree_spec)\nKNN model with knn engine(knn_spec)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#read-data",
    "href": "Multiclass classification/3 multclass classification.html#read-data",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "2.1 read data",
    "text": "2.1 read data\n\n\nCode\nlibrary(tidyverse)\n\ndf_train_raw &lt;- readr::read_csv(\"data/Train.csv\")\n\ndf_test_raw&lt;- readr::read_csv(\"data/Test.csv\")\n\n\n\n\nCode\ndf_train=df_train_raw %&gt;% mutate(target_variable=as.factor(Segmentation)) %&gt;% select(-Segmentation)\ndf_test=df_test_raw\n\n\n\n\nCode\nglimpse(df_train)\n\n\nRows: 8,068\nColumns: 11\n$ ID              &lt;dbl&gt; 462809, 462643, 466315, 461735, 462669, 461319, 460156…\n$ Gender          &lt;chr&gt; \"Male\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", …\n$ Ever_Married    &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"No\", \"…\n$ Age             &lt;dbl&gt; 22, 38, 67, 67, 40, 56, 32, 33, 61, 55, 26, 19, 19, 70…\n$ Graduated       &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", …\n$ Profession      &lt;chr&gt; \"Healthcare\", \"Engineer\", \"Engineer\", \"Lawyer\", \"Enter…\n$ Work_Experience &lt;dbl&gt; 1, NA, 1, 0, NA, 0, 1, 1, 0, 1, 1, 4, 0, NA, 0, 1, 9, …\n$ Spending_Score  &lt;chr&gt; \"Low\", \"Average\", \"Low\", \"High\", \"High\", \"Average\", \"L…\n$ Family_Size     &lt;dbl&gt; 4, 3, 1, 2, 6, 2, 3, 3, 3, 4, 3, 4, NA, 1, 1, 2, 5, 6,…\n$ Var_1           &lt;chr&gt; \"Cat_4\", \"Cat_4\", \"Cat_6\", \"Cat_6\", \"Cat_6\", \"Cat_6\", …\n$ target_variable &lt;fct&gt; D, A, B, B, A, C, C, D, D, C, A, D, D, A, B, C, D, B, …",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#data-split",
    "href": "Multiclass classification/3 multclass classification.html#data-split",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "2.2 data split",
    "text": "2.2 data split\n\n\nCode\nset.seed(1234)\n\ndata_split &lt;- initial_validation_split(data=df_train, prop = c(0.7,0.2))\n\ndata_train=training(data_split)  \n\ndata_test=testing(data_split)  \n\ndata_valid=validation(data_split)\n\n\n\n\nCode\ndim(data_train)\n\n\n[1] 5647   11\n\n\n\n\nCode\ndim(data_test)\n\n\n[1] 807  11\n\n\n\n\nCode\ndim(data_valid)\n\n\n[1] 1614   11\n\n\n10 fold for tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#recipe",
    "href": "Multiclass classification/3 multclass classification.html#recipe",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.1 recipe",
    "text": "3.1 recipe\nbecasue the target class is not balance so using downsample\n\n\nCode\ndata_rec &lt;- recipe(target_variable ~ ., data = data_train) %&gt;%\n  #update_role(ID, new_role = \"ID\") %&gt;% \n  step_rm(ID) %&gt;% \n  #step_downsample(target_variable) %&gt;%\n  \n  step_impute_median(all_numeric(), -all_outcomes())%&gt;% \n  step_impute_mode(all_nominal(), -all_outcomes())%&gt;% \n  \n  step_dummy(all_nominal(), -all_outcomes()) %&gt;%\n  step_zv(all_numeric()) %&gt;%\n  step_normalize(all_numeric())\n\ndata_rec",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#model",
    "href": "Multiclass classification/3 multclass classification.html#model",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.2 model",
    "text": "3.2 model\n\n3.2.1 tree model\n\n\nCode\ntree_spec &lt;- decision_tree() %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"classification\")\n\n\n\n\n3.2.2 KNN model\n\n\nCode\nknn_spec &lt;- nearest_neighbor() %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\n\n\n\n3.2.3 xgb tuning model\n\n\nCode\nxgb_spec &lt;- boost_tree(\n  trees = 10,\n  tree_depth = tune(), min_n = tune(),\n  loss_reduction = tune(),                     ## first three: model complexity\n  sample_size = tune(),  mtry=tune(),       ## randomness\n  learn_rate = tune()                          ## step size\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"classification\")\n\nxgb_spec\n\n\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 10\n  min_n = tune()\n  tree_depth = tune()\n  learn_rate = tune()\n  loss_reduction = tune()\n  sample_size = tune()\n\nComputational engine: xgboost \n\n\nxgb tunning grid\n\n\nCode\nxgb_tune_grid= grid_latin_hypercube(\n  tree_depth(),learn_rate(),loss_reduction(),min_n(),\n  sample_size=sample_prop(),finalize(mtry(),data_train),\n  size=50)\n\nhead(xgb_tune_grid)\n\n\n# A tibble: 6 × 6\n  tree_depth learn_rate loss_reduction min_n sample_size  mtry\n       &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;int&gt;\n1          2   1.79e-10     0.00740       10       0.484     2\n2         15   2.53e- 3     0.0000313     14       0.365     7\n3          5   4.69e- 8     1.51          16       0.697     7\n4          2   3.65e- 6     0.0000550     34       0.834     8\n5         14   6.92e- 7    10.4           30       0.714     6\n6         11   1.47e- 2     0.00000199    36       0.398     8\n\n\nworkflow\n\n\nCode\nknn_wf &lt;- workflow() %&gt;%add_recipe(data_rec) %&gt;% add_model(knn_spec) \n\ntree_wf &lt;- workflow() %&gt;%add_recipe(data_rec)%&gt;% add_model(tree_spec)\n\nxgb_wf &lt;- workflow() %&gt;%add_recipe(data_rec)%&gt;% add_model(xgb_spec)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#training-and-tunning",
    "href": "Multiclass classification/3 multclass classification.html#training-and-tunning",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.3 training and tunning",
    "text": "3.3 training and tunning\n\n\nCode\nset.seed(234)\nfolds &lt;- vfold_cv(data_train)",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "Multiclass classification/3 multclass classification.html#model-performance",
    "href": "Multiclass classification/3 multclass classification.html#model-performance",
    "title": "Multiple Classification Model with recipe,workflow, tuning",
    "section": "3.4 model performance:",
    "text": "3.4 model performance:\n\n3.4.1 KNN performance\n\n\nCode\nknn_wf_result= fit(knn_wf,data_train)\n\n\n\n\nCode\nfuture_result_class=predict(knn_wf_result,data_test)\n\n\n\n\nCode\nfuture_result_prob=predict(knn_wf_result,data_test,type=\"prob\")\n\n\n\n\nCode\nall_future_result=cbind(data_test,future_result_class,future_result_prob)\n\n\n\n\nCode\naccuracy(all_future_result, target_variable,  .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.475\n\n\n\n\nCode\nroc_auc(all_future_result, target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.711\n\n\n\n\nCode\nall_future_result %&gt;% roc_curve(target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D) %&gt;% \n  autoplot()\n\n\n\n\n\n\n\n\n\n\n\n3.4.2 Tree performance\n\n\nCode\ntree_wf_result= fit(tree_wf,data_train)\n\n\n\n\nCode\ntree_future_result_class=predict(tree_wf_result,data_test)\n\n\n\n\nCode\ntree_future_result_prob=predict(tree_wf_result,data_test,type=\"prob\")\n\n\n\n\nCode\ntree_all_future_result=cbind(data_test,tree_future_result_class,tree_future_result_prob)\n\n\n\n\nCode\naccuracy(tree_all_future_result, target_variable,  .pred_class)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.525\n\n\n\n\nCode\nroc_auc(tree_all_future_result, target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D)\n\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc hand_till      0.716\n\n\n\n\nCode\ntree_all_future_result %&gt;% roc_curve(target_variable,.pred_A ,.pred_B,.pred_C ,.pred_D) %&gt;% \n  autoplot()",
    "crumbs": [
      "Multiclass classification",
      "Multiple Classification Model with recipe,workflow, tuning"
    ]
  },
  {
    "objectID": "model type/1 decision tree.html",
    "href": "model type/1 decision tree.html",
    "title": "Decision tree",
    "section": "",
    "text": "1 Pros\n\nEasier to interpret than Neural Network\nFast training and making inference\n\n\n\n2 Cons\n\nProne to overfitting\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=6DlWndLbk90\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "model type",
      "Decision tree"
    ]
  },
  {
    "objectID": "other/5 other/4 quarto tips.html",
    "href": "other/5 other/4 quarto tips.html",
    "title": "quarto tips",
    "section": "",
    "text": "1 add a output folder bottom\n\nadd foldableCodeBlcok.lua into blog root folder\nadd in _quarto.yml\n\nfilters: - fold_results.lua\n\nput following on code chunk\n\n{r, attr.output=‘.details summary=“sessionInfo()”’} #| echo: false sessionInfo()\n\n\n2 render all website\n\n\n\nCode\n\nTerminal\n\nquarto render \"tidymodel in R\"\n\n\n\n\n\n3 referece:\nhttps://github.com/quarto-dev/quarto-cli/issues/341\nhttps://gist.github.com/atusy/f2b5b992e45c68ab6823499f2339c6e6\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.8.1 rstudioapi_0.16.0 yaml_2.3.8       \n [9] rmarkdown_2.26    knitr_1.45        jsonlite_1.8.8    xfun_0.43        \n[13] digest_0.6.35     rlang_1.1.3       evaluate_0.23    \n\n\n\n\n\n4 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/1 chromote.html",
    "href": "other/4 other/1 chromote.html",
    "title": "chromote",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(chromote)\n\n\n\n\nCode\npackageVersion(\"chromote\")\n\n\n\n1 create view\n\n\nCode\nlibrary(chromote)\n\nb &lt;- ChromoteSession$new()\n\n# In a web browser, open a viewer for the headless browser. Works best with\n# Chromium-based browsers.\nb$view()\n\n\n\n\nCode\nb$Browser$getVersion()\n\n\n\n\n2 go to page\n\n\nCode\nb$Page$navigate(\"https://www.r-project.org/\")\n\n\n\n\n3 take picture\n\n\nCode\n# Saves to screenshot.png\nb$screenshot()\n\n\n\n\nCode\n# Takes a screenshot of elements picked out by CSS selector\nis_interactive &lt;- interactive() # Display screenshot if interactive\nb$screenshot(\"sidebar.png\", selector = \"h1\" ,show = is_interactive)\n\n\n\n\n4 take picture as pdf\n\n\nCode\nb$screenshot_pdf(filename='page.pdf')\n\n\n\n\n5 Reference:\nhttps://rstudio.github.io/chromote/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 other",
      "chromote"
    ]
  },
  {
    "objectID": "other/4 other/3 image processing.html",
    "href": "other/4 other/3 image processing.html",
    "title": "image processing",
    "section": "",
    "text": "Code\nlibrary(magick)\n\n\n\n1 input\n\n\nCode\nraw_logo &lt;- image_read('./images/comb.webp')\n\n\n\n\n2 output\n\n\nCode\nimage_info(raw_logo)\n\n\n  format width height colorspace matte filesize density\n1   WEBP   450    303       sRGB  TRUE    49650   72x72\n\n\n\n\n3 change format\n\n\nCode\nnew_png &lt;- image_convert(raw_logo, \"png\")\n\n\n\n\nCode\nimage_info(new_png)\n\n\n  format width height colorspace matte filesize density\n1    PNG   450    303       sRGB  TRUE        0   72x72\n\n\n\n\n4 output\n\n\nCode\nimage_write(new_png, path = \"./images/new_png.png\", format = \"png\")\n\n\n\n\nCode\nraw_logo &lt;- image_read('./images/logo1.png')\n\n\n\n\nCode\nraw_logo %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE    53960   72x72\n\n\n\n\n\n\n\n\n\n\n\n5 fill corner white to greem\neach corner (top left, top right, bottom left, bottom right). For our real usage, we’re going to convert this “green” space to transparent instead.\n\n\nCode\nimg_filled &lt;- raw_logo %&gt;% \n    image_fill(\"green\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\nimg_filled %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n6 rotate\n\n\nCode\nimg_filled %&gt;% image_rotate(45) %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1632   1632       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n7 make backgroup transparent (given 0-100 green color backgroup)\n\n\nCode\nb=img_filled %&gt;% image_transparent(color='green',10)\n\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\nCode\nimage_write(b, path = \"b.png\", format = \"png\")\n\n\n\n\n8 change opacity level\n\n\nCode\nb=img_filled %&gt;% image_colorize(opacity =80, color = 'white')\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n9 change brightness level\n\n\nCode\nb=img_filled %&gt;%image_modulate(brightness = 30)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n10 change blur level\n\n\nCode\nb=img_filled %&gt;%  image_blur(10, 5)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n11 add text into picture\n\n\nCode\nb=img_filled %&gt;% image_annotate( \"The quick brown fox\", font = 'Times', size = 80,gravity = \"southwest\", color = \"red\")\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n12 resize\n\n\nCode\nb= img_filled%&gt;% image_resize(\"500\")\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nCode\nimage_info(img_filled)\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\nCode\nimage_info(b)\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n13 make logo black\n\n\nCode\nimg_filled2 &lt;- raw_logo %&gt;% \n    image_fill(\"transparent\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\n\n\n\nCode\nimg_filled2 %&gt;% \n    image_channel(\"Opacity\") %&gt;% \n    image_convert(matte=FALSE) %&gt;% \n  print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       Gray FALSE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.8.3\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     fastmap_1.1.1     xfun_0.43         magrittr_2.0.3   \n [5] knitr_1.45        htmltools_0.5.8.1 png_0.1-8         rmarkdown_2.26   \n [9] cli_3.6.2         compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1      \n[13] evaluate_0.23     Rcpp_1.0.12       yaml_2.3.8        rlang_1.1.3      \n[17] jsonlite_1.8.8    htmlwidgets_1.6.4\n\n\n\n\n\n14 add backgroup image\n\n\nCode\nlibrary(ggplot2)\nlibrary(png)\nlibrary(grid)\nlibrary(ggimage)\n\n\n\n\nCode\nimg &lt;- readPNG(\"./images/new_png.png\")\n\n\n\n\nCode\nbees &lt;- data.frame(distance = c(0.5, 1, 1.5, 2, 2.5, 3),\n                  number = c(40, 34, 32, 22,18, 10))\n\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_point() +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n15 replace scatter with image\n\n\nCode\nbees$image &lt;- \"./images/bee.png\"\n\n\n\n\nCode\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n16 add logo\n\n\nCode\nimg2 =image_read(\"./images/logo1.png\")\n\n\n\n\nCode\nlibrary(cowplot)\np=ggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\nggdraw() +draw_plot(p,x = 0, y = 0.15, width = 1, height = 0.85) +draw_image(img2,x = 0.1, y = 0.1, width = 0.1, height = 0.1) \n\n\n\n\n\n\n\n\n\n\n\n17 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\nhttps://buzzrbeeline.blog/2018/06/13/fun-and-easy-r-graphs-with-images/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 other",
      "image processing"
    ]
  },
  {
    "objectID": "Plot/3 Map/2 leaflet.html",
    "href": "Plot/3 Map/2 leaflet.html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\n\nlibrary(sf)\nlibrary(leaflet)\nlibrary(geojsonio)\nlibrary(leaflet.extras)\n\n\n\n\n2 display at openstreet map\n\n\nCode\nm &lt;- leaflet() %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\n\nm  \n\n\n\n\n\n\n\n\n3 display at google map\n\n\nCode\nleaflet() |&gt;\n  # add base mao\n  addTiles(urlTemplate = \"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\") |&gt;\n  # set view\n  setView(116.347817690225, 39.997202126977, zoom = 16) |&gt;\n  # add markers\n  addMarkers(116.347817690225, 39.997202126977)\n\n\n\n\n\n\n\n\n4 Third-Party map\n\n\nCode\n#m &lt;- leaflet() %&gt;% setView(lng = -71.0589, lat = 42.3601, zoom = 10)\n#m %&gt;% addProviderTiles(providers$Stadia.StamenToner)\n\n\n\n\n5 add pop up\nPopups are small boxes containing arbitrary HTML, that point to a specific point on the map.\n\n\nCode\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.samurainoodle.com/'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() %&gt;% addTiles() %&gt;%\n  setView(-122.327298, 47.597131,zoom = 12) %&gt;% \n  addPopups(-122.327298, 47.597131, content,\n    #options = popupOptions(closeButton = FALSE)\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\n\n\n6 add Markers\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"\n))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, popup = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n7 add Labels\nA label is a textual or HTML content that can attached to markers and shapes to be always displayed or displayed on mouse over. Unlike popups you don’t need to click a marker/polygon for the label to be shown.\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, label = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n8 World map\n\n\nCode\n#install.packages(\"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\")\n\n\n\n\nCode\njson_data=read_sf(\"world-administrative-boundaries.geojson\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\n#Get my variable\n#name&lt;-c(\"Ghana\", \"Grenada\", \"Guyana\", \"India\", \"Jamaica\", \"Kenya\", \"United States\",\"Canada\")\n#val&lt;-c(1,2,4,5,5,1000,20000, 100)\n\n#per_gdp_usd&lt;-data.frame(name,val)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('world data.xlsx') %&gt;% mutate(\n  name=case_when(\n    name ==\"United States\" ~ \"United States of America\"\n     ,name ==\"Russia\" ~ \"Russian Federation\"\n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name == \"South Korea\"~ \"Republic of Korea\"\n   \n   ,name ==\"Lao People's Democratic Republic\" ~ \"Laos\"\n   \n    ,TRUE ~ name\n  )\n)\n\n\n\n\nCode\n#test=full_join(map_df, per_gdp_usd, by=\"name\")\n\n#left =test %&gt;% filter(is.na(iso3)==TRUE)\n\n#right=test %&gt;% filter(is.na(per_gdp_total)==TRUE)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"name\")\n\n\n\n\nCode\nglimpse(map_df002)\n\n\nRows: 158\nColumns: 12\n$ name                     &lt;chr&gt; \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"A…\n$ geo_point_2d             &lt;chr&gt; \"{ \\\"lon\\\": 20.068384605918776, \\\"lat\\\": 41.1…\n$ iso3                     &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ status                   &lt;chr&gt; \"Member State\", \"Member State\", \"Member State…\n$ color_code               &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ continent                &lt;chr&gt; \"Europe\", \"Africa\", \"Europe\", \"Africa\", \"Amer…\n$ region                   &lt;chr&gt; \"Southern Europe\", \"Northern Africa\", \"Southe…\n$ iso_3166_1_alpha_2_codes &lt;chr&gt; \"AL\", \"DZ\", \"AD\", \"AO\", \"AR\", \"AM\", \"AU\", \"AT…\n$ french_short             &lt;chr&gt; \"Albanie\", \"Algérie\", \"Andorre\", \"Angola\", \"A…\n$ geometry                 &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((20.07142 42..., …\n$ per_gdp_total            &lt;dbl&gt; 1.888210e+10, 1.919130e+11, 3.352033e+09, 1.0…\n$ per_gdp_usd              &lt;dbl&gt; 6643, 4274, 41993, 2999, 13904, 7014, 64003, …\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gdp_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gdp_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_gdp_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$per_gdp_total/1000000), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gdp_usd, opacity = 1.0\n    )\n\n\n\n\n\n\n\n\n9 China one city map\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/citys/440300.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/440300_full.json\")\n\n\n深圳市：\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n\n\n\n\n10 all China each province GPD map\n\n\nCode\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n中国 2022 各省 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('china gdp2022.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nGPD data source:国家统计局数据库\n\n\n11 China one province map each city GPD\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/province/440000.json\") \n\n\n广东省 2021 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('guangdong city gdp2021.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\ndata source:广东统计年鉴2022\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"城市：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"城市：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb*10000000/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nhttps://zh.wikipedia.org/wiki/%E5%B9%BF%E4%B8%9C%E5%90%84%E5%9C%B0%E7%BA%A7%E5%B8%82%E5%9C%B0%E5%8C%BA%E7%94%9F%E4%BA%A7%E6%80%BB%E5%80%BC%E5%88%97%E8%A1%A8\n\n\n12 China province map\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\n\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/china.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nm=leaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n \n\nm\n\n\n\n\n\n\nadd provincial capital\n\n\nCode\nChina=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n\n\nCode\nChina002=China %&gt;% as_data_frame() %&gt;% mutate(\n                                            center2=as.character(center) %&gt;% str_replace('c','')%&gt;% str_replace('[(]','') %&gt;% str_replace('[)]','')\n                                               )\n\n\n\n\nCode\nChina003=China002%&gt;%separate(center2, c(\"x\", \"y\"), \", \")\n\n\n\n\nCode\nChina_point = China003 %&gt;% \n  slice(-35)\n\nm %&gt;% \n  addCircles(data = China_point,\n                  lng = ~as.numeric(x), lat = ~as.numeric(y),color = \"red\",weight = 10,\n                  fillOpacity =2)\n\n\n\n\n\n\n\n\n13 China province and city map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 34\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 119.3183 ymin: 21.75147 xmax: 124.5656 ymax: 25.92592\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 710000 台湾省 121.509062,25.044332 province (((119.5543 23.68248, 119.555 23.…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/province/710000.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 33\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n14 China city and district map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 334\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.5215 ymin: 22.65421 xmax: 114.2603 ymax: 23.14205\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 441900 东莞市 113.746262,23.046237 city  ((114.2292 22.81251, 114.2278 22.813…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.157 ymin: 22.20104 xmax: 113.692 ymax: 22.7726\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 442000 中山市 113.382391,22.521113 city  ((113.5687 22.41193, 113.5666 22.412…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 115.9267 ymin: 20.58265 xmax: 116.9338 ymax: 21.12693\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center               level                            geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                &lt;chr&gt;                  &lt;MULTIPOLYGON [°]&gt;\n1 442100 东沙群岛 116.887312,20.617512 city  (((115.9433 21.09745, 115.95 21.11…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 108.9287 ymin: 19.17894 xmax: 109.7694 ymax: 19.92575\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 460400 儋州市 109.576782,19.517486 city  (((109.4322 19.91302, 109.4253 19.91…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.8483 ymin: 39.65426 xmax: 98.52018 ymax: 39.99979\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center              level                             geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;               &lt;chr&gt;                   &lt;MULTIPOLYGON [°]&gt;\n1 620200 嘉峪关市 98.277304,39.786529 city  (((97.85974 39.7169, 97.85827 39.71…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/citys/620200.json\"\n         ,\"./GeoMapData_CN/citys/460400.json\"\n              ,\"./GeoMapData_CN/citys/442100.json\"\n              ,\"./GeoMapData_CN/citys/442000.json\"\n              ,\"./GeoMapData_CN/citys/441900.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 329\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n15 show all map providers\n\n\nCode\nproviders\n\n\nproviders\n$OpenStreetMap\n[1] \"OpenStreetMap\"\n\n$OpenStreetMap.Mapnik\n[1] \"OpenStreetMap.Mapnik\"\n\n$OpenStreetMap.DE\n[1] \"OpenStreetMap.DE\"\n\n$OpenStreetMap.CH\n[1] \"OpenStreetMap.CH\"\n\n$OpenStreetMap.France\n[1] \"OpenStreetMap.France\"\n\n$OpenStreetMap.HOT\n[1] \"OpenStreetMap.HOT\"\n\n$OpenStreetMap.BZH\n[1] \"OpenStreetMap.BZH\"\n\n$MapTilesAPI\n[1] \"MapTilesAPI\"\n\n$MapTilesAPI.OSMEnglish\n[1] \"MapTilesAPI.OSMEnglish\"\n\n$MapTilesAPI.OSMFrancais\n[1] \"MapTilesAPI.OSMFrancais\"\n\n$MapTilesAPI.OSMEspagnol\n[1] \"MapTilesAPI.OSMEspagnol\"\n\n$OpenSeaMap\n[1] \"OpenSeaMap\"\n\n$OPNVKarte\n[1] \"OPNVKarte\"\n\n$OpenTopoMap\n[1] \"OpenTopoMap\"\n\n$OpenRailwayMap\n[1] \"OpenRailwayMap\"\n\n$OpenFireMap\n[1] \"OpenFireMap\"\n\n$SafeCast\n[1] \"SafeCast\"\n\n$Stadia\n[1] \"Stadia\"\n\n$Stadia.AlidadeSmooth\n[1] \"Stadia.AlidadeSmooth\"\n\n$Stadia.AlidadeSmoothDark\n[1] \"Stadia.AlidadeSmoothDark\"\n\n$Stadia.OSMBright\n[1] \"Stadia.OSMBright\"\n\n$Stadia.Outdoors\n[1] \"Stadia.Outdoors\"\n\n$Stadia.StamenToner\n[1] \"Stadia.StamenToner\"\n\n$Stadia.StamenTonerBackground\n[1] \"Stadia.StamenTonerBackground\"\n\n$Stadia.StamenTonerLines\n[1] \"Stadia.StamenTonerLines\"\n\n$Stadia.StamenTonerLabels\n[1] \"Stadia.StamenTonerLabels\"\n\n$Stadia.StamenTonerLite\n[1] \"Stadia.StamenTonerLite\"\n\n$Stadia.StamenWatercolor\n[1] \"Stadia.StamenWatercolor\"\n\n$Stadia.StamenTerrain\n[1] \"Stadia.StamenTerrain\"\n\n$Stadia.StamenTerrainBackground\n[1] \"Stadia.StamenTerrainBackground\"\n\n$Stadia.StamenTerrainLabels\n[1] \"Stadia.StamenTerrainLabels\"\n\n$Stadia.StamenTerrainLines\n[1] \"Stadia.StamenTerrainLines\"\n\n$Thunderforest\n[1] \"Thunderforest\"\n\n$Thunderforest.OpenCycleMap\n[1] \"Thunderforest.OpenCycleMap\"\n\n$Thunderforest.Transport\n[1] \"Thunderforest.Transport\"\n\n$Thunderforest.TransportDark\n[1] \"Thunderforest.TransportDark\"\n\n$Thunderforest.SpinalMap\n[1] \"Thunderforest.SpinalMap\"\n\n$Thunderforest.Landscape\n[1] \"Thunderforest.Landscape\"\n\n$Thunderforest.Outdoors\n[1] \"Thunderforest.Outdoors\"\n\n$Thunderforest.Pioneer\n[1] \"Thunderforest.Pioneer\"\n\n$Thunderforest.MobileAtlas\n[1] \"Thunderforest.MobileAtlas\"\n\n$Thunderforest.Neighbourhood\n[1] \"Thunderforest.Neighbourhood\"\n\n$CyclOSM\n[1] \"CyclOSM\"\n\n$Jawg\n[1] \"Jawg\"\n\n$Jawg.Streets\n[1] \"Jawg.Streets\"\n\n$Jawg.Terrain\n[1] \"Jawg.Terrain\"\n\n$Jawg.Sunny\n[1] \"Jawg.Sunny\"\n\n$Jawg.Dark\n[1] \"Jawg.Dark\"\n\n$Jawg.Light\n[1] \"Jawg.Light\"\n\n$Jawg.Matrix\n[1] \"Jawg.Matrix\"\n\n$MapBox\n[1] \"MapBox\"\n\n$MapTiler\n[1] \"MapTiler\"\n\n$MapTiler.Streets\n[1] \"MapTiler.Streets\"\n\n$MapTiler.Basic\n[1] \"MapTiler.Basic\"\n\n$MapTiler.Bright\n[1] \"MapTiler.Bright\"\n\n$MapTiler.Pastel\n[1] \"MapTiler.Pastel\"\n\n$MapTiler.Positron\n[1] \"MapTiler.Positron\"\n\n$MapTiler.Hybrid\n[1] \"MapTiler.Hybrid\"\n\n$MapTiler.Toner\n[1] \"MapTiler.Toner\"\n\n$MapTiler.Topo\n[1] \"MapTiler.Topo\"\n\n$MapTiler.Voyager\n[1] \"MapTiler.Voyager\"\n\n$TomTom\n[1] \"TomTom\"\n\n$TomTom.Basic\n[1] \"TomTom.Basic\"\n\n$TomTom.Hybrid\n[1] \"TomTom.Hybrid\"\n\n$TomTom.Labels\n[1] \"TomTom.Labels\"\n\n$Esri\n[1] \"Esri\"\n\n$Esri.WorldStreetMap\n[1] \"Esri.WorldStreetMap\"\n\n$Esri.DeLorme\n[1] \"Esri.DeLorme\"\n\n$Esri.WorldTopoMap\n[1] \"Esri.WorldTopoMap\"\n\n$Esri.WorldImagery\n[1] \"Esri.WorldImagery\"\n\n$Esri.WorldTerrain\n[1] \"Esri.WorldTerrain\"\n\n$Esri.WorldShadedRelief\n[1] \"Esri.WorldShadedRelief\"\n\n$Esri.WorldPhysical\n[1] \"Esri.WorldPhysical\"\n\n$Esri.OceanBasemap\n[1] \"Esri.OceanBasemap\"\n\n$Esri.NatGeoWorldMap\n[1] \"Esri.NatGeoWorldMap\"\n\n$Esri.WorldGrayCanvas\n[1] \"Esri.WorldGrayCanvas\"\n\n$OpenWeatherMap\n[1] \"OpenWeatherMap\"\n\n$OpenWeatherMap.Clouds\n[1] \"OpenWeatherMap.Clouds\"\n\n$OpenWeatherMap.CloudsClassic\n[1] \"OpenWeatherMap.CloudsClassic\"\n\n$OpenWeatherMap.Precipitation\n[1] \"OpenWeatherMap.Precipitation\"\n\n$OpenWeatherMap.PrecipitationClassic\n[1] \"OpenWeatherMap.PrecipitationClassic\"\n\n$OpenWeatherMap.Rain\n[1] \"OpenWeatherMap.Rain\"\n\n$OpenWeatherMap.RainClassic\n[1] \"OpenWeatherMap.RainClassic\"\n\n$OpenWeatherMap.Pressure\n[1] \"OpenWeatherMap.Pressure\"\n\n$OpenWeatherMap.PressureContour\n[1] \"OpenWeatherMap.PressureContour\"\n\n$OpenWeatherMap.Wind\n[1] \"OpenWeatherMap.Wind\"\n\n$OpenWeatherMap.Temperature\n[1] \"OpenWeatherMap.Temperature\"\n\n$OpenWeatherMap.Snow\n[1] \"OpenWeatherMap.Snow\"\n\n$HERE\n[1] \"HERE\"\n\n$HERE.normalDay\n[1] \"HERE.normalDay\"\n\n$HERE.normalDayCustom\n[1] \"HERE.normalDayCustom\"\n\n$HERE.normalDayGrey\n[1] \"HERE.normalDayGrey\"\n\n$HERE.normalDayMobile\n[1] \"HERE.normalDayMobile\"\n\n$HERE.normalDayGreyMobile\n[1] \"HERE.normalDayGreyMobile\"\n\n$HERE.normalDayTransit\n[1] \"HERE.normalDayTransit\"\n\n$HERE.normalDayTransitMobile\n[1] \"HERE.normalDayTransitMobile\"\n\n$HERE.normalDayTraffic\n[1] \"HERE.normalDayTraffic\"\n\n$HERE.normalNight\n[1] \"HERE.normalNight\"\n\n$HERE.normalNightMobile\n[1] \"HERE.normalNightMobile\"\n\n$HERE.normalNightGrey\n[1] \"HERE.normalNightGrey\"\n\n$HERE.normalNightGreyMobile\n[1] \"HERE.normalNightGreyMobile\"\n\n$HERE.normalNightTransit\n[1] \"HERE.normalNightTransit\"\n\n$HERE.normalNightTransitMobile\n[1] \"HERE.normalNightTransitMobile\"\n\n$HERE.reducedDay\n[1] \"HERE.reducedDay\"\n\n$HERE.reducedNight\n[1] \"HERE.reducedNight\"\n\n$HERE.basicMap\n[1] \"HERE.basicMap\"\n\n$HERE.mapLabels\n[1] \"HERE.mapLabels\"\n\n$HERE.trafficFlow\n[1] \"HERE.trafficFlow\"\n\n$HERE.carnavDayGrey\n[1] \"HERE.carnavDayGrey\"\n\n$HERE.hybridDay\n[1] \"HERE.hybridDay\"\n\n$HERE.hybridDayMobile\n[1] \"HERE.hybridDayMobile\"\n\n$HERE.hybridDayTransit\n[1] \"HERE.hybridDayTransit\"\n\n$HERE.hybridDayGrey\n[1] \"HERE.hybridDayGrey\"\n\n$HERE.hybridDayTraffic\n[1] \"HERE.hybridDayTraffic\"\n\n$HERE.pedestrianDay\n[1] \"HERE.pedestrianDay\"\n\n$HERE.pedestrianNight\n[1] \"HERE.pedestrianNight\"\n\n$HERE.satelliteDay\n[1] \"HERE.satelliteDay\"\n\n$HERE.terrainDay\n[1] \"HERE.terrainDay\"\n\n$HERE.terrainDayMobile\n[1] \"HERE.terrainDayMobile\"\n\n$HEREv3\n[1] \"HEREv3\"\n\n$HEREv3.normalDay\n[1] \"HEREv3.normalDay\"\n\n$HEREv3.normalDayCustom\n[1] \"HEREv3.normalDayCustom\"\n\n$HEREv3.normalDayGrey\n[1] \"HEREv3.normalDayGrey\"\n\n$HEREv3.normalDayMobile\n[1] \"HEREv3.normalDayMobile\"\n\n$HEREv3.normalDayGreyMobile\n[1] \"HEREv3.normalDayGreyMobile\"\n\n$HEREv3.normalDayTransit\n[1] \"HEREv3.normalDayTransit\"\n\n$HEREv3.normalDayTransitMobile\n[1] \"HEREv3.normalDayTransitMobile\"\n\n$HEREv3.normalNight\n[1] \"HEREv3.normalNight\"\n\n$HEREv3.normalNightMobile\n[1] \"HEREv3.normalNightMobile\"\n\n$HEREv3.normalNightGrey\n[1] \"HEREv3.normalNightGrey\"\n\n$HEREv3.normalNightGreyMobile\n[1] \"HEREv3.normalNightGreyMobile\"\n\n$HEREv3.normalNightTransit\n[1] \"HEREv3.normalNightTransit\"\n\n$HEREv3.normalNightTransitMobile\n[1] \"HEREv3.normalNightTransitMobile\"\n\n$HEREv3.reducedDay\n[1] \"HEREv3.reducedDay\"\n\n$HEREv3.reducedNight\n[1] \"HEREv3.reducedNight\"\n\n$HEREv3.basicMap\n[1] \"HEREv3.basicMap\"\n\n$HEREv3.mapLabels\n[1] \"HEREv3.mapLabels\"\n\n$HEREv3.trafficFlow\n[1] \"HEREv3.trafficFlow\"\n\n$HEREv3.carnavDayGrey\n[1] \"HEREv3.carnavDayGrey\"\n\n$HEREv3.hybridDay\n[1] \"HEREv3.hybridDay\"\n\n$HEREv3.hybridDayMobile\n[1] \"HEREv3.hybridDayMobile\"\n\n$HEREv3.hybridDayTransit\n[1] \"HEREv3.hybridDayTransit\"\n\n$HEREv3.hybridDayGrey\n[1] \"HEREv3.hybridDayGrey\"\n\n$HEREv3.pedestrianDay\n[1] \"HEREv3.pedestrianDay\"\n\n$HEREv3.pedestrianNight\n[1] \"HEREv3.pedestrianNight\"\n\n$HEREv3.satelliteDay\n[1] \"HEREv3.satelliteDay\"\n\n$HEREv3.terrainDay\n[1] \"HEREv3.terrainDay\"\n\n$HEREv3.terrainDayMobile\n[1] \"HEREv3.terrainDayMobile\"\n\n$FreeMapSK\n[1] \"FreeMapSK\"\n\n$MtbMap\n[1] \"MtbMap\"\n\n$CartoDB\n[1] \"CartoDB\"\n\n$CartoDB.Positron\n[1] \"CartoDB.Positron\"\n\n$CartoDB.PositronNoLabels\n[1] \"CartoDB.PositronNoLabels\"\n\n$CartoDB.PositronOnlyLabels\n[1] \"CartoDB.PositronOnlyLabels\"\n\n$CartoDB.DarkMatter\n[1] \"CartoDB.DarkMatter\"\n\n$CartoDB.DarkMatterNoLabels\n[1] \"CartoDB.DarkMatterNoLabels\"\n\n$CartoDB.DarkMatterOnlyLabels\n[1] \"CartoDB.DarkMatterOnlyLabels\"\n\n$CartoDB.Voyager\n[1] \"CartoDB.Voyager\"\n\n$CartoDB.VoyagerNoLabels\n[1] \"CartoDB.VoyagerNoLabels\"\n\n$CartoDB.VoyagerOnlyLabels\n[1] \"CartoDB.VoyagerOnlyLabels\"\n\n$CartoDB.VoyagerLabelsUnder\n[1] \"CartoDB.VoyagerLabelsUnder\"\n\n$HikeBike\n[1] \"HikeBike\"\n\n$HikeBike.HikeBike\n[1] \"HikeBike.HikeBike\"\n\n$HikeBike.HillShading\n[1] \"HikeBike.HillShading\"\n\n$BasemapAT\n[1] \"BasemapAT\"\n\n$BasemapAT.basemap\n[1] \"BasemapAT.basemap\"\n\n$BasemapAT.grau\n[1] \"BasemapAT.grau\"\n\n$BasemapAT.overlay\n[1] \"BasemapAT.overlay\"\n\n$BasemapAT.terrain\n[1] \"BasemapAT.terrain\"\n\n$BasemapAT.surface\n[1] \"BasemapAT.surface\"\n\n$BasemapAT.highdpi\n[1] \"BasemapAT.highdpi\"\n\n$BasemapAT.orthofoto\n[1] \"BasemapAT.orthofoto\"\n\n$nlmaps\n[1] \"nlmaps\"\n\n$nlmaps.standaard\n[1] \"nlmaps.standaard\"\n\n$nlmaps.pastel\n[1] \"nlmaps.pastel\"\n\n$nlmaps.grijs\n[1] \"nlmaps.grijs\"\n\n$nlmaps.water\n[1] \"nlmaps.water\"\n\n$nlmaps.luchtfoto\n[1] \"nlmaps.luchtfoto\"\n\n$NASAGIBS\n[1] \"NASAGIBS\"\n\n$NASAGIBS.ModisTerraTrueColorCR\n[1] \"NASAGIBS.ModisTerraTrueColorCR\"\n\n$NASAGIBS.ModisTerraBands367CR\n[1] \"NASAGIBS.ModisTerraBands367CR\"\n\n$NASAGIBS.ViirsEarthAtNight2012\n[1] \"NASAGIBS.ViirsEarthAtNight2012\"\n\n$NASAGIBS.ModisTerraLSTDay\n[1] \"NASAGIBS.ModisTerraLSTDay\"\n\n$NASAGIBS.ModisTerraSnowCover\n[1] \"NASAGIBS.ModisTerraSnowCover\"\n\n$NASAGIBS.ModisTerraAOD\n[1] \"NASAGIBS.ModisTerraAOD\"\n\n$NASAGIBS.ModisTerraChlorophyll\n[1] \"NASAGIBS.ModisTerraChlorophyll\"\n\n$NLS\n[1] \"NLS\"\n\n$JusticeMap\n[1] \"JusticeMap\"\n\n$JusticeMap.income\n[1] \"JusticeMap.income\"\n\n$JusticeMap.americanIndian\n[1] \"JusticeMap.americanIndian\"\n\n$JusticeMap.asian\n[1] \"JusticeMap.asian\"\n\n$JusticeMap.black\n[1] \"JusticeMap.black\"\n\n$JusticeMap.hispanic\n[1] \"JusticeMap.hispanic\"\n\n$JusticeMap.multi\n[1] \"JusticeMap.multi\"\n\n$JusticeMap.nonWhite\n[1] \"JusticeMap.nonWhite\"\n\n$JusticeMap.white\n[1] \"JusticeMap.white\"\n\n$JusticeMap.plurality\n[1] \"JusticeMap.plurality\"\n\n$GeoportailFrance\n[1] \"GeoportailFrance\"\n\n$GeoportailFrance.plan\n[1] \"GeoportailFrance.plan\"\n\n$GeoportailFrance.parcels\n[1] \"GeoportailFrance.parcels\"\n\n$GeoportailFrance.orthos\n[1] \"GeoportailFrance.orthos\"\n\n$OneMapSG\n[1] \"OneMapSG\"\n\n$OneMapSG.Default\n[1] \"OneMapSG.Default\"\n\n$OneMapSG.Night\n[1] \"OneMapSG.Night\"\n\n$OneMapSG.Original\n[1] \"OneMapSG.Original\"\n\n$OneMapSG.Grey\n[1] \"OneMapSG.Grey\"\n\n$OneMapSG.LandLot\n[1] \"OneMapSG.LandLot\"\n\n$USGS\n[1] \"USGS\"\n\n$USGS.USTopo\n[1] \"USGS.USTopo\"\n\n$USGS.USImagery\n[1] \"USGS.USImagery\"\n\n$USGS.USImageryTopo\n[1] \"USGS.USImageryTopo\"\n\n$WaymarkedTrails\n[1] \"WaymarkedTrails\"\n\n$WaymarkedTrails.hiking\n[1] \"WaymarkedTrails.hiking\"\n\n$WaymarkedTrails.cycling\n[1] \"WaymarkedTrails.cycling\"\n\n$WaymarkedTrails.mtb\n[1] \"WaymarkedTrails.mtb\"\n\n$WaymarkedTrails.slopes\n[1] \"WaymarkedTrails.slopes\"\n\n$WaymarkedTrails.riding\n[1] \"WaymarkedTrails.riding\"\n\n$WaymarkedTrails.skating\n[1] \"WaymarkedTrails.skating\"\n\n$OpenAIP\n[1] \"OpenAIP\"\n\n$OpenSnowMap\n[1] \"OpenSnowMap\"\n\n$OpenSnowMap.pistes\n[1] \"OpenSnowMap.pistes\"\n\n$AzureMaps\n[1] \"AzureMaps\"\n\n$AzureMaps.MicrosoftImagery\n[1] \"AzureMaps.MicrosoftImagery\"\n\n$AzureMaps.MicrosoftBaseDarkGrey\n[1] \"AzureMaps.MicrosoftBaseDarkGrey\"\n\n$AzureMaps.MicrosoftBaseRoad\n[1] \"AzureMaps.MicrosoftBaseRoad\"\n\n$AzureMaps.MicrosoftBaseHybridRoad\n[1] \"AzureMaps.MicrosoftBaseHybridRoad\"\n\n$AzureMaps.MicrosoftTerraMain\n[1] \"AzureMaps.MicrosoftTerraMain\"\n\n$AzureMaps.MicrosoftWeatherInfraredMain\n[1] \"AzureMaps.MicrosoftWeatherInfraredMain\"\n\n$AzureMaps.MicrosoftWeatherRadarMain\n[1] \"AzureMaps.MicrosoftWeatherRadarMain\"\n\n$SwissFederalGeoportal\n[1] \"SwissFederalGeoportal\"\n\n$SwissFederalGeoportal.NationalMapColor\n[1] \"SwissFederalGeoportal.NationalMapColor\"\n\n$SwissFederalGeoportal.NationalMapGrey\n[1] \"SwissFederalGeoportal.NationalMapGrey\"\n\n$SwissFederalGeoportal.SWISSIMAGE\n[1] \"SwissFederalGeoportal.SWISSIMAGE\"\n\n\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] readxl_1.4.3         openxlsx_4.2.5.2     htmltools_0.5.8.1   \n [4] leaflet.extras_1.0.0 geojsonio_0.11.3     leaflet_2.2.2       \n [7] sf_1.0-16            lubridate_1.9.3      forcats_1.0.0       \n[10] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n[13] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n[16] ggplot2_3.5.1        tidyverse_2.0.0     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5            xfun_0.43               htmlwidgets_1.6.4      \n [4] lattice_0.22-6          tzdb_0.4.0              leaflet.providers_2.0.0\n [7] vctrs_0.6.5             tools_4.3.1             crosstalk_1.2.1        \n[10] generics_0.1.3          curl_5.2.1              proxy_0.4-27           \n[13] fansi_1.0.6             pkgconfig_2.0.3         KernSmooth_2.23-22     \n[16] RColorBrewer_1.1-3      lifecycle_1.0.4         farver_2.1.1           \n[19] compiler_4.3.1          munsell_0.5.1           jqr_1.3.3              \n[22] class_7.3-22            yaml_2.3.8              lazyeval_0.2.2         \n[25] jquerylib_0.1.4         pillar_1.9.0            classInt_0.4-10        \n[28] zip_2.3.1               tidyselect_1.2.1        digest_0.6.35          \n[31] stringi_1.8.4           fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.2               magrittr_2.0.3         \n[37] crul_1.4.2              utf8_1.2.4              e1071_1.7-14           \n[40] withr_3.0.0             scales_1.3.0            sp_2.1-4               \n[43] timechange_0.3.0        rmarkdown_2.26          cellranger_1.1.0       \n[46] hms_1.1.3               evaluate_0.23           knitr_1.45             \n[49] V8_4.4.2                viridisLite_0.4.2       geojson_0.3.5          \n[52] rlang_1.1.3             Rcpp_1.0.12             glue_1.7.0             \n[55] DBI_1.2.2               httpcode_0.3.0          geojsonsf_2.0.3        \n[58] rstudioapi_0.16.0       jsonlite_1.8.8          R6_2.5.1               \n[61] units_0.8-5            \n\n\n\n\n\n16 resouce:\nhttps://rstudio.github.io/leaflet/\nhttps://github.com/Lchiffon/leafletCN\nhttps://github.com/longwosion/geojson-map-china\nhttps://xiangyun.rbind.io/2022/02/draw-china-maps/\nhttps://datav.aliyun.com/portal/school/atlas/area_selector\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "3 Map",
      "map"
    ]
  },
  {
    "objectID": "Plot/4 Shiny/3 China accident map.html",
    "href": "Plot/4 Shiny/3 China accident map.html",
    "title": "Shiny in R:China accident map",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/China_accident_map/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "4 Shiny",
      "Shiny in R:China accident map"
    ]
  },
  {
    "objectID": "Plot/4 Shiny/1 shiny weight tracking.html",
    "href": "Plot/4 Shiny/1 shiny weight tracking.html",
    "title": "Shiny in R:weight tracking",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/weightshiny/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "4 Shiny",
      "Shiny in R:weight tracking"
    ]
  },
  {
    "objectID": "Plot/4 Shiny/2 shiny photo editor.html",
    "href": "Plot/4 Shiny/2 shiny photo editor.html",
    "title": "Shiny in R:photo editor",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/photo_editor/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "4 Shiny",
      "Shiny in R:photo editor"
    ]
  },
  {
    "objectID": "Plot/3 Map/1 China accident map with mapview.html",
    "href": "Plot/3 Map/1 China accident map with mapview.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nall_data=all_data %&gt;% mutate(text=paste0(incident_type,\" \",\"死亡人数:\",person_death_num,\" 受伤人数:\",person_injury_num)\n                             ,month_year= format_ISO8601(ymd(start_date), precision = \"ym\")\n                             )\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 24\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ text               &lt;chr&gt; \"火灾 死亡人数:3 受伤人数:10\", \"溃水 死亡人数:3 受…\n$ month_year         &lt;chr&gt; \"2024-04\", \"2024-04\", \"2024-01\", \"2024-02\", \"2024-0…\n\n\n\n\nCode\n#write.xlsx(all_data,'all_data.xlsx')\n\n\n\n\n4 chart\ngroup to month\n\n\nCode\nchartdata001=all_data %&gt;% group_by(month_year)  %&gt;%  summarise(person_death_num=sum(person_death_num)\n                                                           ,person_injury_num=sum(person_injury_num)\n                                                           )\n\n\nwide to long\n\n\nCode\nchartdata002=chartdata001 %&gt;%select(month_year,person_death_num,person_injury_num) %&gt;% \n  pivot_longer(!c(month_year), names_to = 'type', values_to = 'DATA')\n\n\n\n\nCode\ngg=ggplot(chartdata001, aes(x=month_year, y=person_death_num,label = person_death_num))+\n  geom_bar(stat=\"identity\",fill='red')+ geom_text(vjust = -1,\n              position = position_dodge(width = 0.9))+ theme_bw()\n\n\nggplotly(gg)\n\n\n\n\n\n\n\n\nCode\ngg=ggplot(chartdata002, aes(fill=type, y=DATA, x=month_year)) +\n    geom_col(position = \"dodge\") +\n    geom_text(aes(label = DATA), vjust = 1.5,\n              position = position_dodge(width = 0.9))+scale_y_log10()+ theme_light()\n\npp=ggplotly(gg)\n\npp\n\n\n\n\n\n\n\n\n5 map\n\n\nCode\nall_data2 =all_data %&gt;%  mutate(report=report %&gt;% str_trunc(100))\n\n\n\n\nCode\n#write.xlsx(all_data2,'all_data2.xlsx')\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(stringr)\n\nmapview(all_data2, map.types='OpenStreetMap',label='text',xcol = \"Longitude\", ycol = \"Latitude\", zcol='incident_type',cex=\"person_death_num\",crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n6 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\nhttps://maps.clb.org.hk/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "3 Map",
      "China accident map"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html",
    "href": "other/4 other/4 quarto tips.html",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\n\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)\n\n\n\n\n\n\n\nadd foldableCodeBlcok.lua into blog root folder\nadd in _quarto.yml\n\nfilters: - fold_results.lua\n\nput following on code chunk\n\n{r, attr.output=‘.details summary=“sessionInfo()”’} #| echo: false sessionInfo()\n\n\n\n\n\n\nCode\n\nTerminal\n\nquarto render \"tidymodel in R\"",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/2 translation.html",
    "href": "other/4 other/2 translation.html",
    "title": "Translation",
    "section": "",
    "text": "Code\nlibrary(polyglotr)\n\n\n\n1 Translation word\n\n\nCode\nword_translation &lt;- linguee_word_translation(\"fruit\", source_language = \"en\", target_language = \"zh\")\n\nword_translation\n\n\n[1] \"水果\" \"果香\" \"果子\" \"果品\" \"实\"   \"檎\"  \n\n\n\n\n2 translate sentences\n\n\nCode\ngoogle_get_supported_languages()\n\n\n# A tibble: 134 × 2\n   Language    `ISO-639 code`\n   &lt;chr&gt;       &lt;chr&gt;         \n 1 Afrikaans   af            \n 2 Albanian    sq            \n 3 Amharic     am            \n 4 Arabic      ar            \n 5 Armenian    hy            \n 6 Assamese    as            \n 7 Aymara      ay            \n 8 Azerbaijani az            \n 9 Bambara     bm            \n10 Basque      eu            \n# ℹ 124 more rows\n\n\n\n\nCode\ntexts &lt;- c(\"Hello, how are you?\", \n           \"I love programming!\", \n           \"This is a test.\")\n\nlanguages &lt;- c(\"es\", \"fr\", \"zh-CN\")\n\n\ncreate_translation_table(texts, languages)\n\n\n        original_word                     es                          fr\n1 Hello, how are you?     ¿Hola, cómo estás? Bonjour comment allez-vous?\n2 I love programming! ¡Me encanta programar!  J'adore la programmation !\n3     This is a test.    Esto es una prueba.              C'est un test.\n           zh-CN\n1       你好吗？\n2   我喜欢编程！\n3 这是一个测试。\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "4 other",
      "Translation"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#change-_quarto.yml",
    "href": "other/4 other/4 quarto tips.html#change-_quarto.yml",
    "title": "quarto tips",
    "section": "3.3 change _quarto.yml",
    "text": "3.3 change _quarto.yml\n\n\n_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#ignore-some-file-to-be-upload-to-github",
    "href": "other/4 other/4 quarto tips.html#ignore-some-file-to-be-upload-to-github",
    "title": "quarto tips",
    "section": "3.6 ignore some file to be upload to github",
    "text": "3.6 ignore some file to be upload to github\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#draft-postnot-include-in-the-main-page",
    "href": "other/4 other/4 quarto tips.html#draft-postnot-include-in-the-main-page",
    "title": "quarto tips",
    "section": "2.5 draft post,not include in the main page",
    "text": "2.5 draft post,not include in the main page\n\n\nCode\ndraft:true",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#create-github-repository",
    "href": "other/4 other/4 quarto tips.html#create-github-repository",
    "title": "quarto tips",
    "section": "3.4 create github repository",
    "text": "3.4 create github repository",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#in-github-repository-settingpages-change-branch-to-mian-docs",
    "href": "other/4 other/4 quarto tips.html#in-github-repository-settingpages-change-branch-to-mian-docs",
    "title": "quarto tips",
    "section": "3.5 in github repository setting/Pages change branch to mian /docs",
    "text": "3.5 in github repository setting/Pages change branch to mian /docs\n\nThe github site is created: https://your_github_name.github.io/repository_name/",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#blog-post",
    "href": "other/4 other/4 quarto tips.html#blog-post",
    "title": "quarto tips",
    "section": "2.1 blog post",
    "text": "2.1 blog post\n\n\nCode\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#hide-post-from-main-page",
    "href": "other/4 other/4 quarto tips.html#hide-post-from-main-page",
    "title": "quarto tips",
    "section": "2.2 hide post from main page",
    "text": "2.2 hide post from main page\n\n\nCode\n---\ndraft: true  \n  \n---",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#quarto.yml",
    "href": "other/4 other/4 quarto tips.html#quarto.yml",
    "title": "quarto tips",
    "section": "2.3 _quarto.yml",
    "text": "2.3 _quarto.yml\n\n\nCode\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#index.qmd",
    "href": "other/4 other/4 quarto tips.html#index.qmd",
    "title": "quarto tips",
    "section": "2.4 index.qmd",
    "text": "2.4 index.qmd\n\n\nCode\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/1 ggplot2.html#add-logo",
    "href": "Plot/1 ggplot2.html#add-logo",
    "title": "ggplot2 in R",
    "section": "11.1 add logo",
    "text": "11.1 add logo\n\n\nCode\n# Add your company's logo to the graph you created\nlogo &lt;- image_read(\"logo.png\")\np\ngrid::grid.raster(logo, x = 0.1, y = 0, just = c('left', 'bottom'), width = unit(0.4, 'inches'))",
    "crumbs": [
      "Plot",
      "ggplot2 in R"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#quarto-code-chunk-option",
    "href": "other/4 other/4 quarto tips.html#quarto-code-chunk-option",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\n\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#add-a-output-folder-bottom-at-quarto-file",
    "href": "other/4 other/4 quarto tips.html#add-a-output-folder-bottom-at-quarto-file",
    "title": "quarto tips",
    "section": "",
    "text": "add foldableCodeBlcok.lua into blog root folder\nadd in _quarto.yml\n\nfilters: - fold_results.lua\n\nput following on code chunk\n\n{r, attr.output=‘.details summary=“sessionInfo()”’} #| echo: false sessionInfo()",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#render-all-quarto-website",
    "href": "other/4 other/4 quarto tips.html#render-all-quarto-website",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n\nTerminal\n\nquarto render \"tidymodel in R\"",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#publish-quarto-website-into-quarto-hub",
    "href": "other/4 other/4 quarto tips.html#publish-quarto-website-into-quarto-hub",
    "title": "quarto tips",
    "section": "3.1 Publish quarto website into quarto hub",
    "text": "3.1 Publish quarto website into quarto hub\nyou need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/4 other/4 quarto tips.html#publish-quarto-website-into-github-page",
    "href": "other/4 other/4 quarto tips.html#publish-quarto-website-into-github-page",
    "title": "quarto tips",
    "section": "3.2 Publish quarto website into github page",
    "text": "3.2 Publish quarto website into github page\n\n3.2.1 change _quarto.yml\n\n\n_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n3.2.2 create github repository\n\n\n\n3.2.3 in github repository setting/Pages change branch to mian /docs\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n3.2.4 ignore some file to be upload to github\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Other",
      "4 other",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/3 image processing.html",
    "href": "Plot/3 image processing.html",
    "title": "image processing",
    "section": "",
    "text": "Code\nlibrary(magick)\n\n\n\n1 input\n\n\nCode\nraw_logo &lt;- image_read('./images/comb.webp')\n\n\n\n\n2 output\n\n\nCode\nimage_info(raw_logo)\n\n\n  format width height colorspace matte filesize density\n1   WEBP   450    303       sRGB  TRUE    49650   72x72\n\n\n\n\n3 change format\n\n\nCode\nnew_png &lt;- image_convert(raw_logo, \"png\")\n\n\n\n\nCode\nimage_info(new_png)\n\n\n  format width height colorspace matte filesize density\n1    PNG   450    303       sRGB  TRUE        0   72x72\n\n\n\n\n4 output\n\n\nCode\nimage_write(new_png, path = \"./images/new_png.png\", format = \"png\")\n\n\n\n\nCode\nraw_logo &lt;- image_read('./images/logo1.png')\n\n\n\n\nCode\nraw_logo %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE    53960   72x72\n\n\n\n\n\n\n\n\n\n\n\n5 fill corner white to greem\neach corner (top left, top right, bottom left, bottom right). For our real usage, we’re going to convert this “green” space to transparent instead.\n\n\nCode\nimg_filled &lt;- raw_logo %&gt;% \n    image_fill(\"green\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"green\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\nimg_filled %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n6 rotate\n\n\nCode\nimg_filled %&gt;% image_rotate(45) %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1632   1632       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n7 add border\n\n\nCode\nimg_filled %&gt;% image_border(\"#CD5C5C\",\"20x20\")\n\n\n\n\n\n\n\n\n\n\n\n8 make backgroup transparent\n\n\nCode\n# 0-100 distance fuzz match with green\nb=img_filled %&gt;% image_transparent(color='green',10)\n\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\nCode\nimage_write(b, path = \"b.png\", format = \"png\")\n\n\n\n\n9 change opacity level\n\n\nCode\nb=img_filled %&gt;% image_colorize(opacity =80, color = 'white')\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n10 change brightness level\n\n\nCode\nb=img_filled %&gt;%image_modulate(brightness = 30)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n11 change blur level\n\n\nCode\nb=img_filled %&gt;%  image_blur(10, 5)\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n12 add text into picture\n\n\nCode\nb=img_filled %&gt;% image_annotate( \"The quick brown fox\", font = 'Times', size = 80,gravity = \"southwest\", color = \"red\")\n  \nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\n13 resize\nusing image_resize or image_scale\n\n\nCode\nb= img_filled%&gt;% image_resize(\"500\")\nb %&gt;% print()\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nCode\nimage_info(img_filled)\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       sRGB  TRUE        0   72x72\n\n\n\n\nCode\nimage_info(b)\n\n\n  format width height colorspace matte filesize density\n1    PNG   500    357       sRGB  TRUE        0   72x72\n\n\n\n\n14 make logo black\n\n\nCode\nimg_filled2 &lt;- raw_logo %&gt;% \n    image_fill(\"transparent\", \"+1+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+1\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+1+99\", fuzz = 50, refcolor = \"white\") %&gt;% \n    image_fill(\"transparent\", \"+140+99\", fuzz = 50, refcolor = \"white\")\n\n\n\n\nCode\nimg_filled2 %&gt;% \n    image_channel(\"Opacity\") %&gt;% \n    image_convert(matte=FALSE) %&gt;% \n  print()\n\n\n  format width height colorspace matte filesize density\n1    PNG  1344    960       Gray FALSE        0   72x72\n\n\n\n\n\n\n\n\n\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] magick_2.8.3\n\nloaded via a namespace (and not attached):\n [1] digest_0.6.35     fastmap_1.1.1     xfun_0.43         magrittr_2.0.3   \n [5] knitr_1.45        htmltools_0.5.8.1 png_0.1-8         rmarkdown_2.26   \n [9] cli_3.6.2         compiler_4.3.1    rstudioapi_0.16.0 tools_4.3.1      \n[13] evaluate_0.23     Rcpp_1.0.12       yaml_2.3.8        rlang_1.1.3      \n[17] jsonlite_1.8.8    htmlwidgets_1.6.4\n\n\n\n\n\n15 add backgroup image\n\n\nCode\nlibrary(ggplot2)\nlibrary(png)\nlibrary(grid)\nlibrary(ggimage)\n\n\n\n\nCode\nimg &lt;- readPNG(\"./images/new_png.png\")\n\n\n\n\nCode\nbees &lt;- data.frame(distance = c(0.5, 1, 1.5, 2, 2.5, 3),\n                  number = c(40, 34, 32, 22,18, 10))\n\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_point() +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n16 replace scatter with image\n\n\nCode\nbees$image &lt;- \"./images/bee.png\"\n\n\n\n\nCode\nggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\n\n\n\n\n\n\n\n\n17 add logo\n\n\nCode\nimg2 =image_read(\"./images/logo1.png\")\n\n\n\n\nCode\nlibrary(cowplot)\np=ggplot(data = bees, aes(x = distance, y = number)) +\n  annotation_custom(rasterGrob(img, \n                               width = unit(1,\"npc\"),\n                               height = unit(1,\"npc\")), \n                    -Inf, Inf, -Inf, Inf) +\n  geom_image(aes(image = image), size = 0.15) +\n  xlab(\"Distance (km)\") +\n  ylab(\"Number of Bees\") +\n  ylim(0, 45)\n\n\n\nggdraw() +draw_plot(p,x = 0, y = 0.15, width = 1, height = 0.85) +draw_image(img2,x = 0.1, y = 0.1, width = 0.1, height = 0.1) \n\n\n\n\n\n\n\n\n\n\n\n18 resource:\nhttps://themockup.blog/posts/2021-01-28-removing-image-backgrounds-with-magick/\nhttps://cran.r-project.org/web/packages/magick/vignettes/intro.html\nhttps://buzzrbeeline.blog/2018/06/13/fun-and-easy-r-graphs-with-images/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "image processing"
    ]
  },
  {
    "objectID": "Plot/Map/2 leaflet.html",
    "href": "Plot/Map/2 leaflet.html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\n\nlibrary(sf)\nlibrary(leaflet)\nlibrary(geojsonio)\nlibrary(leaflet.extras)\n\n\n\n\n2 display at openstreet map\n\n\nCode\nm &lt;- leaflet() %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\n\nm  \n\n\n\n\n\n\n\n\n3 display at google map\n\n\nCode\nleaflet() |&gt;\n  # add base mao\n  addTiles(urlTemplate = \"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\") |&gt;\n  # set view\n  setView(116.347817690225, 39.997202126977, zoom = 16) |&gt;\n  # add markers\n  addMarkers(116.347817690225, 39.997202126977)\n\n\n\n\n\n\n\n\n4 Third-Party map\n\n\nCode\n#m &lt;- leaflet() %&gt;% setView(lng = -71.0589, lat = 42.3601, zoom = 10)\n#m %&gt;% addProviderTiles(providers$Stadia.StamenToner)\n\n\n\n\n5 add pop up\nPopups are small boxes containing arbitrary HTML, that point to a specific point on the map.\n\n\nCode\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.samurainoodle.com/'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() %&gt;% addTiles() %&gt;%\n  setView(-122.327298, 47.597131,zoom = 12) %&gt;% \n  addPopups(-122.327298, 47.597131, content,\n    #options = popupOptions(closeButton = FALSE)\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\n\n\n6 add Markers\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"\n))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, popup = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n7 add Labels\nA label is a textual or HTML content that can attached to markers and shapes to be always displayed or displayed on mouse over. Unlike popups you don’t need to click a marker/polygon for the label to be shown.\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, label = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n8 World map\n\n\nCode\n#install.packages(\"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\")\n\n\n\n\nCode\njson_data=read_sf(\"world-administrative-boundaries.geojson\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\n#Get my variable\n#name&lt;-c(\"Ghana\", \"Grenada\", \"Guyana\", \"India\", \"Jamaica\", \"Kenya\", \"United States\",\"Canada\")\n#val&lt;-c(1,2,4,5,5,1000,20000, 100)\n\n#per_gdp_usd&lt;-data.frame(name,val)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('world data.xlsx') %&gt;% mutate(\n  name=case_when(\n    name ==\"United States\" ~ \"United States of America\"\n     ,name ==\"Russia\" ~ \"Russian Federation\"\n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name == \"South Korea\"~ \"Republic of Korea\"\n   \n   ,name ==\"Lao People's Democratic Republic\" ~ \"Laos\"\n   \n    ,TRUE ~ name\n  )\n)\n\n\n\n\nCode\n#test=full_join(map_df, per_gdp_usd, by=\"name\")\n\n#left =test %&gt;% filter(is.na(iso3)==TRUE)\n\n#right=test %&gt;% filter(is.na(per_gdp_total)==TRUE)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"name\")\n\n\n\n\nCode\nglimpse(map_df002)\n\n\nRows: 158\nColumns: 12\n$ name                     &lt;chr&gt; \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"A…\n$ geo_point_2d             &lt;chr&gt; \"{ \\\"lon\\\": 20.068384605918776, \\\"lat\\\": 41.1…\n$ iso3                     &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ status                   &lt;chr&gt; \"Member State\", \"Member State\", \"Member State…\n$ color_code               &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ continent                &lt;chr&gt; \"Europe\", \"Africa\", \"Europe\", \"Africa\", \"Amer…\n$ region                   &lt;chr&gt; \"Southern Europe\", \"Northern Africa\", \"Southe…\n$ iso_3166_1_alpha_2_codes &lt;chr&gt; \"AL\", \"DZ\", \"AD\", \"AO\", \"AR\", \"AM\", \"AU\", \"AT…\n$ french_short             &lt;chr&gt; \"Albanie\", \"Algérie\", \"Andorre\", \"Angola\", \"A…\n$ geometry                 &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((20.07142 42..., …\n$ per_gdp_total            &lt;dbl&gt; 1.888210e+10, 1.919130e+11, 3.352033e+09, 1.0…\n$ per_gdp_usd              &lt;dbl&gt; 6643, 4274, 41993, 2999, 13904, 7014, 64003, …\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gdp_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gdp_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_gdp_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$per_gdp_total/1000000), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gdp_usd, opacity = 1.0\n    )\n\n\n\n\n\n\n\n\n9 China one city map\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/citys/440300.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/440300_full.json\")\n\n\n深圳市：\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n\n\n\n\n10 all China each province GPD map\n\n\nCode\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n中国 2022 各省 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('china gdp2022.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nGPD data source:国家统计局数据库\n\n\n11 China one province map each city GPD\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/province/440000.json\") \n\n\n广东省 2021 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('guangdong city gdp2021.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\ndata source:广东统计年鉴2022\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"城市：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"城市：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb*10000000/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nhttps://zh.wikipedia.org/wiki/%E5%B9%BF%E4%B8%9C%E5%90%84%E5%9C%B0%E7%BA%A7%E5%B8%82%E5%9C%B0%E5%8C%BA%E7%94%9F%E4%BA%A7%E6%80%BB%E5%80%BC%E5%88%97%E8%A1%A8\n\n\n12 China province map\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\n\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/china.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nm=leaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n \n\nm\n\n\n\n\n\n\nadd provincial capital\n\n\nCode\nChina=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n\n\nCode\nChina002=China %&gt;% as_data_frame() %&gt;% mutate(\n                                            center2=as.character(center) %&gt;% str_replace('c','')%&gt;% str_replace('[(]','') %&gt;% str_replace('[)]','')\n                                               )\n\n\n\n\nCode\nChina003=China002%&gt;%separate(center2, c(\"x\", \"y\"), \", \")\n\n\n\n\nCode\nChina_point = China003 %&gt;% \n  slice(-35)\n\nm %&gt;% \n  addCircles(data = China_point,\n                  lng = ~as.numeric(x), lat = ~as.numeric(y),color = \"red\",weight = 10,\n                  fillOpacity =2)\n\n\n\n\n\n\n\n\n13 China province and city map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 34\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 119.3183 ymin: 21.75147 xmax: 124.5656 ymax: 25.92592\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 710000 台湾省 121.509062,25.044332 province (((119.5543 23.68248, 119.555 23.…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/province/710000.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 33\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n14 China city and district map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 334\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.5215 ymin: 22.65421 xmax: 114.2603 ymax: 23.14205\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 441900 东莞市 113.746262,23.046237 city  ((114.2292 22.81251, 114.2278 22.813…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.157 ymin: 22.20104 xmax: 113.692 ymax: 22.7726\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 442000 中山市 113.382391,22.521113 city  ((113.5687 22.41193, 113.5666 22.412…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 115.9267 ymin: 20.58265 xmax: 116.9338 ymax: 21.12693\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center               level                            geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                &lt;chr&gt;                  &lt;MULTIPOLYGON [°]&gt;\n1 442100 东沙群岛 116.887312,20.617512 city  (((115.9433 21.09745, 115.95 21.11…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 108.9287 ymin: 19.17894 xmax: 109.7694 ymax: 19.92575\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 460400 儋州市 109.576782,19.517486 city  (((109.4322 19.91302, 109.4253 19.91…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.8483 ymin: 39.65426 xmax: 98.52018 ymax: 39.99979\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center              level                             geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;               &lt;chr&gt;                   &lt;MULTIPOLYGON [°]&gt;\n1 620200 嘉峪关市 98.277304,39.786529 city  (((97.85974 39.7169, 97.85827 39.71…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/citys/620200.json\"\n         ,\"./GeoMapData_CN/citys/460400.json\"\n              ,\"./GeoMapData_CN/citys/442100.json\"\n              ,\"./GeoMapData_CN/citys/442000.json\"\n              ,\"./GeoMapData_CN/citys/441900.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 329\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n15 show all map providers\n\n\nCode\nproviders\n\n\nproviders\n$OpenStreetMap\n[1] \"OpenStreetMap\"\n\n$OpenStreetMap.Mapnik\n[1] \"OpenStreetMap.Mapnik\"\n\n$OpenStreetMap.DE\n[1] \"OpenStreetMap.DE\"\n\n$OpenStreetMap.CH\n[1] \"OpenStreetMap.CH\"\n\n$OpenStreetMap.France\n[1] \"OpenStreetMap.France\"\n\n$OpenStreetMap.HOT\n[1] \"OpenStreetMap.HOT\"\n\n$OpenStreetMap.BZH\n[1] \"OpenStreetMap.BZH\"\n\n$MapTilesAPI\n[1] \"MapTilesAPI\"\n\n$MapTilesAPI.OSMEnglish\n[1] \"MapTilesAPI.OSMEnglish\"\n\n$MapTilesAPI.OSMFrancais\n[1] \"MapTilesAPI.OSMFrancais\"\n\n$MapTilesAPI.OSMEspagnol\n[1] \"MapTilesAPI.OSMEspagnol\"\n\n$OpenSeaMap\n[1] \"OpenSeaMap\"\n\n$OPNVKarte\n[1] \"OPNVKarte\"\n\n$OpenTopoMap\n[1] \"OpenTopoMap\"\n\n$OpenRailwayMap\n[1] \"OpenRailwayMap\"\n\n$OpenFireMap\n[1] \"OpenFireMap\"\n\n$SafeCast\n[1] \"SafeCast\"\n\n$Stadia\n[1] \"Stadia\"\n\n$Stadia.AlidadeSmooth\n[1] \"Stadia.AlidadeSmooth\"\n\n$Stadia.AlidadeSmoothDark\n[1] \"Stadia.AlidadeSmoothDark\"\n\n$Stadia.OSMBright\n[1] \"Stadia.OSMBright\"\n\n$Stadia.Outdoors\n[1] \"Stadia.Outdoors\"\n\n$Stadia.StamenToner\n[1] \"Stadia.StamenToner\"\n\n$Stadia.StamenTonerBackground\n[1] \"Stadia.StamenTonerBackground\"\n\n$Stadia.StamenTonerLines\n[1] \"Stadia.StamenTonerLines\"\n\n$Stadia.StamenTonerLabels\n[1] \"Stadia.StamenTonerLabels\"\n\n$Stadia.StamenTonerLite\n[1] \"Stadia.StamenTonerLite\"\n\n$Stadia.StamenWatercolor\n[1] \"Stadia.StamenWatercolor\"\n\n$Stadia.StamenTerrain\n[1] \"Stadia.StamenTerrain\"\n\n$Stadia.StamenTerrainBackground\n[1] \"Stadia.StamenTerrainBackground\"\n\n$Stadia.StamenTerrainLabels\n[1] \"Stadia.StamenTerrainLabels\"\n\n$Stadia.StamenTerrainLines\n[1] \"Stadia.StamenTerrainLines\"\n\n$Thunderforest\n[1] \"Thunderforest\"\n\n$Thunderforest.OpenCycleMap\n[1] \"Thunderforest.OpenCycleMap\"\n\n$Thunderforest.Transport\n[1] \"Thunderforest.Transport\"\n\n$Thunderforest.TransportDark\n[1] \"Thunderforest.TransportDark\"\n\n$Thunderforest.SpinalMap\n[1] \"Thunderforest.SpinalMap\"\n\n$Thunderforest.Landscape\n[1] \"Thunderforest.Landscape\"\n\n$Thunderforest.Outdoors\n[1] \"Thunderforest.Outdoors\"\n\n$Thunderforest.Pioneer\n[1] \"Thunderforest.Pioneer\"\n\n$Thunderforest.MobileAtlas\n[1] \"Thunderforest.MobileAtlas\"\n\n$Thunderforest.Neighbourhood\n[1] \"Thunderforest.Neighbourhood\"\n\n$CyclOSM\n[1] \"CyclOSM\"\n\n$Jawg\n[1] \"Jawg\"\n\n$Jawg.Streets\n[1] \"Jawg.Streets\"\n\n$Jawg.Terrain\n[1] \"Jawg.Terrain\"\n\n$Jawg.Sunny\n[1] \"Jawg.Sunny\"\n\n$Jawg.Dark\n[1] \"Jawg.Dark\"\n\n$Jawg.Light\n[1] \"Jawg.Light\"\n\n$Jawg.Matrix\n[1] \"Jawg.Matrix\"\n\n$MapBox\n[1] \"MapBox\"\n\n$MapTiler\n[1] \"MapTiler\"\n\n$MapTiler.Streets\n[1] \"MapTiler.Streets\"\n\n$MapTiler.Basic\n[1] \"MapTiler.Basic\"\n\n$MapTiler.Bright\n[1] \"MapTiler.Bright\"\n\n$MapTiler.Pastel\n[1] \"MapTiler.Pastel\"\n\n$MapTiler.Positron\n[1] \"MapTiler.Positron\"\n\n$MapTiler.Hybrid\n[1] \"MapTiler.Hybrid\"\n\n$MapTiler.Toner\n[1] \"MapTiler.Toner\"\n\n$MapTiler.Topo\n[1] \"MapTiler.Topo\"\n\n$MapTiler.Voyager\n[1] \"MapTiler.Voyager\"\n\n$TomTom\n[1] \"TomTom\"\n\n$TomTom.Basic\n[1] \"TomTom.Basic\"\n\n$TomTom.Hybrid\n[1] \"TomTom.Hybrid\"\n\n$TomTom.Labels\n[1] \"TomTom.Labels\"\n\n$Esri\n[1] \"Esri\"\n\n$Esri.WorldStreetMap\n[1] \"Esri.WorldStreetMap\"\n\n$Esri.DeLorme\n[1] \"Esri.DeLorme\"\n\n$Esri.WorldTopoMap\n[1] \"Esri.WorldTopoMap\"\n\n$Esri.WorldImagery\n[1] \"Esri.WorldImagery\"\n\n$Esri.WorldTerrain\n[1] \"Esri.WorldTerrain\"\n\n$Esri.WorldShadedRelief\n[1] \"Esri.WorldShadedRelief\"\n\n$Esri.WorldPhysical\n[1] \"Esri.WorldPhysical\"\n\n$Esri.OceanBasemap\n[1] \"Esri.OceanBasemap\"\n\n$Esri.NatGeoWorldMap\n[1] \"Esri.NatGeoWorldMap\"\n\n$Esri.WorldGrayCanvas\n[1] \"Esri.WorldGrayCanvas\"\n\n$OpenWeatherMap\n[1] \"OpenWeatherMap\"\n\n$OpenWeatherMap.Clouds\n[1] \"OpenWeatherMap.Clouds\"\n\n$OpenWeatherMap.CloudsClassic\n[1] \"OpenWeatherMap.CloudsClassic\"\n\n$OpenWeatherMap.Precipitation\n[1] \"OpenWeatherMap.Precipitation\"\n\n$OpenWeatherMap.PrecipitationClassic\n[1] \"OpenWeatherMap.PrecipitationClassic\"\n\n$OpenWeatherMap.Rain\n[1] \"OpenWeatherMap.Rain\"\n\n$OpenWeatherMap.RainClassic\n[1] \"OpenWeatherMap.RainClassic\"\n\n$OpenWeatherMap.Pressure\n[1] \"OpenWeatherMap.Pressure\"\n\n$OpenWeatherMap.PressureContour\n[1] \"OpenWeatherMap.PressureContour\"\n\n$OpenWeatherMap.Wind\n[1] \"OpenWeatherMap.Wind\"\n\n$OpenWeatherMap.Temperature\n[1] \"OpenWeatherMap.Temperature\"\n\n$OpenWeatherMap.Snow\n[1] \"OpenWeatherMap.Snow\"\n\n$HERE\n[1] \"HERE\"\n\n$HERE.normalDay\n[1] \"HERE.normalDay\"\n\n$HERE.normalDayCustom\n[1] \"HERE.normalDayCustom\"\n\n$HERE.normalDayGrey\n[1] \"HERE.normalDayGrey\"\n\n$HERE.normalDayMobile\n[1] \"HERE.normalDayMobile\"\n\n$HERE.normalDayGreyMobile\n[1] \"HERE.normalDayGreyMobile\"\n\n$HERE.normalDayTransit\n[1] \"HERE.normalDayTransit\"\n\n$HERE.normalDayTransitMobile\n[1] \"HERE.normalDayTransitMobile\"\n\n$HERE.normalDayTraffic\n[1] \"HERE.normalDayTraffic\"\n\n$HERE.normalNight\n[1] \"HERE.normalNight\"\n\n$HERE.normalNightMobile\n[1] \"HERE.normalNightMobile\"\n\n$HERE.normalNightGrey\n[1] \"HERE.normalNightGrey\"\n\n$HERE.normalNightGreyMobile\n[1] \"HERE.normalNightGreyMobile\"\n\n$HERE.normalNightTransit\n[1] \"HERE.normalNightTransit\"\n\n$HERE.normalNightTransitMobile\n[1] \"HERE.normalNightTransitMobile\"\n\n$HERE.reducedDay\n[1] \"HERE.reducedDay\"\n\n$HERE.reducedNight\n[1] \"HERE.reducedNight\"\n\n$HERE.basicMap\n[1] \"HERE.basicMap\"\n\n$HERE.mapLabels\n[1] \"HERE.mapLabels\"\n\n$HERE.trafficFlow\n[1] \"HERE.trafficFlow\"\n\n$HERE.carnavDayGrey\n[1] \"HERE.carnavDayGrey\"\n\n$HERE.hybridDay\n[1] \"HERE.hybridDay\"\n\n$HERE.hybridDayMobile\n[1] \"HERE.hybridDayMobile\"\n\n$HERE.hybridDayTransit\n[1] \"HERE.hybridDayTransit\"\n\n$HERE.hybridDayGrey\n[1] \"HERE.hybridDayGrey\"\n\n$HERE.hybridDayTraffic\n[1] \"HERE.hybridDayTraffic\"\n\n$HERE.pedestrianDay\n[1] \"HERE.pedestrianDay\"\n\n$HERE.pedestrianNight\n[1] \"HERE.pedestrianNight\"\n\n$HERE.satelliteDay\n[1] \"HERE.satelliteDay\"\n\n$HERE.terrainDay\n[1] \"HERE.terrainDay\"\n\n$HERE.terrainDayMobile\n[1] \"HERE.terrainDayMobile\"\n\n$HEREv3\n[1] \"HEREv3\"\n\n$HEREv3.normalDay\n[1] \"HEREv3.normalDay\"\n\n$HEREv3.normalDayCustom\n[1] \"HEREv3.normalDayCustom\"\n\n$HEREv3.normalDayGrey\n[1] \"HEREv3.normalDayGrey\"\n\n$HEREv3.normalDayMobile\n[1] \"HEREv3.normalDayMobile\"\n\n$HEREv3.normalDayGreyMobile\n[1] \"HEREv3.normalDayGreyMobile\"\n\n$HEREv3.normalDayTransit\n[1] \"HEREv3.normalDayTransit\"\n\n$HEREv3.normalDayTransitMobile\n[1] \"HEREv3.normalDayTransitMobile\"\n\n$HEREv3.normalNight\n[1] \"HEREv3.normalNight\"\n\n$HEREv3.normalNightMobile\n[1] \"HEREv3.normalNightMobile\"\n\n$HEREv3.normalNightGrey\n[1] \"HEREv3.normalNightGrey\"\n\n$HEREv3.normalNightGreyMobile\n[1] \"HEREv3.normalNightGreyMobile\"\n\n$HEREv3.normalNightTransit\n[1] \"HEREv3.normalNightTransit\"\n\n$HEREv3.normalNightTransitMobile\n[1] \"HEREv3.normalNightTransitMobile\"\n\n$HEREv3.reducedDay\n[1] \"HEREv3.reducedDay\"\n\n$HEREv3.reducedNight\n[1] \"HEREv3.reducedNight\"\n\n$HEREv3.basicMap\n[1] \"HEREv3.basicMap\"\n\n$HEREv3.mapLabels\n[1] \"HEREv3.mapLabels\"\n\n$HEREv3.trafficFlow\n[1] \"HEREv3.trafficFlow\"\n\n$HEREv3.carnavDayGrey\n[1] \"HEREv3.carnavDayGrey\"\n\n$HEREv3.hybridDay\n[1] \"HEREv3.hybridDay\"\n\n$HEREv3.hybridDayMobile\n[1] \"HEREv3.hybridDayMobile\"\n\n$HEREv3.hybridDayTransit\n[1] \"HEREv3.hybridDayTransit\"\n\n$HEREv3.hybridDayGrey\n[1] \"HEREv3.hybridDayGrey\"\n\n$HEREv3.pedestrianDay\n[1] \"HEREv3.pedestrianDay\"\n\n$HEREv3.pedestrianNight\n[1] \"HEREv3.pedestrianNight\"\n\n$HEREv3.satelliteDay\n[1] \"HEREv3.satelliteDay\"\n\n$HEREv3.terrainDay\n[1] \"HEREv3.terrainDay\"\n\n$HEREv3.terrainDayMobile\n[1] \"HEREv3.terrainDayMobile\"\n\n$FreeMapSK\n[1] \"FreeMapSK\"\n\n$MtbMap\n[1] \"MtbMap\"\n\n$CartoDB\n[1] \"CartoDB\"\n\n$CartoDB.Positron\n[1] \"CartoDB.Positron\"\n\n$CartoDB.PositronNoLabels\n[1] \"CartoDB.PositronNoLabels\"\n\n$CartoDB.PositronOnlyLabels\n[1] \"CartoDB.PositronOnlyLabels\"\n\n$CartoDB.DarkMatter\n[1] \"CartoDB.DarkMatter\"\n\n$CartoDB.DarkMatterNoLabels\n[1] \"CartoDB.DarkMatterNoLabels\"\n\n$CartoDB.DarkMatterOnlyLabels\n[1] \"CartoDB.DarkMatterOnlyLabels\"\n\n$CartoDB.Voyager\n[1] \"CartoDB.Voyager\"\n\n$CartoDB.VoyagerNoLabels\n[1] \"CartoDB.VoyagerNoLabels\"\n\n$CartoDB.VoyagerOnlyLabels\n[1] \"CartoDB.VoyagerOnlyLabels\"\n\n$CartoDB.VoyagerLabelsUnder\n[1] \"CartoDB.VoyagerLabelsUnder\"\n\n$HikeBike\n[1] \"HikeBike\"\n\n$HikeBike.HikeBike\n[1] \"HikeBike.HikeBike\"\n\n$HikeBike.HillShading\n[1] \"HikeBike.HillShading\"\n\n$BasemapAT\n[1] \"BasemapAT\"\n\n$BasemapAT.basemap\n[1] \"BasemapAT.basemap\"\n\n$BasemapAT.grau\n[1] \"BasemapAT.grau\"\n\n$BasemapAT.overlay\n[1] \"BasemapAT.overlay\"\n\n$BasemapAT.terrain\n[1] \"BasemapAT.terrain\"\n\n$BasemapAT.surface\n[1] \"BasemapAT.surface\"\n\n$BasemapAT.highdpi\n[1] \"BasemapAT.highdpi\"\n\n$BasemapAT.orthofoto\n[1] \"BasemapAT.orthofoto\"\n\n$nlmaps\n[1] \"nlmaps\"\n\n$nlmaps.standaard\n[1] \"nlmaps.standaard\"\n\n$nlmaps.pastel\n[1] \"nlmaps.pastel\"\n\n$nlmaps.grijs\n[1] \"nlmaps.grijs\"\n\n$nlmaps.water\n[1] \"nlmaps.water\"\n\n$nlmaps.luchtfoto\n[1] \"nlmaps.luchtfoto\"\n\n$NASAGIBS\n[1] \"NASAGIBS\"\n\n$NASAGIBS.ModisTerraTrueColorCR\n[1] \"NASAGIBS.ModisTerraTrueColorCR\"\n\n$NASAGIBS.ModisTerraBands367CR\n[1] \"NASAGIBS.ModisTerraBands367CR\"\n\n$NASAGIBS.ViirsEarthAtNight2012\n[1] \"NASAGIBS.ViirsEarthAtNight2012\"\n\n$NASAGIBS.ModisTerraLSTDay\n[1] \"NASAGIBS.ModisTerraLSTDay\"\n\n$NASAGIBS.ModisTerraSnowCover\n[1] \"NASAGIBS.ModisTerraSnowCover\"\n\n$NASAGIBS.ModisTerraAOD\n[1] \"NASAGIBS.ModisTerraAOD\"\n\n$NASAGIBS.ModisTerraChlorophyll\n[1] \"NASAGIBS.ModisTerraChlorophyll\"\n\n$NLS\n[1] \"NLS\"\n\n$JusticeMap\n[1] \"JusticeMap\"\n\n$JusticeMap.income\n[1] \"JusticeMap.income\"\n\n$JusticeMap.americanIndian\n[1] \"JusticeMap.americanIndian\"\n\n$JusticeMap.asian\n[1] \"JusticeMap.asian\"\n\n$JusticeMap.black\n[1] \"JusticeMap.black\"\n\n$JusticeMap.hispanic\n[1] \"JusticeMap.hispanic\"\n\n$JusticeMap.multi\n[1] \"JusticeMap.multi\"\n\n$JusticeMap.nonWhite\n[1] \"JusticeMap.nonWhite\"\n\n$JusticeMap.white\n[1] \"JusticeMap.white\"\n\n$JusticeMap.plurality\n[1] \"JusticeMap.plurality\"\n\n$GeoportailFrance\n[1] \"GeoportailFrance\"\n\n$GeoportailFrance.plan\n[1] \"GeoportailFrance.plan\"\n\n$GeoportailFrance.parcels\n[1] \"GeoportailFrance.parcels\"\n\n$GeoportailFrance.orthos\n[1] \"GeoportailFrance.orthos\"\n\n$OneMapSG\n[1] \"OneMapSG\"\n\n$OneMapSG.Default\n[1] \"OneMapSG.Default\"\n\n$OneMapSG.Night\n[1] \"OneMapSG.Night\"\n\n$OneMapSG.Original\n[1] \"OneMapSG.Original\"\n\n$OneMapSG.Grey\n[1] \"OneMapSG.Grey\"\n\n$OneMapSG.LandLot\n[1] \"OneMapSG.LandLot\"\n\n$USGS\n[1] \"USGS\"\n\n$USGS.USTopo\n[1] \"USGS.USTopo\"\n\n$USGS.USImagery\n[1] \"USGS.USImagery\"\n\n$USGS.USImageryTopo\n[1] \"USGS.USImageryTopo\"\n\n$WaymarkedTrails\n[1] \"WaymarkedTrails\"\n\n$WaymarkedTrails.hiking\n[1] \"WaymarkedTrails.hiking\"\n\n$WaymarkedTrails.cycling\n[1] \"WaymarkedTrails.cycling\"\n\n$WaymarkedTrails.mtb\n[1] \"WaymarkedTrails.mtb\"\n\n$WaymarkedTrails.slopes\n[1] \"WaymarkedTrails.slopes\"\n\n$WaymarkedTrails.riding\n[1] \"WaymarkedTrails.riding\"\n\n$WaymarkedTrails.skating\n[1] \"WaymarkedTrails.skating\"\n\n$OpenAIP\n[1] \"OpenAIP\"\n\n$OpenSnowMap\n[1] \"OpenSnowMap\"\n\n$OpenSnowMap.pistes\n[1] \"OpenSnowMap.pistes\"\n\n$AzureMaps\n[1] \"AzureMaps\"\n\n$AzureMaps.MicrosoftImagery\n[1] \"AzureMaps.MicrosoftImagery\"\n\n$AzureMaps.MicrosoftBaseDarkGrey\n[1] \"AzureMaps.MicrosoftBaseDarkGrey\"\n\n$AzureMaps.MicrosoftBaseRoad\n[1] \"AzureMaps.MicrosoftBaseRoad\"\n\n$AzureMaps.MicrosoftBaseHybridRoad\n[1] \"AzureMaps.MicrosoftBaseHybridRoad\"\n\n$AzureMaps.MicrosoftTerraMain\n[1] \"AzureMaps.MicrosoftTerraMain\"\n\n$AzureMaps.MicrosoftWeatherInfraredMain\n[1] \"AzureMaps.MicrosoftWeatherInfraredMain\"\n\n$AzureMaps.MicrosoftWeatherRadarMain\n[1] \"AzureMaps.MicrosoftWeatherRadarMain\"\n\n$SwissFederalGeoportal\n[1] \"SwissFederalGeoportal\"\n\n$SwissFederalGeoportal.NationalMapColor\n[1] \"SwissFederalGeoportal.NationalMapColor\"\n\n$SwissFederalGeoportal.NationalMapGrey\n[1] \"SwissFederalGeoportal.NationalMapGrey\"\n\n$SwissFederalGeoportal.SWISSIMAGE\n[1] \"SwissFederalGeoportal.SWISSIMAGE\"\n\n\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] readxl_1.4.3         openxlsx_4.2.5.2     htmltools_0.5.8.1   \n [4] leaflet.extras_1.0.0 geojsonio_0.11.3     leaflet_2.2.2       \n [7] sf_1.0-16            lubridate_1.9.3      forcats_1.0.0       \n[10] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n[13] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n[16] ggplot2_3.5.1        tidyverse_2.0.0     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5            xfun_0.43               htmlwidgets_1.6.4      \n [4] lattice_0.22-6          tzdb_0.4.0              leaflet.providers_2.0.0\n [7] vctrs_0.6.5             tools_4.3.1             crosstalk_1.2.1        \n[10] generics_0.1.3          curl_5.2.1              proxy_0.4-27           \n[13] fansi_1.0.6             pkgconfig_2.0.3         KernSmooth_2.23-22     \n[16] RColorBrewer_1.1-3      lifecycle_1.0.4         farver_2.1.1           \n[19] compiler_4.3.1          munsell_0.5.1           jqr_1.3.3              \n[22] class_7.3-22            yaml_2.3.8              lazyeval_0.2.2         \n[25] jquerylib_0.1.4         pillar_1.9.0            classInt_0.4-10        \n[28] zip_2.3.1               tidyselect_1.2.1        digest_0.6.35          \n[31] stringi_1.8.4           fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.2               magrittr_2.0.3         \n[37] crul_1.4.2              utf8_1.2.4              e1071_1.7-14           \n[40] withr_3.0.0             scales_1.3.0            sp_2.1-4               \n[43] timechange_0.3.0        rmarkdown_2.26          cellranger_1.1.0       \n[46] hms_1.1.3               evaluate_0.23           knitr_1.45             \n[49] V8_4.4.2                viridisLite_0.4.2       geojson_0.3.5          \n[52] rlang_1.1.3             Rcpp_1.0.12             glue_1.7.0             \n[55] DBI_1.2.2               httpcode_0.3.0          geojsonsf_2.0.3        \n[58] rstudioapi_0.16.0       jsonlite_1.8.8          R6_2.5.1               \n[61] units_0.8-5            \n\n\n\n\n\n16 resouce:\nhttps://rstudio.github.io/leaflet/\nhttps://github.com/Lchiffon/leafletCN\nhttps://github.com/longwosion/geojson-map-china\nhttps://xiangyun.rbind.io/2022/02/draw-china-maps/\nhttps://datav.aliyun.com/portal/school/atlas/area_selector\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Map",
      "map"
    ]
  },
  {
    "objectID": "Plot/4 Financial data.html",
    "href": "Plot/4 Financial data.html",
    "title": "Financial data",
    "section": "",
    "text": "Code\nlibrary(quantmod)\nlibrary(tidyverse)\nlibrary(yahoofinancer)\nlibrary(Quandl)\nlibrary(plotly)\nlibrary(finreportr)\nlibrary(rvest)\n\n\n\n1 stock price\n\n\nCode\nnifty_50 &lt;- Index$new('^NSEI')\n\ndata001=nifty_50$get_history(start = '2023-01-01', interval = '1d') %&gt;% mutate(adj_close=adj_close %&gt;% as.numeric())\n\na=head(data001$adj_close,1)[[1]]\n\ndata001b=data001 %&gt;% mutate(adj_close2=adj_close/a)\n\n\n\n\nCode\naapl &lt;- Ticker$new('aapl')\n\ndata002=aapl$get_history(start = '2023-01-01', interval = '1d') %&gt;% mutate(adj_close=adj_close %&gt;% as.numeric())\n\na=head(data002$adj_close,1)[[1]]\n\ndata002b=data002 %&gt;% mutate(adj_close2=adj_close/a)\n\n\n\n\nCode\n# initialize plot\nfig &lt;- plot_ly()\n\n# add data from first dataframe Df1\nfig &lt;- fig %&gt;%\n    add_lines(data=data001b, name=\"NSEI50\", x = ~date, y = ~adj_close2)\n\n# add data from second dataframe Df2\nfig &lt;- fig %&gt;%\n    add_lines(data=data002b, name=\"apple\", x = ~date, y = ~adj_close2)\n# show figure\nfig\n\n\n\n\n\n\n\n\n2 financials income statement\n\n\nCode\nlibrary(chromote)\nlibrary(httr)\n\n\n\n\nCode\nurl='https://finance.yahoo.com/quote/AMAT/financials'\n\n\n\n\nCode\nb &lt;- ChromoteSession$new()\n\n\n\n\nCode\n# In a web browser, open a viewer for the headless browser. Works best with\n# Chromium-based browsers.\n#b$view()\nb$Page$navigate(url)\n\n\n$frameId\n[1] \"CC288F4F40D2609DEC6C62E4211051C9\"\n\n$loaderId\n[1] \"B9F093A6E0C38DDFEE66E928EBCC916E\"\n\n\n\n\nCode\nx &lt;- b$DOM$getDocument()\n\n\n\n\nCode\nb$screenshot(\"sidebar.png\")\n\n\n[1] \"An error occurred: Error in onRejected(...): code: -32000\\n  message: Cannot take screenshot with 0 height.\\n\"\n\n\n\n\nCode\npage=b$Runtime$evaluate(\"document.querySelector('html').outerHTML\")$result$value %&gt;% \n  read_html()\n\n\n\n\nCode\nb$close()\n\n\n[1] TRUE\n\n\n\n\nCode\ncol1=page%&gt;% \n  html_elements(\".row .column:nth-child(1)\") %&gt;% html_text2()  %&gt;% head(33)\n\n\n\n\nCode\ncol2=page%&gt;% \n  html_elements(\".row .column:nth-child(2)\") %&gt;% html_text2()\n\n\n\n\nCode\ncol3=page%&gt;% \n  html_elements(\".row .column:nth-child(3)\") %&gt;% html_text2()\n\n\n\n\nCode\ncol4=page%&gt;% \n  html_elements(\".row .column:nth-child(4)\") %&gt;% html_text2()\n\n\n\n\nCode\ncol5=page%&gt;% \n  html_elements(\".row .column:nth-child(5)\") %&gt;% html_text2()\n\n\n\n\nCode\ncol6=page%&gt;% \n  html_elements(\".row .column:nth-child(6)\") %&gt;% html_text2()\n\n\n\n\nCode\ndata001=data.frame(col1,col2,col3,col4,col5,col6)\n\n\n\n\nCode\nlibrary(janitor )\ncolnames(data001) &lt;- data001[1,]\ndata001 &lt;- data001[-1, ]  %&gt;%clean_names()\n\n\n\n\nCode\nglimpse(data001)\n\n\nRows: 32\nColumns: 6\n$ breakdown   &lt;chr&gt; \"Total Revenue\", \"Cost of Revenue\", \"Gross Profit\", \"Opera…\n$ ttm         &lt;chr&gt; \"26,485,000\", \"14,042,000\", \"12,443,000\", \"4,792,000\", \"7,…\n$ x10_31_2023 &lt;chr&gt; \"26,517,000\", \"14,133,000\", \"12,384,000\", \"4,730,000\", \"7,…\n$ x10_31_2022 &lt;chr&gt; \"25,785,000\", \"13,792,000\", \"11,993,000\", \"4,209,000\", \"7,…\n$ x10_31_2021 &lt;chr&gt; \"23,063,000\", \"12,149,000\", \"10,914,000\", \"3,714,000\", \"7,…\n$ x10_31_2020 &lt;chr&gt; \"17,202,000\", \"9,510,000\", \"7,692,000\", \"3,327,000\", \"4,36…\n\n\n\n\nCode\ndata002=data001 %&gt;% mutate(breakdown=breakdown %&gt;% str_remove_all('HTML_TAG_START HTML_TAG_END')\n                           ,ttm=round(as.numeric(gsub(\",\",\"\",ttm)))\n                           ,year_2023=round(as.numeric(gsub(\",\",\"\",x10_31_2023)))\n                             ,year_2022=round(as.numeric(gsub(\",\",\"\",x10_31_2022)))\n                             ,year_2021=round(as.numeric(gsub(\",\",\"\",x10_31_2021)))\n                             ,year_2020=round(as.numeric(gsub(\",\",\"\",x10_31_2020)))\n                           ) %&gt;% select(-x10_31_2023,-x10_31_2022,-x10_31_2021,-x10_31_2020)\n\n\n\n\nCode\nglimpse(data002)\n\n\nRows: 32\nColumns: 6\n$ breakdown &lt;chr&gt; \"Total Revenue\", \"Cost of Revenue\", \"Gross Profit\", \"Operati…\n$ ttm       &lt;dbl&gt; 26485000, 14042000, 12443000, 4792000, 7651000, 407000, NA, …\n$ year_2023 &lt;dbl&gt; 26517000, 14133000, 12384000, 4730000, 7654000, 62000, NA, 7…\n$ year_2022 &lt;dbl&gt; 25785000, 13792000, 11993000, 4209000, 7784000, -189000, 400…\n$ year_2021 &lt;dbl&gt; 23063000, 12149000, 10914000, 3714000, 7200000, -118000, -31…\n$ year_2020 &lt;dbl&gt; 17202000, 9510000, 7692000, 3327000, 4365000, -199000, NA, 4…\n\n\n\n\nCode\noptions(scipen = 999)\n\nlibrary(knitr)\nkable(data002)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbreakdown\nttm\nyear_2023\nyear_2022\nyear_2021\nyear_2020\n\n\n\n\n2\nTotal Revenue\n26485000\n26517000\n25785000\n23063000\n17202000\n\n\n3\nCost of Revenue\n14042000\n14133000\n13792000\n12149000\n9510000\n\n\n4\nGross Profit\n12443000\n12384000\n11993000\n10914000\n7692000\n\n\n5\nOperating Expense\n4792000\n4730000\n4209000\n3714000\n3327000\n\n\n6\nOperating Income\n7651000\n7654000\n7784000\n7200000\n4365000\n\n\n7\nNet Non Operating Interest Income Expense\n407000\n62000\n-189000\n-118000\n-199000\n\n\n8\nOther Income Expense\nNA\nNA\n4000\n-311000\nNA\n\n\n9\nPretax Income\n8058000\n7716000\n7599000\n6771000\n4166000\n\n\n10\nTax Provision\n900000\n860000\n1074000\n883000\n547000\n\n\n11\nNet Income Common Stockholders\n7158000\n6856000\n6525000\n5888000\n3619000\n\n\n12\nDiluted NI Available to Com Stockholders\n7158000\n6856000\n6525000\n5888000\n3619000\n\n\n13\nBasic EPS\n9\n8\n7\n6\n4\n\n\n14\nDiluted EPS\n8\n8\n7\n6\n4\n\n\n15\nBasic Average Shares\n836500\n840000\n871000\n910000\n916000\n\n\n16\nDiluted Average Shares\n842000\n845000\n877000\n919000\n923000\n\n\n17\nTotal Operating Income as Reported\n7651000\n7654000\n7788000\n6889000\n4365000\n\n\n18\nTotal Expenses\n18834000\n18863000\n18001000\n15863000\n12837000\n\n\n19\nNet Income from Continuing & Discontinued Operation\n7158000\n6856000\n6525000\n5888000\n3619000\n\n\n20\nNormalized Income\n7158000\n6856000\n6521564\n6158570\n3619000\n\n\n21\nInterest Income\n645000\n300000\n39000\n118000\n41000\n\n\n22\nInterest Expense\n238000\n238000\n228000\n236000\n240000\n\n\n23\nNet Interest Income\n407000\n62000\n-189000\n-118000\n-199000\n\n\n24\nEBIT\n8296000\n7954000\n7827000\n7007000\n4406000\n\n\n25\nEBITDA\n8782000\n8469000\n8271000\n7401000\n4782000\n\n\n26\nReconciled Cost of Revenue\n14042000\n14133000\n13792000\n12149000\n9510000\n\n\n27\nReconciled Depreciation\n486000\n515000\n444000\n394000\n376000\n\n\n28\nNet Income from Continuing Operation Net Minority Interest\n7158000\n6856000\n6525000\n5888000\n3619000\n\n\n29\nTotal Unusual Items Excluding Goodwill\nNA\nNA\n4000\n-311000\nNA\n\n\n30\nTotal Unusual Items\nNA\nNA\n4000\n-311000\nNA\n\n\n31\nNormalized EBITDA\n8782000\n8469000\n8267000\n7712000\n4782000\n\n\n32\nTax Rate for Calcs\n0\n0\n0\n0\n0\n\n\n33\nTax Effect of Unusual Items\nNA\nNA\n564\n-40430\nNA\n\n\n\n\n\n\n\n3 resource:\nhttps://github.com/rsquaredacademy/yahoofinancer\nhttps://github.com/sewardlee337/finreportr\nhttps://www.youtube.com/watch?v=uVHGgSXtQmE\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Financial data"
    ]
  },
  {
    "objectID": "Plot/Map/3 leaflet US.html",
    "href": "Plot/Map/3 leaflet US.html",
    "title": "US map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(chromote)\nlibrary(janitor)\nlibrary(tidygeocoder)\nlibrary(leaflet)\nlibrary(sf)\n\n\n\n\nCode\nlibrary(maps)\nmapStates = map(\"state\", fill = TRUE, plot = FALSE)\n\n\n\n\nCode\njson_data=read_sf(\"us-states.json\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\n2 map\n\n\nCode\ndata001=read_csv('./data/us shooting dagta001.csv')\n\n\n\n\nCode\ndata001=sample_n(data001,10) %&gt;% clean_names() %&gt;% mutate(full_adress=paste(address,city_or_county,state))\n\n\n\n\nCode\nglimpse(data001)\n\n\nRows: 10\nColumns: 12\n$ incident_id       &lt;dbl&gt; 2780110, 2793699, 2787520, 2788152, 2785933, 2789593…\n$ incident_date     &lt;chr&gt; \"December 15, 2023\", \"December 20, 2023\", \"December …\n$ state             &lt;chr&gt; \"California\", \"North Carolina\", \"Kentucky\", \"Kansas\"…\n$ city_or_county    &lt;chr&gt; \"Bakersfield\", \"Wadesboro\", \"Louisville\", \"Galena\", …\n$ address           &lt;chr&gt; \"5000 block of Evanston Ct\", \"White Store Rd\", \"2300…\n$ victims_killed    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 0, 0, 0\n$ victims_injured   &lt;dbl&gt; 0, 2, 1, 1, 1, 1, 0, 1, 1, 1\n$ suspects_killed   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_injured  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_arrested &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 0, 0, 0, 0\n$ operations        &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/…\n$ full_adress       &lt;chr&gt; \"5000 block of Evanston Ct Bakersfield California\", …\n\n\n\n\n3 search all address to latitude, longitude\n\n\nCode\n# geocode the addresses\ndata002 &lt;- data001 %&gt;%\n  geocode(full_adress, method = 'arcgis', lat = latitude , long = longitude)\n\nglimpse(data002)\n\n\nRows: 10\nColumns: 14\n$ incident_id       &lt;dbl&gt; 2780110, 2793699, 2787520, 2788152, 2785933, 2789593…\n$ incident_date     &lt;chr&gt; \"December 15, 2023\", \"December 20, 2023\", \"December …\n$ state             &lt;chr&gt; \"California\", \"North Carolina\", \"Kentucky\", \"Kansas\"…\n$ city_or_county    &lt;chr&gt; \"Bakersfield\", \"Wadesboro\", \"Louisville\", \"Galena\", …\n$ address           &lt;chr&gt; \"5000 block of Evanston Ct\", \"White Store Rd\", \"2300…\n$ victims_killed    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 0, 0, 0\n$ victims_injured   &lt;dbl&gt; 0, 2, 1, 1, 1, 1, 0, 1, 1, 1\n$ suspects_killed   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_injured  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_arrested &lt;dbl&gt; 1, 0, 0, 1, 0, 1, 0, 0, 0, 0\n$ operations        &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/…\n$ full_adress       &lt;chr&gt; \"5000 block of Evanston Ct Bakersfield California\", …\n$ latitude          &lt;dbl&gt; 35.31938, 34.92870, 38.21242, 37.07492, 41.47294, 39…\n$ longitude         &lt;dbl&gt; -119.05923, -80.17780, -85.75143, -94.63921, -81.591…\n\n\n\n\nCode\ndata003=data002 %&gt;% filter(is.na(latitude)==FALSE,(is.na(longitude)==FALSE))\n\n\n\n\n4 map\n\n\nCode\nm &lt;- leaflet(data=mapStates) %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers( lng=data003$longitude, lat=data003$latitude, popup=data003$state)%&gt;% \n  addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)\n\nm  \n\n\n\n\n\n\n\n\n5 US gdp by State\n\n\nCode\nglimpse(mapStates)\n\n\nList of 4\n $ x    : num [1:15599] -87.5 -87.5 -87.5 -87.5 -87.6 ...\n $ y    : num [1:15599] 30.4 30.4 30.4 30.3 30.3 ...\n $ range: num [1:4] -124.7 -67 25.1 49.4\n $ names: chr [1:63] \"alabama\" \"arizona\" \"arkansas\" \"california\" ...\n - attr(*, \"class\")= chr \"map\"\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('US state gpd 2022.xlsx') %&gt;% mutate(names=str_replace(names,'\\\\*','') %&gt;% str_trim() )\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"names\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"magma\", NULL)\n\n\nm &lt;- leaflet(map_sf002) %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n   addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_2022_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_2022_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_2022_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$total_2022_usd), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_2022_usd, opacity = 1.0\n    )\n  \n\n\n\nm  \n\n\n\n\n\n\n\n\n6 resouce:\nhttps://www.gunviolencearchive.org/reports/mass-shooting?page=8&year=2023\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "Map",
      "US map"
    ]
  },
  {
    "objectID": "other/5 Publish/1 quarto tips.html",
    "href": "other/5 Publish/1 quarto tips.html",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\n\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/5 Publish/1 quarto tips.html#in-yaml-header",
    "href": "other/5 Publish/1 quarto tips.html#in-yaml-header",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\n\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/5 Publish/1 quarto tips.html#in-code-chunk",
    "href": "other/5 Publish/1 quarto tips.html#in-code-chunk",
    "title": "quarto tips",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/5 Publish/2 quarto blog.html",
    "href": "other/5 Publish/2 quarto blog.html",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---\n\n\n\n\n\n\n\nCode\n---\ndraft: true  \n  \n---\n\n\n\n\n\n\n\nCode\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true\n\n\n\n\n\n\n\nCode\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---\n\n\n\n\n\n\n\nCode\ndraft:true",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "other/5 Publish/2 quarto blog.html#blog-post",
    "href": "other/5 Publish/2 quarto blog.html#blog-post",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "other/5 Publish/2 quarto blog.html#hide-post-from-main-page",
    "href": "other/5 Publish/2 quarto blog.html#hide-post-from-main-page",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ndraft: true  \n  \n---",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "other/5 Publish/2 quarto blog.html#quarto.yml",
    "href": "other/5 Publish/2 quarto blog.html#quarto.yml",
    "title": "quarto blog",
    "section": "",
    "text": "Code\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "other/5 Publish/2 quarto blog.html#index.qmd",
    "href": "other/5 Publish/2 quarto blog.html#index.qmd",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "other/5 Publish/2 quarto blog.html#draft-postnot-include-in-the-main-page",
    "href": "other/5 Publish/2 quarto blog.html#draft-postnot-include-in-the-main-page",
    "title": "quarto blog",
    "section": "",
    "text": "Code\ndraft:true",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "other/5 Publish/3 quarto website.html",
    "href": "other/5 Publish/3 quarto website.html",
    "title": "quarto website",
    "section": "",
    "text": "you need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub\n\n\n\n\n\n\n\n\n\n_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n\n\n\n\n\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "other/5 Publish/3 quarto website.html#publish-quarto-website-into-quarto-hub",
    "href": "other/5 Publish/3 quarto website.html#publish-quarto-website-into-quarto-hub",
    "title": "quarto website",
    "section": "",
    "text": "you need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "other/5 Publish/3 quarto website.html#publish-quarto-website-into-github-page",
    "href": "other/5 Publish/3 quarto website.html#publish-quarto-website-into-github-page",
    "title": "quarto website",
    "section": "",
    "text": "_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n\n\n\n\n\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "other/5 Publish/4 quarto presentation .html",
    "href": "other/5 Publish/4 quarto presentation .html",
    "title": "quarto presentation",
    "section": "",
    "text": "1 revealjs YAML\n\n\nCode\n---\ntitle: \"Habits\"\nauthor: \"John Doe\"\nformat: revealjs\n---\n\n\n\n\n2 pages\n\n\nCode\n# pages\n\n# In the morning\n\n## Getting up\n\n- Turn off alarm\n- Get out of bed\n\n## Breakfast\n\n- Eat eggs\n- Drink coffee\n\n\n\n\n3 YAML format setting\n\n\nCode\nformat:\n  revealjs:\n    controls: true\n    navigation-mode: vertical\n    height: 800\n    width: 1000    \n    fontsize: 20pt\n    page-layout: full\n    logo: images/logo.jpg\n    footer: \"This is footer(https://google.com/)\"\n    slide-number: c\n    show-slide-number: all\n    menu: false\n\n\n\n\n4 Main Title Slide Background YAML setting\n\n\nCode\n---\ntitle: My Slide Show\ntitle-slide-attributes:\n    data-background-image: /path/to/title_image.png\n    data-background-size: contain\n    data-background-opacity: \"0.5\"\n---\n\n\n\n\n5 Chalkboard YAML setting\n\n\nCode\n---\ntitle: \"Presentation\"\nformat:\n  revealjs:\n    chalkboard: true\n---\n\n\n\n\n6 center whole page\n\n\nCode\n# This will be centered {.center}\n\nThis text is moved as well\n\n\n\n\n7 reference:\nhttps://quarto.org/docs/presentations/revealjs/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto presentation"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#replace-string",
    "href": "data manipulation/3 data manipulation with tidyverse.html#replace-string",
    "title": "Data manipulation with tidyverse",
    "section": "3.6 replace string",
    "text": "3.6 replace string\n\n3.6.1 str_replace()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace('b','1')\n\n\n[1] \"a1cb\"\n\n\n\n\n3.6.2 str_replace_all()\n\n\nCode\ntext001=\"abcb\"\ntext001 %&gt;% str_replace_all('b','1')\n\n\n[1] \"a1c1\"\n\n\n\n\n3.6.3 replace with regular expression\n\n\nCode\nword2=c('a-b','M6D5','M6D54','M6D55','M6D5') %&gt;% as_tibble()\nword2\n\n\n# A tibble: 5 × 1\n  value\n  &lt;chr&gt;\n1 a-b  \n2 M6D5 \n3 M6D54\n4 M6D55\n5 M6D5 \n\n\nreplace D+all number with ’_’\n\n\nCode\nword2 %&gt;% mutate(new=value %&gt;% str_replace_all('D\\\\d*','_'))\n\n\n# A tibble: 5 × 2\n  value new  \n  &lt;chr&gt; &lt;chr&gt;\n1 a-b   a-b  \n2 M6D5  M6_  \n3 M6D54 M6_  \n4 M6D55 M6_  \n5 M6D5  M6_",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#split-string",
    "href": "data manipulation/3 data manipulation with tidyverse.html#split-string",
    "title": "Data manipulation with tidyverse",
    "section": "3.7 split string",
    "text": "3.7 split string\n\n\nCode\nword=c('a-b','1-c','c-c')\n\ndf_word=word %&gt;% as.data.frame() %&gt;% rename('word'='.')\n\n\n\n3.7.1 make 2 coloumn and split by - using stringr package\n\n\nCode\ndf_word\n\n\n  word\n1  a-b\n2  1-c\n3  c-c\n\n\n\n\nCode\nlibrary(stringr)\ndf_word$word %&gt;% str_split_fixed('-',2)\n\n\n     [,1] [,2]\n[1,] \"a\"  \"b\" \n[2,] \"1\"  \"c\" \n[3,] \"c\"  \"c\" \n\n\n\n\n3.7.2 make 2 coloumn and split by - using tidyr package\n\n\nCode\ndf_word\n\n\n  word\n1  a-b\n2  1-c\n3  c-c\n\n\n\n\nCode\nlibrary(tidyr)\ndf_word %&gt;% separate(word,c('col1','col2'),'-')\n\n\n  col1 col2\n1    a    b\n2    1    c\n3    c    c",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#subset-element-in-list",
    "href": "data manipulation/3 data manipulation with tidyverse.html#subset-element-in-list",
    "title": "Data manipulation with tidyverse",
    "section": "3.8 subset element in list",
    "text": "3.8 subset element in list\n\n\nCode\nword=c('aabbbasdf','apple','pet','melon')\n\n\n\n3.8.1 word with ‘a’\n\n\nCode\nword %&gt;% str_subset('a')\n\n\n[1] \"aabbbasdf\" \"apple\"    \n\n\n\n\n3.8.2 word with ‘a,e,i,o,u’\n\n\nCode\nword %&gt;% str_subset(\"[aeiou]\")\n\n\n[1] \"aabbbasdf\" \"apple\"     \"pet\"       \"melon\"    \n\n\n\n\n3.8.3 word with ‘pet’ or ‘melon’\n\n\nCode\nword %&gt;% str_subset('pet|melon')\n\n\n[1] \"pet\"   \"melon\"\n\n\n\n\n3.8.4 word with ‘pet’ or ‘melon’\n\n\nCode\nword %&gt;% str_subset('aa')\n\n\n[1] \"aabbbasdf\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#extract-string",
    "href": "data manipulation/3 data manipulation with tidyverse.html#extract-string",
    "title": "Data manipulation with tidyverse",
    "section": "3.9 extract string",
    "text": "3.9 extract string\n\n\nCode\ndata001=mtcars\ndata001 &lt;- cbind(names = rownames(data001), data001)\n\n\n\n3.9.1 by postion\nextract 2 to 4\n\n\nCode\ndata001$new_names=data001$names %&gt;% str_sub(2,4)\nhead(data001 %&gt;% select(new_names,names))\n\n\n                  new_names             names\nMazda RX4               azd         Mazda RX4\nMazda RX4 Wag           azd     Mazda RX4 Wag\nDatsun 710              ats        Datsun 710\nHornet 4 Drive          orn    Hornet 4 Drive\nHornet Sportabout       orn Hornet Sportabout\nValiant                 ali           Valiant\n\n\n\n\n3.9.2 extracting with Regular expressions\nextracting one letter\n\n\nCode\ntrx='abc1993 ccc'\ntrx %&gt;% str_extract(\"\\\\w\")\n\n\n[1] \"a\"\n\n\nextracting one letter/number\n\n\nCode\ntrx='abc1993 ccc'\ntrx %&gt;% str_extract(\".\")\n\n\n[1] \"a\"\n\n\nextracting one .\n\n\nCode\ntrx='abc1993.ccc'\ntrx %&gt;% str_extract(\"\\\\.\")\n\n\n[1] \".\"\n\n\nextracting 3 letter start with ‘a’\n\n\nCode\nword=c('aabbbasdfe. e','appl.e e','pet','melon','asdf g 133asd') %&gt;% as_tibble()\nword\n\n\n# A tibble: 5 × 1\n  value        \n  &lt;chr&gt;        \n1 aabbbasdfe. e\n2 appl.e e     \n3 pet          \n4 melon        \n5 asdf g 133asd\n\n\nextracting 2 letter start with ‘a’\n\n\nCode\nword %&gt;%mutate(new=value %&gt;% str_extract(\"a..\"))\n\n\n# A tibble: 5 × 2\n  value         new  \n  &lt;chr&gt;         &lt;chr&gt;\n1 aabbbasdfe. e aab  \n2 appl.e e      app  \n3 pet           &lt;NA&gt; \n4 melon         &lt;NA&gt; \n5 asdf g 133asd asd  \n\n\nextracting all letter start with ‘a’\n\n\nCode\nword %&gt;%mutate(new=value %&gt;% str_extract(\"a.+\"))\n\n\n# A tibble: 5 × 2\n  value         new          \n  &lt;chr&gt;         &lt;chr&gt;        \n1 aabbbasdfe. e aabbbasdfe. e\n2 appl.e e      appl.e e     \n3 pet           &lt;NA&gt;         \n4 melon         &lt;NA&gt;         \n5 asdf g 133asd asdf g 133asd\n\n\nextracting all letter between ‘a’ and ‘e’\n\n\nCode\nword %&gt;%mutate(new=value %&gt;% str_extract(\"(a).*?(e)\"))\n\n\n# A tibble: 5 × 2\n  value         new       \n  &lt;chr&gt;         &lt;chr&gt;     \n1 aabbbasdfe. e aabbbasdfe\n2 appl.e e      appl.e    \n3 pet           &lt;NA&gt;      \n4 melon         &lt;NA&gt;      \n5 asdf g 133asd &lt;NA&gt;      \n\n\nextracting all letter between ‘a’ and ‘.’\n\n\nCode\nword %&gt;%mutate(new=value %&gt;% str_extract(\"(a).*?(\\\\.)\"))\n\n\n# A tibble: 5 × 2\n  value         new        \n  &lt;chr&gt;         &lt;chr&gt;      \n1 aabbbasdfe. e aabbbasdfe.\n2 appl.e e      appl.      \n3 pet           &lt;NA&gt;       \n4 melon         &lt;NA&gt;       \n5 asdf g 133asd &lt;NA&gt;       \n\n\nextracting all letter between ‘a’ and space\n\n\nCode\nword %&gt;%mutate(new=value %&gt;% str_extract(\"(a).*?( )\"))\n\n\n# A tibble: 5 × 2\n  value         new           \n  &lt;chr&gt;         &lt;chr&gt;         \n1 aabbbasdfe. e \"aabbbasdfe. \"\n2 appl.e e      \"appl.e \"     \n3 pet            &lt;NA&gt;         \n4 melon          &lt;NA&gt;         \n5 asdf g 133asd \"asdf \"       \n\n\nextracting all letter end with number\n\n\nCode\nword %&gt;%mutate(new=value %&gt;% str_extract(\".*?\\\\d\")\n               , new2=new %&gt;% str_sub(end=-3)\n                                         \n)\n\n\n# A tibble: 5 × 3\n  value         new      new2  \n  &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt; \n1 aabbbasdfe. e &lt;NA&gt;     &lt;NA&gt;  \n2 appl.e e      &lt;NA&gt;     &lt;NA&gt;  \n3 pet           &lt;NA&gt;     &lt;NA&gt;  \n4 melon         &lt;NA&gt;     &lt;NA&gt;  \n5 asdf g 133asd asdf g 1 asdf g\n\n\nextracting one number\n\n\nCode\ntrx='abc1993 ccc'\ntrx %&gt;% str_extract(\"\\\\d\")\n\n\n[1] \"1\"\n\n\nextracting more number\n\n\nCode\ntrx='abc1993 ccc'\ntrx %&gt;% str_extract(\"(\\\\d)+\")\n\n\n[1] \"1993\"\n\n\nextracting more non number\n\n\nCode\ntrx='abc1993 ccc'\ntrx %&gt;% str_extract_all(\"\\\\D+\")\n\n\n[[1]]\n[1] \"abc\"  \" ccc\"\n\n\nextracting all letter from the begining\n\n\nCode\ntrx='abc1993 ccc'\ntrx %&gt;% str_extract(\"[:alpha:]+\")\n\n\n[1] \"abc\"\n\n\nextracting number after points:\n\n\nCode\ntrx=c('abcpoints:100 ccc','asdfasd','points:66','thisis points:6')\ntrx\n\n\n[1] \"abcpoints:100 ccc\" \"asdfasd\"           \"points:66\"        \n[4] \"thisis points:6\"  \n\n\nextracting number after points: and remove non match\n\n\nCode\nt=trx %&gt;% str_extract(\"points:[:digit:]+\") %&gt;% na.omit()%&gt;% str_extract(\"points:[:digit:]+\")\nt\n\n\n[1] \"points:100\" \"points:66\"  \"points:6\"",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/3 data manipulation with tidyverse.html#regular-expressions",
    "href": "data manipulation/3 data manipulation with tidyverse.html#regular-expressions",
    "title": "Data manipulation with tidyverse",
    "section": "3.10 Regular expressions",
    "text": "3.10 Regular expressions\n\n\nCode\nphones=c('abba','124','anna')\nphones\n\n\n[1] \"abba\" \"124\"  \"anna\"\n\n\n\n3.10.1 get a+ (b or n) + (b or n) + a\n\n\nCode\nphones %&gt;% str_view('a[bn][bn]a')\n\n\n[1] │ &lt;abba&gt;\n[3] │ &lt;anna&gt;\n\n\n\n\n3.10.2 bb or nn\n\n\nCode\nphones %&gt;% str_view('(bb|nn)')\n\n\n[1] │ a&lt;bb&gt;a\n[3] │ a&lt;nn&gt;a",
    "crumbs": [
      "data manipulation",
      "Data manipulation with tidyverse"
    ]
  },
  {
    "objectID": "data manipulation/2 data structure in R.html#compare-two-vector",
    "href": "data manipulation/2 data structure in R.html#compare-two-vector",
    "title": "Data structure in R",
    "section": "1.11 compare two vector",
    "text": "1.11 compare two vector\n\n\nCode\nxx=c(1,2,3,4)\nxx\n\n\n[1] 1 2 3 4\n\n\n\n\nCode\nyy=c(2,4)\nyy\n\n\n[1] 2 4\n\n\nfind number only in xx not in yy\n\n\nCode\nsetdiff(xx, yy)\n\n\n[1] 1 3",
    "crumbs": [
      "data manipulation",
      "Data structure in R"
    ]
  },
  {
    "objectID": "other/5 Publish/1 quarto tips.html#embed-youtube",
    "href": "other/5 Publish/1 quarto tips.html#embed-youtube",
    "title": "quarto tips",
    "section": "embed youtube",
    "text": "embed youtube\n\n\nCode\n&lt;iframe width=\"640\" height=\"480\" src=\"https://www.youtube.com/embed/nku5zFMZAdU\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen&gt;\n&lt;/iframe&gt;",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "other/5 Publish/1 quarto tips.html#embed-local",
    "href": "other/5 Publish/1 quarto tips.html#embed-local",
    "title": "quarto tips",
    "section": "embed local",
    "text": "embed local\n\n\nCode\n{{&lt; video images/vv.mp4 height=\"600\" &gt;}}",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#line-width-and-colour",
    "href": "Plot/2 plotly.html#line-width-and-colour",
    "title": "Plotly in R",
    "section": "1.4 line width and colour",
    "text": "1.4 line width and colour\n\n\nCode\nfig &lt;- plot_ly(data = data002 %&gt;%filter(continent=='Asia'), x = ~year, y = ~pop,mode = 'lines',line = list(color = 'rgb(205, 12, 24)', width = 8))\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "Plot/2 plotly.html#change-x-y-axis-range",
    "href": "Plot/2 plotly.html#change-x-y-axis-range",
    "title": "Plotly in R",
    "section": "7.4 change x y axis range",
    "text": "7.4 change x y axis range\n\n\nCode\nfig &lt;- plot_ly(data=tips,x = ~total_bill,color=~sex, type = \"histogram\") %&gt;% layout(title = 'new title'\n                                                                                   ,xaxis = list(title = 'new x',range=c(20,40))\n                                                                                  ,yaxis = list(title = 'new y',range=c(20,40)) \n                                                                                    )\n\nfig",
    "crumbs": [
      "Plot",
      "Plotly in R"
    ]
  },
  {
    "objectID": "other/3 Web scraping on whiskyfun.com/6 EDA.html",
    "href": "other/3 Web scraping on whiskyfun.com/6 EDA.html",
    "title": "All page clean up",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(stringr)\nlibrary(openxlsx)\nlibrary(readxl)\nlibrary(lubridate)\nlibrary(ggplot2)\n\n\n\n1 input\n\n\nCode\ndata001=read_excel('./output/all_page_review_clean_v2.xlsx') %&gt;% mutate(\n  title_length=nchar(name)\n  ,high_bottle=if_else(score&gt;=90,1,0)\n  \n  )\n\n\n\n\nCode\nglimpse(data001)\n\n\n\n\nCode\ndata002=data001 %&gt;% select(-old_page,-review_date) %&gt;% unique() %&gt;% filter(score&gt;0\n                                                              ,score&lt;=100\n                                                              ,bottle_review2 %&gt;% str_sub(1,6)!='Colour'\n                                                               ,bottle_review2 %&gt;% str_sub(1,4)!='Nose'\n                                                               ,bottle_review2 %&gt;%str_sub(1,5)!='Mouth'\n                                                              ,title_length&lt;=180\n                                                              ) %&gt;% arrange(desc(title_length))\nglimpse(data002)\n\n\n\n\nCode\nsummary001=data002 %&gt;% group_by(review_year) %&gt;% summarise(score=mean(score)\n                                                           ,bottles=n()\n                                                           ,high_bottle=sum(high_bottle)\n                                                           ) %&gt;% mutate(high_bottle_per=high_bottle/bottles)\n\nsummary001\n\n\n\n\nCode\np=ggplot(summary001, aes(review_year,score)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(summary001, aes(review_year,bottles)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\np=ggplot(summary001, aes(review_year,high_bottle_per)) + geom_point()+ geom_line()\np\n\n\n\n\nCode\nlibrary(plotly)\npp=plot_ly(summary001, x = ~review_year, y = ~bottles, type = \"bar\", name = \"bottles\") %&gt;%\n  add_trace(x = ~review_year, y = ~score, type = 'scatter', mode = \"lines\", yaxis = \"y2\", name = \"score\", line = list(color = 'rgb(205, 12, 24)', width = 8)) %&gt;%\n  \n  layout(\n    title = 'Whiksyfun review bottles and average score'\n    ,legend = list(orientation = 'h')\n     ,xaxis = list(range=c(2003,2025))\n    ,yaxis2 = list(overlaying = \"y\", side = \"right\",range=c(80,90))\n    ,yaxis = list(range=c(0,1500))\n         )\n\npp\n\n\n\n\nCode\norca(pp, \"plot.png\")\n\n\n\n\nCode\nlibrary(plotly)\npp=plot_ly(summary001, x = ~review_year, y = ~bottles, type = \"bar\", name = \"瓶\",text=~bottles) %&gt;%\n  add_trace(x = ~review_year, y = ~score, type = 'scatter', mode = \"lines\", yaxis = \"y2\", name = \"平均分\", line = list(color = 'rgb(205, 12, 24)', width = 8)) %&gt;%\n  \n  layout(\n    title = 'WF每年酒评数量和平均分'\n    ,showlegend = FALSE\n     ,xaxis = list(title='年'\n                   ,dtick = 2\n                   ,tick0 = 2004\n      ,tickmode = \"linear\"\n      )\n    ,margin=list(\n  l = 50,\n  r = 50,\n  b = 100,\n  t = 100,\n  pad = 4\n)\n    ,yaxis2 = list(overlaying = \"y\", side = \"left\",range=c(80,90),title='平均分')\n    ,yaxis = list(side=\"left\",zeroline = FALSE,showline = FALSE,showticklabels = FALSE,showgrid = FALSE,title='')\n    ,annotations = list(x = 1, y = -0.2, \n                              text = \"2004-09 to 2024-05\", \n                              showarrow = F, \n                              xref='paper', \n                              yref='paper'\n      )\n                              \n       ,images = list(  \n      list(  \n        source = base64enc::dataURI(file = \"wf logo.png\")\n        ,xref = \"paper\"\n        ,yref = \"paper\" \n        ,x = 0.01\n        ,y = -0.08\n        ,sizex = 0.4\n        ,sizey = 0.4\n       ,xanchor=\"left\"  \n      )  \n    )   )\n\npp\n\n\n\n\nCode\norca(pp, \"plot2.png\")\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Other",
      "3 Web scraping on whiskyfun.com",
      "All page clean up"
    ]
  },
  {
    "objectID": "other/5 Publish/1 quarto tips.html#embed-local-video",
    "href": "other/5 Publish/1 quarto tips.html#embed-local-video",
    "title": "quarto tips",
    "section": "embed local video",
    "text": "embed local video\n\n\nCode\n{{&lt; video images/vv.mp4 height=\"600\" &gt;}}",
    "crumbs": [
      "Other",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/5 Publish/1 quarto tips.html",
    "href": "Plot/5 Publish/1 quarto tips.html",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\n\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/5 Publish/1 quarto tips.html#in-yaml-header",
    "href": "Plot/5 Publish/1 quarto tips.html#in-yaml-header",
    "title": "quarto tips",
    "section": "",
    "text": "Code\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\n\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/5 Publish/1 quarto tips.html#in-code-chunk",
    "href": "Plot/5 Publish/1 quarto tips.html#in-code-chunk",
    "title": "quarto tips",
    "section": "",
    "text": "Code\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/5 Publish/1 quarto tips.html#embed-youtube",
    "href": "Plot/5 Publish/1 quarto tips.html#embed-youtube",
    "title": "quarto tips",
    "section": "embed youtube",
    "text": "embed youtube\n\n\nCode\n&lt;iframe width=\"640\" height=\"480\" src=\"https://www.youtube.com/embed/nku5zFMZAdU\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen&gt;\n&lt;/iframe&gt;",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/5 Publish/1 quarto tips.html#embed-local-video",
    "href": "Plot/5 Publish/1 quarto tips.html#embed-local-video",
    "title": "quarto tips",
    "section": "embed local video",
    "text": "embed local video\n\n\nCode\n{{&lt; video images/vv.mp4 height=\"600\" &gt;}}",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/5 Publish/4 quarto presentation .html",
    "href": "Plot/5 Publish/4 quarto presentation .html",
    "title": "quarto presentation",
    "section": "",
    "text": "1 revealjs YAML\n\n\nCode\n---\ntitle: \"Habits\"\nauthor: \"John Doe\"\nformat: revealjs\n---\n\n\n\n\n2 pages\n\n\nCode\n# pages\n\n# In the morning\n\n## Getting up\n\n- Turn off alarm\n- Get out of bed\n\n## Breakfast\n\n- Eat eggs\n- Drink coffee\n\n\n\n\n3 YAML format setting\n\n\nCode\nformat:\n  revealjs:\n    controls: true\n    navigation-mode: vertical\n    height: 800\n    width: 1000    \n    fontsize: 20pt\n    page-layout: full\n    logo: images/logo.jpg\n    footer: \"This is footer(https://google.com/)\"\n    slide-number: c\n    show-slide-number: all\n    menu: false\n\n\n\n\n4 Main Title Slide Background YAML setting\n\n\nCode\n---\ntitle: My Slide Show\ntitle-slide-attributes:\n    data-background-image: /path/to/title_image.png\n    data-background-size: contain\n    data-background-opacity: \"0.5\"\n---\n\n\n\n\n5 Chalkboard YAML setting\n\n\nCode\n---\ntitle: \"Presentation\"\nformat:\n  revealjs:\n    chalkboard: true\n---\n\n\n\n\n6 center whole page\n\n\nCode\n# This will be centered {.center}\n\nThis text is moved as well\n\n\n\n\n7 reference:\nhttps://quarto.org/docs/presentations/revealjs/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto presentation"
    ]
  },
  {
    "objectID": "Plot/5 Publish/3 quarto website.html",
    "href": "Plot/5 Publish/3 quarto website.html",
    "title": "quarto website",
    "section": "",
    "text": "you need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub\n\n\n\n\n\n\n\n\n\n_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n\n\n\n\n\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "Plot/5 Publish/3 quarto website.html#publish-quarto-website-into-quarto-hub",
    "href": "Plot/5 Publish/3 quarto website.html#publish-quarto-website-into-quarto-hub",
    "title": "quarto website",
    "section": "",
    "text": "you need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "Plot/5 Publish/3 quarto website.html#publish-quarto-website-into-github-page",
    "href": "Plot/5 Publish/3 quarto website.html#publish-quarto-website-into-github-page",
    "title": "quarto website",
    "section": "",
    "text": "_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n\n\n\n\n\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "Plot/5 Publish/2 quarto blog.html",
    "href": "Plot/5 Publish/2 quarto blog.html",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---\n\n\n\n\n\n\n\nCode\n---\ndraft: true  \n  \n---\n\n\n\n\n\n\n\nCode\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true\n\n\n\n\n\n\n\nCode\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---\n\n\n\n\n\n\n\nCode\ndraft:true",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/5 Publish/2 quarto blog.html#blog-post",
    "href": "Plot/5 Publish/2 quarto blog.html#blog-post",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/5 Publish/2 quarto blog.html#hide-post-from-main-page",
    "href": "Plot/5 Publish/2 quarto blog.html#hide-post-from-main-page",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ndraft: true  \n  \n---",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/5 Publish/2 quarto blog.html#quarto.yml",
    "href": "Plot/5 Publish/2 quarto blog.html#quarto.yml",
    "title": "quarto blog",
    "section": "",
    "text": "Code\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/5 Publish/2 quarto blog.html#index.qmd",
    "href": "Plot/5 Publish/2 quarto blog.html#index.qmd",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/5 Publish/2 quarto blog.html#draft-postnot-include-in-the-main-page",
    "href": "Plot/5 Publish/2 quarto blog.html#draft-postnot-include-in-the-main-page",
    "title": "quarto blog",
    "section": "",
    "text": "Code\ndraft:true",
    "crumbs": [
      "Plot",
      "5 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html",
    "href": "Plot/7 Publish/1 quarto tips.html",
    "title": "quarto tips",
    "section": "",
    "text": "https://quarto.org/docs/get-started/\n\n\n\n\n\nCode\ninstall.packages(\"quarto\")",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#in-yaml-header",
    "href": "Plot/7 Publish/1 quarto tips.html#in-yaml-header",
    "title": "quarto tips",
    "section": "in YAML header",
    "text": "in YAML header\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\n\neval： Evaluate the code chunk (if false, just echos the code into the output).\necho： Include the source code in output.\noutput： Include the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\nwarning： Include warnings in the output.\nerror： Evaluate the code chunk (if false, just echos the code into the output).\ninclude： Catch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#in-code-chunk",
    "href": "Plot/7 Publish/1 quarto tips.html#in-code-chunk",
    "title": "quarto tips",
    "section": "in code chunk",
    "text": "in code chunk\n\n\nCode\n #| eval: false",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#embed-youtube",
    "href": "Plot/7 Publish/1 quarto tips.html#embed-youtube",
    "title": "quarto tips",
    "section": "embed youtube",
    "text": "embed youtube\n\n\nCode\n&lt;iframe width=\"640\" height=\"480\" src=\"https://www.youtube.com/embed/nku5zFMZAdU\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen&gt;\n&lt;/iframe&gt;",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#embed-local-video",
    "href": "Plot/7 Publish/1 quarto tips.html#embed-local-video",
    "title": "quarto tips",
    "section": "embed local video",
    "text": "embed local video\n\n\nCode\n{{&lt; video images/vv.mp4 height=\"600\" &gt;}}",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/2 quarto blog.html",
    "href": "Plot/7 Publish/2 quarto blog.html",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---\n\n\n\n\n\n\n\nCode\n---\ndraft: true  \n  \n---\n\n\n\n\n\n\n\nCode\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true\n\n\n\n\n\n\n\nCode\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---\n\n\n\n\n\n\n\nCode\ndraft:true",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/2 quarto blog.html#blog-post",
    "href": "Plot/7 Publish/2 quarto blog.html#blog-post",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"title\"\n\nauthor: \"name\"\ndate: \"2024-05-03\"\ncategories: [R,quarto]\nexecute:\n  warning: false\n  error: false\n  eval: false\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    code-tools: true\n    number-sections: true\n    code-block-bg: true\n    code-block-border-left: \"#31BAE9\"\n    \n---",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/2 quarto blog.html#hide-post-from-main-page",
    "href": "Plot/7 Publish/2 quarto blog.html#hide-post-from-main-page",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ndraft: true  \n  \n---",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/2 quarto blog.html#quarto.yml",
    "href": "Plot/7 Publish/2 quarto blog.html#quarto.yml",
    "title": "quarto blog",
    "section": "",
    "text": "Code\nproject:\n  type: website\n\nwebsite:\n  title: \"tidystep\"\n  site-url: https://tidystep.netlify.app/\n  description: \"A blog for data stuff\"\n  favicon: \"profile3.png\"\n  google-analytics: \"G-2EQK8RFKFX\"\n  navbar:\n    right:\n      - about.qmd\n      - icon: github\n        href: https://github.com/TonyFly3000\n      - icon: twitter\n        href: https://twitter.com/TonyJCD\n      - icon: rss\n        href: index.xml\n\n  page-footer:\n    right: \"This blog is built with ❤️ and [Quarto](https://quarto.org/).\"\n\nformat:\n  html:\n    theme: \n      light: flatly\n      dark: darkly\n    css: styles.css\n    grid:\n      body-width: 1100px\n      margin-width: 300px\n      gutter-width: 1.5rem\n\neditor: visual\nexecute:\n  freeze: true",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/2 quarto blog.html#index.qmd",
    "href": "Plot/7 Publish/2 quarto blog.html#index.qmd",
    "title": "quarto blog",
    "section": "",
    "text": "Code\n---\ntitle: \"微步数据\"\nlisting:\n  page-size: 8\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: true\n  filter-ui: false\n  fields: [image, date, title, author,categories]\n  feed: true\npage-layout: full\ntitle-block-banner: true\n---",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/2 quarto blog.html#draft-postnot-include-in-the-main-page",
    "href": "Plot/7 Publish/2 quarto blog.html#draft-postnot-include-in-the-main-page",
    "title": "quarto blog",
    "section": "",
    "text": "Code\ndraft:true",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto blog"
    ]
  },
  {
    "objectID": "Plot/7 Publish/3 quarto website.html",
    "href": "Plot/7 Publish/3 quarto website.html",
    "title": "quarto website",
    "section": "",
    "text": "you need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub\n\n\n\n\n\n\n\n\n\n_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n\n\n\n\n\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "Plot/7 Publish/3 quarto website.html#publish-quarto-website-into-quarto-hub",
    "href": "Plot/7 Publish/3 quarto website.html#publish-quarto-website-into-quarto-hub",
    "title": "quarto website",
    "section": "",
    "text": "you need to have quarto pub account https://quartopub.com/\n\n\nCode\nquarto publish quarto-pub",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "Plot/7 Publish/3 quarto website.html#publish-quarto-website-into-github-page",
    "href": "Plot/7 Publish/3 quarto website.html#publish-quarto-website-into-github-page",
    "title": "quarto website",
    "section": "",
    "text": "_quarto.yml\n\n#| eval: false\nproject:\n  type: website\n  output-dir: docs\n\n\n\n\n\n\n\n\n\nThe github site is created: https://your_github_name.github.io/repository_name/\n\n\n\nIn mac using {shift+command+.} to show hidden .gitignore file\nfor example,add *.parquet in .gitignore file to ignore all parquet file\n\n\n.gitignore\n\n#| eval: false\n.Rproj.user\n.Rhistory\n.RData\n.Ruserdata\n\n/.quarto/\n\n*.parquet",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto website"
    ]
  },
  {
    "objectID": "Plot/7 Publish/4 quarto presentation .html",
    "href": "Plot/7 Publish/4 quarto presentation .html",
    "title": "quarto presentation",
    "section": "",
    "text": "1 revealjs YAML\n\n\nCode\n---\ntitle: \"Habits\"\nauthor: \"John Doe\"\nformat: revealjs\n---\n\n\n\n\n2 pages\n\n\nCode\n# pages\n\n# In the morning\n\n## Getting up\n\n- Turn off alarm\n- Get out of bed\n\n## Breakfast\n\n- Eat eggs\n- Drink coffee\n\n\n\n\n3 YAML format setting\n\n\nCode\nformat:\n  revealjs:\n    controls: true\n    navigation-mode: vertical\n    height: 800\n    width: 1000    \n    fontsize: 20pt\n    page-layout: full\n    logo: images/logo.jpg\n    footer: \"This is footer(https://google.com/)\"\n    slide-number: c\n    show-slide-number: all\n    menu: false\n\n\n\n\n4 Main Title Slide Background YAML setting\n\n\nCode\n---\ntitle: My Slide Show\ntitle-slide-attributes:\n    data-background-image: /path/to/title_image.png\n    data-background-size: contain\n    data-background-opacity: \"0.5\"\n---\n\n\n\n\n5 Chalkboard YAML setting\n\n\nCode\n---\ntitle: \"Presentation\"\nformat:\n  revealjs:\n    chalkboard: true\n---\n\n\n\n\n6 center whole page\n\n\nCode\n# This will be centered {.center}\n\nThis text is moved as well\n\n\n\n\n7 reference:\nhttps://quarto.org/docs/presentations/revealjs/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto presentation"
    ]
  },
  {
    "objectID": "Plot/5 Map/2 leaflet.html",
    "href": "Plot/5 Map/2 leaflet.html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\n\nlibrary(sf)\nlibrary(leaflet)\nlibrary(geojsonio)\nlibrary(leaflet.extras)\n\n\n\n\n2 display at openstreet map\n\n\nCode\nm &lt;- leaflet() %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\n\nm  \n\n\n\n\n\n\n\n\n3 display at google map\n\n\nCode\nleaflet() |&gt;\n  # add base mao\n  addTiles(urlTemplate = \"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\") |&gt;\n  # set view\n  setView(116.347817690225, 39.997202126977, zoom = 16) |&gt;\n  # add markers\n  addMarkers(116.347817690225, 39.997202126977)\n\n\n\n\n\n\n\n\n4 Third-Party map\n\n\nCode\n#m &lt;- leaflet() %&gt;% setView(lng = -71.0589, lat = 42.3601, zoom = 10)\n#m %&gt;% addProviderTiles(providers$Stadia.StamenToner)\n\n\n\n\n5 add pop up\nPopups are small boxes containing arbitrary HTML, that point to a specific point on the map.\n\n\nCode\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.samurainoodle.com/'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() %&gt;% addTiles() %&gt;%\n  setView(-122.327298, 47.597131,zoom = 12) %&gt;% \n  addPopups(-122.327298, 47.597131, content,\n    #options = popupOptions(closeButton = FALSE)\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\n\n\n6 add Markers\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"\n))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, popup = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n7 add Labels\nA label is a textual or HTML content that can attached to markers and shapes to be always displayed or displayed on mouse over. Unlike popups you don’t need to click a marker/polygon for the label to be shown.\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, label = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n8 World map\n\n\nCode\n#install.packages(\"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\")\n\n\n\n\nCode\njson_data=read_sf(\"world-administrative-boundaries.geojson\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\n#Get my variable\n#name&lt;-c(\"Ghana\", \"Grenada\", \"Guyana\", \"India\", \"Jamaica\", \"Kenya\", \"United States\",\"Canada\")\n#val&lt;-c(1,2,4,5,5,1000,20000, 100)\n\n#per_gdp_usd&lt;-data.frame(name,val)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('world data.xlsx') %&gt;% mutate(\n  name=case_when(\n    name ==\"United States\" ~ \"United States of America\"\n     ,name ==\"Russia\" ~ \"Russian Federation\"\n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name == \"South Korea\"~ \"Republic of Korea\"\n   \n   ,name ==\"Lao People's Democratic Republic\" ~ \"Laos\"\n   \n    ,TRUE ~ name\n  )\n)\n\n\n\n\nCode\n#test=full_join(map_df, per_gdp_usd, by=\"name\")\n\n#left =test %&gt;% filter(is.na(iso3)==TRUE)\n\n#right=test %&gt;% filter(is.na(per_gdp_total)==TRUE)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"name\")\n\n\n\n\nCode\nglimpse(map_df002)\n\n\nRows: 158\nColumns: 12\n$ name                     &lt;chr&gt; \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"A…\n$ geo_point_2d             &lt;chr&gt; \"{ \\\"lon\\\": 20.068384605918776, \\\"lat\\\": 41.1…\n$ iso3                     &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ status                   &lt;chr&gt; \"Member State\", \"Member State\", \"Member State…\n$ color_code               &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ continent                &lt;chr&gt; \"Europe\", \"Africa\", \"Europe\", \"Africa\", \"Amer…\n$ region                   &lt;chr&gt; \"Southern Europe\", \"Northern Africa\", \"Southe…\n$ iso_3166_1_alpha_2_codes &lt;chr&gt; \"AL\", \"DZ\", \"AD\", \"AO\", \"AR\", \"AM\", \"AU\", \"AT…\n$ french_short             &lt;chr&gt; \"Albanie\", \"Algérie\", \"Andorre\", \"Angola\", \"A…\n$ geometry                 &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((20.07142 42..., …\n$ per_gdp_total            &lt;dbl&gt; 1.888210e+10, 1.919130e+11, 3.352033e+09, 1.0…\n$ per_gdp_usd              &lt;dbl&gt; 6643, 4274, 41993, 2999, 13904, 7014, 64003, …\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gdp_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gdp_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_gdp_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$per_gdp_total/1000000), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gdp_usd, opacity = 1.0\n    )\n\n\n\n\n\n\n\n\n9 China one city map\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/citys/440300.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/440300_full.json\")\n\n\n深圳市：\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n\n\n\n\n10 all China each province GPD map\n\n\nCode\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n中国 2022 各省 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('china gdp2022.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nGPD data source:国家统计局数据库\n\n\n11 China one province map each city GPD\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/province/440000.json\") \n\n\n广东省 2021 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('guangdong city gdp2021.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\ndata source:广东统计年鉴2022\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"城市：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"城市：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb*10000000/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nhttps://zh.wikipedia.org/wiki/%E5%B9%BF%E4%B8%9C%E5%90%84%E5%9C%B0%E7%BA%A7%E5%B8%82%E5%9C%B0%E5%8C%BA%E7%94%9F%E4%BA%A7%E6%80%BB%E5%80%BC%E5%88%97%E8%A1%A8\n\n\n12 China province map\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\n\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/china.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nm=leaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n \n\nm\n\n\n\n\n\n\nadd provincial capital\n\n\nCode\nChina=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n\n\nCode\nChina002=China %&gt;% as_data_frame() %&gt;% mutate(\n                                            center2=as.character(center) %&gt;% str_replace('c','')%&gt;% str_replace('[(]','') %&gt;% str_replace('[)]','')\n                                               )\n\n\n\n\nCode\nChina003=China002%&gt;%separate(center2, c(\"x\", \"y\"), \", \")\n\n\n\n\nCode\nChina_point = China003 %&gt;% \n  slice(-35)\n\nm %&gt;% \n  addCircles(data = China_point,\n                  lng = ~as.numeric(x), lat = ~as.numeric(y),color = \"red\",weight = 10,\n                  fillOpacity =2)\n\n\n\n\n\n\n\n\n13 China province and city map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 34\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 119.3183 ymin: 21.75147 xmax: 124.5656 ymax: 25.92592\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 710000 台湾省 121.509062,25.044332 province (((119.5543 23.68248, 119.555 23.…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/province/710000.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 33\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n14 China city and district map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 334\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.5215 ymin: 22.65421 xmax: 114.2603 ymax: 23.14205\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 441900 东莞市 113.746262,23.046237 city  ((114.2292 22.81251, 114.2278 22.813…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.157 ymin: 22.20104 xmax: 113.692 ymax: 22.7726\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 442000 中山市 113.382391,22.521113 city  ((113.5687 22.41193, 113.5666 22.412…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 115.9267 ymin: 20.58265 xmax: 116.9338 ymax: 21.12693\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center               level                            geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                &lt;chr&gt;                  &lt;MULTIPOLYGON [°]&gt;\n1 442100 东沙群岛 116.887312,20.617512 city  (((115.9433 21.09745, 115.95 21.11…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 108.9287 ymin: 19.17894 xmax: 109.7694 ymax: 19.92575\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 460400 儋州市 109.576782,19.517486 city  (((109.4322 19.91302, 109.4253 19.91…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.8483 ymin: 39.65426 xmax: 98.52018 ymax: 39.99979\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center              level                             geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;               &lt;chr&gt;                   &lt;MULTIPOLYGON [°]&gt;\n1 620200 嘉峪关市 98.277304,39.786529 city  (((97.85974 39.7169, 97.85827 39.71…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/citys/620200.json\"\n         ,\"./GeoMapData_CN/citys/460400.json\"\n              ,\"./GeoMapData_CN/citys/442100.json\"\n              ,\"./GeoMapData_CN/citys/442000.json\"\n              ,\"./GeoMapData_CN/citys/441900.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 329\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n15 show all map providers\n\n\nCode\nproviders\n\n\nproviders\n$OpenStreetMap\n[1] \"OpenStreetMap\"\n\n$OpenStreetMap.Mapnik\n[1] \"OpenStreetMap.Mapnik\"\n\n$OpenStreetMap.DE\n[1] \"OpenStreetMap.DE\"\n\n$OpenStreetMap.CH\n[1] \"OpenStreetMap.CH\"\n\n$OpenStreetMap.France\n[1] \"OpenStreetMap.France\"\n\n$OpenStreetMap.HOT\n[1] \"OpenStreetMap.HOT\"\n\n$OpenStreetMap.BZH\n[1] \"OpenStreetMap.BZH\"\n\n$MapTilesAPI\n[1] \"MapTilesAPI\"\n\n$MapTilesAPI.OSMEnglish\n[1] \"MapTilesAPI.OSMEnglish\"\n\n$MapTilesAPI.OSMFrancais\n[1] \"MapTilesAPI.OSMFrancais\"\n\n$MapTilesAPI.OSMEspagnol\n[1] \"MapTilesAPI.OSMEspagnol\"\n\n$OpenSeaMap\n[1] \"OpenSeaMap\"\n\n$OPNVKarte\n[1] \"OPNVKarte\"\n\n$OpenTopoMap\n[1] \"OpenTopoMap\"\n\n$OpenRailwayMap\n[1] \"OpenRailwayMap\"\n\n$OpenFireMap\n[1] \"OpenFireMap\"\n\n$SafeCast\n[1] \"SafeCast\"\n\n$Stadia\n[1] \"Stadia\"\n\n$Stadia.AlidadeSmooth\n[1] \"Stadia.AlidadeSmooth\"\n\n$Stadia.AlidadeSmoothDark\n[1] \"Stadia.AlidadeSmoothDark\"\n\n$Stadia.OSMBright\n[1] \"Stadia.OSMBright\"\n\n$Stadia.Outdoors\n[1] \"Stadia.Outdoors\"\n\n$Stadia.StamenToner\n[1] \"Stadia.StamenToner\"\n\n$Stadia.StamenTonerBackground\n[1] \"Stadia.StamenTonerBackground\"\n\n$Stadia.StamenTonerLines\n[1] \"Stadia.StamenTonerLines\"\n\n$Stadia.StamenTonerLabels\n[1] \"Stadia.StamenTonerLabels\"\n\n$Stadia.StamenTonerLite\n[1] \"Stadia.StamenTonerLite\"\n\n$Stadia.StamenWatercolor\n[1] \"Stadia.StamenWatercolor\"\n\n$Stadia.StamenTerrain\n[1] \"Stadia.StamenTerrain\"\n\n$Stadia.StamenTerrainBackground\n[1] \"Stadia.StamenTerrainBackground\"\n\n$Stadia.StamenTerrainLabels\n[1] \"Stadia.StamenTerrainLabels\"\n\n$Stadia.StamenTerrainLines\n[1] \"Stadia.StamenTerrainLines\"\n\n$Thunderforest\n[1] \"Thunderforest\"\n\n$Thunderforest.OpenCycleMap\n[1] \"Thunderforest.OpenCycleMap\"\n\n$Thunderforest.Transport\n[1] \"Thunderforest.Transport\"\n\n$Thunderforest.TransportDark\n[1] \"Thunderforest.TransportDark\"\n\n$Thunderforest.SpinalMap\n[1] \"Thunderforest.SpinalMap\"\n\n$Thunderforest.Landscape\n[1] \"Thunderforest.Landscape\"\n\n$Thunderforest.Outdoors\n[1] \"Thunderforest.Outdoors\"\n\n$Thunderforest.Pioneer\n[1] \"Thunderforest.Pioneer\"\n\n$Thunderforest.MobileAtlas\n[1] \"Thunderforest.MobileAtlas\"\n\n$Thunderforest.Neighbourhood\n[1] \"Thunderforest.Neighbourhood\"\n\n$CyclOSM\n[1] \"CyclOSM\"\n\n$Jawg\n[1] \"Jawg\"\n\n$Jawg.Streets\n[1] \"Jawg.Streets\"\n\n$Jawg.Terrain\n[1] \"Jawg.Terrain\"\n\n$Jawg.Sunny\n[1] \"Jawg.Sunny\"\n\n$Jawg.Dark\n[1] \"Jawg.Dark\"\n\n$Jawg.Light\n[1] \"Jawg.Light\"\n\n$Jawg.Matrix\n[1] \"Jawg.Matrix\"\n\n$MapBox\n[1] \"MapBox\"\n\n$MapTiler\n[1] \"MapTiler\"\n\n$MapTiler.Streets\n[1] \"MapTiler.Streets\"\n\n$MapTiler.Basic\n[1] \"MapTiler.Basic\"\n\n$MapTiler.Bright\n[1] \"MapTiler.Bright\"\n\n$MapTiler.Pastel\n[1] \"MapTiler.Pastel\"\n\n$MapTiler.Positron\n[1] \"MapTiler.Positron\"\n\n$MapTiler.Hybrid\n[1] \"MapTiler.Hybrid\"\n\n$MapTiler.Toner\n[1] \"MapTiler.Toner\"\n\n$MapTiler.Topo\n[1] \"MapTiler.Topo\"\n\n$MapTiler.Voyager\n[1] \"MapTiler.Voyager\"\n\n$TomTom\n[1] \"TomTom\"\n\n$TomTom.Basic\n[1] \"TomTom.Basic\"\n\n$TomTom.Hybrid\n[1] \"TomTom.Hybrid\"\n\n$TomTom.Labels\n[1] \"TomTom.Labels\"\n\n$Esri\n[1] \"Esri\"\n\n$Esri.WorldStreetMap\n[1] \"Esri.WorldStreetMap\"\n\n$Esri.DeLorme\n[1] \"Esri.DeLorme\"\n\n$Esri.WorldTopoMap\n[1] \"Esri.WorldTopoMap\"\n\n$Esri.WorldImagery\n[1] \"Esri.WorldImagery\"\n\n$Esri.WorldTerrain\n[1] \"Esri.WorldTerrain\"\n\n$Esri.WorldShadedRelief\n[1] \"Esri.WorldShadedRelief\"\n\n$Esri.WorldPhysical\n[1] \"Esri.WorldPhysical\"\n\n$Esri.OceanBasemap\n[1] \"Esri.OceanBasemap\"\n\n$Esri.NatGeoWorldMap\n[1] \"Esri.NatGeoWorldMap\"\n\n$Esri.WorldGrayCanvas\n[1] \"Esri.WorldGrayCanvas\"\n\n$OpenWeatherMap\n[1] \"OpenWeatherMap\"\n\n$OpenWeatherMap.Clouds\n[1] \"OpenWeatherMap.Clouds\"\n\n$OpenWeatherMap.CloudsClassic\n[1] \"OpenWeatherMap.CloudsClassic\"\n\n$OpenWeatherMap.Precipitation\n[1] \"OpenWeatherMap.Precipitation\"\n\n$OpenWeatherMap.PrecipitationClassic\n[1] \"OpenWeatherMap.PrecipitationClassic\"\n\n$OpenWeatherMap.Rain\n[1] \"OpenWeatherMap.Rain\"\n\n$OpenWeatherMap.RainClassic\n[1] \"OpenWeatherMap.RainClassic\"\n\n$OpenWeatherMap.Pressure\n[1] \"OpenWeatherMap.Pressure\"\n\n$OpenWeatherMap.PressureContour\n[1] \"OpenWeatherMap.PressureContour\"\n\n$OpenWeatherMap.Wind\n[1] \"OpenWeatherMap.Wind\"\n\n$OpenWeatherMap.Temperature\n[1] \"OpenWeatherMap.Temperature\"\n\n$OpenWeatherMap.Snow\n[1] \"OpenWeatherMap.Snow\"\n\n$HERE\n[1] \"HERE\"\n\n$HERE.normalDay\n[1] \"HERE.normalDay\"\n\n$HERE.normalDayCustom\n[1] \"HERE.normalDayCustom\"\n\n$HERE.normalDayGrey\n[1] \"HERE.normalDayGrey\"\n\n$HERE.normalDayMobile\n[1] \"HERE.normalDayMobile\"\n\n$HERE.normalDayGreyMobile\n[1] \"HERE.normalDayGreyMobile\"\n\n$HERE.normalDayTransit\n[1] \"HERE.normalDayTransit\"\n\n$HERE.normalDayTransitMobile\n[1] \"HERE.normalDayTransitMobile\"\n\n$HERE.normalDayTraffic\n[1] \"HERE.normalDayTraffic\"\n\n$HERE.normalNight\n[1] \"HERE.normalNight\"\n\n$HERE.normalNightMobile\n[1] \"HERE.normalNightMobile\"\n\n$HERE.normalNightGrey\n[1] \"HERE.normalNightGrey\"\n\n$HERE.normalNightGreyMobile\n[1] \"HERE.normalNightGreyMobile\"\n\n$HERE.normalNightTransit\n[1] \"HERE.normalNightTransit\"\n\n$HERE.normalNightTransitMobile\n[1] \"HERE.normalNightTransitMobile\"\n\n$HERE.reducedDay\n[1] \"HERE.reducedDay\"\n\n$HERE.reducedNight\n[1] \"HERE.reducedNight\"\n\n$HERE.basicMap\n[1] \"HERE.basicMap\"\n\n$HERE.mapLabels\n[1] \"HERE.mapLabels\"\n\n$HERE.trafficFlow\n[1] \"HERE.trafficFlow\"\n\n$HERE.carnavDayGrey\n[1] \"HERE.carnavDayGrey\"\n\n$HERE.hybridDay\n[1] \"HERE.hybridDay\"\n\n$HERE.hybridDayMobile\n[1] \"HERE.hybridDayMobile\"\n\n$HERE.hybridDayTransit\n[1] \"HERE.hybridDayTransit\"\n\n$HERE.hybridDayGrey\n[1] \"HERE.hybridDayGrey\"\n\n$HERE.hybridDayTraffic\n[1] \"HERE.hybridDayTraffic\"\n\n$HERE.pedestrianDay\n[1] \"HERE.pedestrianDay\"\n\n$HERE.pedestrianNight\n[1] \"HERE.pedestrianNight\"\n\n$HERE.satelliteDay\n[1] \"HERE.satelliteDay\"\n\n$HERE.terrainDay\n[1] \"HERE.terrainDay\"\n\n$HERE.terrainDayMobile\n[1] \"HERE.terrainDayMobile\"\n\n$HEREv3\n[1] \"HEREv3\"\n\n$HEREv3.normalDay\n[1] \"HEREv3.normalDay\"\n\n$HEREv3.normalDayCustom\n[1] \"HEREv3.normalDayCustom\"\n\n$HEREv3.normalDayGrey\n[1] \"HEREv3.normalDayGrey\"\n\n$HEREv3.normalDayMobile\n[1] \"HEREv3.normalDayMobile\"\n\n$HEREv3.normalDayGreyMobile\n[1] \"HEREv3.normalDayGreyMobile\"\n\n$HEREv3.normalDayTransit\n[1] \"HEREv3.normalDayTransit\"\n\n$HEREv3.normalDayTransitMobile\n[1] \"HEREv3.normalDayTransitMobile\"\n\n$HEREv3.normalNight\n[1] \"HEREv3.normalNight\"\n\n$HEREv3.normalNightMobile\n[1] \"HEREv3.normalNightMobile\"\n\n$HEREv3.normalNightGrey\n[1] \"HEREv3.normalNightGrey\"\n\n$HEREv3.normalNightGreyMobile\n[1] \"HEREv3.normalNightGreyMobile\"\n\n$HEREv3.normalNightTransit\n[1] \"HEREv3.normalNightTransit\"\n\n$HEREv3.normalNightTransitMobile\n[1] \"HEREv3.normalNightTransitMobile\"\n\n$HEREv3.reducedDay\n[1] \"HEREv3.reducedDay\"\n\n$HEREv3.reducedNight\n[1] \"HEREv3.reducedNight\"\n\n$HEREv3.basicMap\n[1] \"HEREv3.basicMap\"\n\n$HEREv3.mapLabels\n[1] \"HEREv3.mapLabels\"\n\n$HEREv3.trafficFlow\n[1] \"HEREv3.trafficFlow\"\n\n$HEREv3.carnavDayGrey\n[1] \"HEREv3.carnavDayGrey\"\n\n$HEREv3.hybridDay\n[1] \"HEREv3.hybridDay\"\n\n$HEREv3.hybridDayMobile\n[1] \"HEREv3.hybridDayMobile\"\n\n$HEREv3.hybridDayTransit\n[1] \"HEREv3.hybridDayTransit\"\n\n$HEREv3.hybridDayGrey\n[1] \"HEREv3.hybridDayGrey\"\n\n$HEREv3.pedestrianDay\n[1] \"HEREv3.pedestrianDay\"\n\n$HEREv3.pedestrianNight\n[1] \"HEREv3.pedestrianNight\"\n\n$HEREv3.satelliteDay\n[1] \"HEREv3.satelliteDay\"\n\n$HEREv3.terrainDay\n[1] \"HEREv3.terrainDay\"\n\n$HEREv3.terrainDayMobile\n[1] \"HEREv3.terrainDayMobile\"\n\n$FreeMapSK\n[1] \"FreeMapSK\"\n\n$MtbMap\n[1] \"MtbMap\"\n\n$CartoDB\n[1] \"CartoDB\"\n\n$CartoDB.Positron\n[1] \"CartoDB.Positron\"\n\n$CartoDB.PositronNoLabels\n[1] \"CartoDB.PositronNoLabels\"\n\n$CartoDB.PositronOnlyLabels\n[1] \"CartoDB.PositronOnlyLabels\"\n\n$CartoDB.DarkMatter\n[1] \"CartoDB.DarkMatter\"\n\n$CartoDB.DarkMatterNoLabels\n[1] \"CartoDB.DarkMatterNoLabels\"\n\n$CartoDB.DarkMatterOnlyLabels\n[1] \"CartoDB.DarkMatterOnlyLabels\"\n\n$CartoDB.Voyager\n[1] \"CartoDB.Voyager\"\n\n$CartoDB.VoyagerNoLabels\n[1] \"CartoDB.VoyagerNoLabels\"\n\n$CartoDB.VoyagerOnlyLabels\n[1] \"CartoDB.VoyagerOnlyLabels\"\n\n$CartoDB.VoyagerLabelsUnder\n[1] \"CartoDB.VoyagerLabelsUnder\"\n\n$HikeBike\n[1] \"HikeBike\"\n\n$HikeBike.HikeBike\n[1] \"HikeBike.HikeBike\"\n\n$HikeBike.HillShading\n[1] \"HikeBike.HillShading\"\n\n$BasemapAT\n[1] \"BasemapAT\"\n\n$BasemapAT.basemap\n[1] \"BasemapAT.basemap\"\n\n$BasemapAT.grau\n[1] \"BasemapAT.grau\"\n\n$BasemapAT.overlay\n[1] \"BasemapAT.overlay\"\n\n$BasemapAT.terrain\n[1] \"BasemapAT.terrain\"\n\n$BasemapAT.surface\n[1] \"BasemapAT.surface\"\n\n$BasemapAT.highdpi\n[1] \"BasemapAT.highdpi\"\n\n$BasemapAT.orthofoto\n[1] \"BasemapAT.orthofoto\"\n\n$nlmaps\n[1] \"nlmaps\"\n\n$nlmaps.standaard\n[1] \"nlmaps.standaard\"\n\n$nlmaps.pastel\n[1] \"nlmaps.pastel\"\n\n$nlmaps.grijs\n[1] \"nlmaps.grijs\"\n\n$nlmaps.water\n[1] \"nlmaps.water\"\n\n$nlmaps.luchtfoto\n[1] \"nlmaps.luchtfoto\"\n\n$NASAGIBS\n[1] \"NASAGIBS\"\n\n$NASAGIBS.ModisTerraTrueColorCR\n[1] \"NASAGIBS.ModisTerraTrueColorCR\"\n\n$NASAGIBS.ModisTerraBands367CR\n[1] \"NASAGIBS.ModisTerraBands367CR\"\n\n$NASAGIBS.ViirsEarthAtNight2012\n[1] \"NASAGIBS.ViirsEarthAtNight2012\"\n\n$NASAGIBS.ModisTerraLSTDay\n[1] \"NASAGIBS.ModisTerraLSTDay\"\n\n$NASAGIBS.ModisTerraSnowCover\n[1] \"NASAGIBS.ModisTerraSnowCover\"\n\n$NASAGIBS.ModisTerraAOD\n[1] \"NASAGIBS.ModisTerraAOD\"\n\n$NASAGIBS.ModisTerraChlorophyll\n[1] \"NASAGIBS.ModisTerraChlorophyll\"\n\n$NLS\n[1] \"NLS\"\n\n$JusticeMap\n[1] \"JusticeMap\"\n\n$JusticeMap.income\n[1] \"JusticeMap.income\"\n\n$JusticeMap.americanIndian\n[1] \"JusticeMap.americanIndian\"\n\n$JusticeMap.asian\n[1] \"JusticeMap.asian\"\n\n$JusticeMap.black\n[1] \"JusticeMap.black\"\n\n$JusticeMap.hispanic\n[1] \"JusticeMap.hispanic\"\n\n$JusticeMap.multi\n[1] \"JusticeMap.multi\"\n\n$JusticeMap.nonWhite\n[1] \"JusticeMap.nonWhite\"\n\n$JusticeMap.white\n[1] \"JusticeMap.white\"\n\n$JusticeMap.plurality\n[1] \"JusticeMap.plurality\"\n\n$GeoportailFrance\n[1] \"GeoportailFrance\"\n\n$GeoportailFrance.plan\n[1] \"GeoportailFrance.plan\"\n\n$GeoportailFrance.parcels\n[1] \"GeoportailFrance.parcels\"\n\n$GeoportailFrance.orthos\n[1] \"GeoportailFrance.orthos\"\n\n$OneMapSG\n[1] \"OneMapSG\"\n\n$OneMapSG.Default\n[1] \"OneMapSG.Default\"\n\n$OneMapSG.Night\n[1] \"OneMapSG.Night\"\n\n$OneMapSG.Original\n[1] \"OneMapSG.Original\"\n\n$OneMapSG.Grey\n[1] \"OneMapSG.Grey\"\n\n$OneMapSG.LandLot\n[1] \"OneMapSG.LandLot\"\n\n$USGS\n[1] \"USGS\"\n\n$USGS.USTopo\n[1] \"USGS.USTopo\"\n\n$USGS.USImagery\n[1] \"USGS.USImagery\"\n\n$USGS.USImageryTopo\n[1] \"USGS.USImageryTopo\"\n\n$WaymarkedTrails\n[1] \"WaymarkedTrails\"\n\n$WaymarkedTrails.hiking\n[1] \"WaymarkedTrails.hiking\"\n\n$WaymarkedTrails.cycling\n[1] \"WaymarkedTrails.cycling\"\n\n$WaymarkedTrails.mtb\n[1] \"WaymarkedTrails.mtb\"\n\n$WaymarkedTrails.slopes\n[1] \"WaymarkedTrails.slopes\"\n\n$WaymarkedTrails.riding\n[1] \"WaymarkedTrails.riding\"\n\n$WaymarkedTrails.skating\n[1] \"WaymarkedTrails.skating\"\n\n$OpenAIP\n[1] \"OpenAIP\"\n\n$OpenSnowMap\n[1] \"OpenSnowMap\"\n\n$OpenSnowMap.pistes\n[1] \"OpenSnowMap.pistes\"\n\n$AzureMaps\n[1] \"AzureMaps\"\n\n$AzureMaps.MicrosoftImagery\n[1] \"AzureMaps.MicrosoftImagery\"\n\n$AzureMaps.MicrosoftBaseDarkGrey\n[1] \"AzureMaps.MicrosoftBaseDarkGrey\"\n\n$AzureMaps.MicrosoftBaseRoad\n[1] \"AzureMaps.MicrosoftBaseRoad\"\n\n$AzureMaps.MicrosoftBaseHybridRoad\n[1] \"AzureMaps.MicrosoftBaseHybridRoad\"\n\n$AzureMaps.MicrosoftTerraMain\n[1] \"AzureMaps.MicrosoftTerraMain\"\n\n$AzureMaps.MicrosoftWeatherInfraredMain\n[1] \"AzureMaps.MicrosoftWeatherInfraredMain\"\n\n$AzureMaps.MicrosoftWeatherRadarMain\n[1] \"AzureMaps.MicrosoftWeatherRadarMain\"\n\n$SwissFederalGeoportal\n[1] \"SwissFederalGeoportal\"\n\n$SwissFederalGeoportal.NationalMapColor\n[1] \"SwissFederalGeoportal.NationalMapColor\"\n\n$SwissFederalGeoportal.NationalMapGrey\n[1] \"SwissFederalGeoportal.NationalMapGrey\"\n\n$SwissFederalGeoportal.SWISSIMAGE\n[1] \"SwissFederalGeoportal.SWISSIMAGE\"\n\n\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] readxl_1.4.3         openxlsx_4.2.5.2     htmltools_0.5.8.1   \n [4] leaflet.extras_1.0.0 geojsonio_0.11.3     leaflet_2.2.2       \n [7] sf_1.0-16            lubridate_1.9.3      forcats_1.0.0       \n[10] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n[13] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n[16] ggplot2_3.5.1        tidyverse_2.0.0     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5            xfun_0.43               htmlwidgets_1.6.4      \n [4] lattice_0.22-6          tzdb_0.4.0              leaflet.providers_2.0.0\n [7] vctrs_0.6.5             tools_4.3.1             crosstalk_1.2.1        \n[10] generics_0.1.3          curl_5.2.1              proxy_0.4-27           \n[13] fansi_1.0.6             pkgconfig_2.0.3         KernSmooth_2.23-22     \n[16] RColorBrewer_1.1-3      lifecycle_1.0.4         farver_2.1.1           \n[19] compiler_4.3.1          munsell_0.5.1           jqr_1.3.3              \n[22] class_7.3-22            yaml_2.3.8              lazyeval_0.2.2         \n[25] jquerylib_0.1.4         pillar_1.9.0            classInt_0.4-10        \n[28] zip_2.3.1               tidyselect_1.2.1        digest_0.6.35          \n[31] stringi_1.8.4           fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.2               magrittr_2.0.3         \n[37] crul_1.4.2              utf8_1.2.4              e1071_1.7-14           \n[40] withr_3.0.0             scales_1.3.0            sp_2.1-4               \n[43] timechange_0.3.0        rmarkdown_2.26          cellranger_1.1.0       \n[46] hms_1.1.3               evaluate_0.23           knitr_1.45             \n[49] V8_4.4.2                viridisLite_0.4.2       geojson_0.3.5          \n[52] rlang_1.1.3             Rcpp_1.0.12             glue_1.7.0             \n[55] DBI_1.2.2               httpcode_0.3.0          geojsonsf_2.0.3        \n[58] rstudioapi_0.16.0       jsonlite_1.8.8          R6_2.5.1               \n[61] units_0.8-5            \n\n\n\n\n\n16 resouce:\nhttps://rstudio.github.io/leaflet/\nhttps://github.com/Lchiffon/leafletCN\nhttps://github.com/longwosion/geojson-map-china\nhttps://xiangyun.rbind.io/2022/02/draw-china-maps/\nhttps://datav.aliyun.com/portal/school/atlas/area_selector\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "5 Map",
      "map"
    ]
  },
  {
    "objectID": "Plot/5 Map/3 leaflet US.html",
    "href": "Plot/5 Map/3 leaflet US.html",
    "title": "US map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(chromote)\nlibrary(janitor)\nlibrary(tidygeocoder)\nlibrary(leaflet)\nlibrary(sf)\n\n\n\n\nCode\nlibrary(maps)\nmapStates = map(\"state\", fill = TRUE, plot = FALSE)\n\n\n\n\nCode\njson_data=read_sf(\"us-states.json\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\n2 map\n\n\nCode\ndata001=read_csv('./data/us shooting dagta001.csv')\n\n\n\n\nCode\ndata001=sample_n(data001,10) %&gt;% clean_names() %&gt;% mutate(full_adress=paste(address,city_or_county,state))\n\n\n\n\nCode\nglimpse(data001)\n\n\nRows: 10\nColumns: 12\n$ incident_id       &lt;dbl&gt; 2787329, 2788929, 2782375, 2786672, 2790629, 2780411…\n$ incident_date     &lt;chr&gt; \"December 24, 2023\", \"December 27, 2023\", \"December …\n$ state             &lt;chr&gt; \"Georgia\", \"Florida\", \"Florida\", \"Nevada\", \"Californ…\n$ city_or_county    &lt;chr&gt; \"Augusta\", \"Tallahassee\", \"Pompano Beach\", \"North La…\n$ address           &lt;chr&gt; \"4200 block of James Dr\", \"2000 block of Old Saint A…\n$ victims_killed    &lt;dbl&gt; 1, 0, 1, 1, 0, 1, 1, 0, 0, 0\n$ victims_injured   &lt;dbl&gt; 0, 1, 0, 0, 1, 2, 0, 1, 1, 1\n$ suspects_killed   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_injured  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_arrested &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ operations        &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/…\n$ full_adress       &lt;chr&gt; \"4200 block of James Dr Augusta Georgia\", \"2000 bloc…\n\n\n\n\n3 search all address to latitude, longitude\n\n\nCode\n# geocode the addresses\ndata002 &lt;- data001 %&gt;%\n  geocode(full_adress, method = 'arcgis', lat = latitude , long = longitude)\n\nglimpse(data002)\n\n\nRows: 10\nColumns: 14\n$ incident_id       &lt;dbl&gt; 2787329, 2788929, 2782375, 2786672, 2790629, 2780411…\n$ incident_date     &lt;chr&gt; \"December 24, 2023\", \"December 27, 2023\", \"December …\n$ state             &lt;chr&gt; \"Georgia\", \"Florida\", \"Florida\", \"Nevada\", \"Californ…\n$ city_or_county    &lt;chr&gt; \"Augusta\", \"Tallahassee\", \"Pompano Beach\", \"North La…\n$ address           &lt;chr&gt; \"4200 block of James Dr\", \"2000 block of Old Saint A…\n$ victims_killed    &lt;dbl&gt; 1, 0, 1, 1, 0, 1, 1, 0, 0, 0\n$ victims_injured   &lt;dbl&gt; 0, 1, 0, 0, 1, 2, 0, 1, 1, 1\n$ suspects_killed   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_injured  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ suspects_arrested &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0\n$ operations        &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/…\n$ full_adress       &lt;chr&gt; \"4200 block of James Dr Augusta Georgia\", \"2000 bloc…\n$ latitude          &lt;dbl&gt; 33.36299, 30.42625, 26.23754, 36.21801, 34.45968, 32…\n$ longitude         &lt;dbl&gt; -82.07112, -84.24690, -80.12642, -115.18388, -117.27…\n\n\n\n\nCode\ndata003=data002 %&gt;% filter(is.na(latitude)==FALSE,(is.na(longitude)==FALSE))\n\n\n\n\n4 map\n\n\nCode\nm &lt;- leaflet(data=mapStates) %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers( lng=data003$longitude, lat=data003$latitude, popup=data003$state)%&gt;% \n  addPolygons(fillColor = topo.colors(10, alpha = NULL), stroke = FALSE)\n\nm  \n\n\n\n\n\n\n\n\n5 US gdp by State\n\n\nCode\nglimpse(mapStates)\n\n\nList of 4\n $ x    : num [1:15599] -87.5 -87.5 -87.5 -87.5 -87.6 ...\n $ y    : num [1:15599] 30.4 30.4 30.4 30.3 30.3 ...\n $ range: num [1:4] -124.7 -67 25.1 49.4\n $ names: chr [1:63] \"alabama\" \"arizona\" \"arkansas\" \"california\" ...\n - attr(*, \"class\")= chr \"map\"\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('US state gpd 2022.xlsx') %&gt;% mutate(names=str_replace(names,'\\\\*','') %&gt;% str_trim() )\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"names\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"magma\", NULL)\n\n\nm &lt;- leaflet(map_sf002) %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n   addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_2022_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_2022_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_2022_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$total_2022_usd), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_2022_usd, opacity = 1.0\n    )\n  \n\n\n\nm  \n\n\n\n\n\n\n\n\n6 resouce:\nhttps://www.gunviolencearchive.org/reports/mass-shooting?page=8&year=2023\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "5 Map",
      "US map"
    ]
  },
  {
    "objectID": "intro/2 probability.html#draw-10-number-from-1-to-10",
    "href": "intro/2 probability.html#draw-10-number-from-1-to-10",
    "title": "Probability",
    "section": "1.1 draw 10 number from 1 to 10",
    "text": "1.1 draw 10 number from 1 to 10\n\n\nCode\na=sample(1:10,10, replace=T) \na\n\n\n [1]  9  4  1 10  1 10  5  9  3  5\n\n\neach number around 10%\n\n\nCode\nas.data.frame(table(a))\n\n\n   a Freq\n1  1    2\n2  3    1\n3  4    1\n4  5    2\n5  9    2\n6 10    2",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#draw-10000-number-from-1-to-10",
    "href": "intro/2 probability.html#draw-10000-number-from-1-to-10",
    "title": "Probability",
    "section": "1.2 draw 10,000 number from 1 to 10",
    "text": "1.2 draw 10,000 number from 1 to 10\n\n\nCode\na=sample(1:10,10000, replace=T) \n\n\neach number around 10%\n\n\nCode\nas.data.frame(table(a))\n\n\n    a Freq\n1   1  988\n2   2  991\n3   3 1009\n4   4  989\n5   5  982\n6   6 1035\n7   7 1050\n8   8 1016\n9   9  969\n10 10  971",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#permutationsorder-dose-not-matter-2-number-from-4-number",
    "href": "intro/2 probability.html#permutationsorder-dose-not-matter-2-number-from-4-number",
    "title": "Probability",
    "section": "2.1 Permutations(order dose not matter), 2 number from 4 number",
    "text": "2.1 Permutations(order dose not matter), 2 number from 4 number\n\n\nCode\nlibrary(gtools)\nall_num=4\nchoose=2\n\nres&lt;- permutations(n= all_num, r = choose, v = c(1:all_num))\nres\n\n\n      [,1] [,2]\n [1,]    1    2\n [2,]    1    3\n [3,]    1    4\n [4,]    2    1\n [5,]    2    3\n [6,]    2    4\n [7,]    3    1\n [8,]    3    2\n [9,]    3    4\n[10,]    4    1\n[11,]    4    2\n[12,]    4    3\n\n\n\n\nCode\nprint (nrow(res))\n\n\n[1] 12\n\n\nall_num!/choose!\n4!/2!\n\n\nCode\n(4*3*2*1)/(2*1)\n\n\n[1] 12\n\n\nor\n\n\nCode\nfactorial(4) / factorial(4-2)\n\n\n[1] 12",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#combinationsorder-matter-2-number-from-4-number",
    "href": "intro/2 probability.html#combinationsorder-matter-2-number-from-4-number",
    "title": "Probability",
    "section": "2.2 Combinations(order matter), 2 number from 4 number",
    "text": "2.2 Combinations(order matter), 2 number from 4 number\n\n\nCode\nlibrary(gtools)\nall_num=4\nchoose=2\n\nres&lt;- combinations(n= all_num, r = choose, v = c(1:all_num))\nres\n\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    1    3\n[3,]    1    4\n[4,]    2    3\n[5,]    2    4\n[6,]    3    4\n\n\n\n\nCode\nprint (nrow(res))\n\n\n[1] 6\n\n\nall_num!/((all_num-choose)! * choose!\n4!/((4-2)! * 2!)\n\n\nCode\n(4*3*2*1)/((2*1)*(2*1))\n\n\n[1] 6\n\n\nor\n\n\nCode\nfactorial(4) / (factorial(4-2)*factorial(2))\n\n\n[1] 6",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#soluition-1pat-least-onep1-snoringp2-snoringp3-snoringp4-snoring",
    "href": "intro/2 probability.html#soluition-1pat-least-onep1-snoringp2-snoringp3-snoringp4-snoring",
    "title": "Probability",
    "section": "3.1 soluition 1:P(at least one)=P(1 snoring)+P(2 snoring)+P(3 snoring)+P(4 snoring)",
    "text": "3.1 soluition 1:P(at least one)=P(1 snoring)+P(2 snoring)+P(3 snoring)+P(4 snoring)\n\n3.1.1 0 snoring\n\n\nCode\np0=(0.8*0.8*0.8*0.8)\np0\n\n\n[1] 0.4096\n\n\n\n\n3.1.2 1 snoring\n\n\nCode\np1=(0.2*0.8*0.8*0.8)*4\np1\n\n\n[1] 0.4096\n\n\n\n\n3.1.3 2 snoring\nchoose 2 from 4: factorial(4) / (factorial(4-2)*factorial(2))\ntotal 6 Permutations\n\n\nCode\nfactorial(4) / (factorial(4-2)*factorial(2))\n\n\n[1] 6\n\n\n\n\nCode\np2=(0.2*0.2*0.8*0.8)*6\np2\n\n\n[1] 0.1536\n\n\n\n\n3.1.4 3 snoring\nchoose 3 from 4 Combinations(order matter),factorial(4) / (factorial(4-3)*factorial(3))\n4 Combinations:\n\n\nCode\nfactorial(4) / (factorial(4-3)*factorial(3))\n\n\n[1] 4\n\n\n\n\nCode\np3=(0.2*0.2*0.2*0.8)*4\np3\n\n\n[1] 0.0256\n\n\n\n\n3.1.5 4 snoring\n\n\nCode\np4=(0.2*0.2*0.2*0.2)\np4\n\n\n[1] 0.0016\n\n\n\n\n3.1.6 at least one:\n\n\nCode\nP_at_least_one=p1+p2+p3+p4\nP_at_least_one\n\n\n[1] 0.5904",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#soluition-2pat-least-one1-pno-one-snoring",
    "href": "intro/2 probability.html#soluition-2pat-least-one1-pno-one-snoring",
    "title": "Probability",
    "section": "3.2 soluition 2:P(at least one)=1-P(no one snoring)",
    "text": "3.2 soluition 2:P(at least one)=1-P(no one snoring)\n\n\nCode\nP_at_least_one2=1-0.8*0.8*0.8*0.8\nP_at_least_one2\n\n\n[1] 0.5904",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#section",
    "href": "intro/2 probability.html#section",
    "title": "Probability",
    "section": "4.1 ",
    "text": "4.1 \n\n\nCode\nx &lt;- seq(-3, 3, length = 100)\ntrue_density &lt;- dnorm(x, mean = 0, sd = 1)\nplot(x, true_density, ylab = \"f(x)\", main = \"Standard Normal Density\", type = \"l\")",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#binomial-distribution",
    "href": "intro/2 probability.html#binomial-distribution",
    "title": "Probability",
    "section": "5.1 Binomial distribution",
    "text": "5.1 Binomial distribution\nthe binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question, and each with its own Boolean-valued outcome: success (with probability p) or failure (with probability 1-p)\nfor a single trial, i.e., n = 1, the binomial distribution is a Bernoulli distribution\n\n5.1.1 Probability density function (pdf)\n1 people snoring Probability\n\n\nCode\nn = 4 # number of people in a room\np = 0.2 # snoring\n\ndbinom(x=1, size=n, prob=p) # 1 people snoring Probability\n\n\n[1] 0.4096\n\n\n1,2,3,4 people snoring Probability\n\n\nCode\nn = 4 # number of people in a room\np = 0.2 # snoring\n\ndbinom(x=c(0,1,2,3,4), size=n, prob=p) # 1 people snoring Probability\n\n\n[1] 0.4096 0.4096 0.1536 0.0256 0.0016\n\n\nsum of all event Probability is always 1\n\n\nCode\nsum(dbinom(x=c(0,1,2,3,4), size=n, prob=p))\n\n\n[1] 1\n\n\n\n\n5.1.2 Probability function\n&lt;=1 people snoring\n\n\nCode\npbinom(q=1, size=n,prob=p, lower.tail=TRUE) \n\n\n[1] 0.8192\n\n\n\n\n5.1.3 generate 10000 number from 0 to 4 with Probability=0.2\n\n\nCode\na=rbinom(1000,size=4,0.2) \n\ntable(a)\n\n\na\n  0   1   2   3   4 \n407 394 167  30   2",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#normal-distribtionalso-called-gaussian-distribution",
    "href": "intro/2 probability.html#normal-distribtionalso-called-gaussian-distribution",
    "title": "Probability",
    "section": "5.2 Normal Distribtion(also called Gaussian distribution)",
    "text": "5.2 Normal Distribtion(also called Gaussian distribution)\nX is a random variable following a normal distribution with mean μ and variance σ2\n68% within 1 standard deviation\n95% within 2 standard deviation\n99.7% within 3 standard deviation\n\n\n5.2.1 Probability Density Function (pdf)\n\ncomputes the pdf at location 0 of N(0,4),normal distribution with mean 1 and variance 4.\nsd is the standard deviation, which is the square root of the variance.\n\n\nCode\ndnorm(0, mean = 1, sd = 2)\n\n\n[1] 0.1760327\n\n\n\n\n5.2.2 cumulative distribution function(cdf)\n\nProbability of &lt;=70 from Normal Distribtion with mean=75 and sd=5\nsmaller than 1 standard deviation from the mean\n\n\nCode\npnorm(q=70,mean=75,sd=5)\n\n\n[1] 0.1586553\n\n\nProbability of &gt;=80 from Normal Distribtion with mean=75 and sd=5\nlarger than 1 standard deviation from the mean\n\n\nCode\n1-pnorm(q=80,mean=75,sd=5)\n\n\n[1] 0.1586553\n\n\n\n\n5.2.3 quantile function\n\nQ1\n\n\nCode\nqnorm(p=0.25,mean=75,sd=5)\n\n\n[1] 71.62755\n\n\nQ3\n\n\nCode\nqnorm(p=0.75,mean=75,sd=5)\n\n\n[1] 78.37245\n\n\n\n\n5.2.4 random number generator\n\n\n\n5.2.5 generate 1000 number from Normal Distribtion with mean=75 and sd=5\n\n\nCode\nnd=rnorm(n=1000,mean=75,sd=5)\nnd=sort(nd)\n\n\n\n\nCode\nmean(nd)\n\n\n[1] 75.05545\n\n\n\n\nCode\nsd(nd)\n\n\n[1] 4.999038\n\n\n\n\nCode\nhist(nd)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndens=dnorm(nd,mean=mean(nd),sd=sd(nd))\n\n\n\n\nCode\nplot(nd,dens,type='l')\n\n\n\n\n\n\n\n\n\n\n\n5.2.6 check data normally distributed\n\n\nCode\nnd_data=rnorm(n=1000,mean=0,sd=2)\nnd_data=sort(nd_data)\n\n\n\n\nCode\nnon_nd_data=seq(1:1000)\nnon_nd_data=sort(non_nd_data)\n\n\n\n5.2.6.1 method 1 :histogram\n\n\nCode\n#define plotting region\npar(mfrow=c(1,2)) \n\n#create histogram for both datasets\nhist(nd_data, col='steelblue', main='Normal')\nhist(non_nd_data, col='steelblue', main='Non-normal')\n\n\n\n\n\n\n\n\n\n\n\n5.2.6.2 method 2 :Q-Q plot\n\n\nCode\n#define plotting region\npar(mfrow=c(1,2)) \n\n#create Q-Q plot for both datasets\nqqnorm(nd_data, main='Normal')\nqqline(nd_data)\n\nqqnorm(non_nd_data, main='Non-normal')\nqqline(non_nd_data)\n\n\n\n\n\n\n\n\n\n\n\n5.2.6.3 Method 3: Shapiro-Wilk Test\nnull hypothesis (H0):The data is normally distributed.\nif p-value =&gt;0.05 then normally distributed\n\n\nCode\n#perform shapiro-wilk test\nshapiro.test(nd_data)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  nd_data\nW = 0.99868, p-value = 0.6748\n\n\nif p-value &lt;0.05 then not normally distributed(reject the null hypothesis)\n\n\nCode\n#perform shapiro-wilk test\nshapiro.test(non_nd_data)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  non_nd_data\nW = 0.95481, p-value &lt; 2.2e-16",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#student-t-distribution",
    "href": "intro/2 probability.html#student-t-distribution",
    "title": "Probability",
    "section": "5.3 student t distribution",
    "text": "5.3 student t distribution\n\n\n5.3.1 one sample t test\n\n\n5.3.2 two sample t test\n\n\n5.3.3 Paired t test\n\n\n5.3.4 Pearson correlation coefficient",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#poisson-distribution",
    "href": "intro/2 probability.html#poisson-distribution",
    "title": "Probability",
    "section": "5.6 Poisson Distribution",
    "text": "5.6 Poisson Distribution",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#f-distribution",
    "href": "intro/2 probability.html#f-distribution",
    "title": "Probability",
    "section": "5.4 F distribution",
    "text": "5.4 F distribution\n\n5.4.1 ANOVA",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#chi-square",
    "href": "intro/2 probability.html#chi-square",
    "title": "Probability",
    "section": "5.5 Chi-square",
    "text": "5.5 Chi-square\n\n5.5.1 Chi-square goodness of fit test\n\n\n5.5.2 Chi-square test of independence",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#permutationsorder-dose-matter-2-number-from-4-number",
    "href": "intro/2 probability.html#permutationsorder-dose-matter-2-number-from-4-number",
    "title": "Probability",
    "section": "2.1 Permutations(order dose matter), 2 number from 4 number",
    "text": "2.1 Permutations(order dose matter), 2 number from 4 number\n\n\nCode\nlibrary(gtools)\nall_num=4\nchoose=2\n\nres&lt;- permutations(n= all_num, r = choose, v = c(1:all_num))\nres\n\n\n      [,1] [,2]\n [1,]    1    2\n [2,]    1    3\n [3,]    1    4\n [4,]    2    1\n [5,]    2    3\n [6,]    2    4\n [7,]    3    1\n [8,]    3    2\n [9,]    3    4\n[10,]    4    1\n[11,]    4    2\n[12,]    4    3\n\n\n\n\nCode\nprint (nrow(res))\n\n\n[1] 12\n\n\nall_num!/choose!\n4!/2!\n\n\nCode\n(4*3*2*1)/(2*1)\n\n\n[1] 12\n\n\nor\n\n\nCode\nfactorial(4) / factorial(2)\n\n\n[1] 12",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#combinationsorder-no-matter-2-number-from-4-number",
    "href": "intro/2 probability.html#combinationsorder-no-matter-2-number-from-4-number",
    "title": "Probability",
    "section": "2.2 Combinations(order no matter), 2 number from 4 number",
    "text": "2.2 Combinations(order no matter), 2 number from 4 number\n\n\nCode\nlibrary(gtools)\nall_num=4\nchoose=2\n\nres&lt;- combinations(n= all_num, r = choose, v = c(1:all_num))\nres\n\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    1    3\n[3,]    1    4\n[4,]    2    3\n[5,]    2    4\n[6,]    3    4\n\n\n\n\nCode\nprint (nrow(res))\n\n\n[1] 6\n\n\nall_num!/((all_num-choose)! * choose!\n4!/((4-2)! * 2!)\n\n\nCode\n(4*3*2*1)/((2*1)*(2*1))\n\n\n[1] 6\n\n\nor\n\n\nCode\nfactorial(4) / (factorial(4-2)*factorial(2))\n\n\n[1] 6",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#question-1.what-is-probability-of-choose-4-number-from-4-number-and-0-correctall-wrong.",
    "href": "intro/2 probability.html#question-1.what-is-probability-of-choose-4-number-from-4-number-and-0-correctall-wrong.",
    "title": "Probability",
    "section": "4.1 Question 1.what is probability of choose 4 number from 4 number and 0 correct(all wrong).",
    "text": "4.1 Question 1.what is probability of choose 4 number from 4 number and 0 correct(all wrong).\n\n4.1.1 permutations(order matter)\n4!=432*1=24 combination\n\n\nCode\n4*3*2*1\n\n\n[1] 24\n\n\n\n\n4.1.2 Derangement\n\nor\n\nThere are 9 Derangement(all wrong)\n\n\nCode\ne=2.71828\n#D(4)=(4!+1)/e\n\nD_4=floor((4*3*2*1+1)/e)\nD_4\n\n\n[1] 9\n\n\nSo the all wrong probability of choose 4 number from 4 number is\n\n\nCode\nQ1=(floor((4*3*2*1+1)/e))/(4*3*2*1)\nQ1\n\n\n[1] 0.375",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#question-2.-what-is-probability-of-choose-4-number-from-4-number-and-only-1-correct",
    "href": "intro/2 probability.html#question-2.-what-is-probability-of-choose-4-number-from-4-number-and-only-1-correct",
    "title": "Probability",
    "section": "4.2 Question 2. what is probability of choose 4 number from 4 number and only 1 correct",
    "text": "4.2 Question 2. what is probability of choose 4 number from 4 number and only 1 correct\n\n4.2.1 permutations(order matter)\n4!=432*1=24 combination\n\n\nCode\n4*3*2*1\n\n\n[1] 24\n\n\n\n\n4.2.2 Derangement\nany of the 4 number can be correct, and remaining 3 number all wrong and it become the D(3) Derangement problem\n\n\nCode\ne=2.71828\n#D(3)=(3!+1)/e\n\nD_3=floor((3*2*1+1)/e)\nD_3\n\n\n[1] 2\n\n\nSo the probability of choose 4 number from 4 number and only 1 correct is\n\n\nCode\nQ2=(4*2)/(4*3*2*1)\nQ2\n\n\n[1] 0.3333333",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#question-3.-what-is-probability-of-choose-4-number-from-4-number-and-only-2-correct",
    "href": "intro/2 probability.html#question-3.-what-is-probability-of-choose-4-number-from-4-number-and-only-2-correct",
    "title": "Probability",
    "section": "4.3 Question 3. what is probability of choose 4 number from 4 number and only 2 correct",
    "text": "4.3 Question 3. what is probability of choose 4 number from 4 number and only 2 correct\nthe problem is same as choose 2 number from 4 number.total 6 Combinations(order no matter)\n\n\nCode\nfactorial(4) / (factorial(4-2)*factorial(2))\n\n\n[1] 6\n\n\nSo the probability of choose 4 number from 4 number and only 2 correct is\n\n\nCode\nQ3=6/(4*3*2*1)\nQ3\n\n\n[1] 0.25",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#question-4.what-is-probability-of-choose-4-number-from-4-number-and-only-3-correct",
    "href": "intro/2 probability.html#question-4.what-is-probability-of-choose-4-number-from-4-number-and-only-3-correct",
    "title": "Probability",
    "section": "4.4 Question 4.what is probability of choose 4 number from 4 number and only 3 correct",
    "text": "4.4 Question 4.what is probability of choose 4 number from 4 number and only 3 correct\nIts same as all correct. since 3 correct the last one will be also correct\n\n\nCode\nQ4=1/(4*3*2*1)\nQ4\n\n\n[1] 0.04166667",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#question-5.what-is-probability-of-choose-4-number-from-4-number-and-4-correct",
    "href": "intro/2 probability.html#question-5.what-is-probability-of-choose-4-number-from-4-number-and-4-correct",
    "title": "Probability",
    "section": "4.5 Question 5.what is probability of choose 4 number from 4 number and 4 correct",
    "text": "4.5 Question 5.what is probability of choose 4 number from 4 number and 4 correct\n\n\nCode\nQ5=1/(4*3*2*1)\nQ5\n\n\n[1] 0.04166667\n\n\nSo all event total probability is 1\n\n\nCode\nQ1+Q2+Q3+Q4\n\n\n[1] 1",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html",
    "href": "intro/2 probability.html",
    "title": "Probability",
    "section": "",
    "text": "Probability is the branch of mathematics concerning events and numerical descriptions of how likely they are to occur. The probability of an event is a number between 0 and 1; the larger the probability, the more likely an event is to occur.",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#solution-2pat-least-one1-pno-one-snoring",
    "href": "intro/2 probability.html#solution-2pat-least-one1-pno-one-snoring",
    "title": "Probability",
    "section": "3.2 solution 2:P(at least one)=1-P(no one snoring)",
    "text": "3.2 solution 2:P(at least one)=1-P(no one snoring)\n\n\nCode\nP_at_least_one2=1-0.8*0.8*0.8*0.8\nP_at_least_one2\n\n\n[1] 0.5904",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/2 probability.html#normal-distributionalso-called-gaussian-distribution",
    "href": "intro/2 probability.html#normal-distributionalso-called-gaussian-distribution",
    "title": "Probability",
    "section": "5.2 Normal Distribution(also called Gaussian distribution)",
    "text": "5.2 Normal Distribution(also called Gaussian distribution)\nX is a random variable following a normal distribution with mean μ and variance σ2\n68% within 1 standard deviation\n95% within 2 standard deviation\n99.7% within 3 standard deviation\n\n5.2.1 Z score and standard Normal Distribution\nstandard Normal Distribution is special Normal Distribution with mean=0 and standard deviation =1\n\nZ table\n\n\n\n5.2.2 Standardization\ntransfer any normal Distribution into standard Normal Distribution\n\nformula:\n\n\n\n5.2.3 R function\n\n\n\n5.2.4 Probability Density Function (pdf)\n\ncomputes the pdf at location 0 of N(0,4),normal distribution with mean 1 and variance 4.\nsd is the standard deviation, which is the square root of the variance.\n\n\nCode\ndnorm(0, mean = 1, sd = 2)\n\n\n[1] 0.1760327\n\n\n\n\n5.2.5 cumulative distribution function(cdf)\n\nProbability of &lt;=70 from Normal Distribtion with mean=75 and sd=5\nsmaller than 1 standard deviation from the mean\n\n\nCode\npnorm(q=70,mean=75,sd=5)\n\n\n[1] 0.1586553\n\n\nProbability of &gt;=80 from Normal Distribtion with mean=75 and sd=5\nlarger than 1 standard deviation from the mean\n\n\nCode\n1-pnorm(q=80,mean=75,sd=5)\n\n\n[1] 0.1586553\n\n\n\n\n5.2.6 quantile function\n\nQ1\n\n\nCode\nqnorm(p=0.25,mean=75,sd=5)\n\n\n[1] 71.62755\n\n\nQ3\n\n\nCode\nqnorm(p=0.75,mean=75,sd=5)\n\n\n[1] 78.37245\n\n\n\n\n5.2.7 random number generator\n\n\n\n5.2.8 generate 1000 number from Normal Distribtion with mean=75 and sd=5\n\n\nCode\nnd=rnorm(n=1000,mean=75,sd=5)\nnd=sort(nd)\n\n\n\n\nCode\nmean(nd)\n\n\n[1] 74.87661\n\n\n\n\nCode\nsd(nd)\n\n\n[1] 4.988259\n\n\n\n\nCode\nhist(nd)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndens=dnorm(nd,mean=mean(nd),sd=sd(nd))\n\n\n\n\nCode\nplot(nd,dens,type='l')\n\n\n\n\n\n\n\n\n\n\n\n5.2.9 check data normally distributed\n\n\nCode\nnd_data=rnorm(n=1000,mean=0,sd=2)\nnd_data=sort(nd_data)\n\n\n\n\nCode\nnon_nd_data=seq(1:1000)\nnon_nd_data=sort(non_nd_data)\n\n\n\n5.2.9.1 method 1 :histogram\n\n\nCode\n#define plotting region\npar(mfrow=c(1,2)) \n\n#create histogram for both datasets\nhist(nd_data, col='steelblue', main='Normal')\nhist(non_nd_data, col='steelblue', main='Non-normal')\n\n\n\n\n\n\n\n\n\n\n\n5.2.9.2 method 2 :Q-Q plot\n\n\nCode\n#define plotting region\npar(mfrow=c(1,2)) \n\n#create Q-Q plot for both datasets\nqqnorm(nd_data, main='Normal')\nqqline(nd_data)\n\nqqnorm(non_nd_data, main='Non-normal')\nqqline(non_nd_data)\n\n\n\n\n\n\n\n\n\n\n\n5.2.9.3 Method 3: Shapiro-Wilk Test\nnull hypothesis (H0):The data is normally distributed.\nif p-value =&gt;0.05 then normally distributed\n\n\nCode\n#perform shapiro-wilk test\nshapiro.test(nd_data)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  nd_data\nW = 0.99879, p-value = 0.7491\n\n\nif p-value &lt;0.05 then not normally distributed(reject the null hypothesis)\n\n\nCode\n#perform shapiro-wilk test\nshapiro.test(non_nd_data)\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  non_nd_data\nW = 0.95481, p-value &lt; 2.2e-16",
    "crumbs": [
      "Intro",
      "Probability"
    ]
  },
  {
    "objectID": "intro/3 Statistics.html",
    "href": "intro/3 Statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "1 Statistics\n\n\n\n2 Variable\n\n\n\n3 Categorical variable\n\n\n\n4 Quantitative variable\n\n\n\n5 Variance vs Standard deviation\n\n\n\n6 Reference\nhttps://www.youtube.com/watch?v=MXaJ7sa7q-8\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.3.1    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.3.1       htmltools_0.5.8.1 rstudioapi_0.16.0 yaml_2.3.8       \n [9] rmarkdown_2.26    knitr_1.45        jsonlite_1.8.8    xfun_0.43        \n[13] digest_0.6.35     rlang_1.1.3       evaluate_0.23    \n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Intro",
      "Statistics"
    ]
  },
  {
    "objectID": "Plot/5 Map/1 leaflet.html",
    "href": "Plot/5 Map/1 leaflet.html",
    "title": "map",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\n\nlibrary(sf)\nlibrary(leaflet)\nlibrary(geojsonio)\nlibrary(leaflet.extras)\n\n\n\n\n2 display at openstreet map\n\n\nCode\nm &lt;- leaflet() %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers(lng=174.768, lat=-36.852, popup=\"The birthplace of R\")\n\nm  \n\n\n\n\n\n\n\n\n3 display at google map\n\n\nCode\nleaflet() |&gt;\n  # add base mao\n  addTiles(urlTemplate = \"https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}\") |&gt;\n  # set view\n  setView(116.347817690225, 39.997202126977, zoom = 16) |&gt;\n  # add markers\n  addMarkers(116.347817690225, 39.997202126977)\n\n\n\n\n\n\n\n\n4 Third-Party map\n\n\nCode\n#m &lt;- leaflet() %&gt;% setView(lng = -71.0589, lat = 42.3601, zoom = 10)\n#m %&gt;% addProviderTiles(providers$Stadia.StamenToner)\n\n\n\n\n5 add pop up\nPopups are small boxes containing arbitrary HTML, that point to a specific point on the map.\n\n\nCode\ncontent &lt;- paste(sep = \"&lt;br/&gt;\",\n  \"&lt;b&gt;&lt;a href='https://www.samurainoodle.com/'&gt;Samurai Noodle&lt;/a&gt;&lt;/b&gt;\",\n  \"606 5th Ave. S\",\n  \"Seattle, WA 98138\"\n)\n\nleaflet() %&gt;% addTiles() %&gt;%\n  setView(-122.327298, 47.597131,zoom = 12) %&gt;% \n  addPopups(-122.327298, 47.597131, content,\n    #options = popupOptions(closeButton = FALSE)\n    options = popupOptions(closeButton = FALSE)\n  )\n\n\n\n\n\n\n\n\n6 add Markers\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"\n))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, popup = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n7 add Labels\nA label is a textual or HTML content that can attached to markers and shapes to be always displayed or displayed on mouse over. Unlike popups you don’t need to click a marker/polygon for the label to be shown.\n\n\nCode\nlibrary(htmltools)\n\ndf &lt;- read.csv(textConnection(\n\"Name,Lat,Long\nSamurai Noodle,47.597131,-122.327298\nKukai Ramen,47.6154,-122.327157\nTsukushinbo,47.59987,-122.326726\"))\n\nleaflet(df) %&gt;% addTiles() %&gt;%\n  addMarkers(~Long, ~Lat, label = ~htmlEscape(Name))\n\n\n\n\n\n\n\n\n8 World map\n\n\nCode\n#install.packages(\"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\")\n\n\n\n\nCode\njson_data=read_sf(\"world-administrative-boundaries.geojson\")\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\n#Get my variable\n#name&lt;-c(\"Ghana\", \"Grenada\", \"Guyana\", \"India\", \"Jamaica\", \"Kenya\", \"United States\",\"Canada\")\n#val&lt;-c(1,2,4,5,5,1000,20000, 100)\n\n#per_gdp_usd&lt;-data.frame(name,val)\n\n\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\n\nper_gdp_usd=read_excel('world data.xlsx') %&gt;% mutate(\n  name=case_when(\n    name ==\"United States\" ~ \"United States of America\"\n     ,name ==\"Russia\" ~ \"Russian Federation\"\n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name ==\"U.K. of Great Britain and Northern Ireland\" ~ \"United Kingdom\"\n   \n   ,name == \"South Korea\"~ \"Republic of Korea\"\n   \n   ,name ==\"Lao People's Democratic Republic\" ~ \"Laos\"\n   \n    ,TRUE ~ name\n  )\n)\n\n\n\n\nCode\n#test=full_join(map_df, per_gdp_usd, by=\"name\")\n\n#left =test %&gt;% filter(is.na(iso3)==TRUE)\n\n#right=test %&gt;% filter(is.na(per_gdp_total)==TRUE)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"name\")\n\n\n\n\nCode\nglimpse(map_df002)\n\n\nRows: 158\nColumns: 12\n$ name                     &lt;chr&gt; \"Albania\", \"Algeria\", \"Andorra\", \"Angola\", \"A…\n$ geo_point_2d             &lt;chr&gt; \"{ \\\"lon\\\": 20.068384605918776, \\\"lat\\\": 41.1…\n$ iso3                     &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ status                   &lt;chr&gt; \"Member State\", \"Member State\", \"Member State…\n$ color_code               &lt;chr&gt; \"ALB\", \"DZA\", \"AND\", \"AGO\", \"ARG\", \"ARM\", \"AU…\n$ continent                &lt;chr&gt; \"Europe\", \"Africa\", \"Europe\", \"Africa\", \"Amer…\n$ region                   &lt;chr&gt; \"Southern Europe\", \"Northern Africa\", \"Southe…\n$ iso_3166_1_alpha_2_codes &lt;chr&gt; \"AL\", \"DZ\", \"AD\", \"AO\", \"AR\", \"AM\", \"AU\", \"AT…\n$ french_short             &lt;chr&gt; \"Albanie\", \"Algérie\", \"Andorre\", \"Angola\", \"A…\n$ geometry                 &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((20.07142 42..., …\n$ per_gdp_total            &lt;dbl&gt; 1.888210e+10, 1.919130e+11, 3.352033e+09, 1.0…\n$ per_gdp_usd              &lt;dbl&gt; 6643, 4274, 41993, 2999, 13904, 7014, 64003, …\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gdp_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gdp_usd, \"（千 美元）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", round(map_sf002$per_gdp_usd/1000), \"K &lt;br/&gt;\",\n       \"总gpd 美元：\", round(map_sf002$per_gdp_total/1000000), \"M &lt;br/&gt;\"\n\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gdp_usd, opacity = 1.0\n    )\n\n\n\n\n\n\n\n\n9 China one city map\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/citys/440300.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/440300_full.json\")\n\n\n深圳市：\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n\n\n\n\n10 all China each province GPD map\n\n\nCode\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n中国 2022 各省 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('china gdp2022.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"地区：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"地区：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nGPD data source:国家统计局数据库\n\n\n11 China one province map each city GPD\n\n\nCode\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/province/440000.json\") \n\n\n广东省 2021 人均gpd usd：\n\n\nCode\nlibrary(openxlsx)\nlibrary(readxl)\nper_gdp_usd=read_excel('guangdong city gdp2021.xlsx')\n\n\n\n\nCode\nmap_df &lt;- as.data.frame(json_data)\n\n\n\n\nCode\nmap_df002 &lt;- merge(map_df, per_gdp_usd, by.x = \"name\", by.y = \"city\")\n\n\n\n\nCode\nmap_sf002 &lt;- sf::st_as_sf(map_df002, sf_column_name = \"geometry\")\n\n\ndata source:广东统计年鉴2022\n\n\nCode\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nleaflet(map_sf002) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.5,weight = 1,\n    fillColor = ~ pal(per_gpd_usd)\n    ,popup = ~ paste0(\n      \"城市：\", name, \"&lt;br/&gt;\",\n      \"&lt;hr/&gt;\",\n      \"人均gpd：\", per_gpd_usd, \"（美万）\", \"&lt;br/&gt;\"\n      \n    )\n     ,label = lapply(paste0(\n      \"城市：\", \"&lt;b&gt;\", map_sf002$name, \"&lt;/b&gt;\", \"&lt;br/&gt;\",\n      \"人均gpd 美元：\", map_sf002$per_gpd_usd, \"&lt;br/&gt;\",\n      \"人均gpd 人民币：\", map_sf002$per_gpd_rmb, \"&lt;br/&gt;\",\n       \"人口：\", round(map_sf002$total_gpd_rmb*10000000/map_sf002$per_gpd_rmb), \"&lt;br/&gt;\"\n    ), htmltools::HTML)\n    )%&gt;% addLegend(\n    position = \"bottomright\", title = \"人均gpd(美元)\",\n    pal = pal, values = ~per_gpd_usd, opacity = 1.0\n    )\n\n\n\n\n\n\nhttps://zh.wikipedia.org/wiki/%E5%B9%BF%E4%B8%9C%E5%90%84%E5%9C%B0%E7%BA%A7%E5%B8%82%E5%9C%B0%E5%8C%BA%E7%94%9F%E4%BA%A7%E6%80%BB%E5%80%BC%E5%88%97%E8%A1%A8\n\n\n12 China province map\n\n\nCode\nlibrary(leaflet)\nlibrary(sf)\n\njson_data &lt;- sf::read_sf(\"./GeoMapData_CN/china.json\") \n#or\njson_data=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\npal &lt;- colorNumeric(\"viridis\", NULL)\n\nm=leaflet(json_data) %&gt;%\n  addTiles() %&gt;%\n  addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n \n\nm\n\n\n\n\n\n\nadd provincial capital\n\n\nCode\nChina=read_sf(\"https://geo.datav.aliyun.com/areas_v2/bound/100000_full.json\")\n\n\n\n\nCode\nChina002=China %&gt;% as_data_frame() %&gt;% mutate(\n                                            center2=as.character(center) %&gt;% str_replace('c','')%&gt;% str_replace('[(]','') %&gt;% str_replace('[)]','')\n                                               )\n\n\n\n\nCode\nChina003=China002%&gt;%separate(center2, c(\"x\", \"y\"), \", \")\n\n\n\n\nCode\nChina_point = China003 %&gt;% \n  slice(-35)\n\nm %&gt;% \n  addCircles(data = China_point,\n                  lng = ~as.numeric(x), lat = ~as.numeric(y),color = \"red\",weight = 10,\n                  fillOpacity =2)\n\n\n\n\n\n\n\n\n13 China province and city map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 34\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 119.3183 ymin: 21.75147 xmax: 124.5656 ymax: 25.92592\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 710000 台湾省 121.509062,25.044332 province (((119.5543 23.68248, 119.555 23.…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/province\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/province/710000.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 33\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n14 China city and district map\n\n\nCode\nmap_list &lt;- lapply(\n  X = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T),\n  FUN = sf::read_sf\n)\n\nlength(map_list)\n\n\n[1] 334\n\n\n\n\nCode\nfor (i in c(1:length(map_list))){\n   #print(i)\n  #print(dim(map_list[[i]]))\n  #print(ncol(map_list[[i]]))\n  if(ncol(map_list[[i]])!=10){print(map_list[[i]])}\n  }\n\n\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.5215 ymin: 22.65421 xmax: 114.2603 ymax: 23.14205\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 441900 东莞市 113.746262,23.046237 city  ((114.2292 22.81251, 114.2278 22.813…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 113.157 ymin: 22.20104 xmax: 113.692 ymax: 22.7726\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                         &lt;POLYGON [°]&gt;\n1 442000 中山市 113.382391,22.521113 city  ((113.5687 22.41193, 113.5666 22.412…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 115.9267 ymin: 20.58265 xmax: 116.9338 ymax: 21.12693\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center               level                            geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                &lt;chr&gt;                  &lt;MULTIPOLYGON [°]&gt;\n1 442100 东沙群岛 116.887312,20.617512 city  (((115.9433 21.09745, 115.95 21.11…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 108.9287 ymin: 19.17894 xmax: 109.7694 ymax: 19.92575\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name   center               level                              geometry\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 460400 儋州市 109.576782,19.517486 city  (((109.4322 19.91302, 109.4253 19.91…\nSimple feature collection with 1 feature and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.8483 ymin: 39.65426 xmax: 98.52018 ymax: 39.99979\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 5\n  adcode name     center              level                             geometry\n  &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;               &lt;chr&gt;                   &lt;MULTIPOLYGON [°]&gt;\n1 620200 嘉峪关市 98.277304,39.786529 city  (((97.85974 39.7169, 97.85827 39.71…\n\n\n\n\nCode\nX = list.files(\"./GeoMapData_CN/citys\", recursive = T, full.names = T)\n\nX2=X[-which(X %in% c(\"./GeoMapData_CN/citys/620200.json\"\n         ,\"./GeoMapData_CN/citys/460400.json\"\n              ,\"./GeoMapData_CN/citys/442100.json\"\n              ,\"./GeoMapData_CN/citys/442000.json\"\n              ,\"./GeoMapData_CN/citys/441900.json\"\n         ))]\n\nmap_list &lt;- lapply(\n  X = X2,\n  FUN = sf::read_sf\n)\n\n\n\n\nCode\nlength(map_list)\n\n\n[1] 329\n\n\n\n\nCode\nprovince_map &lt;- Reduce(\"rbind\", map_list)\n\n\n\n\nCode\n# library(leaflet)\n# library(sf)\n# \n# json_data &lt;- province_map\n# \n# \n# pal &lt;- colorNumeric(c(\"red\", \"green\", \"blue\"), 1:10)\n# \n# leaflet(json_data) %&gt;%\n#   addTiles() %&gt;%\n#   addPolygons(smoothFactor = 0.3, fillOpacity = 0.1)\n\n\n\n\n15 show all map providers\n\n\nCode\nproviders\n\n\nproviders\n$OpenStreetMap\n[1] \"OpenStreetMap\"\n\n$OpenStreetMap.Mapnik\n[1] \"OpenStreetMap.Mapnik\"\n\n$OpenStreetMap.DE\n[1] \"OpenStreetMap.DE\"\n\n$OpenStreetMap.CH\n[1] \"OpenStreetMap.CH\"\n\n$OpenStreetMap.France\n[1] \"OpenStreetMap.France\"\n\n$OpenStreetMap.HOT\n[1] \"OpenStreetMap.HOT\"\n\n$OpenStreetMap.BZH\n[1] \"OpenStreetMap.BZH\"\n\n$MapTilesAPI\n[1] \"MapTilesAPI\"\n\n$MapTilesAPI.OSMEnglish\n[1] \"MapTilesAPI.OSMEnglish\"\n\n$MapTilesAPI.OSMFrancais\n[1] \"MapTilesAPI.OSMFrancais\"\n\n$MapTilesAPI.OSMEspagnol\n[1] \"MapTilesAPI.OSMEspagnol\"\n\n$OpenSeaMap\n[1] \"OpenSeaMap\"\n\n$OPNVKarte\n[1] \"OPNVKarte\"\n\n$OpenTopoMap\n[1] \"OpenTopoMap\"\n\n$OpenRailwayMap\n[1] \"OpenRailwayMap\"\n\n$OpenFireMap\n[1] \"OpenFireMap\"\n\n$SafeCast\n[1] \"SafeCast\"\n\n$Stadia\n[1] \"Stadia\"\n\n$Stadia.AlidadeSmooth\n[1] \"Stadia.AlidadeSmooth\"\n\n$Stadia.AlidadeSmoothDark\n[1] \"Stadia.AlidadeSmoothDark\"\n\n$Stadia.OSMBright\n[1] \"Stadia.OSMBright\"\n\n$Stadia.Outdoors\n[1] \"Stadia.Outdoors\"\n\n$Stadia.StamenToner\n[1] \"Stadia.StamenToner\"\n\n$Stadia.StamenTonerBackground\n[1] \"Stadia.StamenTonerBackground\"\n\n$Stadia.StamenTonerLines\n[1] \"Stadia.StamenTonerLines\"\n\n$Stadia.StamenTonerLabels\n[1] \"Stadia.StamenTonerLabels\"\n\n$Stadia.StamenTonerLite\n[1] \"Stadia.StamenTonerLite\"\n\n$Stadia.StamenWatercolor\n[1] \"Stadia.StamenWatercolor\"\n\n$Stadia.StamenTerrain\n[1] \"Stadia.StamenTerrain\"\n\n$Stadia.StamenTerrainBackground\n[1] \"Stadia.StamenTerrainBackground\"\n\n$Stadia.StamenTerrainLabels\n[1] \"Stadia.StamenTerrainLabels\"\n\n$Stadia.StamenTerrainLines\n[1] \"Stadia.StamenTerrainLines\"\n\n$Thunderforest\n[1] \"Thunderforest\"\n\n$Thunderforest.OpenCycleMap\n[1] \"Thunderforest.OpenCycleMap\"\n\n$Thunderforest.Transport\n[1] \"Thunderforest.Transport\"\n\n$Thunderforest.TransportDark\n[1] \"Thunderforest.TransportDark\"\n\n$Thunderforest.SpinalMap\n[1] \"Thunderforest.SpinalMap\"\n\n$Thunderforest.Landscape\n[1] \"Thunderforest.Landscape\"\n\n$Thunderforest.Outdoors\n[1] \"Thunderforest.Outdoors\"\n\n$Thunderforest.Pioneer\n[1] \"Thunderforest.Pioneer\"\n\n$Thunderforest.MobileAtlas\n[1] \"Thunderforest.MobileAtlas\"\n\n$Thunderforest.Neighbourhood\n[1] \"Thunderforest.Neighbourhood\"\n\n$CyclOSM\n[1] \"CyclOSM\"\n\n$Jawg\n[1] \"Jawg\"\n\n$Jawg.Streets\n[1] \"Jawg.Streets\"\n\n$Jawg.Terrain\n[1] \"Jawg.Terrain\"\n\n$Jawg.Sunny\n[1] \"Jawg.Sunny\"\n\n$Jawg.Dark\n[1] \"Jawg.Dark\"\n\n$Jawg.Light\n[1] \"Jawg.Light\"\n\n$Jawg.Matrix\n[1] \"Jawg.Matrix\"\n\n$MapBox\n[1] \"MapBox\"\n\n$MapTiler\n[1] \"MapTiler\"\n\n$MapTiler.Streets\n[1] \"MapTiler.Streets\"\n\n$MapTiler.Basic\n[1] \"MapTiler.Basic\"\n\n$MapTiler.Bright\n[1] \"MapTiler.Bright\"\n\n$MapTiler.Pastel\n[1] \"MapTiler.Pastel\"\n\n$MapTiler.Positron\n[1] \"MapTiler.Positron\"\n\n$MapTiler.Hybrid\n[1] \"MapTiler.Hybrid\"\n\n$MapTiler.Toner\n[1] \"MapTiler.Toner\"\n\n$MapTiler.Topo\n[1] \"MapTiler.Topo\"\n\n$MapTiler.Voyager\n[1] \"MapTiler.Voyager\"\n\n$TomTom\n[1] \"TomTom\"\n\n$TomTom.Basic\n[1] \"TomTom.Basic\"\n\n$TomTom.Hybrid\n[1] \"TomTom.Hybrid\"\n\n$TomTom.Labels\n[1] \"TomTom.Labels\"\n\n$Esri\n[1] \"Esri\"\n\n$Esri.WorldStreetMap\n[1] \"Esri.WorldStreetMap\"\n\n$Esri.DeLorme\n[1] \"Esri.DeLorme\"\n\n$Esri.WorldTopoMap\n[1] \"Esri.WorldTopoMap\"\n\n$Esri.WorldImagery\n[1] \"Esri.WorldImagery\"\n\n$Esri.WorldTerrain\n[1] \"Esri.WorldTerrain\"\n\n$Esri.WorldShadedRelief\n[1] \"Esri.WorldShadedRelief\"\n\n$Esri.WorldPhysical\n[1] \"Esri.WorldPhysical\"\n\n$Esri.OceanBasemap\n[1] \"Esri.OceanBasemap\"\n\n$Esri.NatGeoWorldMap\n[1] \"Esri.NatGeoWorldMap\"\n\n$Esri.WorldGrayCanvas\n[1] \"Esri.WorldGrayCanvas\"\n\n$OpenWeatherMap\n[1] \"OpenWeatherMap\"\n\n$OpenWeatherMap.Clouds\n[1] \"OpenWeatherMap.Clouds\"\n\n$OpenWeatherMap.CloudsClassic\n[1] \"OpenWeatherMap.CloudsClassic\"\n\n$OpenWeatherMap.Precipitation\n[1] \"OpenWeatherMap.Precipitation\"\n\n$OpenWeatherMap.PrecipitationClassic\n[1] \"OpenWeatherMap.PrecipitationClassic\"\n\n$OpenWeatherMap.Rain\n[1] \"OpenWeatherMap.Rain\"\n\n$OpenWeatherMap.RainClassic\n[1] \"OpenWeatherMap.RainClassic\"\n\n$OpenWeatherMap.Pressure\n[1] \"OpenWeatherMap.Pressure\"\n\n$OpenWeatherMap.PressureContour\n[1] \"OpenWeatherMap.PressureContour\"\n\n$OpenWeatherMap.Wind\n[1] \"OpenWeatherMap.Wind\"\n\n$OpenWeatherMap.Temperature\n[1] \"OpenWeatherMap.Temperature\"\n\n$OpenWeatherMap.Snow\n[1] \"OpenWeatherMap.Snow\"\n\n$HERE\n[1] \"HERE\"\n\n$HERE.normalDay\n[1] \"HERE.normalDay\"\n\n$HERE.normalDayCustom\n[1] \"HERE.normalDayCustom\"\n\n$HERE.normalDayGrey\n[1] \"HERE.normalDayGrey\"\n\n$HERE.normalDayMobile\n[1] \"HERE.normalDayMobile\"\n\n$HERE.normalDayGreyMobile\n[1] \"HERE.normalDayGreyMobile\"\n\n$HERE.normalDayTransit\n[1] \"HERE.normalDayTransit\"\n\n$HERE.normalDayTransitMobile\n[1] \"HERE.normalDayTransitMobile\"\n\n$HERE.normalDayTraffic\n[1] \"HERE.normalDayTraffic\"\n\n$HERE.normalNight\n[1] \"HERE.normalNight\"\n\n$HERE.normalNightMobile\n[1] \"HERE.normalNightMobile\"\n\n$HERE.normalNightGrey\n[1] \"HERE.normalNightGrey\"\n\n$HERE.normalNightGreyMobile\n[1] \"HERE.normalNightGreyMobile\"\n\n$HERE.normalNightTransit\n[1] \"HERE.normalNightTransit\"\n\n$HERE.normalNightTransitMobile\n[1] \"HERE.normalNightTransitMobile\"\n\n$HERE.reducedDay\n[1] \"HERE.reducedDay\"\n\n$HERE.reducedNight\n[1] \"HERE.reducedNight\"\n\n$HERE.basicMap\n[1] \"HERE.basicMap\"\n\n$HERE.mapLabels\n[1] \"HERE.mapLabels\"\n\n$HERE.trafficFlow\n[1] \"HERE.trafficFlow\"\n\n$HERE.carnavDayGrey\n[1] \"HERE.carnavDayGrey\"\n\n$HERE.hybridDay\n[1] \"HERE.hybridDay\"\n\n$HERE.hybridDayMobile\n[1] \"HERE.hybridDayMobile\"\n\n$HERE.hybridDayTransit\n[1] \"HERE.hybridDayTransit\"\n\n$HERE.hybridDayGrey\n[1] \"HERE.hybridDayGrey\"\n\n$HERE.hybridDayTraffic\n[1] \"HERE.hybridDayTraffic\"\n\n$HERE.pedestrianDay\n[1] \"HERE.pedestrianDay\"\n\n$HERE.pedestrianNight\n[1] \"HERE.pedestrianNight\"\n\n$HERE.satelliteDay\n[1] \"HERE.satelliteDay\"\n\n$HERE.terrainDay\n[1] \"HERE.terrainDay\"\n\n$HERE.terrainDayMobile\n[1] \"HERE.terrainDayMobile\"\n\n$HEREv3\n[1] \"HEREv3\"\n\n$HEREv3.normalDay\n[1] \"HEREv3.normalDay\"\n\n$HEREv3.normalDayCustom\n[1] \"HEREv3.normalDayCustom\"\n\n$HEREv3.normalDayGrey\n[1] \"HEREv3.normalDayGrey\"\n\n$HEREv3.normalDayMobile\n[1] \"HEREv3.normalDayMobile\"\n\n$HEREv3.normalDayGreyMobile\n[1] \"HEREv3.normalDayGreyMobile\"\n\n$HEREv3.normalDayTransit\n[1] \"HEREv3.normalDayTransit\"\n\n$HEREv3.normalDayTransitMobile\n[1] \"HEREv3.normalDayTransitMobile\"\n\n$HEREv3.normalNight\n[1] \"HEREv3.normalNight\"\n\n$HEREv3.normalNightMobile\n[1] \"HEREv3.normalNightMobile\"\n\n$HEREv3.normalNightGrey\n[1] \"HEREv3.normalNightGrey\"\n\n$HEREv3.normalNightGreyMobile\n[1] \"HEREv3.normalNightGreyMobile\"\n\n$HEREv3.normalNightTransit\n[1] \"HEREv3.normalNightTransit\"\n\n$HEREv3.normalNightTransitMobile\n[1] \"HEREv3.normalNightTransitMobile\"\n\n$HEREv3.reducedDay\n[1] \"HEREv3.reducedDay\"\n\n$HEREv3.reducedNight\n[1] \"HEREv3.reducedNight\"\n\n$HEREv3.basicMap\n[1] \"HEREv3.basicMap\"\n\n$HEREv3.mapLabels\n[1] \"HEREv3.mapLabels\"\n\n$HEREv3.trafficFlow\n[1] \"HEREv3.trafficFlow\"\n\n$HEREv3.carnavDayGrey\n[1] \"HEREv3.carnavDayGrey\"\n\n$HEREv3.hybridDay\n[1] \"HEREv3.hybridDay\"\n\n$HEREv3.hybridDayMobile\n[1] \"HEREv3.hybridDayMobile\"\n\n$HEREv3.hybridDayTransit\n[1] \"HEREv3.hybridDayTransit\"\n\n$HEREv3.hybridDayGrey\n[1] \"HEREv3.hybridDayGrey\"\n\n$HEREv3.pedestrianDay\n[1] \"HEREv3.pedestrianDay\"\n\n$HEREv3.pedestrianNight\n[1] \"HEREv3.pedestrianNight\"\n\n$HEREv3.satelliteDay\n[1] \"HEREv3.satelliteDay\"\n\n$HEREv3.terrainDay\n[1] \"HEREv3.terrainDay\"\n\n$HEREv3.terrainDayMobile\n[1] \"HEREv3.terrainDayMobile\"\n\n$FreeMapSK\n[1] \"FreeMapSK\"\n\n$MtbMap\n[1] \"MtbMap\"\n\n$CartoDB\n[1] \"CartoDB\"\n\n$CartoDB.Positron\n[1] \"CartoDB.Positron\"\n\n$CartoDB.PositronNoLabels\n[1] \"CartoDB.PositronNoLabels\"\n\n$CartoDB.PositronOnlyLabels\n[1] \"CartoDB.PositronOnlyLabels\"\n\n$CartoDB.DarkMatter\n[1] \"CartoDB.DarkMatter\"\n\n$CartoDB.DarkMatterNoLabels\n[1] \"CartoDB.DarkMatterNoLabels\"\n\n$CartoDB.DarkMatterOnlyLabels\n[1] \"CartoDB.DarkMatterOnlyLabels\"\n\n$CartoDB.Voyager\n[1] \"CartoDB.Voyager\"\n\n$CartoDB.VoyagerNoLabels\n[1] \"CartoDB.VoyagerNoLabels\"\n\n$CartoDB.VoyagerOnlyLabels\n[1] \"CartoDB.VoyagerOnlyLabels\"\n\n$CartoDB.VoyagerLabelsUnder\n[1] \"CartoDB.VoyagerLabelsUnder\"\n\n$HikeBike\n[1] \"HikeBike\"\n\n$HikeBike.HikeBike\n[1] \"HikeBike.HikeBike\"\n\n$HikeBike.HillShading\n[1] \"HikeBike.HillShading\"\n\n$BasemapAT\n[1] \"BasemapAT\"\n\n$BasemapAT.basemap\n[1] \"BasemapAT.basemap\"\n\n$BasemapAT.grau\n[1] \"BasemapAT.grau\"\n\n$BasemapAT.overlay\n[1] \"BasemapAT.overlay\"\n\n$BasemapAT.terrain\n[1] \"BasemapAT.terrain\"\n\n$BasemapAT.surface\n[1] \"BasemapAT.surface\"\n\n$BasemapAT.highdpi\n[1] \"BasemapAT.highdpi\"\n\n$BasemapAT.orthofoto\n[1] \"BasemapAT.orthofoto\"\n\n$nlmaps\n[1] \"nlmaps\"\n\n$nlmaps.standaard\n[1] \"nlmaps.standaard\"\n\n$nlmaps.pastel\n[1] \"nlmaps.pastel\"\n\n$nlmaps.grijs\n[1] \"nlmaps.grijs\"\n\n$nlmaps.water\n[1] \"nlmaps.water\"\n\n$nlmaps.luchtfoto\n[1] \"nlmaps.luchtfoto\"\n\n$NASAGIBS\n[1] \"NASAGIBS\"\n\n$NASAGIBS.ModisTerraTrueColorCR\n[1] \"NASAGIBS.ModisTerraTrueColorCR\"\n\n$NASAGIBS.ModisTerraBands367CR\n[1] \"NASAGIBS.ModisTerraBands367CR\"\n\n$NASAGIBS.ViirsEarthAtNight2012\n[1] \"NASAGIBS.ViirsEarthAtNight2012\"\n\n$NASAGIBS.ModisTerraLSTDay\n[1] \"NASAGIBS.ModisTerraLSTDay\"\n\n$NASAGIBS.ModisTerraSnowCover\n[1] \"NASAGIBS.ModisTerraSnowCover\"\n\n$NASAGIBS.ModisTerraAOD\n[1] \"NASAGIBS.ModisTerraAOD\"\n\n$NASAGIBS.ModisTerraChlorophyll\n[1] \"NASAGIBS.ModisTerraChlorophyll\"\n\n$NLS\n[1] \"NLS\"\n\n$JusticeMap\n[1] \"JusticeMap\"\n\n$JusticeMap.income\n[1] \"JusticeMap.income\"\n\n$JusticeMap.americanIndian\n[1] \"JusticeMap.americanIndian\"\n\n$JusticeMap.asian\n[1] \"JusticeMap.asian\"\n\n$JusticeMap.black\n[1] \"JusticeMap.black\"\n\n$JusticeMap.hispanic\n[1] \"JusticeMap.hispanic\"\n\n$JusticeMap.multi\n[1] \"JusticeMap.multi\"\n\n$JusticeMap.nonWhite\n[1] \"JusticeMap.nonWhite\"\n\n$JusticeMap.white\n[1] \"JusticeMap.white\"\n\n$JusticeMap.plurality\n[1] \"JusticeMap.plurality\"\n\n$GeoportailFrance\n[1] \"GeoportailFrance\"\n\n$GeoportailFrance.plan\n[1] \"GeoportailFrance.plan\"\n\n$GeoportailFrance.parcels\n[1] \"GeoportailFrance.parcels\"\n\n$GeoportailFrance.orthos\n[1] \"GeoportailFrance.orthos\"\n\n$OneMapSG\n[1] \"OneMapSG\"\n\n$OneMapSG.Default\n[1] \"OneMapSG.Default\"\n\n$OneMapSG.Night\n[1] \"OneMapSG.Night\"\n\n$OneMapSG.Original\n[1] \"OneMapSG.Original\"\n\n$OneMapSG.Grey\n[1] \"OneMapSG.Grey\"\n\n$OneMapSG.LandLot\n[1] \"OneMapSG.LandLot\"\n\n$USGS\n[1] \"USGS\"\n\n$USGS.USTopo\n[1] \"USGS.USTopo\"\n\n$USGS.USImagery\n[1] \"USGS.USImagery\"\n\n$USGS.USImageryTopo\n[1] \"USGS.USImageryTopo\"\n\n$WaymarkedTrails\n[1] \"WaymarkedTrails\"\n\n$WaymarkedTrails.hiking\n[1] \"WaymarkedTrails.hiking\"\n\n$WaymarkedTrails.cycling\n[1] \"WaymarkedTrails.cycling\"\n\n$WaymarkedTrails.mtb\n[1] \"WaymarkedTrails.mtb\"\n\n$WaymarkedTrails.slopes\n[1] \"WaymarkedTrails.slopes\"\n\n$WaymarkedTrails.riding\n[1] \"WaymarkedTrails.riding\"\n\n$WaymarkedTrails.skating\n[1] \"WaymarkedTrails.skating\"\n\n$OpenAIP\n[1] \"OpenAIP\"\n\n$OpenSnowMap\n[1] \"OpenSnowMap\"\n\n$OpenSnowMap.pistes\n[1] \"OpenSnowMap.pistes\"\n\n$AzureMaps\n[1] \"AzureMaps\"\n\n$AzureMaps.MicrosoftImagery\n[1] \"AzureMaps.MicrosoftImagery\"\n\n$AzureMaps.MicrosoftBaseDarkGrey\n[1] \"AzureMaps.MicrosoftBaseDarkGrey\"\n\n$AzureMaps.MicrosoftBaseRoad\n[1] \"AzureMaps.MicrosoftBaseRoad\"\n\n$AzureMaps.MicrosoftBaseHybridRoad\n[1] \"AzureMaps.MicrosoftBaseHybridRoad\"\n\n$AzureMaps.MicrosoftTerraMain\n[1] \"AzureMaps.MicrosoftTerraMain\"\n\n$AzureMaps.MicrosoftWeatherInfraredMain\n[1] \"AzureMaps.MicrosoftWeatherInfraredMain\"\n\n$AzureMaps.MicrosoftWeatherRadarMain\n[1] \"AzureMaps.MicrosoftWeatherRadarMain\"\n\n$SwissFederalGeoportal\n[1] \"SwissFederalGeoportal\"\n\n$SwissFederalGeoportal.NationalMapColor\n[1] \"SwissFederalGeoportal.NationalMapColor\"\n\n$SwissFederalGeoportal.NationalMapGrey\n[1] \"SwissFederalGeoportal.NationalMapGrey\"\n\n$SwissFederalGeoportal.SWISSIMAGE\n[1] \"SwissFederalGeoportal.SWISSIMAGE\"\n\n\n\n\n\nCode\nsessionInfo()\n\n\nsessionInfo()\nR version 4.3.1 (2023-06-16)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Sonoma 14.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Shanghai\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] readxl_1.4.3         openxlsx_4.2.5.2     htmltools_0.5.8.1   \n [4] leaflet.extras_1.0.0 geojsonio_0.11.3     leaflet_2.2.2       \n [7] sf_1.0-16            lubridate_1.9.3      forcats_1.0.0       \n[10] stringr_1.5.1        dplyr_1.1.4          purrr_1.0.2         \n[13] readr_2.1.5          tidyr_1.3.1          tibble_3.2.1        \n[16] ggplot2_3.5.1        tidyverse_2.0.0     \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5            xfun_0.43               htmlwidgets_1.6.4      \n [4] lattice_0.22-6          tzdb_0.4.0              leaflet.providers_2.0.0\n [7] vctrs_0.6.5             tools_4.3.1             crosstalk_1.2.1        \n[10] generics_0.1.3          curl_5.2.1              proxy_0.4-27           \n[13] fansi_1.0.6             pkgconfig_2.0.3         KernSmooth_2.23-22     \n[16] RColorBrewer_1.1-3      lifecycle_1.0.4         farver_2.1.1           \n[19] compiler_4.3.1          munsell_0.5.1           jqr_1.3.3              \n[22] class_7.3-22            yaml_2.3.8              lazyeval_0.2.2         \n[25] jquerylib_0.1.4         pillar_1.9.0            classInt_0.4-10        \n[28] zip_2.3.1               tidyselect_1.2.1        digest_0.6.35          \n[31] stringi_1.8.4           fastmap_1.1.1           grid_4.3.1             \n[34] colorspace_2.1-0        cli_3.6.2               magrittr_2.0.3         \n[37] crul_1.4.2              utf8_1.2.4              e1071_1.7-14           \n[40] withr_3.0.0             scales_1.3.0            sp_2.1-4               \n[43] timechange_0.3.0        rmarkdown_2.26          cellranger_1.1.0       \n[46] hms_1.1.3               evaluate_0.23           knitr_1.45             \n[49] V8_4.4.2                viridisLite_0.4.2       geojson_0.3.5          \n[52] rlang_1.1.3             Rcpp_1.0.12             glue_1.7.0             \n[55] DBI_1.2.2               httpcode_0.3.0          geojsonsf_2.0.3        \n[58] rstudioapi_0.16.0       jsonlite_1.8.8          R6_2.5.1               \n[61] units_0.8-5            \n\n\n\n\n\n16 resouce:\nhttps://rstudio.github.io/leaflet/\nhttps://github.com/Lchiffon/leafletCN\nhttps://github.com/longwosion/geojson-map-china\nhttps://xiangyun.rbind.io/2022/02/draw-china-maps/\nhttps://datav.aliyun.com/portal/school/atlas/area_selector\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "5 Map",
      "map"
    ]
  },
  {
    "objectID": "Plot/5 Map/2 China accident map with mapview.html",
    "href": "Plot/5 Map/2 China accident map with mapview.html",
    "title": "China accident map",
    "section": "",
    "text": "1 data\ndata source :https://github.com/percent4/chinese_incident_tracker\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(curl)\nlibrary(lubridate)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(readxl)\n\n\n\n\n2 one file\n\n\nCode\n#url &lt;- \"https://raw.githubusercontent.com/percent4/chinese_incident_tracker/main/elk/data/00105670-df53-4be8-9039-8a07fe2d2b4d.json\"\n#download.file(url,\"./data/SAFI.json\", mode = \"wb\")\n\n\n\n\nCode\ndata001 &lt;- read_json(\"./data/SAFI.json\")\n\n\n\n\nCode\ndata002=data001 %&gt;% as.data.frame()\ncolnames(data002)[14] = \"latitude\"\ncolnames(data002)[15] = \"longitude\"\nglimpse(data002)\n\n\nRows: 1\nColumns: 22\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\"\n$ news_channel       &lt;chr&gt; \"新闻坊\"\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\"\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"\n$ start_date         &lt;chr&gt; \"2024-04-04\"\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\"\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\"\n$ incident_type      &lt;chr&gt; \"火灾\"\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3\n$ person_injury_num  &lt;int&gt; 10\n$ person_missing_num &lt;int&gt; 0\n$ latitude           &lt;dbl&gt; 113.6952\n$ longitude          &lt;dbl&gt; 23.07464\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\"\n$ province           &lt;chr&gt; \"广东省\"\n$ city               &lt;chr&gt; \"东莞市\"\n$ county             &lt;chr&gt; \"\"\n$ town               &lt;chr&gt; \"万江街道\"\n$ village            &lt;chr&gt; \"\"\n$ is_final           &lt;lgl&gt; TRUE\n\n\n\n\n3 all file\n\n\nCode\n#url=\"https://github.com/percent4/chinese_incident_tracker/archive/refs/heads/main.zip\"\n#download.file(url,\"./data/data.zip\", mode = \"wb\")\n\n\n\n\nCode\n#unzip(\"./data/data.zip\",exdir=\"./data/out\")\n\n\n\n\nCode\nfrom &lt;- \"./data/out/chinese_incident_tracker-main/elk/data\"\nto   &lt;- \"./data/json_folder\"\nfile.copy(list.files(from, full.names = TRUE), \n          to, \n          recursive = TRUE)\n\n\n [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\n\n\nCode\n#list.files(\"./data/json_folder\")\n\n\n\n\nCode\nall_data=tibble()\n\nfor (i in list.files(\"./data/json_folder\")) {\n  #print(i)\n  data001=read_json(paste0(\"./data/json_folder/\",i))\n  data002=data001 %&gt;% as.data.frame()\n  colnames(data002)[14] = \"Longitude\"\n  colnames(data002)[15] = \"Latitude\"\n  #print(data002)\n  \n  all_data=rbind(all_data,data002)\n}\n\n\n\n\nCode\nall_data=all_data %&gt;% mutate(text=paste0(incident_type,\" \",\"死亡人数:\",person_death_num,\" 受伤人数:\",person_injury_num)\n                             ,month_year= format_ISO8601(ymd(start_date), precision = \"ym\")\n                             )\n\n\n\n\nCode\nglimpse(all_data)\n\n\nRows: 60\nColumns: 24\n$ item_id            &lt;chr&gt; \"00105670-df53-4be8-9039-8a07fe2d2b4d\", \"0683ba1e-7…\n$ news_channel       &lt;chr&gt; \"新闻坊\", \"中国新闻网\", \"凤凰网\", \"搜狐网\", \"每日经…\n$ title              &lt;chr&gt; \"一养老院突发火灾，已致3死10伤！\", \"江西于都一矿企…\n$ report             &lt;chr&gt; \"4月4日\\n\\n“东莞应急管理”\\n\\n发布情况通报\\n\\n↓↓↓\\n\\…\n$ original_websites  &lt;chr&gt; \"https://mp.weixin.qq.com/s/xUZR8gZ_N0UqGj0GvH6L8A\"…\n$ start_date         &lt;chr&gt; \"2024-04-04\", \"2024-04-24\", \"2024-01-22\", \"2024-02-…\n$ start_time         &lt;chr&gt; \"2024-04-04 04:21:00\", \"2024-04-24 00:08:48\", \"2024…\n$ update_time        &lt;chr&gt; \"2024-05-03 10:50:01\", \"2024-05-03 00:08:48\", \"2024…\n$ incident_type      &lt;chr&gt; \"火灾\", \"溃水\", \"山体滑坡\", \"房屋坍塌\", \"燃气爆炸\",…\n$ incident_reason    &lt;chr&gt; \"该建筑为一栋11层楼房，起火部位为第三层303房，过火…\n$ person_death_num   &lt;int&gt; 3, 3, 44, 1, 7, 4, 1, 1, 7, 1, 18, 4, 5, 1, 15, 12,…\n$ person_injury_num  &lt;int&gt; 10, 2, 2, 0, 27, 4, 0, 0, 0, 11, 1155, 0, 3, 2, 44,…\n$ person_missing_num &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, …\n$ Longitude          &lt;dbl&gt; 113.69524, 115.32158, 104.95514, 113.28304, 116.808…\n$ Latitude           &lt;dbl&gt; 23.07464, 25.72126, 27.49063, 32.22574, 39.95258, 4…\n$ place              &lt;chr&gt; \"东莞万江街道康怡护理院（公助民办养老院）\", \"于都县…\n$ province           &lt;chr&gt; \"广东省\", \"江西省\", \"云南省\", \"湖北省\", \"河北省\", \"…\n$ city               &lt;chr&gt; \"东莞市\", \"赣州市\", \"昭通市\", \"随州市\", \"廊坊市\", \"…\n$ county             &lt;chr&gt; \"\", \"于都县\", \"镇雄县\", \"随县\", \"三河市\", \"新城区\",…\n$ town               &lt;chr&gt; \"万江街道\", \"祁禄山镇\", \"塘房镇\", \"万和镇\", \"燕郊镇…\n$ village            &lt;chr&gt; \"\", \"金沙村\", \"\", \"\", \"小张各庄\", \"\", \"\", \"\", \"乔家…\n$ is_final           &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n$ text               &lt;chr&gt; \"火灾 死亡人数:3 受伤人数:10\", \"溃水 死亡人数:3 受…\n$ month_year         &lt;chr&gt; \"2024-04\", \"2024-04\", \"2024-01\", \"2024-02\", \"2024-0…\n\n\n\n\nCode\n#write.xlsx(all_data,'all_data.xlsx')\n\n\n\n\n4 chart\ngroup to month\n\n\nCode\nchartdata001=all_data %&gt;% group_by(month_year)  %&gt;%  summarise(person_death_num=sum(person_death_num)\n                                                           ,person_injury_num=sum(person_injury_num)\n                                                           )\n\n\nwide to long\n\n\nCode\nchartdata002=chartdata001 %&gt;%select(month_year,person_death_num,person_injury_num) %&gt;% \n  pivot_longer(!c(month_year), names_to = 'type', values_to = 'DATA')\n\n\n\n\nCode\ngg=ggplot(chartdata001, aes(x=month_year, y=person_death_num,label = person_death_num))+\n  geom_bar(stat=\"identity\",fill='red')+ geom_text(vjust = -1,\n              position = position_dodge(width = 0.9))+ theme_bw()\n\n\nggplotly(gg)\n\n\n\n\n\n\n\n\nCode\ngg=ggplot(chartdata002, aes(fill=type, y=DATA, x=month_year)) +\n    geom_col(position = \"dodge\") +\n    geom_text(aes(label = DATA), vjust = 1.5,\n              position = position_dodge(width = 0.9))+scale_y_log10()+ theme_light()\n\npp=ggplotly(gg)\n\npp\n\n\n\n\n\n\n\n\n5 map\n\n\nCode\nall_data2 =all_data %&gt;%  mutate(report=report %&gt;% str_trunc(100))\n\n\n\n\nCode\n#write.xlsx(all_data2,'all_data2.xlsx')\n\n\n\n\nCode\nlibrary(mapview)\nlibrary(sf)\nlibrary(stringr)\n\nmapview(all_data2, map.types='OpenStreetMap',label='text',xcol = \"Longitude\", ycol = \"Latitude\", zcol='incident_type',cex=\"person_death_num\",crs = 4269, grid = FALSE)\n\n\n\n\n\n\n\n\n6 resouce:\nhttps://github.com/percent4/chinese_incident_tracker\nhttps://github.com/r-spatial/mapview\nhttps://maps.clb.org.hk/\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "5 Map",
      "China accident map"
    ]
  },
  {
    "objectID": "Plot/5 Map/4 HK whisky bar.html",
    "href": "Plot/5 Map/4 HK whisky bar.html",
    "title": "HK whisk bar",
    "section": "",
    "text": "1 data\n\n\nCode\nlibrary(tidyverse)\nlibrary(rvest)\nlibrary(chromote)\nlibrary(janitor)\nlibrary(tidygeocoder)\nlibrary(leaflet)\nlibrary(sf)\n\n\n\n\nCode\nbar_name=c('Maltcask@太子','House Welley@中環','Casky@灣仔')\nbar_address=c('169 Sai Yeung Choi St N, Mong Kok,Hongkong','97 Wellington St, Central,Hongkong','20-24 Lockhart Road, Wan Chai,Hongkong')\n\nbar_logo=c('https://img.shoplineapp.com/media/image_clips/62f16f8d7df01b0025a82bad/original.png','https://static.wixstatic.com/media/2d390e_27d0b3da21a94459bccf741600782591~mv2.jpg/v1/fill/w_160,h_160,al_c,q_80,usm_0.66_1.00_0.01,enc_auto/Grey.jpg','https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQsSelY2PRVxaxyU_Ydf9CHgtUrClzpxpqJ2g&s')\n\n\ndata001=tibble(bar_name,bar_address,bar_logo)\n\n\n\n\n2 search all address to latitude, longitude\n\n\nCode\n# geocode the addresses\ndata002 =data001 %&gt;% geocode(bar_address, method = 'osm',lat = latitude , long = longitude)\n\nglimpse(data002)\n\n\nRows: 3\nColumns: 5\n$ bar_name    &lt;chr&gt; \"Maltcask@太子\", \"House Welley@中環\", \"Casky@灣仔\"\n$ bar_address &lt;chr&gt; \"169 Sai Yeung Choi St N, Mong Kok,Hongkong\", \"97 Wellingt…\n$ bar_logo    &lt;chr&gt; \"https://img.shoplineapp.com/media/image_clips/62f16f8d7df…\n$ latitude    &lt;dbl&gt; 22.32539, 22.28360, 22.27858\n$ longitude   &lt;dbl&gt; 114.1688, 114.1543, 114.1770\n\n\n\n\n3 map\n\n\nCode\n# Choose Icon:\nleafIcons &lt;- icons(data002$bar_logo,iconWidth =60, iconHeight = 50)\n\n\nm &lt;- leaflet() %&gt;%\n  \n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addMarkers(lng=data002$longitude, lat=data002$latitude,icon = leafIcons)\n \n\nm  \n\n\n\n\n\n\n\n\nCode\nm &lt;- leaflet(height=2000, width=2000) %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n  addPopups( lng=data002$longitude, lat=data002$latitude, data002$bar_name\n             ,options = popupOptions(closeButton = FALSE)\n             \n            )\n \n\nm  \n\n\n\n\n\n\n\n\nCode\nm &lt;- leaflet(height=2500, width=2000) %&gt;%\n   # Add default OpenStreetMap map tiles\n  addTiles() %&gt;%  \n  # add markers\n addMarkers(\n    lng=data002$longitude, lat=data002$latitude\n    ,label = data002$bar_name,options = popupOptions(closeButton = FALSE),\n   \n    labelOptions = labelOptions(noHide = TRUE, direction = \"bottom\",\n      style = list(\n        \"color\" = \"red\",\n        \"font-family\" = \"serif\",\n        \"font-style\" = \"italic\",\n        \"box-shadow\" = \"2px 2px rgba(0,0,0,0.25)\",\n        \"font-size\" = \"12px\",\n        \"border-color\" = \"rgba(0,0,0,0.5)\"\n      ))) \n  \n\nm  \n\n\n\n\n\n\n\n\n4 resouce:\nhttps://www.gunviolencearchive.org/reports/mass-shooting?page=8&year=2023\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "5 Map",
      "HK whisk bar"
    ]
  },
  {
    "objectID": "Plot/6 Shiny/3 China accident map.html",
    "href": "Plot/6 Shiny/3 China accident map.html",
    "title": "Shiny in R:China accident map",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/China_accident_map/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "6 Shiny",
      "Shiny in R:China accident map"
    ]
  },
  {
    "objectID": "Plot/6 Shiny/2 shiny photo editor.html",
    "href": "Plot/6 Shiny/2 shiny photo editor.html",
    "title": "Shiny in R:photo editor",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/photo_editor/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "6 Shiny",
      "Shiny in R:photo editor"
    ]
  },
  {
    "objectID": "Plot/6 Shiny/1 shiny weight tracking.html",
    "href": "Plot/6 Shiny/1 shiny weight tracking.html",
    "title": "Shiny in R:weight tracking",
    "section": "",
    "text": "1 Shiny app:https://tduan.shinyapps.io/weightshiny/\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "6 Shiny",
      "Shiny in R:weight tracking"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#install-quarto-cli",
    "href": "Plot/7 Publish/1 quarto tips.html#install-quarto-cli",
    "title": "quarto tips",
    "section": "",
    "text": "https://quarto.org/docs/get-started/",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#install-quarto-pacakge",
    "href": "Plot/7 Publish/1 quarto tips.html#install-quarto-pacakge",
    "title": "quarto tips",
    "section": "",
    "text": "Code\ninstall.packages(\"quarto\")",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/5 quarto extensions.html#quarto-extension-lightbox",
    "href": "Plot/7 Publish/5 quarto extensions.html#quarto-extension-lightbox",
    "title": "quarto Extensioins",
    "section": "",
    "text": "An extension that uses the GLightbox javascript library to add lightbox styling and behavior to images in your HTML documents.\n\n\nquarto install extension quarto-ext/lightbox\n\n\n\nThe Lightbox extension can automatically give images in your web page a lightbox treatment. You can enable this like:\nin header yaml:\n\n\nCode\n---\ntitle: Simple Lightbox Example\nfilters:\n   - lightbox\nlightbox: auto\n---\n\n\nIn addition to simply providing a lightbox treatment for individual images, you can also group images into a ‘gallery’. When the user activates the lightbox, they will be able to page through the images in the gallery without returning to the main document.\nin content:\n\n\nCode\n![](images/image-562149792.png){group=\"my-gallery\"\ndescription=\"its a picture\"}\n\n\n\n\n\ncode:example.qmd\nwebsite:example.qmd.\n\n\n\ngo to folder which have added quarto extension\n\n\nCode\nquarto list extensions\n\n\n\n\n\n\n\n\nCode\nquarto update quarto-ext/fontawesome\n\n\n\n\n\n\n\nCode\nquarto remove quarto-ext/fontawesome\n\n\nIf you run the quarto remove extension command with no extension-id, you will be presented with a list of extensions that are present and you may select which extensions to remove.",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto Extensioins"
    ]
  },
  {
    "objectID": "Plot/7 Publish/5 quarto extensions.html#reference",
    "href": "Plot/7 Publish/5 quarto extensions.html#reference",
    "title": "quarto Extensioins",
    "section": "",
    "text": "https://quarto.org/docs/extensions/\nhttps://github.com/quarto-ext/lightbox",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto Extensioins"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#in-terminal",
    "href": "Plot/7 Publish/1 quarto tips.html#in-terminal",
    "title": "quarto tips",
    "section": "in Terminal",
    "text": "in Terminal\n\n\n\nCode\n\nTerminal\n\nquarto check",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#in-r",
    "href": "Plot/7 Publish/1 quarto tips.html#in-r",
    "title": "quarto tips",
    "section": "in R",
    "text": "in R\n\n\nCode\nlibrary(quarto)\nquarto_version()\n\n\n[1] '1.5.57'\n\n\nquarto location\n\n\nCode\nquarto_path()\n\n\n[1] \"/Applications/quarto/bin/quarto\"",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/5 quarto extensions.html",
    "href": "Plot/7 Publish/5 quarto extensions.html",
    "title": "quarto Extensioins",
    "section": "",
    "text": "Extensions are a powerful way to modify and extend the behavior of Quarto. Quarto v1.2 Required for Quarto Extensions.\n\n1 quarto extension： lightbox\nAn extension that uses the GLightbox javascript library to add lightbox styling and behavior to images in your HTML documents.\n\n\n2 Installation:\n\n\n\nCode\n\nTerminal\n\nquarto install extension quarto-ext/lightbox\n\n\n\n\n\n3 Usage:\nThe Lightbox extension can automatically give images in your web page a lightbox treatment. You can enable this like:\nin header yaml:\n\n\nCode\n---\ntitle: Simple Lightbox Example\nfilters:\n   - lightbox\nlightbox: auto\n---\n\n\nIn addition to simply providing a lightbox treatment for individual images, you can also group images into a ‘gallery’. When the user activates the lightbox, they will be able to page through the images in the gallery without returning to the main document.\nin content:\n\n\nCode\n![](images/image-562149792.png){group=\"my-gallery\"\ndescription=\"its a picture\"}\n\n\n\n\n4 quarto extension lightbox example:\ncode:example.qmd\nwebsite:example.qmd.\n\n\n5 list quarto extension\ngo to folder which have added quarto extension\n\n\n\nCode\n\nTerminal\n\n\nquarto list extensions\n\n\n\n\n\n\n6 update quarto extension\n\n\n\nCode\n\nTerminal\n\n\nquarto update quarto-ext/fontawesome\n\n\n\n\n\n7 remove quarto extension\n\n\n\nCode\n\nTerminal\n\n\nquarto remove quarto-ext/fontawesome\n\n\n\nIf you run the quarto remove extension command with no extension-id, you will be presented with a list of extensions that are present and you may select which extensions to remove.\n\n\n8 Reference\nhttps://quarto.org/docs/extensions/\nhttps://github.com/quarto-ext/lightbox\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto Extensioins"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#r",
    "href": "Plot/7 Publish/1 quarto tips.html#r",
    "title": "quarto tips",
    "section": "R",
    "text": "R\n```{R}\nversion\n```",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#python",
    "href": "Plot/7 Publish/1 quarto tips.html#python",
    "title": "quarto tips",
    "section": "Python",
    "text": "Python\n```{python}\nimport sys\nprint(sys.version)\n```",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  },
  {
    "objectID": "Plot/7 Publish/1 quarto tips.html#bath",
    "href": "Plot/7 Publish/1 quarto tips.html#bath",
    "title": "quarto tips",
    "section": "Bath",
    "text": "Bath\n```{bash}\necho \"foo\" \n```",
    "crumbs": [
      "Plot",
      "7 Publish",
      "quarto tips"
    ]
  }
]